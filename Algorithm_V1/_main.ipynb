{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08d16924",
   "metadata": {},
   "source": [
    "# NEW IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ad8e08",
   "metadata": {},
   "source": [
    "# OLD IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e444afc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install folium routingpy openrouteservice geopy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f01705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from src.get_data import get_data \n",
    "from src.get_data import get_connection\n",
    "from datetime import datetime, timedelta\n",
    "from src.routing.routing_optimizer import RouteOptimizer\n",
    "from src.routing.routing import get_valhalla_routes_info, plot_routes_on_map\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score \n",
    "import folium\n",
    "from src.map_viz.plot_cluster import create_enhanced_cluster_map\n",
    "import openrouteservice as ors\n",
    "import math\n",
    "import numpy as np\n",
    "import os \n",
    "from routingpy import Valhalla\n",
    "# client = ors.Client(key='5b3ce3597851110001cf62485a415b103df64104ad2680c9210ef936') \n",
    "\n",
    "import logging\n",
    "import pandas as pd\n",
    "from pyodbc import Connection\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "# from src.route_optimization import run_route_optimizer\n",
    "\n",
    "\n",
    "VALHALLA_BASE_URL = \"http://localhost:8002\" # Pointing to your self-hosted Valhalla\n",
    "VALHALLA_API_KEY = \"\" # No API key needed for your self-hosted instance\n",
    "\n",
    "\n",
    "CURRENT_DATE  = datetime.today().date() # + timedelta(days=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a4fa03",
   "metadata": {},
   "source": [
    "## **Utils**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75e2ca2",
   "metadata": {},
   "source": [
    "#### Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7cc1de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_invalid_coordinates_DEP(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Replaces invalid Latitude (< -90 or > 90) and Longitude (< -180 or > 180) values with 0.0.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame with 'Latitude' and 'Longitude' columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with corrected coordinate values.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    df.loc[(df['Latitude'] < -90) | (df['Latitude'] > 90), 'Latitude'] = 0.0\n",
    "    df.loc[(df['Longitude'] < -180) | (df['Longitude'] > 180), 'Longitude'] = 0.0\n",
    "\n",
    "\n",
    "    ### Nigeria \n",
    "    # ADD NIGERIA FILTER HERE\n",
    "    return df\n",
    "\n",
    "def clean_invalid_coordinates(df: pd.DataFrame, offset_degrees: float = 0.1) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Replaces invalid Latitude (< -90 or > 90) and Longitude (< -180 or > 180) values with 0.0.\n",
    "    Also replaces coordinates outside Nigeria's approximate boundaries (with an optional offset) with 0.0.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame with 'Latitude' and 'Longitude' columns.\n",
    "        offset_degrees (float): Degrees to add/subtract from the strict Nigeria boundary\n",
    "                                to expand the bounding box. Default is 0.1 degrees.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with corrected coordinate values.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Global invalid coordinate ranges\n",
    "    df.loc[(df['Latitude'] < -90) | (df['Latitude'] > 90), 'Latitude'] = 0.0\n",
    "    df.loc[(df['Longitude'] < -180) | (df['Longitude'] > 180), 'Longitude'] = 0.0\n",
    "\n",
    "    ### Nigeria Boundary Filter ###\n",
    "    # Approximate decimal degree boundaries for Nigeria\n",
    "    STRICT_NIGERIA_MIN_LAT = 4.10\n",
    "    STRICT_NIGERIA_MAX_LAT = 13.90\n",
    "    STRICT_NIGERIA_MIN_LON = 2.60\n",
    "    STRICT_NIGERIA_MAX_LON = 14.70\n",
    "\n",
    "    # Apply offset to expand the bounding box\n",
    "    NIGERIA_MIN_LAT = STRICT_NIGERIA_MIN_LAT - offset_degrees\n",
    "    NIGERIA_MAX_LAT = STRICT_NIGERIA_MAX_LAT + offset_degrees\n",
    "    NIGERIA_MIN_LON = STRICT_NIGERIA_MIN_LON - offset_degrees\n",
    "    NIGERIA_MAX_LON = STRICT_NIGERIA_MAX_LON + offset_degrees\n",
    "\n",
    "    # Identify coordinates outside Nigeria's expanded bounding box\n",
    "    # Condition for rows outside Nigeria's latitude range\n",
    "    outside_nigeria_lat = (df['Latitude'] < NIGERIA_MIN_LAT) | \\\n",
    "                          (df['Latitude'] > NIGERIA_MAX_LAT)\n",
    "\n",
    "    # Condition for rows outside Nigeria's longitude range\n",
    "    outside_nigeria_lon = (df['Longitude'] < NIGERIA_MIN_LON) | \\\n",
    "                          (df['Longitude'] > NIGERIA_MAX_LON)\n",
    "\n",
    "    # Combine conditions: if EITHER latitude OR longitude is outside Nigeria's expanded box,\n",
    "    # then set BOTH Latitude and Longitude for that row to 0.0.\n",
    "    # We apply this only to coordinates that are already globally valid (i.e., not 0.0).\n",
    "    df.loc[\n",
    "        (df['Latitude'] != 0.0) &\n",
    "        (df['Longitude'] != 0.0) &\n",
    "        (outside_nigeria_lat | outside_nigeria_lon),\n",
    "        ['Latitude', 'Longitude']\n",
    "    ] = 0.0\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "589e0f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df_customer_sku_recommendation_raw, \n",
    "                      df_customer_dim_with_affinity_score_raw, \n",
    "                      df_stockpoint_dim_raw,\n",
    "                      df_customer_score,\n",
    "                      df_kyc_customer) :\n",
    "    \n",
    "    df_customer_sku_recommendation_raw['Stock_Point_ID'] = df_customer_sku_recommendation_raw['Stock_Point_ID'].astype(int)\n",
    "    df_customer_dim_with_affinity_score_raw['Stock_Point_ID'] = df_customer_dim_with_affinity_score_raw['Stock_Point_ID'].astype(int)\n",
    "    df_stockpoint_dim_raw['Stock_Point_ID'] = df_stockpoint_dim_raw['Stock_Point_ID'].astype(int)\n",
    "    df_customer_score = df_customer_score.rename(columns={'StockPointID':'Stock_Point_ID'})\n",
    "    df_customer_score['Stock_Point_ID'] = df_customer_score['Stock_Point_ID'].astype(int)\n",
    "\n",
    "\n",
    "    # ----------------- CUSTOMER DIM TABLE \n",
    "    col_sel_affinity = ['Region', 'Stock_Point_ID', 'CustomerID']\n",
    "\n",
    "    col_sel_kyc = ['CustomerID', 'ContactName', 'BusinessName', 'CustomerModeName',\n",
    "        'CustomerRef', 'ContactPhone', 'CustomerType', 'FullAddress', \n",
    "        'StateName', 'CityName', 'TownName', 'Latitude','Longitude', \n",
    "        'DistanceVarianceInMeter', 'IsLocationSubmitted',\n",
    "        'IsLocationCaptured', 'IsLocationVerified','CustomerStatus',\n",
    "        'RejectReason',  'KYC_Capture_Status',  'lastDelvDate', \n",
    "        # 'hasPOS','hasVAS', 'hasBNPL', 'lastDelvDate', \n",
    "        'isActive']\n",
    "\n",
    "    col_sel_score = ['Stock_Point_ID', 'CustomerID', 'composite_customer_score',\n",
    "        'percentile_rank', 'active_months_pct', 'avg_orders_per_active_month',\n",
    "        'avg_qty_per_month', 'avg_revenue_per_month', 'days_since_last_order']\n",
    "\n",
    "    df_master_customer_dim = (\n",
    "                df_customer_dim_with_affinity_score_raw[col_sel_affinity]\n",
    "                .merge(df_kyc_customer[col_sel_kyc], how='inner', on=['CustomerID'])\n",
    "                .merge(df_customer_score[col_sel_score], how='left', on=['Stock_Point_ID', 'CustomerID'])\n",
    "                .rename(columns = {'CityName':'LGA',\n",
    "                                'TownName':'LCDA'\n",
    "                                })\n",
    "\n",
    "            )\n",
    "\n",
    "    # Change CustomerPurchaseRecency from lastDelvDate to days since last order (order creation date)\n",
    "    df_master_customer_dim['CustomerPurchaseRecency'] =  df_master_customer_dim['days_since_last_order']\n",
    "    # df_master_customer_dim['CustomerPurchaseRecency'] =  df_master_customer_dim['lastDelvDate'].apply(lambda x: (datetime.now() - x).days)\n",
    "    df_master_customer_dim['CustomerPurchaseRecency'] = df_master_customer_dim['CustomerPurchaseRecency'].fillna(max(df_master_customer_dim['CustomerPurchaseRecency']))\n",
    "    df_master_customer_dim['KYC_Capture_Status'] = df_master_customer_dim['KYC_Capture_Status'].apply(lambda x: 'Yes' if x == 1 else 'No')\n",
    "\n",
    "    # Add to Score\n",
    "    # Fix Missing value -------------------------------------------\n",
    "    for col in ['BusinessName', 'CustomerModeName', 'FullAddress', 'LGA', 'LCDA']:\n",
    "        df_master_customer_dim[col] = df_master_customer_dim[col].fillna('')\n",
    "\n",
    "    for col in ['Latitude',  'Longitude', 'composite_customer_score',  \n",
    "                'percentile_rank',  'active_months_pct', 'avg_orders_per_active_month',  \n",
    "                'avg_qty_per_month',  'avg_revenue_per_month'\n",
    "                ]:\n",
    "        df_master_customer_dim[col] = pd.to_numeric(df_master_customer_dim[col], errors='coerce').fillna(0) \n",
    "\n",
    "    df_master_customer_dim = clean_invalid_coordinates(df_master_customer_dim)\n",
    "    \n",
    "    # Add to Score \n",
    "    # Boost composite score and percentile rank for customers with completed KYC\n",
    "    mask_kyc = df_master_customer_dim['KYC_Capture_Status'] == 'Yes'\n",
    "\n",
    "    df_master_customer_dim.loc[mask_kyc, 'composite_customer_score'] += 5\n",
    "    df_master_customer_dim.loc[mask_kyc, 'percentile_rank'] += 0.1 \n",
    "\n",
    "    # ----------------- RECOMMENDATION\n",
    "    col2 = ['EstimatedQuantity', 'CustomerSKUscore', 'CustomerSKUscoreStandardize', 'CustomerSKUscoreRank']\n",
    "    for col in col2: \n",
    "        df_customer_sku_recommendation_raw[col] = pd.to_numeric(df_customer_sku_recommendation_raw[col], errors='coerce')\n",
    "\n",
    "    df_customer_sku_recommendation_raw['LastDeliveredDate'] = pd.to_datetime(df_customer_sku_recommendation_raw['LastDeliveredDate'])\n",
    "    # Get today's date\n",
    "    today = pd.Timestamp.today()\n",
    "\n",
    "    df_customer_sku_recommendation_raw['Recency'] = df_customer_sku_recommendation_raw['LastDeliveredDate'].apply(lambda x: (datetime.now() - x).days)\n",
    "    df_customer_sku_recommendation_raw['Recency'] = df_customer_sku_recommendation_raw['Recency'].fillna(max(df_customer_sku_recommendation_raw['Recency']))\n",
    "    \n",
    "    # ----------------- STOCKPOINT\n",
    "    df_stockpoint_dim_raw.rename(columns={'lattitude':'Latitude', 'longitude':'Longitude'}, inplace=True) \n",
    "    col3 = ['Latitude', 'Longitude']\n",
    "    for col in col3: \n",
    "        df_stockpoint_dim_raw[col] = pd.to_numeric(df_stockpoint_dim_raw[col], errors='coerce').fillna(0)    \n",
    "\n",
    "    # Replace invalid latitude values with NaN\n",
    "    df_stockpoint_dim_raw = clean_invalid_coordinates(df_stockpoint_dim_raw)   \n",
    "    \n",
    "\n",
    "    return df_customer_sku_recommendation_raw, df_master_customer_dim, df_stockpoint_dim_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50d39f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_filter(df_customer_sku_recommendation, df_master_customer_dim, df_stockpoint_dim,\n",
    "                stockpoint_id,  sku_recency = 7, customer_recency = 90, number_recommendation = 5,\n",
    "                estimate_qty_scale_factor = .90, max_estimated_qty = 5, exclude_recency_customer = 4):\n",
    "    \n",
    "    df_customer_sku_recommendation = df_customer_sku_recommendation.copy().query(f'Stock_Point_ID == {stockpoint_id}')\n",
    "    # Filter Recommendation\n",
    "    df_customer_sku_recommendation = df_customer_sku_recommendation[df_customer_sku_recommendation['ProductTag'] != 'Standard-Inactive']\n",
    "    df_customer_sku_recommendation = df_customer_sku_recommendation[df_customer_sku_recommendation['Medium'] != 'Never Purchased']\n",
    "\n",
    "    # Filter customer base\n",
    "    df_master_customer_dim['valid_for_push'] = np.where(\n",
    "                                                    #  df_master_customer_dim['KYC_Capture_Status'] == 'Yes'   \n",
    "                                                    (\n",
    "                                                        (df_master_customer_dim['IsLocationCaptured'] == 'Yes') |\n",
    "                                                        (df_master_customer_dim['DistanceVarianceInMeter'] <= 150.0) |\n",
    "                                                        (df_master_customer_dim['KYC_Capture_Status'] == 'Yes') |\n",
    "                                                        (df_master_customer_dim['CustomerPurchaseRecency'] <= customer_recency)\n",
    "                                                    )\n",
    "                                                    ,1,0\n",
    "                                                )\n",
    "    # df_master_customer_dim = df_master_customer_dim[df_master_customer_dim['CustomerPurchaseRecency'] <= customer_recency]\n",
    "    df_master_customer_dim = df_master_customer_dim.query('valid_for_push == 1')  \n",
    "    # Exclude Customer with recent purchase of any SKU\n",
    "    df_master_customer_dim = df_master_customer_dim.query(f'CustomerPurchaseRecency > {exclude_recency_customer}')\n",
    "    # Customer with valid Location Coordination\n",
    "    df_master_customer_dim = df_master_customer_dim.query('Latitude != 0').reset_index(drop=True)\n",
    "    \n",
    "    # # Clipping Max Estimated Quantity to 10 qty\n",
    "    df_customer_sku_recommendation['EstimatedQuantity_bck'] = df_customer_sku_recommendation['EstimatedQuantity']\n",
    "    df_customer_sku_recommendation['EstimatedQuantity'] = df_customer_sku_recommendation['EstimatedQuantity'].apply(lambda x: max_estimated_qty if int((x*estimate_qty_scale_factor)) > max_estimated_qty else int((x*estimate_qty_scale_factor)) )\n",
    "\n",
    "\n",
    "    # Select top 10 SKU by SKURank per customer\n",
    "    df_customer_sku_recommendation = (\n",
    "        df_customer_sku_recommendation\n",
    "        .query('EstimatedQuantity > 1')\n",
    "        .sort_values(['CustomerID','CustomerSKUscoreRank'])\n",
    "        .groupby('CustomerID', group_keys=False)\n",
    "        .head(number_recommendation)\n",
    "        .reset_index(drop=True) \n",
    "    )\n",
    "\n",
    "    df_customer_sku_recommendation_ = df_master_customer_dim.merge(df_customer_sku_recommendation, how='inner', on = ['CustomerID','Stock_Point_ID'])  \n",
    "\n",
    "    df_stockpoint_dim = df_stockpoint_dim.query(f'Stock_Point_ID == {stockpoint_id}').reset_index(drop=True) \n",
    "    \n",
    "\n",
    "    df_customer_dim = df_master_customer_dim.merge(df_customer_sku_recommendation_['CustomerID'].drop_duplicates(), how='inner', on = 'CustomerID')\n",
    "    # df_customer_dim = df_customer_dim.merge(df_customer_dim_with_affinity_score[sel_cols], how='inner', on = 'CustomerID').reset_index(drop = True) \n",
    "    \n",
    "    print(f'Total Quantity before filter: {df_customer_sku_recommendation.query(f\"Stock_Point_ID == {stockpoint_id}\").EstimatedQuantity.sum():,}')\n",
    "    print(f'Total Quantity: {df_customer_sku_recommendation_.EstimatedQuantity.sum():,}')\n",
    "    print(f'Total Number of Customers before filter: {df_customer_sku_recommendation.query(f\"Stock_Point_ID == {stockpoint_id}\").CustomerID.nunique():,}')\n",
    "    print(f'Total Number of Customers: {df_customer_dim.CustomerID.nunique():,}')\n",
    "\n",
    " \n",
    "    return df_customer_sku_recommendation_, df_customer_dim,   df_stockpoint_dim  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b10555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a26754f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_data(\n",
    "        selected_trip,\n",
    "        all_push_recommendation,\n",
    "        cluster_summary,\n",
    "        stock_point_name\n",
    "    ): \n",
    "    dir_path = f'./recommendation_output/{CURRENT_DATE}'\n",
    "    \n",
    "    # Ensure directory exists\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    \n",
    "    file_path = f'{dir_path}/{stock_point_name}_{CURRENT_DATE}.xlsx'\n",
    "\n",
    "    with pd.ExcelWriter(file_path) as writer:\n",
    "        selected_trip.to_excel(writer, sheet_name='Selected Trip', index=False)\n",
    "        all_push_recommendation.to_excel(writer, sheet_name='All Recommendation', index=False)\n",
    "        cluster_summary.to_excel(writer, sheet_name='Recommendation Cluster Summary', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939127f3",
   "metadata": {},
   "source": [
    "#### Map-Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7525cc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_and_save(df_routes, \n",
    "                 df_stockpoint = None,   \n",
    "                 filename=None,\n",
    "                 cluster_col='cluster',\n",
    "                 popup_cols=['CustomerID', 'LGA', 'LCDA'],\n",
    "                 tooltip_cols=['LGA', 'LCDA'],\n",
    "                 depot_marker_size=10\n",
    "                 ):\n",
    "    \n",
    "    map_clusters = create_enhanced_cluster_map(\n",
    "        df_routes,\n",
    "        popup_cols=popup_cols,\n",
    "        tooltip_cols=tooltip_cols, \n",
    "        cluster_col = cluster_col,\n",
    "        zoom_start=10, \n",
    "        radius=8\n",
    "    )\n",
    "    \n",
    "    if df_stockpoint:\n",
    "        depot_location = [df_stockpoint.Latitude[0], df_stockpoint.Longitude[0]]\n",
    "        depot_name = df_stockpoint.Stock_point_Name[0]\n",
    "        map_clusters = map_clusters.add_child(folium.Marker(location=depot_location, \n",
    "                                size = depot_marker_size, \n",
    "                                tooltip=depot_name, \n",
    "                                icon=folium.Icon(color=\"green\", \n",
    "                                icon=\"home\")))  \n",
    "    if filename:\n",
    "        map_clusters.save(filename)\n",
    "    return map_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ff9846",
   "metadata": {},
   "source": [
    "#### Cluster Summary Route-Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee878c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_unsupervised_clustering(df):\n",
    "    # Usage:\n",
    "    X = df[['Latitude', 'Longitude']].values\n",
    "    labels = df['cluster'].values\n",
    "    scores = {\n",
    "        \"Silhouette Score\":  silhouette_score(X, labels).round(2),\n",
    "        \"Davies-Bouldin Index\": davies_bouldin_score(X, labels).round(2),\n",
    "        \"Calinski-Harabasz Score\": calinski_harabasz_score(X, labels).round(2)\n",
    "    }\n",
    "\n",
    "    for key in scores:\n",
    "        print(f\"{key}: {scores[key]}\")\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b65cbb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stockpoint_dict(df_selected_trip, df_stockpoint_dim):\n",
    "    \"\"\"\n",
    "    Create a dictionary structure with stock point information and associated trips.\n",
    "    \n",
    "    Parameters:\n",
    "    df_selected_trip: DataFrame with columns ['StockPointID', 'StockPointName', 'TripID', 'CustomerID', 'Latitude', 'Longitude', 'EstimatedQuantity']\n",
    "    df_stockpoint_dim: DataFrame with columns ['Stock_Point_ID', 'Stock_point_Name', 'Latitude', 'Longitude']\n",
    "    \n",
    "    Returns:\n",
    "    dict: Dictionary with stock point information and trips\n",
    "    \"\"\"\n",
    "    if df_selected_trip.empty:\n",
    "        logger.info('Dataframe is empty')\n",
    "        return {}\n",
    "    \n",
    "    # Group by StockPointID to handle each stock point\n",
    "    stockpoint_groups = df_selected_trip.groupby('StockPointID')\n",
    "    \n",
    "    result = {}\n",
    "    \n",
    "    for stock_point_id, group in stockpoint_groups:\n",
    "        # Get stock point information from df_stockpoint_dim\n",
    "        stock_point_info = df_stockpoint_dim[df_stockpoint_dim['Stock_Point_ID'] == stock_point_id]\n",
    "        \n",
    "        if stock_point_info.empty:\n",
    "            # If stock point not found in dimension table, use info from selected_trip\n",
    "            stock_point_name = group['StockPointName'].iloc[0]\n",
    "            # Note: We'll need to get coordinates from somewhere since customer coordinates \n",
    "            # in df_selected_trip are for destinations, not stock points\n",
    "            stock_point_coord = [0, 0]  # Placeholder - you may need to adjust this\n",
    "        else:\n",
    "            stock_point_name = stock_point_info['Stock_point_Name'].iloc[0]\n",
    "            stock_point_coord = [\n",
    "                stock_point_info['Longitude'].iloc[0], \n",
    "                stock_point_info['Latitude'].iloc[0]\n",
    "            ]\n",
    "        \n",
    "        # Group by TripID to organize trips\n",
    "        trip_groups = group.groupby('TripID')\n",
    "        trips = []\n",
    "        \n",
    "        for trip_id, trip_group in trip_groups:\n",
    "            # Create destinations list for this trip\n",
    "            destinations = []\n",
    "            for _, row in trip_group.iterrows():\n",
    "                destination = {\n",
    "                    'CustomerID': row['CustomerID'],\n",
    "                    'Coordinate': [row['Longitude'], row['Latitude']]\n",
    "                }\n",
    "                destinations.append(destination)\n",
    "            \n",
    "            # Create trip dictionary\n",
    "            trip_dict = {\n",
    "                'TripID': trip_id,\n",
    "                'Destinations': destinations\n",
    "            }\n",
    "            trips.append(trip_dict)\n",
    "        \n",
    "        # Create the final dictionary structure for this stock point\n",
    "        result[stock_point_id] = {\n",
    "            'StockPointName': stock_point_name,\n",
    "            'StockPointID': stock_point_id,\n",
    "            'StockPointCoord': stock_point_coord,\n",
    "            'Trips': trips\n",
    "        }\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# Alternative version if you want a single dictionary (assuming only one stock point)\n",
    "def create_single_stockpoint_dict(df_selected_trip, df_stockpoint_dim):\n",
    "    \"\"\"\n",
    "    Create a single dictionary structure for one stock point.\n",
    "    \n",
    "    Parameters:\n",
    "    df_selected_trip: DataFrame with trip data for one stock point\n",
    "    df_stockpoint_dim: DataFrame with stock point dimension data\n",
    "    \n",
    "    Returns:\n",
    "    dict: Single dictionary with stock point information and trips\n",
    "    \"\"\"\n",
    "    if df_selected_trip.empty:\n",
    "        logger.info('Dataframe is empty')\n",
    "        return {}\n",
    "    \n",
    "    # Get the stock point ID (assuming all rows have the same stock point)\n",
    "    stock_point_id = df_selected_trip['StockPointID'].iloc[0]\n",
    "    \n",
    "    # Get stock point information from df_stockpoint_dim\n",
    "    stock_point_info = df_stockpoint_dim[df_stockpoint_dim['Stock_Point_ID'] == stock_point_id]\n",
    "    \n",
    "    if stock_point_info.empty:\n",
    "        stock_point_name = df_selected_trip['StockPointName'].iloc[0]\n",
    "        stock_point_coord = [0, 0]  # Placeholder\n",
    "    else:\n",
    "        stock_point_name = stock_point_info['Stock_point_Name'].iloc[0] \n",
    "        stock_point_coord = [\n",
    "            stock_point_info['Longitude'].iloc[0], \n",
    "            stock_point_info['Latitude'].iloc[0]\n",
    "        ]\n",
    "    \n",
    "    # Group by TripID\n",
    "    trip_groups = df_selected_trip.groupby('TripID')\n",
    "    trips = []\n",
    "    \n",
    "    for trip_id, trip_group in trip_groups:\n",
    "        destinations = []\n",
    "        for _, row in trip_group.iterrows():\n",
    "            destination = {\n",
    "                'CustomerID': row['CustomerID'],\n",
    "                'Coordinate': [row['Longitude'], row['Latitude']]\n",
    "            }\n",
    "            destinations.append(destination)\n",
    "        \n",
    "        trip_dict = {\n",
    "            'TripID': trip_id,\n",
    "            'Destinations': destinations\n",
    "        }\n",
    "        trips.append(trip_dict)\n",
    "    \n",
    "    # Return the final dictionary\n",
    "    return {\n",
    "        'StockPointName': stock_point_name,\n",
    "        'StockPointID': stock_point_id,\n",
    "        'StockPointCoord': stock_point_coord,\n",
    "        'Trips': trips\n",
    "    }\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# \"\"\"\n",
    "# # For multiple stock points:\n",
    "# result_dict = create_stockpoint_dict(df_selected_trip, df_stockpoint_dim)\n",
    "\n",
    "# # For a single stock point:\n",
    "# single_result = create_single_stockpoint_dict(df_selected_trip, df_stockpoint_dim)\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f4c7281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_route(df_selected_trip, df_stockpoint_dim):\n",
    "    # Path \n",
    "    main_dir = f'./recommendation_output/selected_trip_map/{CURRENT_DATE}' \n",
    "    os.makedirs(f'{main_dir}', exist_ok=True)\n",
    "\n",
    "\n",
    "    trip_dict = create_single_stockpoint_dict(df_selected_trip, df_stockpoint_dim) \n",
    "\n",
    "    if trip_dict == {}:\n",
    "        logger.info('Trip Data is empty')\n",
    "    else:\n",
    "        try:\n",
    "            StockPointID = trip_dict['StockPointID']\n",
    "            output_filename = f'{main_dir}/{StockPointID}.html'\n",
    "            # Step 1: Get route information for all trips\n",
    "            calculated_routes_info = get_valhalla_routes_info(trip_dict)\n",
    "\n",
    "            # Step 2: Plot all routes on a map\n",
    "            plot_routes_on_map(trip_data=trip_dict, routes_info=calculated_routes_info, output_filename = output_filename)\n",
    "        except Exception as e:\n",
    "            logger.warn(f'Some vital error occured while creating route {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dce62501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_route_optimizer(df_clustering, sel_cluster_tuple, df_stockpoint, \n",
    "                        stock_point_name,\n",
    "                        sel_total_customer_count, capacity_size = 20):\n",
    "     # ---- SETUP CLIENT\n",
    "     try:\n",
    "          client = Valhalla(base_url=VALHALLA_BASE_URL)\n",
    "          if VALHALLA_API_KEY:\n",
    "               client = Valhalla(base_url=VALHALLA_BASE_URL, api_key=VALHALLA_API_KEY)\n",
    "          \n",
    "          logger.info('Setting up routing client via LOCAL host Valhalla')\n",
    "     except Exception as e:\n",
    "          logger.warning('Setting up routing client via ORS')\n",
    "          client = ors.Client(key=os.getenv('ORS_KEY')) \n",
    "\n",
    "     # Select cluster 37\n",
    "     df_sel_clust = df_clustering.query(f'cluster in {sel_cluster_tuple}').query('Latitude > 0')\n",
    "\n",
    "     # Ensure coordinates are in [longitude, latitude] for ORS\n",
    "     coords = [[lon, lat] for lat, lon in zip(df_sel_clust.Latitude, df_sel_clust.Longitude)]\n",
    "     # Print number of jobs\n",
    "     print(\"Number of customer locations:\", len(coords))\n",
    "     # Convert depot_location to ORS format\n",
    "     # Assuming depot_location is [lat, lon], flip to [lon, lat]\n",
    "     vehicle_start = [df_stockpoint.Longitude[0], df_stockpoint.Latitude[0]]\n",
    "     num_vehicles = math.floor(sel_total_customer_count / capacity_size)\n",
    "     vehicles = [\n",
    "          ors.optimization.Vehicle(\n",
    "               id=i,\n",
    "               profile='driving-car',\n",
    "               start=vehicle_start,\n",
    "               end=vehicle_start,\n",
    "               capacity=[capacity_size]\n",
    "          ) for i in range(num_vehicles)\n",
    "     ]\n",
    "\n",
    "     # Define jobs (each customer gets amount=[1])\n",
    "     jobs = [ors.optimization.Job(id=index, location=coord, amount=[1]) for index, coord in enumerate(coords)]\n",
    "\n",
    "     # Call ORS optimization API\n",
    "     optimized = client.optimization(jobs=jobs, vehicles=vehicles, geometry=True)\n",
    "\n",
    "     #     ------ MAP\n",
    "     depot_location = [df_stockpoint.Latitude[0], df_stockpoint.Longitude[0]]\n",
    "     depot_name = df_stockpoint.Stock_point_Name[0]\n",
    "\n",
    "     map_clusters_route = create_enhanced_cluster_map(\n",
    "     df_sel_clust,\n",
    "     popup_cols=['CustomerID', 'LGA', 'LCDA'],\n",
    "     tooltip_cols=['LGA', 'LCDA'], \n",
    "     zoom_start=10, \n",
    "     radius=10\n",
    "     ).add_child(folium.Marker(location=depot_location, \n",
    "                         size = 10, \n",
    "                         tooltip=depot_name, \n",
    "                         icon=folium.Icon(color=\"green\", \n",
    "                         icon=\"home\")))\n",
    "\n",
    "     # line_colors = ['green', 'orange', 'blue', 'yellow']\n",
    "     separable_colors = [\n",
    "          \"#1f77b4\",  # blue\n",
    "          \"#ff7f0e\",  # orange\n",
    "          \"#2ca02c\",  # green\n",
    "          \"#d62728\",  # red\n",
    "          \"#9467bd\",  # purple\n",
    "          \"#8c564b\",  # brown\n",
    "          \"#e377c2\",  # pink\n",
    "          \"#7f7f7f\",  # gray\n",
    "          \"#bcbd22\",  # yellow-green\n",
    "          \"#17becf\",  # cyan\n",
    "          \"#aec7e8\",  # light blue\n",
    "          \"#ffbb78\",  # light orange\n",
    "          ]\n",
    "\n",
    "     line_colors = separable_colors[0:num_vehicles] #['green', 'orange', 'blue', 'yellow']\n",
    "     for route in optimized['routes']:\n",
    "          folium.PolyLine(locations=[list(reversed(coords)) for coords in ors.convert.decode_polyline(route['geometry'])['coordinates']], color=line_colors[route['vehicle']]).add_to(map_clusters_route)\n",
    "\n",
    "     #\n",
    "     selected_trip_map_path = f'./recommendation_output/selected_trip_map/{stock_point_name}_{CURRENT_DATE}.html' \n",
    "     map_clusters_route.save(selected_trip_map_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b107eaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_trip_route(df_sku_rec, \n",
    "                       df_customer_dim, \n",
    "                       df_stockpoint,\n",
    "                       stock_point_id,\n",
    "                       max_customers_per_route, \n",
    "                       max_volume_per_route,\n",
    "                       max_distance_km, \n",
    "                       clustering_method='divisive',\n",
    "                       skip_route_optimization = False):\n",
    "     \n",
    "\n",
    "    optimizer = RouteOptimizer(\n",
    "        max_customers_per_route=max_customers_per_route,\n",
    "        max_volume_per_route=max_volume_per_route,\n",
    "        max_distance_km = max_distance_km\n",
    "    )\n",
    "\n",
    "    optimizer.load_data(df_sku_rec, df_customer_dim, df_stockpoint)\n",
    "    print(\"✓ Route optimizer initialized\")\n",
    "\n",
    "    # STEP 3: Generate Routes for Stock Point 1647113\n",
    "    print(\"\\n3. Generating Optimized Routes...\")\n",
    "    print(\"-\" * 40) \n",
    "\n",
    "    stock_point = df_stockpoint[df_stockpoint['Stock_Point_ID'] == stock_point_id].reset_index(drop = True)\n",
    "    \n",
    "    stock_point_coords = (stock_point['Latitude'], stock_point['Longitude'])\n",
    "        \n",
    "    clustering_customers_df = optimizer.filter_customers_for_stockpoint(stock_point_id)\n",
    "\n",
    "    df_clustering, n_clusters = optimizer.create_geographic_clusters(clustering_customers_df, \n",
    "                                                                     clustering_method = clustering_method)\n",
    "\n",
    "    if skip_route_optimization == True:\n",
    "        routes = optimizer.generate_multi_trip_routes(stock_point_id, \n",
    "                                                    max_trips=5, \n",
    "                                                    clustering_method=clustering_method)\n",
    "        df_routes = pd.DataFrame(routes)\n",
    "    else:\n",
    "        df_routes = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "    # STEP 4: Analyze Results\n",
    "    print(\"\\n4. Route Analysis & Results...\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    push_recommendation = df_sku_rec.merge(df_clustering[['Stock_Point_ID','CustomerID', 'cluster']], \n",
    "                                           how='inner', on =['Stock_Point_ID','CustomerID'] )\n",
    "    \n",
    "    ### Cluster Evaluation\n",
    "    try:\n",
    "        evaluate_unsupervised_clustering(df_clustering)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return push_recommendation, df_clustering, df_routes, stock_point_coords\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1bc8a429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_summary_and_selection(push_recommendation,\n",
    "                                  sel_trip_cluster,\n",
    "                                  min_ncust_per_cluster = 4\n",
    "                                  ):\n",
    "    ### Cluster Summary \n",
    "    cluster_summary = (\n",
    "        push_recommendation\n",
    "        .groupby('cluster').agg(\n",
    "            LGA_list = ('LGA', lambda x: x.unique().tolist()),\n",
    "            LCDA_List = ('LCDA', lambda x: x.unique().tolist()),\n",
    "            ncustomer = ('CustomerID','nunique'),\n",
    "            totalQty = ('EstimatedQuantity','sum'), \n",
    "            avg_customer_score = ('composite_customer_score','mean'),\n",
    "        )\n",
    "        .reset_index()\n",
    "        .sort_values(['avg_customer_score','ncustomer', 'totalQty'], \n",
    "                     ascending=[False, False, False])\n",
    "        )\n",
    "\n",
    "    ### Select Trip   \n",
    "    df_high_value_cluster_summary = (\n",
    "            cluster_summary\n",
    "            .query(f'ncustomer >= {min_ncust_per_cluster}')\n",
    "            .head(max(10, sel_trip_cluster))\n",
    "            .reset_index(drop = True)\n",
    "        )\n",
    "    sel_cluster_tuple = df_high_value_cluster_summary.cluster[0:sel_trip_cluster].to_list()\n",
    "    sel_total_customer_count = df_high_value_cluster_summary.head(sel_trip_cluster).ncustomer.sum()\n",
    "    print(f'''Select ClusterIDs: {sel_cluster_tuple}''')\n",
    "    print(f'''Total Number of Customers: {sel_total_customer_count}''')\n",
    "    print(df_high_value_cluster_summary.head(sel_trip_cluster))\n",
    "\n",
    "    return cluster_summary, df_high_value_cluster_summary, sel_cluster_tuple, sel_total_customer_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "171a5cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_selected_trip(push_recommendation, \n",
    "                       cluster_summary,\n",
    "                       df_master_customer_dim,  \n",
    "                       df_stockpoint,\n",
    "                       sel_cluster_tuple):\n",
    "    \n",
    "        \n",
    "\n",
    "    sel_columns = ['Stock_Point_ID', \n",
    "                'StateName', # 'Region', \n",
    "                'Latitude', 'Longitude', 'LGA', 'LCDA', 'cluster', \n",
    "                'CustomerID', 'SKUID', 'ProductName', 'Output',\n",
    "                'LastDeliveredDate', 'Recency', 'InventoryCheck', 'ProductTag', 'Medium',\n",
    "                'EstimatedQuantity', \n",
    "                # 'CustomerSKUscoreRank'\n",
    "                ]\n",
    "\n",
    "    sel_cols_cust= ['Stock_Point_ID', 'CustomerID', 'ContactName',  'CustomerModeName',   'ContactPhone', 'FullAddress', \n",
    "                    'composite_customer_score', 'percentile_rank',  'KYC_Capture_Status', 'CustomerPurchaseRecency']\n",
    "\n",
    "    final_cols = ['Stock_Point_ID', 'Stock_point_Name', 'TripID', 'LGA_list', 'LCDA_List', \n",
    "                  'ncustomer', 'totalQty','avg_customer_score', 'CustomerID', 'ContactName',  \n",
    "                  'CustomerModeName',   'ContactPhone', 'FullAddress', 'Latitude',\n",
    "                  'Longitude', 'LGA', 'LCDA', 'composite_customer_score', #, 'percentile_rank',  \n",
    "                  'KYC_Capture_Status', 'SKUID', 'ProductName', #'Output', 'LastDeliveredDate', \n",
    "                  'Recency','CustomerPurchaseRecency', 'InventoryCheck', 'ProductTag', 'Medium', 'EstimatedQuantity',\n",
    "                ]\n",
    "    \n",
    "    def _merge_select(df):\n",
    "        modified_df = (\n",
    "                        df[sel_columns]\n",
    "                        .merge(cluster_summary, how='left', on = 'cluster' )\n",
    "                        .merge(df_master_customer_dim[sel_cols_cust], how='left', on = ['Stock_Point_ID', 'CustomerID'])\n",
    "                        .merge(df_stockpoint[['Stock_Point_ID', 'Stock_point_Name']], how='left', on = ['Stock_Point_ID'])\n",
    "                        .rename(columns={'cluster':'TripID'})\n",
    "                        [final_cols]\n",
    "                        .rename(columns = {\n",
    "                                           'Stock_point_Name': 'StockPointName'\n",
    "                                           ,'Stock_Point_ID': 'StockPointID'\n",
    "                                           ,'ncustomer': 'TotalCustonerCount'\n",
    "                                           ,'totalQty': 'TripTotalQuantity'\n",
    "                                           ,'avg_customer_score': 'TripAvgCustomerScore'\n",
    "                                           ,'LastDeliveredDate': 'CustomerLastDeliveredDate'\n",
    "                                           ,'Medium': 'RecommendationType'\n",
    "                                           ,'Recency': 'SKUDaysSinceLastBuy'\n",
    "                                           ,'CustomerPurchaseRecency': 'CustomerDaysSinceLastBuy'\n",
    "                                           ,'composite_customer_score': 'CustomerScore'\n",
    "                                           ,'KYC_Capture_Status': 'kycCaptureStatus'\n",
    "                                           ,'LGA_list': 'ClusterLGAs'\n",
    "                                           ,'LCDA_List': 'ClusterLCDAs'\n",
    "                                           })\n",
    "                        )\n",
    "        return modified_df\n",
    "\n",
    "    df_selected_trip = push_recommendation[push_recommendation['cluster'].isin(sel_cluster_tuple)]\n",
    "    selected_push_recommendation_trip = _merge_select(df_selected_trip)\n",
    "    all_push_recommendation =  _merge_select(push_recommendation)\n",
    "    all_push_recommendation['isTripSelected'] = np.where(all_push_recommendation['TripID'].isin(sel_cluster_tuple) ,\n",
    "                                                    'Yes',\n",
    "                                                    'No'\n",
    "                                                )\n",
    "    \n",
    "\n",
    "    return selected_push_recommendation_trip, all_push_recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762d067f",
   "metadata": {},
   "source": [
    "### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd91edc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_push_recommendation(df_customer_sku_recommendation, \n",
    "                            df_master_customer_dim, \n",
    "                            df_stockpoint_dim, \n",
    "                            stock_point_id,\n",
    "                            stock_point_name,\n",
    "                            sku_recency = 7, \n",
    "                            customer_recency = 60, number_recommendation = 5, \n",
    "                            estimate_qty_scale_factor = 1, max_estimated_qty = 5, \n",
    "                            exclude_recency_customer = 4,\n",
    "                            max_customers_per_route=20,\n",
    "                            max_volume_per_route=300,\n",
    "                            max_distance_km = 40,\n",
    "                            sel_trip_cluster = 5,\n",
    "                            min_ncust_per_cluster = 5,\n",
    "                            clustering_method = 'divisive',\n",
    "                            skip_route_optimization = False):\n",
    "    \"\"\"\n",
    "    Main execution function demonstrating complete route optimization workflow\n",
    "    \"\"\" \n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\")\n",
    "    print(f\"StockPoint: {stock_point_name}, StockPointID: {stock_point_id},\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # STEP 1: Load or Generate Data\n",
    "    print(\"\\n1. Loading Data...\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    df_sku_rec, df_customer_dim, df_stockpoint  = data_filter(df_customer_sku_recommendation, \n",
    "                                                                df_master_customer_dim, \n",
    "                                                                df_stockpoint_dim, \n",
    "                                                                stockpoint_id = stock_point_id,  \n",
    "                                                                sku_recency = sku_recency, \n",
    "                                                                customer_recency = customer_recency, \n",
    "                                                                number_recommendation = number_recommendation,\n",
    "                                                                estimate_qty_scale_factor = estimate_qty_scale_factor, \n",
    "                                                                max_estimated_qty = max_estimated_qty,\n",
    "                                                                exclude_recency_customer = exclude_recency_customer)\n",
    "\n",
    "    if len(df_customer_dim) < min_ncust_per_cluster:\n",
    "        return {}\n",
    "    \n",
    "    print(f\"✓ Loaded {len(df_sku_rec)} SKU recommendations\")\n",
    "    print(f\"✓ Loaded {len(df_customer_dim)} customer records\")\n",
    "    print(f\"✓ Loaded {len(df_stockpoint)} stock points\")\n",
    "\n",
    "    push_recommendation, df_clustering, df_routes, stock_point_coords = cluster_trip_route(df_sku_rec, \n",
    "                                                                                            df_customer_dim, \n",
    "                                                                                            df_stockpoint,\n",
    "                                                                                            stock_point_id,\n",
    "                                                                                            max_customers_per_route, \n",
    "                                                                                            max_volume_per_route,\n",
    "                                                                                            max_distance_km,\n",
    "                                                                                            clustering_method,\n",
    "                                                                                            skip_route_optimization)\n",
    "\n",
    "    ### Cluster Evaluation\n",
    "    try:\n",
    "        evaluate_unsupervised_clustering(df_clustering)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    ### Cluster Summary \n",
    "    cluster_summary, df_high_value_cluster_summary, sel_cluster_tuple, sel_total_customer_count = cluster_summary_and_selection(\n",
    "                                                                                                        push_recommendation,\n",
    "                                                                                                        sel_trip_cluster,\n",
    "                                                                                                        min_ncust_per_cluster = min_ncust_per_cluster\n",
    "                                                                                                        )\n",
    "\n",
    "    ## Trip\n",
    "    selected_push_recommendation_trip, all_push_recommendation = prep_selected_trip(push_recommendation, \n",
    "                                                  cluster_summary, \n",
    "                                                  df_master_customer_dim,  \n",
    "                                                  df_stockpoint,\n",
    "                                                  sel_cluster_tuple)\n",
    "    \n",
    " \n",
    "    ### Trip Maps\n",
    "    if skip_route_optimization:\n",
    "        try:\n",
    "            df_selected_trip_summary =  selected_push_recommendation_trip.groupby(['StockPointID','TripID', \n",
    "                                                                                   'CustomerID', 'Latitude','Longitude',\n",
    "                                                                                   'LGA', 'LCDA','CustomerScore']).agg( \n",
    "                        TotalQuantity = ('EstimatedQuantity','sum')\n",
    "                        ,TotalSKU = ('SKUID','nunique')\n",
    "                    ).reset_index()\n",
    "            create_route(df_selected_trip_summary, df_stockpoint)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    else:\n",
    "        try:\n",
    "            trip_map_path = f'./recommendation_output/trip_map/{stock_point_name}_{CURRENT_DATE}.html' \n",
    "            map_clusters = vis_and_save(df_routes= (df_routes\n",
    "                                                .rename(columns={'cluster':'cluster_bck'})\n",
    "                                                .rename(columns={'TripNumber':'cluster'})\n",
    "                                                ), \n",
    "                                        df_stockpoint=df_stockpoint, \n",
    "                                        filename=trip_map_path)\n",
    "        except Exception as e:\n",
    "            print(f'Unable to save the generated map image: {e}')\n",
    "\n",
    "        try:\n",
    "            run_route_optimizer(df_clustering, sel_cluster_tuple, df_stockpoint, \n",
    "                            stock_point_name,\n",
    "                            sel_total_customer_count, \n",
    "                            capacity_size = 20)\n",
    "        except Exception as e:\n",
    "            print(f'Unable to generate route mapping using orc: {e}')       \n",
    "    \n",
    "\n",
    "    ### Export Data\n",
    "    try:\n",
    "        export_data(\n",
    "                selected_trip = selected_push_recommendation_trip,\n",
    "                all_push_recommendation = all_push_recommendation,\n",
    "                cluster_summary = cluster_summary,\n",
    "                stock_point_name = stock_point_name,\n",
    "                CURRENT_DATE = CURRENT_DATE\n",
    "            )\n",
    "    except Exception as e:\n",
    "        print(f'Unable to generate route mapping using orc: {e}')\n",
    "\n",
    "    dict_ = {\n",
    "        'stock_point_name': stock_point_name,\n",
    "        'selected_trip': selected_push_recommendation_trip,\n",
    "        'all_push_recommendation': all_push_recommendation,\n",
    "        'cluster_summary': cluster_summary\n",
    "    }\n",
    "\n",
    "    return dict_\n",
    "    #push_recommendation, df_clustering, df_routes, trip_summary, stock_point_coords, df_stockpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44619d0",
   "metadata": {},
   "source": [
    "# Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8cc0a172",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Data\n",
    "df_customer_sku_recommendation_raw = pd.read_feather('./input/customer_sku_recommendation.feather').rename(columns={'FCID':'Stock_Point_ID','CustomerId':'CustomerID'})\n",
    "df_customer_dim_with_affinity_score_raw = pd.read_feather('./input/customer_dim_with_affinity_score.feather').rename(columns={'FCID':'Stock_Point_ID'})\n",
    "df_stockpoint_dim_raw = pd.read_feather('./input/stockpoint_dim.feather')\n",
    "df_kyc_customer = pd.read_feather('./input/kyc_customers.feather')\n",
    "df_customer_score = pd.read_feather('./input/df_customer_score.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1617177c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "df_customer_sku_recommendation, df_master_customer_dim, df_stockpoint_dim = preprocessing(df_customer_sku_recommendation_raw, \n",
    "                                                                                                        df_customer_dim_with_affinity_score_raw, \n",
    "                                                                                                        df_stockpoint_dim_raw,\n",
    "                                                                                                        df_customer_score,\n",
    "                                                                                                        df_kyc_customer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fe979f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# causeway_customer_dim.query(\"days_since_last_order > 60\")[['KYC_Capture_Status']].value_counts()\n",
    "# causeway_customer_dim.query(\"KYC_Capture_Status == 'No'\")[['days_since_last_order']].hist()#.value_counts()#.reset_index().sort_values('days_since_last_order')\n",
    "# causeway_customer_dim.KYC_Capture_Status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "904b1d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [col for col in df_stockpoint_dim.Stock_point_Name if 'C' in col] \n",
    "# test_sp = 'OmniHub Apapa Lagos - CAUSEWAY'\n",
    "# # # test_spid = 1647402\n",
    "# # test_sp = 'OmniHub Alimosho Lagos - Barka Agro Mix'\n",
    "# # test_spid = 1647345\n",
    "\n",
    "# df_stockpoint_dim[df_stockpoint_dim['Stock_point_Name'] == test_sp]\n",
    "# # # df_customer_sku_recommendation.query(f'Stock_Point_ID == {test_spid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518e3101",
   "metadata": {},
   "source": [
    "### Iterative Run - All SPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d43aaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/72 \n",
      "Stock Point ID: 1647128 || Stock Point Name: OmniHub Obio Akpor Rivers - Rivoc\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Obio Akpor Rivers - Rivoc, StockPointID: 1647128,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 50\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 1\n",
      "Total Number of Customers: 0\n",
      "1/72 \n",
      "Stock Point ID: 1647401 || Stock Point Name: OmniHub Ado Odo/Ota Ogun - Prince Tunadek\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ado Odo/Ota Ogun - Prince Tunadek, StockPointID: 1647401,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 218\n",
      "Total Quantity: 67\n",
      "Total Number of Customers before filter: 19\n",
      "Total Number of Customers: 4\n",
      "2/72 \n",
      "Stock Point ID: 1647402 || Stock Point Name: OmniHub AMAC 1 Abuja - Elriah\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub AMAC 1 Abuja - Elriah, StockPointID: 1647402,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Dataframe is empty\n",
      "INFO:__main__:Trip Data is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Quantity before filter: 100\n",
      "Total Quantity: 55\n",
      "Total Number of Customers before filter: 9\n",
      "Total Number of Customers: 5\n",
      "✓ Loaded 16 SKU recommendations\n",
      "✓ Loaded 5 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.41\n",
      "Davies-Bouldin Index: 0.18\n",
      "Calinski-Harabasz Score: 23.69\n",
      "Silhouette Score: 0.41\n",
      "Davies-Bouldin Index: 0.18\n",
      "Calinski-Harabasz Score: 23.69\n",
      "Select ClusterIDs: []\n",
      "Total Number of Customers: 0\n",
      "Empty DataFrame\n",
      "Columns: [cluster, LGA_list, LCDA_List, ncustomer, totalQty, avg_customer_score]\n",
      "Index: []\n",
      "3/72 \n",
      "Stock Point ID: 1647136 || Stock Point Name: OmniHub Tarauni Kano - Amjabil\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Tarauni Kano - Amjabil, StockPointID: 1647136,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 5\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 1\n",
      "Total Number of Customers: 0\n",
      "4/72 \n",
      "Stock Point ID: 1647076 || Stock Point Name: OmniHub Alimosho Lagos - Isukoshi MFC\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Alimosho Lagos - Isukoshi MFC, StockPointID: 1647076,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "5/72 \n",
      "Stock Point ID: 1647394 || Stock Point Name: OmniHub Port Harcourt Rivers - WCG 2\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Port Harcourt Rivers - WCG 2, StockPointID: 1647394,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 16,230\n",
      "Total Quantity: 11,053\n",
      "Total Number of Customers before filter: 476\n",
      "Total Number of Customers: 322\n",
      "✓ Loaded 2978 SKU recommendations\n",
      "✓ Loaded 322 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.55\n",
      "Davies-Bouldin Index: 0.51\n",
      "Calinski-Harabasz Score: 48389.57\n",
      "Silhouette Score: 0.55\n",
      "Davies-Bouldin Index: 0.51\n",
      "Calinski-Harabasz Score: 48389.57\n",
      "Select ClusterIDs: [19, 10, 17, 6]\n",
      "Total Number of Customers: 48\n",
      "   cluster                              LGA_list  \\\n",
      "0       19                             [Ikwerre]   \n",
      "1       10  [Obio Akpor, Ikwerre, Port Harcourt]   \n",
      "2       17  [Ikwerre, Obio Akpor, Port Harcourt]   \n",
      "3        6                             [Ikwerre]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0                         [Igwuruta-Ali, Igwuruta, ]          5       188   \n",
      "1  [Woji, Trans Amadi, , Port Harcourt-Transamadi...         14       505   \n",
      "2                    [Omagwa, Rukpokwu, Amadi Ama, ]          6       208   \n",
      "3                [, Omagwa, Omuegwa, Isiokpo, Imogu]         23       896   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           41.748163  \n",
      "1           37.795191  \n",
      "2           36.171754  \n",
      "3           35.817982  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 6 (24 waypoints)...\n",
      "  Trip ID 6 calculated. Distance: 65.27 km, Duration: 66.33 min\n",
      "  Calculating route for Trip ID: 10 (15 waypoints)...\n",
      "  Trip ID 10 calculated. Distance: 40.70 km, Duration: 51.87 min\n",
      "  Calculating route for Trip ID: 17 (7 waypoints)...\n",
      "  Trip ID 17 calculated. Distance: 28.36 km, Duration: 35.08 min\n",
      "  Calculating route for Trip ID: 19 (6 waypoints)...\n",
      "  Trip ID 19 calculated. Distance: 30.52 km, Duration: 35.37 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647394.html\n",
      "6/72 \n",
      "Stock Point ID: 1647396 || Stock Point Name: OmniHub Oshodi Isolo Lagos - Eloramore\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Oshodi Isolo Lagos - Eloramore, StockPointID: 1647396,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 3,314\n",
      "Total Quantity: 2,034\n",
      "Total Number of Customers before filter: 162\n",
      "Total Number of Customers: 101\n",
      "✓ Loaded 651 SKU recommendations\n",
      "✓ Loaded 101 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.32\n",
      "Davies-Bouldin Index: 0.76\n",
      "Calinski-Harabasz Score: 9177.94\n",
      "Silhouette Score: 0.32\n",
      "Davies-Bouldin Index: 0.76\n",
      "Calinski-Harabasz Score: 9177.94\n",
      "Select ClusterIDs: [3, 6, 1, 5]\n",
      "Total Number of Customers: 56\n",
      "   cluster                         LGA_list  \\\n",
      "0        3  [Oshodi Isolo, Push - Alimosho]   \n",
      "1        6                   [Oshodi Isolo]   \n",
      "2        1                   [Oshodi Isolo]   \n",
      "3        5                 [Oshodi Isolo, ]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [, Oshodi Isolo - Ago Palace, Push - Alimosho ...         12       273   \n",
      "1  [Oshodi Isolo - Ago Palace, , Oshodi Isolo - O...          8       185   \n",
      "2  [, Oshodi Isolo - Isolo, Oshodi Isolo - Orile,...         28       550   \n",
      "3  [Oshodi Isolo - Isolo, , Oshodi Isolo - Ejigbo...          8       160   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           32.061477  \n",
      "1           30.457667  \n",
      "2           29.847697  \n",
      "3           29.015686  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (29 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 75.16 km, Duration: 146.30 min\n",
      "  Calculating route for Trip ID: 3 (13 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 34.53 km, Duration: 84.25 min\n",
      "  Calculating route for Trip ID: 5 (9 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 15.85 km, Duration: 27.92 min\n",
      "  Calculating route for Trip ID: 6 (9 waypoints)...\n",
      "  Trip ID 6 calculated. Distance: 21.86 km, Duration: 41.73 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647396.html\n",
      "7/72 \n",
      "Stock Point ID: 1647075 || Stock Point Name: OmniHub Dugbe Oyo - Derints Enterprises\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Dugbe Oyo - Derints Enterprises, StockPointID: 1647075,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "8/72 \n",
      "Stock Point ID: 1647077 || Stock Point Name: OmniHub Surulere Lagos - Platform Height MFC\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Surulere Lagos - Platform Height MFC, StockPointID: 1647077,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "9/72 \n",
      "Stock Point ID: 1647400 || Stock Point Name: OmniHub Eleme Rivers - Berclynv\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Eleme Rivers - Berclynv, StockPointID: 1647400,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 7,062\n",
      "Total Quantity: 4,121\n",
      "Total Number of Customers before filter: 290\n",
      "Total Number of Customers: 162\n",
      "✓ Loaded 1204 SKU recommendations\n",
      "✓ Loaded 162 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.59\n",
      "Davies-Bouldin Index: 0.44\n",
      "Calinski-Harabasz Score: 51926.17\n",
      "Silhouette Score: 0.59\n",
      "Davies-Bouldin Index: 0.44\n",
      "Calinski-Harabasz Score: 51926.17\n",
      "Select ClusterIDs: [7, 8, 4, 1]\n",
      "Total Number of Customers: 64\n",
      "   cluster  LGA_list                                          LCDA_List  \\\n",
      "0        7   [Eleme]  [Agbnchia, Nichia-Eleme, , Aleto, ELEME-AGBONC...   \n",
      "1        8   [Eleme]        [ELEME-ALESA, , Alese, Aleto, Nichia-Eleme]   \n",
      "2        4  [Okrika]      [Okirika, Ogoloma, Okochiri, , Abam – Ama Ii]   \n",
      "3        1   [Eleme]                               [Onne, , ELEME-ONNE]   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0         10       277           44.515063  \n",
      "1          7       191           38.960000  \n",
      "2         18       465           33.041761  \n",
      "3         29       774           28.101511  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (30 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 26.20 km, Duration: 39.95 min\n",
      "  Calculating route for Trip ID: 4 (19 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 33.17 km, Duration: 48.77 min\n",
      "  Calculating route for Trip ID: 7 (11 waypoints)...\n",
      "  Trip ID 7 calculated. Distance: 5.44 km, Duration: 7.15 min\n",
      "  Calculating route for Trip ID: 8 (8 waypoints)...\n",
      "  Trip ID 8 calculated. Distance: 26.71 km, Duration: 40.87 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647400.html\n",
      "10/72 \n",
      "Stock Point ID: 1647081 || Stock Point Name: OmniHub Alimosho Lagos - Barka-Agro and General Services MFC\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Alimosho Lagos - Barka-Agro and General Services MFC, StockPointID: 1647081,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 5,317\n",
      "Total Quantity: 3,462\n",
      "Total Number of Customers before filter: 205\n",
      "Total Number of Customers: 129\n",
      "✓ Loaded 1079 SKU recommendations\n",
      "✓ Loaded 129 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.36\n",
      "Davies-Bouldin Index: 0.69\n",
      "Calinski-Harabasz Score: 307.99\n",
      "Silhouette Score: 0.36\n",
      "Davies-Bouldin Index: 0.69\n",
      "Calinski-Harabasz Score: 307.99\n",
      "Select ClusterIDs: [1, 7, 2, 3]\n",
      "Total Number of Customers: 91\n",
      "   cluster            LGA_list  \\\n",
      "0        1  [Alimosho, Egbeda]   \n",
      "1        7          [Alimosho]   \n",
      "2        2          [Alimosho]   \n",
      "3        3          [Alimosho]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [Alimosho - Iyana Ipaja (egbeda), , Alimosho -...         29       832   \n",
      "1  [Alimosho - Idimu, Alimosho - Egbe/idimu, Alim...          7       192   \n",
      "2  [Alimosho - Idimu, , Alimosho - Iyana Ipaja (s...         28       717   \n",
      "3  [Alimosho - Iyana Ipaja (egbeda), , Alimosho -...         27       758   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           54.343156  \n",
      "1           44.375424  \n",
      "2           41.963333  \n",
      "3           41.386653  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (30 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 32.42 km, Duration: 76.37 min\n",
      "  Calculating route for Trip ID: 2 (29 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 48.63 km, Duration: 104.98 min\n",
      "  Calculating route for Trip ID: 3 (28 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 55.08 km, Duration: 114.02 min\n",
      "  Calculating route for Trip ID: 7 (8 waypoints)...\n",
      "  Trip ID 7 calculated. Distance: 25.81 km, Duration: 42.78 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647081.html\n",
      "11/72 \n",
      "Stock Point ID: 1647398 || Stock Point Name: OmniHub Ifako Ijaiye Lagos - Bickson\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ifako Ijaiye Lagos - Bickson, StockPointID: 1647398,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 1,457\n",
      "Total Quantity: 915\n",
      "Total Number of Customers before filter: 87\n",
      "Total Number of Customers: 59\n",
      "✓ Loaded 267 SKU recommendations\n",
      "✓ Loaded 59 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.41\n",
      "Davies-Bouldin Index: 0.74\n",
      "Calinski-Harabasz Score: 71.94\n",
      "Silhouette Score: 0.41\n",
      "Davies-Bouldin Index: 0.74\n",
      "Calinski-Harabasz Score: 71.94\n",
      "Select ClusterIDs: [2, 5, 3, 4]\n",
      "Total Number of Customers: 37\n",
      "   cluster                                    LGA_list  \\\n",
      "0        2  [Ifako Ijaiye, Agege, Push - Ifako Ijaiye]   \n",
      "1        5                       [Agege, Ifako Ijaiye]   \n",
      "2        3                              [Ifako Ijaiye]   \n",
      "3        4                              [Ifako Ijaiye]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [, Ifako Ijaiye - Ojokoro, Agege - Iju Road, P...         11       198   \n",
      "1                      [, Agege - Ajuwon Akute Road]          5        99   \n",
      "2  [, Ifako Ijaiye - Ojokoro, Ifako Ijaiye - Ogba...         11       168   \n",
      "3                         [Ifako Ijaiye - Ojokoro, ]         10       190   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           49.976379  \n",
      "1           47.067586  \n",
      "2           39.604630  \n",
      "3           38.366415  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 2 (12 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 14.30 km, Duration: 45.87 min\n",
      "  Calculating route for Trip ID: 3 (12 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 31.66 km, Duration: 93.68 min\n",
      "  Calculating route for Trip ID: 4 (11 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 38.20 km, Duration: 64.73 min\n",
      "  Calculating route for Trip ID: 5 (6 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 17.20 km, Duration: 44.57 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647398.html\n",
      "12/72 \n",
      "Stock Point ID: 1646941 || Stock Point Name: OmniHub Ido Oyo - CARESGATE AFRICA LTD\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ido Oyo - CARESGATE AFRICA LTD, StockPointID: 1646941,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 1,904\n",
      "Total Quantity: 1,106\n",
      "Total Number of Customers before filter: 101\n",
      "Total Number of Customers: 59\n",
      "✓ Loaded 299 SKU recommendations\n",
      "✓ Loaded 59 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.33\n",
      "Davies-Bouldin Index: 0.66\n",
      "Calinski-Harabasz Score: 1440.75\n",
      "Silhouette Score: 0.33\n",
      "Davies-Bouldin Index: 0.66\n",
      "Calinski-Harabasz Score: 1440.75\n",
      "Select ClusterIDs: [3, 4, 2, 1]\n",
      "Total Number of Customers: 39\n",
      "   cluster                    LGA_list                     LCDA_List  \\\n",
      "0        3    [Ido, Ibadan South West]       [IBADAN-APATA, , Apata]   \n",
      "1        4    [Ido, Ibadan South West]           [Ido, Apete, Apata]   \n",
      "2        2    [Ibadan South West, Ido]                     [, Apata]   \n",
      "3        1  [Ibadan South West, Ido, ]  [Apata, IBADAN-APATA, , Ido]   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0          9       154           27.966190  \n",
      "1          8       190           23.316923  \n",
      "2         10       163           20.416279  \n",
      "3         12       185           20.253617  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (13 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 33.19 km, Duration: 45.02 min\n",
      "  Calculating route for Trip ID: 2 (11 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 40.09 km, Duration: 51.15 min\n",
      "  Calculating route for Trip ID: 3 (10 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 21.74 km, Duration: 31.72 min\n",
      "  Calculating route for Trip ID: 4 (9 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 35.61 km, Duration: 40.63 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1646941.html\n",
      "13/72 \n",
      "Stock Point ID: 1646945 || Stock Point Name: OmniHub Ado Odo/Ota Ogun - RAZCO ENERGY\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ado Odo/Ota Ogun - RAZCO ENERGY, StockPointID: 1646945,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 20\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 1\n",
      "Total Number of Customers: 0\n",
      "14/72 \n",
      "Stock Point ID: 1646999 || Stock Point Name: OmniHub Eti Osa Lagos - Motomori\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Eti Osa Lagos - Motomori, StockPointID: 1646999,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 4,846\n",
      "Total Quantity: 3,045\n",
      "Total Number of Customers before filter: 161\n",
      "Total Number of Customers: 99\n",
      "✓ Loaded 765 SKU recommendations\n",
      "✓ Loaded 99 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.48\n",
      "Davies-Bouldin Index: 0.58\n",
      "Calinski-Harabasz Score: 47.77\n",
      "Silhouette Score: 0.48\n",
      "Davies-Bouldin Index: 0.58\n",
      "Calinski-Harabasz Score: 47.77\n",
      "Select ClusterIDs: [7, 1, 6, 2]\n",
      "Total Number of Customers: 57\n",
      "   cluster   LGA_list                                          LCDA_List  \\\n",
      "0        7  [Eti Osa]  [, Eti Osa - Ikoyi Mtn - Pickup Station, Eti O...   \n",
      "1        1  [Eti Osa]  [Eti Osa - Ajah (lekki), Eti Osa - Lekki - Aja...   \n",
      "2        6  [Eti Osa]  [, Eti Osa - Lekki - Ajah (sangotedo), Eti Osa...   \n",
      "3        2  [Eti Osa]  [Eti Osa - Lekki - Ajah (addo Road), , Eti Osa...   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0          7       191           45.005714  \n",
      "1         26       725           36.880321  \n",
      "2          7       242           36.813770  \n",
      "3         17       487           36.684574  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (27 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 71.03 km, Duration: 96.32 min\n",
      "  Calculating route for Trip ID: 2 (18 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 53.38 km, Duration: 77.35 min\n",
      "  Calculating route for Trip ID: 6 (8 waypoints)...\n",
      "  Trip ID 6 calculated. Distance: 25.58 km, Duration: 26.05 min\n",
      "  Calculating route for Trip ID: 7 (8 waypoints)...\n",
      "  Trip ID 7 calculated. Distance: 47.78 km, Duration: 52.50 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1646999.html\n",
      "15/72 \n",
      "Stock Point ID: 1647010 || Stock Point Name: OmniHub Alimosho Lagos - LARDAMIC\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Alimosho Lagos - LARDAMIC, StockPointID: 1647010,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 1,997\n",
      "Total Quantity: 1,373\n",
      "Total Number of Customers before filter: 69\n",
      "Total Number of Customers: 48\n",
      "✓ Loaded 430 SKU recommendations\n",
      "✓ Loaded 48 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.39\n",
      "Davies-Bouldin Index: 0.62\n",
      "Calinski-Harabasz Score: 36.73\n",
      "Silhouette Score: 0.39\n",
      "Davies-Bouldin Index: 0.62\n",
      "Calinski-Harabasz Score: 36.73\n",
      "Select ClusterIDs: [2, 1]\n",
      "Total Number of Customers: 41\n",
      "   cluster    LGA_list                                          LCDA_List  \\\n",
      "0        2  [Alimosho]  [, Alimosho - Iyana Ipaja (command Road), Alim...   \n",
      "1        1  [Alimosho]  [Alimosho - Abule Egba (ajasa Command Rd), Ali...   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0         16       445           47.138143  \n",
      "1         25       737           45.426332  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (26 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 60.39 km, Duration: 110.00 min\n",
      "  Calculating route for Trip ID: 2 (17 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 25.69 km, Duration: 57.80 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647010.html\n",
      "16/72 \n",
      "Stock Point ID: 1646991 || Stock Point Name: OmniHub Badagry Lagos - STEAVESON\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Badagry Lagos - STEAVESON, StockPointID: 1646991,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 2,212\n",
      "Total Quantity: 1,557\n",
      "Total Number of Customers before filter: 122\n",
      "Total Number of Customers: 80\n",
      "✓ Loaded 394 SKU recommendations\n",
      "✓ Loaded 80 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.57\n",
      "Davies-Bouldin Index: 0.27\n",
      "Calinski-Harabasz Score: 38968.06\n",
      "Silhouette Score: 0.57\n",
      "Davies-Bouldin Index: 0.27\n",
      "Calinski-Harabasz Score: 38968.06\n",
      "Select ClusterIDs: [1, 2, 3]\n",
      "Total Number of Customers: 54\n",
      "   cluster                   LGA_list  \\\n",
      "0        1                  [Badagry]   \n",
      "1        2  [Badagry, Push - Badagry]   \n",
      "2        3                  [Badagry]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [Badagry - Ajara Topa, , Badagry - Agbalata, B...         30       689   \n",
      "1  [Badagry - Oko-afor, , Badagry - Mowo, Badagry...         16       294   \n",
      "2  [, Badagry - Ajara Topa, Badagry - Badagry Tow...          8       169   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           58.280116  \n",
      "1           49.887821  \n",
      "2           48.265897  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (31 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 28.90 km, Duration: 41.02 min\n",
      "  Calculating route for Trip ID: 2 (17 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 40.80 km, Duration: 44.18 min\n",
      "  Calculating route for Trip ID: 3 (9 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 12.63 km, Duration: 19.38 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1646991.html\n",
      "17/72 \n",
      "Stock Point ID: 1647024 || Stock Point Name: OmniHub Oyigbo Rivers - LAMDA GLOBAL\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Oyigbo Rivers - LAMDA GLOBAL, StockPointID: 1647024,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 11,385\n",
      "Total Quantity: 7,041\n",
      "Total Number of Customers before filter: 307\n",
      "Total Number of Customers: 183\n",
      "✓ Loaded 1715 SKU recommendations\n",
      "✓ Loaded 183 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.5\n",
      "Davies-Bouldin Index: 0.41\n",
      "Calinski-Harabasz Score: 18313.94\n",
      "Silhouette Score: 0.5\n",
      "Davies-Bouldin Index: 0.41\n",
      "Calinski-Harabasz Score: 18313.94\n",
      "Select ClusterIDs: [8, 3, 5, 2]\n",
      "Total Number of Customers: 74\n",
      "   cluster           LGA_list  \\\n",
      "0        8           [Oyigbo]   \n",
      "1        3    [Etche, Oyigbo]   \n",
      "2        5  [Oyigbo, Etche, ]   \n",
      "3        2    [Oyigbo, Etche]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [Komkom, OYIGBO (DUPLICATE), , OYIGBO-EGBERU, ...          9       350   \n",
      "1             [Umuebulu, , OYIGBO (DUPLICATE), Afam]         18       661   \n",
      "2                               [Komkom, Umuebulu, ]         17       643   \n",
      "3  [OYIGBO (DUPLICATE), Komkom, Umuebulu, Egberu,...         30      1207   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           50.116707  \n",
      "1           45.387931  \n",
      "2           44.358323  \n",
      "3           38.193322  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 2 (31 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 15.02 km, Duration: 14.47 min\n",
      "  Calculating route for Trip ID: 3 (19 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 30.52 km, Duration: 28.35 min\n",
      "  Calculating route for Trip ID: 5 (18 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 18.92 km, Duration: 16.80 min\n",
      "  Calculating route for Trip ID: 8 (10 waypoints)...\n",
      "  Trip ID 8 calculated. Distance: 33.47 km, Duration: 44.48 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647024.html\n",
      "18/72 \n",
      "Stock Point ID: 1646989 || Stock Point Name: OmniHub Amuwo Odofin Lagos - GOLDVIRTUES\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Amuwo Odofin Lagos - GOLDVIRTUES, StockPointID: 1646989,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "19/72 \n",
      "Stock Point ID: 1647033 || Stock Point Name: OmniHub Ilorin_East Kwara - REAL HEIGHT SERVICES\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ilorin_East Kwara - REAL HEIGHT SERVICES, StockPointID: 1647033,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 933\n",
      "Total Quantity: 726\n",
      "Total Number of Customers before filter: 82\n",
      "Total Number of Customers: 62\n",
      "✓ Loaded 165 SKU recommendations\n",
      "✓ Loaded 62 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.41\n",
      "Davies-Bouldin Index: 0.58\n",
      "Calinski-Harabasz Score: 51.55\n",
      "Silhouette Score: 0.41\n",
      "Davies-Bouldin Index: 0.58\n",
      "Calinski-Harabasz Score: 51.55\n",
      "Select ClusterIDs: [2, 5, 4, 1]\n",
      "Total Number of Customers: 41\n",
      "   cluster                                  LGA_list  \\\n",
      "0        2  [Ilorin West, Ilorin South, Ilorin East]   \n",
      "1        5  [Ilorin East, Ilorin South, Ilorin West]   \n",
      "2        4               [Ilorin East, Ilorin South]   \n",
      "3        1                [Ilorin West, Ilorin East]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [Babaoko, Coca-Cola Road, , Oja-Gboro, Offa Ga...         11       141   \n",
      "1          [Okelele, Idi-Ape, , Oja-Gboro, Agbo-Oba]          6        73   \n",
      "2     [Oja-Gboro, , Maraba, Sango, Kulende, Gambari]          8        86   \n",
      "3  [General Hospital, Agbo-Oba, Asa Dam, Babaoko,...         16       191   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           54.422812  \n",
      "1           52.919500  \n",
      "2           42.992500  \n",
      "3           37.952927  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (17 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 41.96 km, Duration: 53.72 min\n",
      "  Calculating route for Trip ID: 2 (12 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 99.74 km, Duration: 705.35 min\n",
      "  Calculating route for Trip ID: 4 (9 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 32.73 km, Duration: 39.35 min\n",
      "  Calculating route for Trip ID: 5 (7 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 25.36 km, Duration: 27.70 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647033.html\n",
      "20/72 \n",
      "Stock Point ID: 1646976 || Stock Point Name: \n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: , StockPointID: 1646976,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "21/72 \n",
      "Stock Point ID: 1646971 || Stock Point Name: OmniHub Abeokuta Ogun - Brooks\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Abeokuta Ogun - Brooks, StockPointID: 1646971,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 1,252\n",
      "Total Quantity: 894\n",
      "Total Number of Customers before filter: 86\n",
      "Total Number of Customers: 61\n",
      "✓ Loaded 265 SKU recommendations\n",
      "✓ Loaded 61 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.56\n",
      "Davies-Bouldin Index: 0.43\n",
      "Calinski-Harabasz Score: 589.15\n",
      "Silhouette Score: 0.56\n",
      "Davies-Bouldin Index: 0.43\n",
      "Calinski-Harabasz Score: 589.15\n",
      "Select ClusterIDs: [3, 4, 5, 1]\n",
      "Total Number of Customers: 39\n",
      "   cluster                          LGA_list  \\\n",
      "0        3  [Abeokuta South, Abeokuta North]   \n",
      "1        4           [Abeokuta South, Odeda]   \n",
      "2        5  [Abeokuta South, Abeokuta North]   \n",
      "3        1                  [Abeokuta North]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0                 [Adatan, Elega, Kuto, , Iberekodo]          9       128   \n",
      "1                         [Adatan, Eleweran, Aregbe]          8       132   \n",
      "2  [Gbokoniyi, Onikolobo, Ibara, Totoro, Akinolug...          6        82   \n",
      "3  [Bode - Olude, Elega, Akomoje, Mokola, Iberekodo]         16       208   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           40.255385  \n",
      "1           40.165714  \n",
      "2           36.740000  \n",
      "3           35.424032  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (17 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 31.05 km, Duration: 67.53 min\n",
      "  Calculating route for Trip ID: 3 (10 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 23.10 km, Duration: 26.15 min\n",
      "  Calculating route for Trip ID: 4 (9 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 22.82 km, Duration: 34.00 min\n",
      "  Calculating route for Trip ID: 5 (7 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 19.56 km, Duration: 34.10 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1646971.html\n",
      "22/72 \n",
      "Stock Point ID: 1647011 || Stock Point Name: OmniHub Badagry Lagos - NEEMYGHT MULTI-VENTURE ENTERPRISES\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Badagry Lagos - NEEMYGHT MULTI-VENTURE ENTERPRISES, StockPointID: 1647011,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 1,127\n",
      "Total Quantity: 953\n",
      "Total Number of Customers before filter: 59\n",
      "Total Number of Customers: 48\n",
      "✓ Loaded 240 SKU recommendations\n",
      "✓ Loaded 48 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.76\n",
      "Davies-Bouldin Index: 0.19\n",
      "Calinski-Harabasz Score: 9983.97\n",
      "Silhouette Score: 0.76\n",
      "Davies-Bouldin Index: 0.19\n",
      "Calinski-Harabasz Score: 9983.97\n",
      "Select ClusterIDs: [3, 1, 2]\n",
      "Total Number of Customers: 37\n",
      "   cluster   LGA_list                                          LCDA_List  \\\n",
      "0        3  [Badagry]  [Badagry - Agbara (checking Point), Badagry - ...   \n",
      "1        1  [Badagry]  [Badagry - Agbara (checking Point), Badagry - ...   \n",
      "2        2  [Badagry]  [Badagry - Agbara (magbon), , Badagry - Agbara...   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0          8       135           56.196452  \n",
      "1         18       355           47.352069  \n",
      "2         11       241           44.269833  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (19 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 6.32 km, Duration: 9.68 min\n",
      "  Calculating route for Trip ID: 2 (12 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 58.43 km, Duration: 47.22 min\n",
      "  Calculating route for Trip ID: 3 (9 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 50.83 km, Duration: 39.03 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647011.html\n",
      "23/72 \n",
      "Stock Point ID: 1647050 || Stock Point Name: OMNIHUB-OREDO-EDO-AMA-PEE ENTERPRISE\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OMNIHUB-OREDO-EDO-AMA-PEE ENTERPRISE, StockPointID: 1647050,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 1,784\n",
      "Total Quantity: 1,199\n",
      "Total Number of Customers before filter: 184\n",
      "Total Number of Customers: 117\n",
      "✓ Loaded 280 SKU recommendations\n",
      "✓ Loaded 117 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.48\n",
      "Davies-Bouldin Index: 0.8\n",
      "Calinski-Harabasz Score: 773.41\n",
      "Silhouette Score: 0.48\n",
      "Davies-Bouldin Index: 0.8\n",
      "Calinski-Harabasz Score: 773.41\n",
      "Select ClusterIDs: [7, 5, 2, 11]\n",
      "Total Number of Customers: 31\n",
      "   cluster              LGA_list                           LCDA_List  \\\n",
      "0        7  [Oredo, Ikpoba Okha]         [Benin, , Gorretti, Idogbo]   \n",
      "1        5  [Ikpoba Okha, Oredo]        [Obayantor, Benin, Gorretti]   \n",
      "2        2  [Ikpoba Okha, Oredo]  [Gorretti, , Benin, Etete, Idogbo]   \n",
      "3       11  [Oredo, Ikpoba Okha]            [Benin, Gorretti, G.R.A]   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0          6        59           58.722143  \n",
      "1          8        77           56.074444  \n",
      "2         12       132           51.296452  \n",
      "3          5        65           45.323333  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 2 (13 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 14.37 km, Duration: 17.80 min\n",
      "  Calculating route for Trip ID: 5 (9 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 22.83 km, Duration: 24.53 min\n",
      "  Calculating route for Trip ID: 7 (7 waypoints)...\n",
      "  Trip ID 7 calculated. Distance: 20.37 km, Duration: 25.38 min\n",
      "  Calculating route for Trip ID: 11 (6 waypoints)...\n",
      "  Trip ID 11 calculated. Distance: 13.03 km, Duration: 17.68 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647050.html\n",
      "24/72 \n",
      "Stock Point ID: 1647006 || Stock Point Name: OmniHub Ogba/Egbema Ndoni Rivers - JIB\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ogba/Egbema Ndoni Rivers - JIB, StockPointID: 1647006,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "25/72 \n",
      "Stock Point ID: 1646995 || Stock Point Name: OmniHub Epe Lagos - WONUOLA SUPER STORE\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Epe Lagos - WONUOLA SUPER STORE, StockPointID: 1646995,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "26/72 \n",
      "Stock Point ID: 1647391 || Stock Point Name: OmniHub Ibeju Lekki Lagos - SI & A\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ibeju Lekki Lagos - SI & A, StockPointID: 1647391,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 690\n",
      "Total Quantity: 504\n",
      "Total Number of Customers before filter: 47\n",
      "Total Number of Customers: 34\n",
      "✓ Loaded 137 SKU recommendations\n",
      "✓ Loaded 34 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.38\n",
      "Davies-Bouldin Index: 0.37\n",
      "Calinski-Harabasz Score: 132.93\n",
      "Silhouette Score: 0.38\n",
      "Davies-Bouldin Index: 0.37\n",
      "Calinski-Harabasz Score: 132.93\n",
      "Select ClusterIDs: [1, 2]\n",
      "Total Number of Customers: 25\n",
      "   cluster       LGA_list                                          LCDA_List  \\\n",
      "0        1  [Ibeju Lekki]  [Ibeju Lekki - Lakowe - School Gate, Ibeju Lek...   \n",
      "1        2  [Ibeju Lekki]  [Ibeju Lekki - Eleko, Ibeju Lekki - Igando - O...   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0         20       327           32.833333  \n",
      "1          5        57           27.856667  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (21 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 128.87 km, Duration: 165.38 min\n",
      "  Calculating route for Trip ID: 2 (6 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 34.39 km, Duration: 31.83 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647391.html\n",
      "27/72 \n",
      "Stock Point ID: 1647372 || Stock Point Name: OmniHub AMAC 1 Abuja - Roekwi\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub AMAC 1 Abuja - Roekwi, StockPointID: 1647372,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 2,050\n",
      "Total Quantity: 1,524\n",
      "Total Number of Customers before filter: 160\n",
      "Total Number of Customers: 118\n",
      "✓ Loaded 459 SKU recommendations\n",
      "✓ Loaded 118 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.67\n",
      "Davies-Bouldin Index: 0.41\n",
      "Calinski-Harabasz Score: 4275.79\n",
      "Silhouette Score: 0.67\n",
      "Davies-Bouldin Index: 0.41\n",
      "Calinski-Harabasz Score: 4275.79\n",
      "Select ClusterIDs: [5, 1, 2, 3]\n",
      "Total Number of Customers: 71\n",
      "   cluster                                           LGA_list  \\\n",
      "0        5                                           [AMAC 1]   \n",
      "1        1  [Kuje/Gwagwalada/Abaji, AMAC 1, Push - Abuja M...   \n",
      "2        2                            [Kuje/Gwagwalada/Abaji]   \n",
      "3        3                            [Kuje/Gwagwalada/Abaji]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0                              [Lugbe, Airport Road]          8       117   \n",
      "1  [ABUJA-KUJE, ABUJA-GWAGWALADA, , Airport Road,...         27       355   \n",
      "2                [Dobi, ABUJA-GWAGWALADA, , Kutunku]         20       249   \n",
      "3                               [ABUJA-KUJE, , Pegi]         16       160   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           50.136316  \n",
      "1           37.116636  \n",
      "2           36.865068  \n",
      "3           34.033778  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (28 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 51.20 km, Duration: 58.95 min\n",
      "  Calculating route for Trip ID: 2 (21 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 104.08 km, Duration: 99.83 min\n",
      "  Calculating route for Trip ID: 3 (17 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 44.25 km, Duration: 55.58 min\n",
      "  Calculating route for Trip ID: 5 (9 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 18.39 km, Duration: 31.78 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647372.html\n",
      "28/72 \n",
      "Stock Point ID: 1647377 || Stock Point Name: OmniHub Ikorodu Lagos - Sitrest\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ikorodu Lagos - Sitrest, StockPointID: 1647377,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 4,063\n",
      "Total Quantity: 2,823\n",
      "Total Number of Customers before filter: 153\n",
      "Total Number of Customers: 105\n",
      "✓ Loaded 774 SKU recommendations\n",
      "✓ Loaded 105 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.4\n",
      "Davies-Bouldin Index: 0.6\n",
      "Calinski-Harabasz Score: 280.56\n",
      "Silhouette Score: 0.4\n",
      "Davies-Bouldin Index: 0.6\n",
      "Calinski-Harabasz Score: 280.56\n",
      "Select ClusterIDs: [3, 9, 5, 7]\n",
      "Total Number of Customers: 32\n",
      "   cluster   LGA_list                                          LCDA_List  \\\n",
      "0        3  [Ikorodu]  [Ikorodu - Agufoye, Ikorodu - Bayeku, Ikorodu ...   \n",
      "1        9  [Ikorodu]      [Ikorodu - Igbogbo, Ikorodu - Oreyo - Igbe, ]   \n",
      "2        5  [Ikorodu]  [Ikorodu - Offin, Ikorodu - Igbogbo, Ikorodu -...   \n",
      "3        7  [Ikorodu]  [Ikorodu - Agufoye, Ikorodu - Oreyo - Igbe, Ik...   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0         11       334           27.219785  \n",
      "1          5       169           27.150000  \n",
      "2          9       220           24.996167  \n",
      "3          7       211           24.612131  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 3 (12 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 51.34 km, Duration: 55.32 min\n",
      "  Calculating route for Trip ID: 5 (10 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 65.86 km, Duration: 80.90 min\n",
      "  Calculating route for Trip ID: 7 (8 waypoints)...\n",
      "  Trip ID 7 calculated. Distance: 75.93 km, Duration: 96.33 min\n",
      "  Calculating route for Trip ID: 9 (6 waypoints)...\n",
      "  Trip ID 9 calculated. Distance: 45.50 km, Duration: 47.18 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647377.html\n",
      "29/72 \n",
      "Stock Point ID: 1647387 || Stock Point Name: OmniHub Ogba/Egbema Ndoni Rivers - Nest-Och\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ogba/Egbema Ndoni Rivers - Nest-Och, StockPointID: 1647387,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 3,086\n",
      "Total Quantity: 2,578\n",
      "Total Number of Customers before filter: 154\n",
      "Total Number of Customers: 122\n",
      "✓ Loaded 740 SKU recommendations\n",
      "✓ Loaded 122 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.66\n",
      "Davies-Bouldin Index: 0.43\n",
      "Calinski-Harabasz Score: 20392.81\n",
      "Silhouette Score: 0.66\n",
      "Davies-Bouldin Index: 0.43\n",
      "Calinski-Harabasz Score: 20392.81\n",
      "Select ClusterIDs: [4, 6, 2, 5]\n",
      "Total Number of Customers: 51\n",
      "   cluster             LGA_list                LCDA_List  ncustomer  totalQty  \\\n",
      "0        4  [Ogba/Egbema Ndoni]                [Omoku, ]         10       255   \n",
      "1        6  [Ogba/Egbema Ndoni]  [Omoku, Obosi, , Ndoni]          9       214   \n",
      "2        2  [Ogba/Egbema Ndoni]       [Omoku, , Usomini]         23       568   \n",
      "3        5  [Ogba/Egbema Ndoni]                  [Omoku]          9       233   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           47.968289  \n",
      "1           46.958361  \n",
      "2           42.980621  \n",
      "3           39.897761  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 2 (24 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 2.08 km, Duration: 2.50 min\n",
      "  Calculating route for Trip ID: 4 (11 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 2.22 km, Duration: 2.82 min\n",
      "  Calculating route for Trip ID: 5 (10 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 11.15 km, Duration: 14.48 min\n",
      "  Calculating route for Trip ID: 6 (10 waypoints)...\n",
      "  Trip ID 6 calculated. Distance: 12.90 km, Duration: 21.63 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647387.html\n",
      "Unable to generate route mapping using orc: Cannot save file into a non-existent directory: 'recommendation_output/2025-06-28/OmniHub Ogba'\n",
      "30/72 \n",
      "Stock Point ID: 1647062 || Stock Point Name: OmniHub Kosofe Lagos - KOLF \n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Kosofe Lagos - KOLF , StockPointID: 1647062,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 6,925\n",
      "Total Quantity: 4,150\n",
      "Total Number of Customers before filter: 225\n",
      "Total Number of Customers: 132\n",
      "✓ Loaded 1235 SKU recommendations\n",
      "✓ Loaded 132 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.47\n",
      "Davies-Bouldin Index: 0.56\n",
      "Calinski-Harabasz Score: 15093.14\n",
      "Silhouette Score: 0.47\n",
      "Davies-Bouldin Index: 0.56\n",
      "Calinski-Harabasz Score: 15093.14\n",
      "Select ClusterIDs: [6, 3, 4, 2]\n",
      "Total Number of Customers: 74\n",
      "   cluster  LGA_list                                          LCDA_List  \\\n",
      "0        6  [Kosofe]   [, Kosofe - Mile 12, Kosofe - Ketu - Ikosi Road]   \n",
      "1        3  [Kosofe]  [, Kosofe - Mile 12, Kosofe - Ketu - Alapere, ...   \n",
      "2        4  [Kosofe]  [Kosofe - Oworonshoki, , Kosofe - Ketu - Demurin]   \n",
      "3        2  [Kosofe]  [, Kosofe - Ketu - Demurin, Kosofe - Ketu - Ti...   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0         12       410           55.523390  \n",
      "1         20       582           54.229560  \n",
      "2         19       646           51.237234  \n",
      "3         23       710           47.408804  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 2 (24 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 43.80 km, Duration: 64.25 min\n",
      "  Calculating route for Trip ID: 3 (21 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 43.99 km, Duration: 59.78 min\n",
      "  Calculating route for Trip ID: 4 (20 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 51.91 km, Duration: 60.62 min\n",
      "  Calculating route for Trip ID: 6 (13 waypoints)...\n",
      "  Trip ID 6 calculated. Distance: 14.30 km, Duration: 23.82 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647062.html\n",
      "31/72 \n",
      "Stock Point ID: 1647381 || Stock Point Name: OmniHub Ado Odo/Ota Ogun - Sam-Samron\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ado Odo/Ota Ogun - Sam-Samron, StockPointID: 1647381,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 64\n",
      "Total Quantity: 57\n",
      "Total Number of Customers before filter: 5\n",
      "Total Number of Customers: 4\n",
      "32/72 \n",
      "Stock Point ID: 1647345 || Stock Point Name: OmniHub Alimosho Lagos - Barka Agro Mix\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Alimosho Lagos - Barka Agro Mix, StockPointID: 1647345,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 3,539\n",
      "Total Quantity: 2,452\n",
      "Total Number of Customers before filter: 163\n",
      "Total Number of Customers: 115\n",
      "✓ Loaded 763 SKU recommendations\n",
      "✓ Loaded 115 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.26\n",
      "Davies-Bouldin Index: 0.66\n",
      "Calinski-Harabasz Score: 3316.85\n",
      "Silhouette Score: 0.26\n",
      "Davies-Bouldin Index: 0.66\n",
      "Calinski-Harabasz Score: 3316.85\n",
      "Select ClusterIDs: [2, 3, 4, 1]\n",
      "Total Number of Customers: 74\n",
      "   cluster      LGA_list                                          LCDA_List  \\\n",
      "0        2    [Alimosho]           [Alimosho - Ijegun, Alimosho - Ikotun, ]   \n",
      "1        3    [Alimosho]  [Alimosho - Ikotun, Alimosho - Ejigbo-isheri O...   \n",
      "2        4    [Alimosho]  [Alimosho - Ejigbo-nnpc Road, Alimosho - Idimu...   \n",
      "3        1  [Alimosho, ]  [Alimosho - Ejigbo-ijegun, Alimosho - Ijegun, ...   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0         20       422           40.089104  \n",
      "1         19       502           39.968658  \n",
      "2          9       191           39.089167  \n",
      "3         26       445           34.496667  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (27 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 77.59 km, Duration: 195.05 min\n",
      "  Calculating route for Trip ID: 2 (21 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 62.84 km, Duration: 187.02 min\n",
      "  Calculating route for Trip ID: 3 (20 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 63.22 km, Duration: 131.33 min\n",
      "  Calculating route for Trip ID: 4 (10 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 52.99 km, Duration: 101.85 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647345.html\n",
      "33/72 \n",
      "Stock Point ID: 1647376 || Stock Point Name: OmniHub Ijebu Ode Ogun - WCG\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ijebu Ode Ogun - WCG, StockPointID: 1647376,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "34/72 \n",
      "Stock Point ID: 1647353 || Stock Point Name: OmniHub Yenagoa Bayelsa - Schist & Scoria\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Yenagoa Bayelsa - Schist & Scoria, StockPointID: 1647353,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 658\n",
      "Total Quantity: 390\n",
      "Total Number of Customers before filter: 82\n",
      "Total Number of Customers: 52\n",
      "✓ Loaded 88 SKU recommendations\n",
      "✓ Loaded 52 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.55\n",
      "Davies-Bouldin Index: 0.46\n",
      "Calinski-Harabasz Score: 312.09\n",
      "Silhouette Score: 0.55\n",
      "Davies-Bouldin Index: 0.46\n",
      "Calinski-Harabasz Score: 312.09\n",
      "Select ClusterIDs: [1, 4, 3, 2]\n",
      "Total Number of Customers: 48\n",
      "   cluster   LGA_list                                          LCDA_List  \\\n",
      "0        1  [Yenagoa]  [Amarata, Ovelemini, Kpansia, Azikoro, Omom, E...   \n",
      "1        4  [Yenagoa]                  [Tombia, Agudama-Epie, Ovelemini]   \n",
      "2        3  [Yenagoa]          [Opolo, Anyamabele, Epie, Kpansia, Ekeki]   \n",
      "3        2  [Yenagoa]                     [Tombia, Ekeki, Epie, Azikoro]   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0         25       208           36.189333  \n",
      "1          5        42           34.059000  \n",
      "2          9        63           31.902143  \n",
      "3          9        45           23.697273  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (26 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 32.96 km, Duration: 44.65 min\n",
      "  Calculating route for Trip ID: 2 (10 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 14.78 km, Duration: 22.60 min\n",
      "  Calculating route for Trip ID: 3 (10 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 37.10 km, Duration: 38.78 min\n",
      "  Calculating route for Trip ID: 4 (6 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 16.91 km, Duration: 20.12 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647353.html\n",
      "35/72 \n",
      "Stock Point ID: 1647347 || Stock Point Name: OmniHub Ikorodu Lagos - Pleck\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ikorodu Lagos - Pleck, StockPointID: 1647347,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 7,137\n",
      "Total Quantity: 4,007\n",
      "Total Number of Customers before filter: 249\n",
      "Total Number of Customers: 137\n",
      "✓ Loaded 1047 SKU recommendations\n",
      "✓ Loaded 137 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.58\n",
      "Davies-Bouldin Index: 0.58\n",
      "Calinski-Harabasz Score: 2493.95\n",
      "Silhouette Score: 0.58\n",
      "Davies-Bouldin Index: 0.58\n",
      "Calinski-Harabasz Score: 2493.95\n",
      "Select ClusterIDs: [2, 4, 6, 1]\n",
      "Total Number of Customers: 73\n",
      "   cluster   LGA_list                                          LCDA_List  \\\n",
      "0        2  [Ikorodu]            [Ikorodu - Gberigbe, , Ikorodu - Adamo]   \n",
      "1        4  [Ikorodu]  [Ikorodu - Elepe, , Ikorodu - Adamo, Ikorodu -...   \n",
      "2        6  [Ikorodu]                                [Ikorodu - Adamo, ]   \n",
      "3        1  [Ikorodu]  [, Ikorodu - Itamaga, Ikorodu - Elepe, Ikorodu...   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0         20       541           37.591088  \n",
      "1         12       370           37.282424  \n",
      "2         12       331           35.136265  \n",
      "3         29       936           31.910245  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (30 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 48.60 km, Duration: 79.88 min\n",
      "  Calculating route for Trip ID: 2 (21 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 48.73 km, Duration: 64.62 min\n",
      "  Calculating route for Trip ID: 4 (13 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 35.95 km, Duration: 54.13 min\n",
      "  Calculating route for Trip ID: 6 (13 waypoints)...\n",
      "  Trip ID 6 calculated. Distance: 32.21 km, Duration: 47.23 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647347.html\n",
      "36/72 \n",
      "Stock Point ID: 1647341 || Stock Point Name: OmniHub AMAC 3 Nasarawa - Utmaab Kurudu\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub AMAC 3 Nasarawa - Utmaab Kurudu, StockPointID: 1647341,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 3,554\n",
      "Total Quantity: 2,060\n",
      "Total Number of Customers before filter: 253\n",
      "Total Number of Customers: 139\n",
      "✓ Loaded 711 SKU recommendations\n",
      "✓ Loaded 139 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.71\n",
      "Davies-Bouldin Index: 0.4\n",
      "Calinski-Harabasz Score: 938.05\n",
      "Silhouette Score: 0.71\n",
      "Davies-Bouldin Index: 0.4\n",
      "Calinski-Harabasz Score: 938.05\n",
      "Select ClusterIDs: [9, 2, 7, 5]\n",
      "Total Number of Customers: 42\n",
      "   cluster          LGA_list            LCDA_List  ncustomer  totalQty  \\\n",
      "0        9          [AMAC 3]           [Karshi, ]          6       104   \n",
      "1        2          [AMAC 3]       [Nyanya, Karu]         14       221   \n",
      "2        7          [AMAC 3]  [Jikwoyi, , Kurudu]         10       150   \n",
      "3        5  [AMAC 3, AMAC 2]    [Karu, , Jikwoyi]         12       172   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           48.845676  \n",
      "1           40.119333  \n",
      "2           39.733137  \n",
      "3           35.886825  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 2 (15 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 23.48 km, Duration: 21.60 min\n",
      "  Calculating route for Trip ID: 5 (13 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 29.75 km, Duration: 42.07 min\n",
      "  Calculating route for Trip ID: 7 (11 waypoints)...\n",
      "  Trip ID 7 calculated. Distance: 23.67 km, Duration: 27.08 min\n",
      "  Calculating route for Trip ID: 9 (7 waypoints)...\n",
      "  Trip ID 9 calculated. Distance: 18.60 km, Duration: 18.68 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647341.html\n",
      "37/72 \n",
      "Stock Point ID: 1647350 || Stock Point Name: OmniHub OBI AKPOR Rivers - CHARRYSWIFT\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub OBI AKPOR Rivers - CHARRYSWIFT, StockPointID: 1647350,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 18,475\n",
      "Total Quantity: 12,284\n",
      "Total Number of Customers before filter: 512\n",
      "Total Number of Customers: 335\n",
      "✓ Loaded 3162 SKU recommendations\n",
      "✓ Loaded 335 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.54\n",
      "Davies-Bouldin Index: 0.55\n",
      "Calinski-Harabasz Score: 1376.06\n",
      "Silhouette Score: 0.54\n",
      "Davies-Bouldin Index: 0.55\n",
      "Calinski-Harabasz Score: 1376.06\n",
      "Select ClusterIDs: [17, 12, 6, 19]\n",
      "Total Number of Customers: 47\n",
      "   cluster                     LGA_list                   LCDA_List  \\\n",
      "0       17        [Obio Akpor, Ikwerre]     [Choba, , Aluu, Ozuoba]   \n",
      "1       12  [Obio Akpor, Port Harcourt]      [Rumuolumeni, Diobu, ]   \n",
      "2        6                 [Obio Akpor]  [Rumuolumeni, Mgbuosimini]   \n",
      "3       19                 [Obio Akpor]               [Rumuolumeni]   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0          8       294           53.216250  \n",
      "1         13       482           52.875285  \n",
      "2         19       770           52.200215  \n",
      "3          7       264           51.120000  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 6 (20 waypoints)...\n",
      "  Trip ID 6 calculated. Distance: 17.67 km, Duration: 29.85 min\n",
      "  Calculating route for Trip ID: 12 (14 waypoints)...\n",
      "  Trip ID 12 calculated. Distance: 46.30 km, Duration: 66.45 min\n",
      "  Calculating route for Trip ID: 17 (9 waypoints)...\n",
      "  Trip ID 17 calculated. Distance: 81.66 km, Duration: 118.53 min\n",
      "  Calculating route for Trip ID: 19 (8 waypoints)...\n",
      "  Trip ID 19 calculated. Distance: 14.86 km, Duration: 23.82 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647350.html\n",
      "38/72 \n",
      "Stock Point ID: 1647125 || Stock Point Name: OmniHub Ikorodu Lagos - Mofaz\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ikorodu Lagos - Mofaz, StockPointID: 1647125,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 15,007\n",
      "Total Quantity: 8,578\n",
      "Total Number of Customers before filter: 560\n",
      "Total Number of Customers: 334\n",
      "✓ Loaded 2324 SKU recommendations\n",
      "✓ Loaded 334 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.27\n",
      "Davies-Bouldin Index: 0.7\n",
      "Calinski-Harabasz Score: 244.66\n",
      "Silhouette Score: 0.27\n",
      "Davies-Bouldin Index: 0.7\n",
      "Calinski-Harabasz Score: 244.66\n",
      "Select ClusterIDs: [6, 8, 11, 13]\n",
      "Total Number of Customers: 60\n",
      "   cluster   LGA_list                                          LCDA_List  \\\n",
      "0        6  [Ikorodu]  [Ikorodu - Ogolonto, Ikorodu - Agric, , Ikorod...   \n",
      "1        8  [Ikorodu]  [Ikorodu - Eyita, Ikorodu - Isawo, Ikorodu - A...   \n",
      "2       11  [Ikorodu]  [Ikorodu - Agric, , Ikorodu - Eyita, Ikorodu -...   \n",
      "3       13  [Ikorodu]  [Ikorodu - Sabo, Ikorodu - Eyita, Ikorodu - Ag...   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0         20       484           55.678485  \n",
      "1         17       400           53.612661  \n",
      "2         14       292           49.648974  \n",
      "3          9       240           48.069194  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 6 (21 waypoints)...\n",
      "  Trip ID 6 calculated. Distance: 43.10 km, Duration: 48.58 min\n",
      "  Calculating route for Trip ID: 8 (18 waypoints)...\n",
      "  Trip ID 8 calculated. Distance: 32.89 km, Duration: 47.12 min\n",
      "  Calculating route for Trip ID: 11 (15 waypoints)...\n",
      "  Trip ID 11 calculated. Distance: 30.33 km, Duration: 43.10 min\n",
      "  Calculating route for Trip ID: 13 (10 waypoints)...\n",
      "  Trip ID 13 calculated. Distance: 20.39 km, Duration: 30.87 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647125.html\n",
      "39/72 \n",
      "Stock Point ID: 1647120 || Stock Point Name: OmniHub Surulere Lagos - Jimoh Odutola\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Surulere Lagos - Jimoh Odutola, StockPointID: 1647120,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "40/72 \n",
      "Stock Point ID: 1647122 || Stock Point Name: OmniHub Egbeda Oyo - Vizazi\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Egbeda Oyo - Vizazi, StockPointID: 1647122,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 9,400\n",
      "Total Quantity: 5,524\n",
      "Total Number of Customers before filter: 340\n",
      "Total Number of Customers: 202\n",
      "✓ Loaded 1479 SKU recommendations\n",
      "✓ Loaded 202 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.57\n",
      "Davies-Bouldin Index: 0.41\n",
      "Calinski-Harabasz Score: 17199.69\n",
      "Silhouette Score: 0.57\n",
      "Davies-Bouldin Index: 0.41\n",
      "Calinski-Harabasz Score: 17199.69\n",
      "Select ClusterIDs: [8, 1, 3, 7]\n",
      "Total Number of Customers: 67\n",
      "   cluster                                      LGA_list  \\\n",
      "0        8                                      [Egbeda]   \n",
      "1        1                     [Egbeda, Oluyole, Ibadan]   \n",
      "2        3                             [Egbeda, Ona Ara]   \n",
      "3        7  [Egbeda, Ibadan North East, Ibadan, Ona Ara]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0          [IBADAN-NEW GBAGI MARKET, Old Ife Road, ]          9       280   \n",
      "1  [IBADAN-NEW GBAGI MARKET, Old Ife Road, Iwo Ro...         27       835   \n",
      "2  [IBADAN-NEW GBAGI MARKET, IBADAN-ALAKIA, Olodo...         21       734   \n",
      "3               [Olodo, , Olorunsogo, Olunloyo, no6]         10       275   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           45.992667  \n",
      "1           44.174749  \n",
      "2           42.730867  \n",
      "3           39.163553  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (28 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 11.87 km, Duration: 21.87 min\n",
      "  Calculating route for Trip ID: 3 (22 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 45.94 km, Duration: 63.63 min\n",
      "  Calculating route for Trip ID: 7 (11 waypoints)...\n",
      "  Trip ID 7 calculated. Distance: 23.00 km, Duration: 31.42 min\n",
      "  Calculating route for Trip ID: 8 (10 waypoints)...\n",
      "  Trip ID 8 calculated. Distance: 11.40 km, Duration: 13.92 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647122.html\n",
      "41/72 \n",
      "Stock Point ID: 1647112 || Stock Point Name: OmniHub Lagos - OmniHub Eti Osa Lagos - Jimbass\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Lagos - OmniHub Eti Osa Lagos - Jimbass, StockPointID: 1647112,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "42/72 \n",
      "Stock Point ID: 1647113 || Stock Point Name: OmniHub Apapa Lagos - CAUSEWAY\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Apapa Lagos - CAUSEWAY, StockPointID: 1647113,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 29,872\n",
      "Total Quantity: 18,310\n",
      "Total Number of Customers before filter: 1,063\n",
      "Total Number of Customers: 652\n",
      "✓ Loaded 5484 SKU recommendations\n",
      "✓ Loaded 652 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.34\n",
      "Davies-Bouldin Index: 0.69\n",
      "Calinski-Harabasz Score: 36835.96\n",
      "Silhouette Score: 0.34\n",
      "Davies-Bouldin Index: 0.69\n",
      "Calinski-Harabasz Score: 36835.96\n",
      "Select ClusterIDs: [21, 10, 13, 29]\n",
      "Total Number of Customers: 74\n",
      "   cluster                          LGA_list  \\\n",
      "0       21        [Mushin, Ajeromi Ifelodun]   \n",
      "1       10                          [Mushin]   \n",
      "2       13         [Ajeromi Ifelodun, Apapa]   \n",
      "3       29  [Mushin, Surulere, Lagos Island]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [Mushin - Mushin Market, Mushin - Isolo Road, ...         17       585   \n",
      "1  [Mushin - Mushin Market, , Mushin - Idi Oro, M...         24       736   \n",
      "2  [, Ajeromi Ifelodun - Olodi, Ajeromi Ifelodun ...         23       695   \n",
      "3  [Mushin - Mushin Market, , Lagos Island - Sura...         10       286   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           55.519212  \n",
      "1           55.256746  \n",
      "2           54.211429  \n",
      "3           51.597160  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 10 (25 waypoints)...\n",
      "  Trip ID 10 calculated. Distance: 13.31 km, Duration: 28.13 min\n",
      "  Calculating route for Trip ID: 13 (24 waypoints)...\n",
      "  Trip ID 13 calculated. Distance: 27.23 km, Duration: 71.82 min\n",
      "  Calculating route for Trip ID: 21 (18 waypoints)...\n",
      "  Trip ID 21 calculated. Distance: 18.93 km, Duration: 36.47 min\n",
      "  Calculating route for Trip ID: 29 (11 waypoints)...\n",
      "  Trip ID 29 calculated. Distance: 12.73 km, Duration: 25.07 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647113.html\n",
      "43/72 \n",
      "Stock Point ID: 1647132 || Stock Point Name: OmniHub Ibadan North Oyo - Eby 99\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ibadan North Oyo - Eby 99, StockPointID: 1647132,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 5,269\n",
      "Total Quantity: 3,093\n",
      "Total Number of Customers before filter: 243\n",
      "Total Number of Customers: 144\n",
      "✓ Loaded 832 SKU recommendations\n",
      "✓ Loaded 144 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.53\n",
      "Davies-Bouldin Index: 0.54\n",
      "Calinski-Harabasz Score: 1176.93\n",
      "Silhouette Score: 0.53\n",
      "Davies-Bouldin Index: 0.54\n",
      "Calinski-Harabasz Score: 1176.93\n",
      "Select ClusterIDs: [9, 8, 1, 3]\n",
      "Total Number of Customers: 55\n",
      "   cluster                                          LGA_list  \\\n",
      "0        9                               [Ibadan North, Ido]   \n",
      "1        8                     [Ido, Ibadan North, Akinyele]   \n",
      "2        1  [Ibadan North, Ibadan North West, Akinyele, Ido]   \n",
      "3        3            [Ido, Ibadan North, Akinyele, Oluyole]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0                             [, Apete, Poly Ibadan]          7       165   \n",
      "1            [Apete, , Bodija, Sango, Eleyele, Ojoo]          7       172   \n",
      "2  [, 3, Bodija, Poly Ibadan, Ibadan-UI, Ui, IBAD...         23       557   \n",
      "3           [Apete, Poly Ibadan, Ojoo, , IBADAN-7UP]         18       401   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           44.764889  \n",
      "1           44.112766  \n",
      "2           41.196528  \n",
      "3           38.840090  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (24 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 57.06 km, Duration: 74.43 min\n",
      "  Calculating route for Trip ID: 3 (19 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 24.10 km, Duration: 30.25 min\n",
      "  Calculating route for Trip ID: 8 (8 waypoints)...\n",
      "  Trip ID 8 calculated. Distance: 122.88 km, Duration: 110.02 min\n",
      "  Calculating route for Trip ID: 9 (8 waypoints)...\n",
      "  Trip ID 9 calculated. Distance: 15.90 km, Duration: 21.65 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647132.html\n",
      "44/72 \n",
      "Stock Point ID: 1647124 || Stock Point Name: OmniHub Ibadan South West Oyo - Cemalon\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ibadan South West Oyo - Cemalon, StockPointID: 1647124,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 2,739\n",
      "Total Quantity: 1,354\n",
      "Total Number of Customers before filter: 136\n",
      "Total Number of Customers: 73\n",
      "✓ Loaded 348 SKU recommendations\n",
      "✓ Loaded 73 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.6\n",
      "Davies-Bouldin Index: 0.39\n",
      "Calinski-Harabasz Score: 1304.01\n",
      "Silhouette Score: 0.6\n",
      "Davies-Bouldin Index: 0.39\n",
      "Calinski-Harabasz Score: 1304.01\n",
      "Select ClusterIDs: [2, 4, 3, 1]\n",
      "Total Number of Customers: 58\n",
      "   cluster                                LGA_list  \\\n",
      "0        2                     [Ibadan South West]   \n",
      "1        4            [Ibadan South West, Oluyole]   \n",
      "2        3            [Ibadan South West, Oluyole]   \n",
      "3        1  [Ibadan North West, Ibadan South West]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0                        [Agbeni, Molete, , Oke Ado]         15       360   \n",
      "1           [Agbeni, IBADAN-ODO-ONA ELEWE, , Molete]          6        97   \n",
      "2  [Oluyole Estreet, IBADAN-TIPPER GARAGE, IBADAN...          7       105   \n",
      "3     [, Agbeni, IBADAN-DUGBE, Oke Ado, Orita Merin]         30       451   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           38.429438  \n",
      "1           31.492692  \n",
      "2           26.359118  \n",
      "3           23.133125  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (31 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 23.37 km, Duration: 36.93 min\n",
      "  Calculating route for Trip ID: 2 (16 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 28.62 km, Duration: 37.15 min\n",
      "  Calculating route for Trip ID: 3 (8 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 18.47 km, Duration: 32.20 min\n",
      "  Calculating route for Trip ID: 4 (7 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 21.73 km, Duration: 25.07 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647124.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Dataframe is empty\n",
      "INFO:__main__:Trip Data is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/72 \n",
      "Stock Point ID: 1647380 || Stock Point Name: OmniHub Owerri Municipal Imo - Bonaventure \n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Owerri Municipal Imo - Bonaventure , StockPointID: 1647380,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 205\n",
      "Total Quantity: 67\n",
      "Total Number of Customers before filter: 18\n",
      "Total Number of Customers: 8\n",
      "✓ Loaded 14 SKU recommendations\n",
      "✓ Loaded 8 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.42\n",
      "Davies-Bouldin Index: 0.31\n",
      "Calinski-Harabasz Score: 55.48\n",
      "Silhouette Score: 0.42\n",
      "Davies-Bouldin Index: 0.31\n",
      "Calinski-Harabasz Score: 55.48\n",
      "Select ClusterIDs: []\n",
      "Total Number of Customers: 0\n",
      "Empty DataFrame\n",
      "Columns: [cluster, LGA_list, LCDA_List, ncustomer, totalQty, avg_customer_score]\n",
      "Index: []\n",
      "46/72 \n",
      "Stock Point ID: 1647126 || Stock Point Name: OmniHub Sagamu Ogun - Ajaka\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Sagamu Ogun - Ajaka, StockPointID: 1647126,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 78\n",
      "Total Quantity: 50\n",
      "Total Number of Customers before filter: 2\n",
      "Total Number of Customers: 1\n",
      "47/72 \n",
      "Stock Point ID: 1647109 || Stock Point Name: OmniHub Oluyole Oyo - Techcomserve\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Oluyole Oyo - Techcomserve, StockPointID: 1647109,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 302\n",
      "Total Quantity: 277\n",
      "Total Number of Customers before filter: 22\n",
      "Total Number of Customers: 19\n",
      "✓ Loaded 77 SKU recommendations\n",
      "✓ Loaded 19 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.31\n",
      "Davies-Bouldin Index: 0.42\n",
      "Calinski-Harabasz Score: 613.95\n",
      "Silhouette Score: 0.31\n",
      "Davies-Bouldin Index: 0.42\n",
      "Calinski-Harabasz Score: 613.95\n",
      "Select ClusterIDs: [1]\n",
      "Total Number of Customers: 10\n",
      "   cluster                      LGA_list  \\\n",
      "0        1  [Oluyole, Ibadan South West]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [IBADAN-OLUYOLE, Orita Challenge, Ososami, IBA...         10       139   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           37.329524  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (11 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 39.43 km, Duration: 58.72 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647109.html\n",
      "48/72 \n",
      "Stock Point ID: 1647371 || Stock Point Name: OmniHub Alimosho Lagos - Demadek\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Alimosho Lagos - Demadek, StockPointID: 1647371,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 1,229\n",
      "Total Quantity: 797\n",
      "Total Number of Customers before filter: 64\n",
      "Total Number of Customers: 39\n",
      "✓ Loaded 242 SKU recommendations\n",
      "✓ Loaded 39 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.29\n",
      "Davies-Bouldin Index: 0.66\n",
      "Calinski-Harabasz Score: 29161.75\n",
      "Silhouette Score: 0.29\n",
      "Davies-Bouldin Index: 0.66\n",
      "Calinski-Harabasz Score: 29161.75\n",
      "Select ClusterIDs: [3, 1, 4, 2]\n",
      "Total Number of Customers: 32\n",
      "   cluster    LGA_list              LCDA_List  ncustomer  totalQty  \\\n",
      "0        3  [Alimosho]  [Alimosho - Igando, ]          7       150   \n",
      "1        1  [Alimosho]  [, Alimosho - Igando]         12       226   \n",
      "2        4  [Alimosho]  [Alimosho - Igando, ]          5       101   \n",
      "3        2  [Alimosho]  [, Alimosho - Igando]          8       195   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           30.869583  \n",
      "1           30.575294  \n",
      "2           19.697813  \n",
      "3           18.048727  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (13 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 44.29 km, Duration: 100.62 min\n",
      "  Calculating route for Trip ID: 2 (9 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 42.26 km, Duration: 88.83 min\n",
      "  Calculating route for Trip ID: 3 (8 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 17.33 km, Duration: 45.05 min\n",
      "  Calculating route for Trip ID: 4 (6 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 28.48 km, Duration: 47.12 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647371.html\n",
      "49/72 \n",
      "Stock Point ID: 1647131 || Stock Point Name: OmniHub Alimosho Lagos - Pafeak\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Alimosho Lagos - Pafeak, StockPointID: 1647131,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 4,358\n",
      "Total Quantity: 2,545\n",
      "Total Number of Customers before filter: 170\n",
      "Total Number of Customers: 95\n",
      "✓ Loaded 830 SKU recommendations\n",
      "✓ Loaded 95 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.44\n",
      "Davies-Bouldin Index: 0.61\n",
      "Calinski-Harabasz Score: 176.88\n",
      "Silhouette Score: 0.44\n",
      "Davies-Bouldin Index: 0.61\n",
      "Calinski-Harabasz Score: 176.88\n",
      "Select ClusterIDs: [3, 1, 2, 4]\n",
      "Total Number of Customers: 63\n",
      "   cluster                  LGA_list  \\\n",
      "0        3  [Alimosho, Ifako Ijaiye]   \n",
      "1        1                [Alimosho]   \n",
      "2        2                [Alimosho]   \n",
      "3        4                [Alimosho]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [, Alimosho - Abule Egba (agbado Ijaye Road), ...         10       302   \n",
      "1  [Alimosho - Abule Egba (ekoro Road), Alimosho ...         25       641   \n",
      "2  [, Alimosho - Abule Egba (meiran Road), Alimos...         18       471   \n",
      "3      [Alimosho - Abule Egba (agbado Ijaye Road), ]         10       266   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           52.656444  \n",
      "1           46.705587  \n",
      "2           46.125321  \n",
      "3           44.772235  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (26 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 58.09 km, Duration: 96.47 min\n",
      "  Calculating route for Trip ID: 2 (19 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 38.87 km, Duration: 56.23 min\n",
      "  Calculating route for Trip ID: 3 (11 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 24.74 km, Duration: 62.17 min\n",
      "  Calculating route for Trip ID: 4 (11 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 8.90 km, Duration: 29.45 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647131.html\n",
      "50/72 \n",
      "Stock Point ID: 1647110 || Stock Point Name: OmniHub Ado Odo/Ota Ogun - Hardej\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ado Odo/Ota Ogun - Hardej, StockPointID: 1647110,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 1,467\n",
      "Total Quantity: 1,053\n",
      "Total Number of Customers before filter: 104\n",
      "Total Number of Customers: 72\n",
      "✓ Loaded 255 SKU recommendations\n",
      "✓ Loaded 72 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.36\n",
      "Davies-Bouldin Index: 0.35\n",
      "Calinski-Harabasz Score: 11879.39\n",
      "Silhouette Score: 0.36\n",
      "Davies-Bouldin Index: 0.35\n",
      "Calinski-Harabasz Score: 11879.39\n",
      "Select ClusterIDs: [5, 3, 1, 4]\n",
      "Total Number of Customers: 37\n",
      "   cluster       LGA_list             LCDA_List  ncustomer  totalQty  \\\n",
      "0        5  [Ado Odo/Ota]      [Sango-Ota, Ota]          5        71   \n",
      "1        3  [Ado Odo/Ota]  [Sango-Ota, , Sango]          7       112   \n",
      "2        1  [Ado Odo/Ota]    [Ota, Sango-Ota, ]         19       300   \n",
      "3        4  [Ado Odo/Ota]  [Sango, Sango-Ota, ]          6        83   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           58.892941  \n",
      "1           47.305000  \n",
      "2           43.717273  \n",
      "3           38.668095  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (20 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 60.32 km, Duration: 104.75 min\n",
      "  Calculating route for Trip ID: 3 (8 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 21.94 km, Duration: 47.75 min\n",
      "  Calculating route for Trip ID: 4 (7 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 17.15 km, Duration: 31.73 min\n",
      "  Calculating route for Trip ID: 5 (6 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 25.45 km, Duration: 47.12 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647110.html\n",
      "Unable to generate route mapping using orc: Cannot save file into a non-existent directory: 'recommendation_output/2025-06-28/OmniHub Ado Odo'\n",
      "51/72 \n",
      "Stock Point ID: 1647137 || Stock Point Name: OmniHub Shomolu Lagos - Autograph\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Shomolu Lagos - Autograph, StockPointID: 1647137,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 12,022\n",
      "Total Quantity: 7,674\n",
      "Total Number of Customers before filter: 460\n",
      "Total Number of Customers: 286\n",
      "✓ Loaded 2481 SKU recommendations\n",
      "✓ Loaded 286 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.3\n",
      "Davies-Bouldin Index: 0.73\n",
      "Calinski-Harabasz Score: 7047.07\n",
      "Silhouette Score: 0.3\n",
      "Davies-Bouldin Index: 0.73\n",
      "Calinski-Harabasz Score: 7047.07\n",
      "Select ClusterIDs: [16, 14, 3, 4]\n",
      "Total Number of Customers: 63\n",
      "   cluster                   LGA_list  \\\n",
      "0       16                  [Shomolu]   \n",
      "1       14  [Shomolu, Lagos Mainland]   \n",
      "2        3           [Lagos Mainland]   \n",
      "3        4           [Lagos Mainland]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0         [Shomolu - Bariga, Shomolu - Ilaje Bariga]          5       104   \n",
      "1  [Shomolu - Bariga, Shomolu - Bashua, Lagos Mai...          7       163   \n",
      "2  [Lagos Mainland - Yaba - Oyingbo, Lagos Mainla...         26       718   \n",
      "3  [Lagos Mainland - Yaba - Adekunle, Lagos Mainl...         25       631   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           52.464000  \n",
      "1           45.109200  \n",
      "2           43.083915  \n",
      "3           41.450817  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 3 (27 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 109.40 km, Duration: 183.55 min\n",
      "  Calculating route for Trip ID: 4 (26 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 38.81 km, Duration: 55.72 min\n",
      "  Calculating route for Trip ID: 14 (8 waypoints)...\n",
      "  Trip ID 14 calculated. Distance: 9.42 km, Duration: 25.50 min\n",
      "  Calculating route for Trip ID: 16 (6 waypoints)...\n",
      "  Trip ID 16 calculated. Distance: 27.01 km, Duration: 26.72 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647137.html\n",
      "52/72 \n",
      "Stock Point ID: 1647106 || Stock Point Name: OmniHub Ikeja Lagos - Barka-Agro Food Ogba\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ikeja Lagos - Barka-Agro Food Ogba, StockPointID: 1647106,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 2,909\n",
      "Total Quantity: 1,539\n",
      "Total Number of Customers before filter: 194\n",
      "Total Number of Customers: 96\n",
      "✓ Loaded 431 SKU recommendations\n",
      "✓ Loaded 96 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.36\n",
      "Davies-Bouldin Index: 0.61\n",
      "Calinski-Harabasz Score: 17055.88\n",
      "Silhouette Score: 0.36\n",
      "Davies-Bouldin Index: 0.61\n",
      "Calinski-Harabasz Score: 17055.88\n",
      "Select ClusterIDs: [3, 1, 5, 2]\n",
      "Total Number of Customers: 64\n",
      "   cluster               LGA_list  \\\n",
      "0        3  [Ifako Ijaiye, Agege]   \n",
      "1        1  [Ifako Ijaiye, Ikeja]   \n",
      "2        5  [Ifako Ijaiye, Ikeja]   \n",
      "3        2  [Ifako Ijaiye, Agege]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [Ifako Ijaiye - Ogba - Ifako - Idiagbon, , Ifa...         16       316   \n",
      "1  [Agege - Ajuwon Akute Road, Ifako Ijaiye - Ogb...         20       285   \n",
      "2  [Ifako Ijaiye - Ogba - College Road, Ifako Ija...         11       206   \n",
      "3  [, Ifako Ijaiye - Ogba - Oke Ira, Ifako Ijaiye...         17       280   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           55.165889  \n",
      "1           50.857470  \n",
      "2           44.064237  \n",
      "3           38.971711  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (21 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 63.41 km, Duration: 144.20 min\n",
      "  Calculating route for Trip ID: 2 (18 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 34.45 km, Duration: 60.85 min\n",
      "  Calculating route for Trip ID: 3 (17 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 44.34 km, Duration: 101.72 min\n",
      "  Calculating route for Trip ID: 5 (12 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 26.49 km, Duration: 72.67 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647106.html\n",
      "53/72 \n",
      "Stock Point ID: 1647115 || Stock Point Name: OmniHub Lagos - OmniHub Amuwo Odofin Lagos - EMPRESS KOT.\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Lagos - OmniHub Amuwo Odofin Lagos - EMPRESS KOT., StockPointID: 1647115,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "54/72 \n",
      "Stock Point ID: 1647424 || Stock Point Name: OmniHub Obafemi Owode Ogun - Favoured Goodness\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Obafemi Owode Ogun - Favoured Goodness, StockPointID: 1647424,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "55/72 \n",
      "Stock Point ID: 1647127 || Stock Point Name: OmniHub Obio Akpor Rivers - FHS\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Obio Akpor Rivers - FHS, StockPointID: 1647127,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 15,869\n",
      "Total Quantity: 10,926\n",
      "Total Number of Customers before filter: 420\n",
      "Total Number of Customers: 290\n",
      "✓ Loaded 2788 SKU recommendations\n",
      "✓ Loaded 290 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.46\n",
      "Davies-Bouldin Index: 0.61\n",
      "Calinski-Harabasz Score: 21362.93\n",
      "Silhouette Score: 0.46\n",
      "Davies-Bouldin Index: 0.61\n",
      "Calinski-Harabasz Score: 21362.93\n",
      "Select ClusterIDs: [14, 11, 12, 3]\n",
      "Total Number of Customers: 60\n",
      "   cluster      LGA_list                                          LCDA_List  \\\n",
      "0       14  [Obio Akpor]                  [Rumuaghaolu, Nkpelu, , Rumuigbo]   \n",
      "1       11  [Obio Akpor]  [Rumuomasi, Rumuaghaolu, Rumuodomaya, Eliozu, ...   \n",
      "2       12  [Obio Akpor]       [Rumuigbo, , Rumuokoro, Rumuokwuota, Nkpelu]   \n",
      "3        3  [Obio Akpor]  [Rumuodomaya, Rumuokoro, Rumuaghaolu, Rumuigbo...   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0         10       361           52.628889  \n",
      "1         12       436           52.458174  \n",
      "2         12       415           46.532091  \n",
      "3         26      1042           46.200661  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 3 (27 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 91.87 km, Duration: 133.17 min\n",
      "  Calculating route for Trip ID: 11 (13 waypoints)...\n",
      "  Trip ID 11 calculated. Distance: 36.32 km, Duration: 56.78 min\n",
      "  Calculating route for Trip ID: 12 (13 waypoints)...\n",
      "  Trip ID 12 calculated. Distance: 52.83 km, Duration: 80.22 min\n",
      "  Calculating route for Trip ID: 14 (11 waypoints)...\n",
      "  Trip ID 14 calculated. Distance: 28.51 km, Duration: 43.40 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647127.html\n",
      "56/72 \n",
      "Stock Point ID: 1647130 || Stock Point Name: OmniHub Abuja - OmniHub Bwari Abuja - NETLINK\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Abuja - OmniHub Bwari Abuja - NETLINK, StockPointID: 1647130,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 3,162\n",
      "Total Quantity: 1,635\n",
      "Total Number of Customers before filter: 274\n",
      "Total Number of Customers: 125\n",
      "✓ Loaded 508 SKU recommendations\n",
      "✓ Loaded 125 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.56\n",
      "Davies-Bouldin Index: 0.51\n",
      "Calinski-Harabasz Score: 4584.66\n",
      "Silhouette Score: 0.56\n",
      "Davies-Bouldin Index: 0.51\n",
      "Calinski-Harabasz Score: 4584.66\n",
      "Select ClusterIDs: [3, 1, 4, 7]\n",
      "Total Number of Customers: 62\n",
      "   cluster               LGA_list  \\\n",
      "0        3                [Bwari]   \n",
      "1        1  [Bwari, Push - Bwari]   \n",
      "2        4        [Bwari, AMAC 1]   \n",
      "3        7        [Bwari, AMAC 1]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0                     [Dutsen Alhaji, , ABUJA-BWARI]         17       227   \n",
      "1  [Kogo, Dawaki, ABUJA-BWARI, , Kubwa, Dutsen Al...         25       254   \n",
      "2                                 [Kubwa, , Dei Dei]         14       200   \n",
      "3       [Kubwa, , Dei Dei, ABUJA- KUBWA 2/2 PHASE 2]          6        54   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           56.986232  \n",
      "1           41.978462  \n",
      "2           40.951250  \n",
      "3           38.620588  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (26 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 38.28 km, Duration: 57.15 min\n",
      "  Calculating route for Trip ID: 3 (18 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 68.73 km, Duration: 85.08 min\n",
      "  Calculating route for Trip ID: 4 (15 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 35.43 km, Duration: 60.23 min\n",
      "  Calculating route for Trip ID: 7 (7 waypoints)...\n",
      "  Trip ID 7 calculated. Distance: 38.69 km, Duration: 37.07 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647130.html\n",
      "57/72 \n",
      "Stock Point ID: 1647111 || Stock Point Name: OmniHub Bwari Abuja - BAFAL\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Bwari Abuja - BAFAL, StockPointID: 1647111,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 4,169\n",
      "Total Quantity: 1,716\n",
      "Total Number of Customers before filter: 435\n",
      "Total Number of Customers: 184\n",
      "✓ Loaded 537 SKU recommendations\n",
      "✓ Loaded 184 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.61\n",
      "Davies-Bouldin Index: 0.58\n",
      "Calinski-Harabasz Score: 1987.2\n",
      "Silhouette Score: 0.61\n",
      "Davies-Bouldin Index: 0.58\n",
      "Calinski-Harabasz Score: 1987.2\n",
      "Select ClusterIDs: [12, 4, 13, 3]\n",
      "Total Number of Customers: 37\n",
      "   cluster         LGA_list        LCDA_List  ncustomer  totalQty  \\\n",
      "0       12  [AMAC 1, Bwari]  [Jabi, Katampe]          5        57   \n",
      "1        4         [AMAC 1]    [Jabi, Idu, ]         13       138   \n",
      "2       13         [AMAC 1]      [, Dei Dei]          5        40   \n",
      "3        3         [AMAC 1]            [Idu]         14       114   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           47.972000  \n",
      "1           46.511489  \n",
      "2           42.370000  \n",
      "3           38.738750  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 3 (15 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 50.24 km, Duration: 58.72 min\n",
      "  Calculating route for Trip ID: 4 (14 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 51.90 km, Duration: 59.82 min\n",
      "  Calculating route for Trip ID: 12 (6 waypoints)...\n",
      "  Trip ID 12 calculated. Distance: 51.53 km, Duration: 50.30 min\n",
      "  Calculating route for Trip ID: 13 (6 waypoints)...\n",
      "  Trip ID 13 calculated. Distance: 43.74 km, Duration: 36.70 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647111.html\n",
      "58/72 \n",
      "Stock Point ID: 1647382 || Stock Point Name: OmniHub Port Harcourt Rivers - IFO\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Port Harcourt Rivers - IFO, StockPointID: 1647382,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 4,977\n",
      "Total Quantity: 3,681\n",
      "Total Number of Customers before filter: 170\n",
      "Total Number of Customers: 124\n",
      "✓ Loaded 954 SKU recommendations\n",
      "✓ Loaded 124 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.56\n",
      "Davies-Bouldin Index: 0.34\n",
      "Calinski-Harabasz Score: 34151.71\n",
      "Silhouette Score: 0.56\n",
      "Davies-Bouldin Index: 0.34\n",
      "Calinski-Harabasz Score: 34151.71\n",
      "Select ClusterIDs: [3, 1, 5, 4]\n",
      "Total Number of Customers: 80\n",
      "   cluster                     LGA_list  \\\n",
      "0        3              [Port Harcourt]   \n",
      "1        1              [Port Harcourt]   \n",
      "2        5  [Obio Akpor, Port Harcourt]   \n",
      "3        4              [Port Harcourt]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0                        [Diobu, PORTHARCOURT-DIOBU]         22       681   \n",
      "1  [Diobu, PORTHARCOURT-DIOBU, , Eagle Island, PO...         30       951   \n",
      "2     [Rumudara, , Woji, PORTHARCOURT-MILE 3, Diobu]          7       207   \n",
      "3  [, Ogbunabali, Nkpogu, D-Line, New Gra, PORTHA...         21       572   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           43.406550  \n",
      "1           37.633953  \n",
      "2           35.315769  \n",
      "3           33.711401  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (31 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 62.67 km, Duration: 88.78 min\n",
      "  Calculating route for Trip ID: 3 (23 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 24.86 km, Duration: 36.50 min\n",
      "  Calculating route for Trip ID: 4 (22 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 53.63 km, Duration: 71.05 min\n",
      "  Calculating route for Trip ID: 5 (8 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 36.04 km, Duration: 45.75 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647382.html\n",
      "59/72 \n",
      "Stock Point ID: 1647108 || Stock Point Name: OmniHub AMAC 2 Abuja - PearlCity Maraba\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub AMAC 2 Abuja - PearlCity Maraba, StockPointID: 1647108,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 9,105\n",
      "Total Quantity: 5,747\n",
      "Total Number of Customers before filter: 568\n",
      "Total Number of Customers: 342\n",
      "✓ Loaded 2026 SKU recommendations\n",
      "✓ Loaded 342 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.48\n",
      "Davies-Bouldin Index: 0.33\n",
      "Calinski-Harabasz Score: 4228.29\n",
      "Silhouette Score: 0.48\n",
      "Davies-Bouldin Index: 0.33\n",
      "Calinski-Harabasz Score: 4228.29\n",
      "Select ClusterIDs: [10, 11, 9, 2]\n",
      "Total Number of Customers: 61\n",
      "   cluster                                LGA_list  \\\n",
      "0       10                                [AMAC 3]   \n",
      "1       11                                [AMAC 3]   \n",
      "2        9  [Karu, AMAC 3, Push - Abuja Municipal]   \n",
      "3        2                                [AMAC 3]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0                                            [Maska]          9       163   \n",
      "1                                         [, Durumi]          8       121   \n",
      "2      [Mararaba, Garki 2, , Durumi, Push - Garki 2]         14       240   \n",
      "3  [Durumi, Damangaza, Apo, Maska, , Garki 2, One...         30       466   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           50.250566  \n",
      "1           49.076923  \n",
      "2           48.935714  \n",
      "3           47.415636  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 2 (31 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 102.87 km, Duration: 78.15 min\n",
      "  Calculating route for Trip ID: 9 (15 waypoints)...\n",
      "  Trip ID 9 calculated. Distance: 25.99 km, Duration: 38.90 min\n",
      "  Calculating route for Trip ID: 10 (10 waypoints)...\n",
      "  Trip ID 10 calculated. Distance: 42.92 km, Duration: 40.17 min\n",
      "  Calculating route for Trip ID: 11 (9 waypoints)...\n",
      "  Trip ID 11 calculated. Distance: 16.36 km, Duration: 22.35 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647108.html\n",
      "60/72 \n",
      "Stock Point ID: 1647141 || Stock Point Name: OmniHub Ojo Lagos - Mas Global\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ojo Lagos - Mas Global, StockPointID: 1647141,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 8,442\n",
      "Total Quantity: 6,282\n",
      "Total Number of Customers before filter: 492\n",
      "Total Number of Customers: 360\n",
      "✓ Loaded 1593 SKU recommendations\n",
      "✓ Loaded 360 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.36\n",
      "Davies-Bouldin Index: 0.49\n",
      "Calinski-Harabasz Score: 14881.83\n",
      "Silhouette Score: 0.36\n",
      "Davies-Bouldin Index: 0.49\n",
      "Calinski-Harabasz Score: 14881.83\n",
      "Select ClusterIDs: [13, 8, 5, 10]\n",
      "Total Number of Customers: 66\n",
      "   cluster        LGA_list                                          LCDA_List  \\\n",
      "0       13           [Ojo]                 [Ojo - Aka Road, Ojo - Okokomaiko]   \n",
      "1        8  [Amuwo Odofin]  [Amuwo Odofin - Festac (4th Avenue), , Amuwo O...   \n",
      "2        5           [Ojo]  [Ojo - Iyana School, , Ojo - Iyana Iba, Ojo - ...   \n",
      "3       10           [Ojo]                                 [Ojo - Okokomaiko]   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0         11       204           46.430000  \n",
      "1         18       294           46.321282  \n",
      "2         22       411           42.765185  \n",
      "3         15       290           41.844189  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 5 (23 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 55.33 km, Duration: 102.43 min\n",
      "  Calculating route for Trip ID: 8 (19 waypoints)...\n",
      "  Trip ID 8 calculated. Distance: 70.88 km, Duration: 115.45 min\n",
      "  Calculating route for Trip ID: 10 (16 waypoints)...\n",
      "  Trip ID 10 calculated. Distance: 8.53 km, Duration: 22.75 min\n",
      "  Calculating route for Trip ID: 13 (12 waypoints)...\n",
      "  Trip ID 13 calculated. Distance: 7.14 km, Duration: 15.73 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647141.html\n",
      "61/72 \n",
      "Stock Point ID: 1647187 || Stock Point Name: OmniHub Calabar Municipal Cross River - Eyong Obot\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Calabar Municipal Cross River - Eyong Obot, StockPointID: 1647187,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 1,537\n",
      "Total Quantity: 1,073\n",
      "Total Number of Customers before filter: 202\n",
      "Total Number of Customers: 130\n",
      "✓ Loaded 284 SKU recommendations\n",
      "✓ Loaded 130 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.49\n",
      "Davies-Bouldin Index: 0.66\n",
      "Calinski-Harabasz Score: 101903.69\n",
      "Silhouette Score: 0.49\n",
      "Davies-Bouldin Index: 0.66\n",
      "Calinski-Harabasz Score: 101903.69\n",
      "Select ClusterIDs: [8, 6, 2, 3]\n",
      "Total Number of Customers: 61\n",
      "   cluster                            LGA_list  \\\n",
      "0        8  [Calabar South, Calabar Municipal]   \n",
      "1        6                     [Calabar South]   \n",
      "2        2                     [Calabar South]   \n",
      "3        3                     [Calabar South]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [MBUKPA, GOLDIE, Airport Road., Esuk Atu Road....          6        51   \n",
      "1  [Chambley Street., EGERTON, MAYNE AVENUE, MBUK...         10        70   \n",
      "2  [Etim Edem Street., GOLDIE, Watt Market, EGERT...         26       235   \n",
      "3        [MBUKPA, MAYNE AVENUE, GOLDIE, YELLOW DUKE]         19       147   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           52.652308  \n",
      "1           49.692778  \n",
      "2           48.246885  \n",
      "3           47.647692  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 2 (27 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 11.16 km, Duration: 23.00 min\n",
      "  Calculating route for Trip ID: 3 (20 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 19.09 km, Duration: 35.00 min\n",
      "  Calculating route for Trip ID: 6 (11 waypoints)...\n",
      "  Trip ID 6 calculated. Distance: 6.04 km, Duration: 8.73 min\n",
      "  Calculating route for Trip ID: 8 (7 waypoints)...\n",
      "  Trip ID 8 calculated. Distance: 22.41 km, Duration: 31.63 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647187.html\n",
      "62/72 \n",
      "Stock Point ID: 1647403 || Stock Point Name: OmniHub Calabar Municipal Cross River - Alpha Grafix\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Calabar Municipal Cross River - Alpha Grafix, StockPointID: 1647403,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 712\n",
      "Total Quantity: 483\n",
      "Total Number of Customers before filter: 84\n",
      "Total Number of Customers: 51\n",
      "✓ Loaded 110 SKU recommendations\n",
      "✓ Loaded 51 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.34\n",
      "Davies-Bouldin Index: 0.55\n",
      "Calinski-Harabasz Score: 3084.68\n",
      "Silhouette Score: 0.34\n",
      "Davies-Bouldin Index: 0.55\n",
      "Calinski-Harabasz Score: 3084.68\n",
      "Select ClusterIDs: [2, 1, 3, 4]\n",
      "Total Number of Customers: 46\n",
      "   cluster                            LGA_list  \\\n",
      "0        2                 [Calabar Municipal]   \n",
      "1        1                 [Calabar Municipal]   \n",
      "2        3  [Calabar Municipal, Calabar South]   \n",
      "3        4                 [Calabar Municipal]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [Abang Asang Street., Esuk Atu Road., Calabar ...         14       144   \n",
      "1  [Old Odukpani Road., Nsemo Road., Marian Road....         17       150   \n",
      "2  [Old Odukpani Road., Eyo Ita Street., Abang As...         10        77   \n",
      "3  [Asim Ita Close Close, Old Odukpani Road., Iko...          5        58   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           12.170938  \n",
      "1           11.887941  \n",
      "2            7.988947  \n",
      "3            5.000000  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (18 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 34.64 km, Duration: 38.57 min\n",
      "  Calculating route for Trip ID: 2 (15 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 27.34 km, Duration: 40.52 min\n",
      "  Calculating route for Trip ID: 3 (11 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 38.50 km, Duration: 52.22 min\n",
      "  Calculating route for Trip ID: 4 (6 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 16.89 km, Duration: 20.30 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647403.html\n",
      "63/72 \n",
      "Stock Point ID: 1647419 || Stock Point Name: OmniHub Alimosho Lagos - Kay24\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Alimosho Lagos - Kay24, StockPointID: 1647419,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 201\n",
      "Total Quantity: 79\n",
      "Total Number of Customers before filter: 13\n",
      "Total Number of Customers: 5\n",
      "✓ Loaded 24 SKU recommendations\n",
      "✓ Loaded 5 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Select ClusterIDs: [1]\n",
      "Total Number of Customers: 5\n",
      "   cluster    LGA_list                                          LCDA_List  \\\n",
      "0        1  [Alimosho]  [Alimosho - Iyana Ipaja (iyana Ipaja Road), Al...   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0          5        79            2.708333  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (6 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 40.10 km, Duration: 65.95 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647419.html\n",
      "64/72 \n",
      "Stock Point ID: 1647420 || Stock Point Name: OmniHub Ojo Lagos - Barka Agro 3\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ojo Lagos - Barka Agro 3, StockPointID: 1647420,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "65/72 \n",
      "Stock Point ID: 1647421 || Stock Point Name: OmniHub Ikpoba Okha Edo - Real Care\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ikpoba Okha Edo - Real Care, StockPointID: 1647421,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "66/72 \n",
      "Stock Point ID: 1647422 || Stock Point Name: OmniHub Oshodi Isolo Lagos - Fabb\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Oshodi Isolo Lagos - Fabb, StockPointID: 1647422,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "67/72 \n",
      "Stock Point ID: 1647425 || Stock Point Name: OmniHub Keffi Nasarawa - Donsam\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Keffi Nasarawa - Donsam, StockPointID: 1647425,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "68/72 \n",
      "Stock Point ID: 1647434 || Stock Point Name: OmniHub Kuje/Gwagwalada/Abaji Abuja - Deschek\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Kuje/Gwagwalada/Abaji Abuja - Deschek, StockPointID: 1647434,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "69/72 \n",
      "Stock Point ID: 1647436 || Stock Point Name: OmniHub Egor Edo - 10TH Gear\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Egor Edo - 10TH Gear, StockPointID: 1647436,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "70/72 \n",
      "Stock Point ID: 1647437 || Stock Point Name: OmniHub Ado Odo/Ota Ogun - Azacram\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ado Odo/Ota Ogun - Azacram, StockPointID: 1647437,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "71/72 \n",
      "Stock Point ID: 1647438 || Stock Point Name: OmniHub Ado Odo/Ota Ogun - Soffy's Concept\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ado Odo/Ota Ogun - Soffy's Concept, StockPointID: 1647438,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n"
     ]
    }
   ],
   "source": [
    "ALL_STOCKPOINTS_RESULT = {}\n",
    "for index, row in df_stockpoint_dim.iterrows():\n",
    "    # if index == 12:\n",
    "    # if index == 5:\n",
    "    stock_point_id =  row['Stock_Point_ID']\n",
    "    stock_point_name = row['Stock_point_Name']\n",
    "    print(f'{index}/{len(df_stockpoint_dim)} \\nStock Point ID: {stock_point_id} || Stock Point Name: {stock_point_name}')  # Access by column name\n",
    "\n",
    "    res_dict = run_push_recommendation(df_customer_sku_recommendation, \n",
    "                                df_master_customer_dim, \n",
    "                                df_stockpoint_dim, \n",
    "                                stock_point_id,\n",
    "                                stock_point_name,\n",
    "                                sku_recency = 7, \n",
    "                                customer_recency = 60, number_recommendation = 10, \n",
    "                                estimate_qty_scale_factor = 1, max_estimated_qty = 5, \n",
    "                                exclude_recency_customer = 5,\n",
    "                                max_customers_per_route=20,\n",
    "                                max_volume_per_route=300,\n",
    "                                max_distance_km = 5,\n",
    "                                sel_trip_cluster = 4,\n",
    "                                min_ncust_per_cluster = 5,\n",
    "                                clustering_method = 'divisive',\n",
    "                                skip_route_optimization = True)\n",
    "    \n",
    "    ALL_STOCKPOINTS_RESULT[stock_point_name] = res_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d067f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res_dict.keys())\n",
    "# [col  for col in res_dict['all_push_recommendation'].columns if 'KYC_Capture_Status' in col]\n",
    "# res_dict['cluster_summary'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6f9cbb",
   "metadata": {},
   "source": [
    "## Routing 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04decfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = ALL_STOCKPOINTS_RESULT['OmniHub Apapa Lagos - CAUSEWAY'] \n",
    "df_selected_trip = df_test['selected_trip']\n",
    "print(df_selected_trip.TripID.nunique())\n",
    "# dict_keys(['stock_point_name', 'selected_trip', 'all_push_recommendation', 'cluster_summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5b661f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected_trip_summary =  df_selected_trip.groupby(['StockPointID','TripID', \n",
    "                                                                                   'CustomerID', 'Latitude','Longitude',\n",
    "                                                                                   'LGA', 'LCDA','CustomerScore']).agg( \n",
    "                        TotalQuantity = ('EstimatedQuantity','sum')\n",
    "                        ,TotalSKU = ('SKUID','nunique')\n",
    "                    ).reset_index() \n",
    "# trip_dict = create_single_stockpoint_dict(df_selected_trip_summary, df_stockpoint_dim) \n",
    "# route_info = calculated_routes_info = get_valhalla_routes_info(trip_dict)\n",
    "# route_info[0].keys()\n",
    "# len(trip_dict['Trips'][0]['Destinations'])\n",
    "create_route(df_selected_trip_summary, df_stockpoint_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889871c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_route(df_selected_trip_summary, df_stockpoint_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b199e2",
   "metadata": {},
   "source": [
    "# Data Export to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7a9217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL_STOCKPOINTS_RESULT.keys()\n",
    "# # ALL_STOCKPOINTS_RESULT['OmniHub Obio Akpor Rivers - Rivoc']\n",
    "# ALL_STOCKPOINTS_RESULT['OmniHub Ado Odo/Ota Ogun - Prince Tunadek']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "58bc8c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_ALL_RECOMMENDATION = pd.DataFrame() \n",
    "for key in ALL_STOCKPOINTS_RESULT.keys():\n",
    "    dict_f = ALL_STOCKPOINTS_RESULT[key]\n",
    "    if dict_f != {}:\n",
    "        df_ = dict_f['all_push_recommendation']\n",
    "    \n",
    "        if len(df_) > 0:\n",
    "            df_['ClusterLGAs'] = df_['ClusterLGAs'].apply(str)\n",
    "            df_['ClusterLCDAs'] = df_['ClusterLCDAs'].apply(str)\n",
    "            DF_ALL_RECOMMENDATION = pd.concat([DF_ALL_RECOMMENDATION, df_])\n",
    "            DF_ALL_RECOMMENDATION['ModifiedDate'] = CURRENT_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f705d251",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_summary = ['StockPointID', 'StockPointName', 'TripID', 'ClusterLGAs', 'ClusterLCDAs', 'TotalCustonerCount', 'TripTotalQuantity','TripAvgCustomerScore', 'ModifiedDate']  \n",
    "DF_CLUSTER_SUMMARY = DF_ALL_RECOMMENDATION[cols_summary].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d60a7d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StockPointID</th>\n",
       "      <th>StockPointName</th>\n",
       "      <th>TripID</th>\n",
       "      <th>ClusterLGAs</th>\n",
       "      <th>ClusterLCDAs</th>\n",
       "      <th>TotalCustonerCount</th>\n",
       "      <th>TripTotalQuantity</th>\n",
       "      <th>TripAvgCustomerScore</th>\n",
       "      <th>ModifiedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>1647372</td>\n",
       "      <td>OmniHub AMAC 1 Abuja - Roekwi</td>\n",
       "      <td>8</td>\n",
       "      <td>['Kuje/Gwagwalada/Abaji']</td>\n",
       "      <td>['ABUJA- ZUBA', 'ABUJA-GWAGWALADA']</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>20.015</td>\n",
       "      <td>2025-06-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     StockPointID                 StockPointName  TripID  \\\n",
       "245       1647372  OmniHub AMAC 1 Abuja - Roekwi       8   \n",
       "\n",
       "                   ClusterLGAs                         ClusterLCDAs  \\\n",
       "245  ['Kuje/Gwagwalada/Abaji']  ['ABUJA- ZUBA', 'ABUJA-GWAGWALADA']   \n",
       "\n",
       "     TotalCustonerCount  TripTotalQuantity  TripAvgCustomerScore ModifiedDate  \n",
       "245                   3                 28                20.015   2025-06-28  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "# DF_ALL_RECOMMENDATION.sample(1)\n",
    "DF_CLUSTER_SUMMARY.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605ba250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_lengths = DF_ALL_RECOMMENDATION.astype(str).applymap(len).max().reset_index(name = 'max_length')\n",
    "# print(max_lengths)\n",
    "# print(DF_ALL_RECOMMENDATION.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "15686f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsert_dataframe(df, table_name, conn, match_cols, update_cols, batch_size = 2000, fast_executemany = True):\n",
    "    # Input validation\n",
    "    if df.empty:\n",
    "        raise ValueError(\"DataFrame is empty.\")\n",
    "    if not match_cols or not update_cols:\n",
    "        raise ValueError(\"match_cols and update_cols cannot be empty.\")\n",
    "    if not all(col in df.columns for col in match_cols + update_cols):\n",
    "        raise ValueError(\"Some match_cols or update_cols are not in the DataFrame.\")\n",
    "    if not table_name.strip() or any(c in table_name for c in \".;[]\"):\n",
    "        raise ValueError(\"Invalid table_name.\")\n",
    "\n",
    "    cursor = None\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.fast_executemany = fast_executemany \n",
    "\n",
    "        staging_table = f\"#{table_name}_staging\"\n",
    "        cols = df.columns.tolist()\n",
    "        col_list = ', '.join(f\"[{col}]\" for col in cols)\n",
    "        placeholders = ', '.join(['?'] * len(cols))\n",
    "\n",
    "        # Step 1: Create staging table from real schema\n",
    "        create_staging_sql = f\"\"\"\n",
    "        SELECT TOP 0 {col_list}\n",
    "        INTO {staging_table}\n",
    "        FROM {table_name}\n",
    "        WHERE 1 = 0;\n",
    "        \"\"\"\n",
    "        cursor.execute(create_staging_sql)\n",
    "\n",
    "        # Step 2: Bulk insert into staging table using fast_executemany\n",
    "        insert_sql = f\"INSERT INTO {staging_table} ({col_list}) VALUES ({placeholders})\"\n",
    "        cursor.executemany(insert_sql, df[cols].values.tolist())\n",
    "        conn.commit()\n",
    "\n",
    "        # insert_sql = f\"INSERT INTO {staging_table} ({col_list}) VALUES ({placeholders})\"\n",
    "        # data = df[cols].values.tolist()\n",
    "        # for i in range(0, len(data), batch_size):\n",
    "        #     cursor.executemany(insert_sql, data[i:i+batch_size])\n",
    "        # conn.commit()\n",
    "\n",
    "        # Step 3: MERGE for upsert\n",
    "        on_clause = ' AND '.join([f\"TARGET.[{col}] = SOURCE.[{col}]\" for col in match_cols])\n",
    "        update_clause = ', '.join([f\"TARGET.[{col}] = SOURCE.[{col}]\" for col in update_cols])\n",
    "        insert_cols = ', '.join([f\"[{col}]\" for col in cols])\n",
    "        insert_values = ', '.join([f\"SOURCE.[{col}]\" for col in cols])\n",
    "\n",
    "        merge_sql = f\"\"\"\n",
    "        MERGE {table_name} AS TARGET\n",
    "        USING {staging_table} AS SOURCE\n",
    "        ON {on_clause}\n",
    "        WHEN MATCHED THEN\n",
    "            UPDATE SET {update_clause}\n",
    "        WHEN NOT MATCHED THEN\n",
    "            INSERT ({insert_cols})\n",
    "            VALUES ({insert_values});\n",
    "        \"\"\"\n",
    "        cursor.execute(merge_sql)\n",
    "        conn.commit()\n",
    "    except Exception as e:\n",
    "        if conn:\n",
    "            conn.rollback()\n",
    "        logger.error(f\"Upsert failed for table {table_name}: {e}\")\n",
    "        raise Exception(f\"Upsert failed for table {table_name}: {e}\") from e\n",
    "    finally:\n",
    "        if cursor:\n",
    "            cursor.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "605c6399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "df_insert = DF_ALL_RECOMMENDATION.drop(columns=['ClusterLGAs',\t'ClusterLCDAs']).reset_index(drop=True)\n",
    "# Replace 'YourProblematicColumn' with the actual column name you found\n",
    "df_insert['SKUDaysSinceLastBuy'] = df_insert['SKUDaysSinceLastBuy'].astype(float, errors='ignore').astype(int, errors='ignore')\n",
    "df_insert['CustomerDaysSinceLastBuy'] = df_insert['CustomerDaysSinceLastBuy'].astype(float, errors='ignore').astype(int, errors='ignore')\n",
    "\n",
    "match_cols = ['StockPointID', 'CustomerID', 'SKUID', 'ModifiedDate']\n",
    "update_cols = list(set(df_insert.columns) - set(match_cols))\n",
    "\n",
    "conn = get_connection()\n",
    "upsert_dataframe(\n",
    "    df=df_insert,\n",
    "    table_name='dailyPredictedPull',\n",
    "    conn=conn,\n",
    "    match_cols=match_cols,\n",
    "    update_cols=update_cols   \n",
    ") \n",
    " \n",
    "print(conn.closed)\n",
    "conn.close()\n",
    "print(conn.closed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5e9d8104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "df = DF_CLUSTER_SUMMARY.copy() \n",
    "\n",
    "df['ClusterLGAs'] = df['ClusterLGAs'].astype(str).str.slice(0, 500)\n",
    "df['ClusterLCDAs'] = df['ClusterLCDAs'].astype(str).str.slice(0, 500)\n",
    "\n",
    "\n",
    "match_cols = ['StockPointID', 'TripID', 'ModifiedDate']\n",
    "update_cols = list(set(df.columns) - set(match_cols))\n",
    "\n",
    "conn = get_connection()\n",
    "upsert_dataframe(\n",
    "    df=df,\n",
    "    table_name='dailyPredictedPullClusterSummary',\n",
    "    conn=conn,\n",
    "    match_cols=match_cols,\n",
    "    update_cols=update_cols ,\n",
    "    fast_executemany = False  \n",
    ")\n",
    "\n",
    "print(conn.closed)\n",
    "conn.close()\n",
    "print(conn.closed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa188a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d7a360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pd.set_option('display.width', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# res_dict['all_push_recommendation'].sample(1)\n",
    "# # res_dict['cluster_summary'].sort_values('ncustomer', ascending = False)\n",
    "# from collections import Counter\n",
    "# Counter(res_dict['all_push_recommendation'].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d210a690",
   "metadata": {},
   "source": [
    "# Case Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cced9601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Filter - Testing \n",
    "causeway, causeway_customer_dim, causeway_stockpoint, = data_filter(df_customer_sku_recommendation, \n",
    "                                                                    df_master_customer_dim, \n",
    "                                                                    df_stockpoint_dim, \n",
    "                                                                    stockpoint_id = 1647394,  \n",
    "                                                                    # stockpoint_id = 1647113,  \n",
    "                                                                    sku_recency = 7, customer_recency = 60, number_recommendation = 10,\n",
    "                                                                    estimate_qty_scale_factor = 1, max_estimated_qty = 5, \n",
    "                                                                    exclude_recency_customer = 4)\n",
    "\n",
    "# Total Number of Customers: 905 || 901\n",
    "\n",
    "df_all_cluster = causeway_customer_dim[['CustomerID', 'Latitude','Longitude']].drop_duplicates()\n",
    "df_all_cluster.shape\n",
    "# df_all_cluster = res_dict['all_push_recommendation'][['CustomerID','TripID', 'Latitude','Longitude']].drop_duplicates().rename(columns={'TripID':'cluster'})\n",
    "\n",
    "\n",
    "# vis_and_save(df_routes = df_all_cluster,\n",
    "#                  df_stockpoint = None,   \n",
    "#                  filename=None,\n",
    "#                  cluster_col = 'cluster')\n",
    "\n",
    "# 459\n",
    "# 364"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb813416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_cluster.Latitude.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a397ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = ['CustomerID', 'SKUID', 'Medium','CustomerPurchaseRecency']\n",
    "# causeway[cols].query('(CustomerID == 5271729) or (CustomerID ==  5266873)')\n",
    "# causeway.groupby(['CustomerPurchaseRecency'])['CustomerID'].nunique().reset_index().sort_values('CustomerID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee26108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# causeway.columns\n",
    "# causeway['Medium'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b73d94d",
   "metadata": {},
   "source": [
    "### Test New Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee242d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clustering.divisive_clustering import DivisiveGeographicClustering, OptimizedDivisiveGeographicClustering\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"2. DIVISIVE HIERARCHICAL CLUSTERING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "divisive_clusterer = OptimizedDivisiveGeographicClustering( \n",
    "    # Rivers: Divisive clusters created: 48 || Silhouette Score: 0.54 || Constraint violations: Size=6, Distance=3\n",
    "    max_customers_per_cluster=30,  # REQUIRED\n",
    "    max_distance_km=5            # REQUIRED\n",
    "    ,use_vectorized_distances=True, balance_clusters=False\n",
    ")\n",
    "\n",
    "divisive_result = divisive_clusterer.divisive_clustering(df_all_cluster.copy())\n",
    "print(f\"\\nDivisive clusters created: {divisive_result['cluster'].nunique()}\")\n",
    "# print(f\"Cluster sizes: {divisive_result['cluster'].value_counts().sort_index().head()}\")\n",
    "_ = evaluate_unsupervised_clustering(divisive_result)\n",
    "\n",
    "# # Get detailed statistics\n",
    "stats = divisive_clusterer.get_cluster_stats(divisive_result)\n",
    "print(f\"Total clusters: {stats['summary']['total_clusters']}\")\n",
    "print(f\"Constraint violations: Size={stats['summary']['size_violations']}, Distance={stats['summary']['distance_violations']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc977318",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clustering.agglomerative_clustering import AgglomerativeGeographicClustering\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"2. AGGLOMERATIVE CLUSTERING\")\n",
    "print(\"=\"*60)\n",
    " \n",
    "agg_clusterer = AgglomerativeGeographicClustering(\n",
    "    max_customers_per_cluster=30, # Aim for clusters of max 50 customers\n",
    "    max_distance_km=5.0,        # Max diameter of 5 km\n",
    "    linkage_method='ward',       # Common choice for compact clusters\n",
    "    sub_cluster_if_oversized=True\n",
    ")\n",
    "clustered_agg_df = agg_clusterer.agglomerative_clustering(df_all_cluster.copy())\n",
    "\n",
    "# print(\"\\nAgglomerative Clustering Stats:\")\n",
    "# for k, v in agg_stats['summary'].items():\n",
    "#     print(f\"  {k}: {v}\")\n",
    "# print(\"\\nSample Agglomerative Cluster Details:\")\n",
    "# for cluster_id, details in list(agg_stats.items())[:5]: # Show first 5 clusters\n",
    "#     if cluster_id != 'summary':\n",
    "#         print(f\"  Cluster {cluster_id}: Size={details['size']}, Diameter={details['diameter_km']:.2f} km, Size OK={details['meets_size_constraint']}, Distance OK={details['meets_distance_constraint']}\")\n",
    "\n",
    "\n",
    "_ = evaluate_unsupervised_clustering(clustered_agg_df)\n",
    "\n",
    "\n",
    "stats = agg_clusterer.get_cluster_stats(clustered_agg_df, agg_clusterer.max_customers_per_cluster, agg_clusterer.max_distance_km) \n",
    "print(f\"Total clusters: {stats['summary']['total_clusters']}\")\n",
    "print(f\"Constraint violations: Size={stats['summary']['size_violations']}, Distance={stats['summary']['distance_violations']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd35595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_and_save(df_routes = clustered_agg_df,\n",
    "                 df_stockpoint = None,   \n",
    "                 filename='agglomerative-clustering-test.html',\n",
    "                 cluster_col = 'cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a73b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_and_save(df_routes = divisive_result,\n",
    "                 df_stockpoint = None,   \n",
    "                 filename='divisive-clustering-test.html',\n",
    "                 cluster_col = 'cluster')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08980d8e",
   "metadata": {},
   "source": [
    "### New Clustering Algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2266ee03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.cluster.hierarchy import fcluster, linkage\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "## Best\n",
    "class OptimizedDivisiveGeographicClustering_b:\n",
    "    def __init__(self, max_customers_per_cluster=20, max_distance_km=50, \n",
    "                 use_vectorized_distances=True, balance_clusters=False):\n",
    "        self.max_customers_per_cluster = max_customers_per_cluster\n",
    "        self.max_distance_km = max_distance_km\n",
    "        self.earth_radius_km = 6371.0\n",
    "        self.use_vectorized_distances = use_vectorized_distances\n",
    "        self.balance_clusters = balance_clusters\n",
    "        \n",
    "    def haversine_vectorized(self, coords1, coords2=None):\n",
    "        \"\"\"\n",
    "        Highly optimized vectorized haversine distance calculation.\n",
    "        If coords2 is None, calculates pairwise distances within coords1.\n",
    "        \"\"\"\n",
    "        if coords2 is None:\n",
    "            # Pairwise distances within coords1\n",
    "            coords1_rad = np.radians(coords1)\n",
    "            n = len(coords1)\n",
    "            \n",
    "            # Create meshgrids for vectorized calculation\n",
    "            lat1 = coords1_rad[:, 0]\n",
    "            lon1 = coords1_rad[:, 1]\n",
    "            \n",
    "            lat1_mesh, lat2_mesh = np.meshgrid(lat1, lat1)\n",
    "            lon1_mesh, lon2_mesh = np.meshgrid(lon1, lon1)\n",
    "            \n",
    "            dlat = lat2_mesh - lat1_mesh\n",
    "            dlon = lon2_mesh - lon1_mesh\n",
    "            \n",
    "            a = (np.sin(dlat / 2) ** 2 + \n",
    "                 np.cos(lat1_mesh) * np.cos(lat2_mesh) * np.sin(dlon / 2) ** 2)\n",
    "            c = 2 * np.arcsin(np.sqrt(np.clip(a, 0, 1)))\n",
    "            \n",
    "            return self.earth_radius_km * c\n",
    "        else:\n",
    "            # Distance from each point in coords1 to each point in coords2\n",
    "            coords1_rad = np.radians(coords1)\n",
    "            coords2_rad = np.radians(coords2)\n",
    "            \n",
    "            lat1 = coords1_rad[:, 0][:, np.newaxis]\n",
    "            lon1 = coords1_rad[:, 1][:, np.newaxis]\n",
    "            lat2 = coords2_rad[:, 0][np.newaxis, :]\n",
    "            lon2 = coords2_rad[:, 1][np.newaxis, :]\n",
    "            \n",
    "            dlat = lat2 - lat1\n",
    "            dlon = lon2 - lon1\n",
    "            \n",
    "            a = (np.sin(dlat / 2) ** 2 + \n",
    "                 np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2)\n",
    "            c = 2 * np.arcsin(np.sqrt(np.clip(a, 0, 1)))\n",
    "            \n",
    "            return self.earth_radius_km * c\n",
    "    \n",
    "    def haversine_pdist(self, coords):\n",
    "        \"\"\"\n",
    "        Optimized haversine distance calculation using scipy's pdist.\n",
    "        \"\"\"\n",
    "        def haversine_metric(u, v):\n",
    "            lat1, lon1 = np.radians(u)\n",
    "            lat2, lon2 = np.radians(v)\n",
    "            \n",
    "            dlat = lat2 - lat1\n",
    "            dlon = lon2 - lon1\n",
    "            \n",
    "            a = (np.sin(dlat / 2) ** 2 + \n",
    "                 np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2)\n",
    "            c = 2 * np.arcsin(np.sqrt(np.clip(a, 0, 1)))\n",
    "            \n",
    "            return self.earth_radius_km * c\n",
    "        \n",
    "        return pdist(coords, metric=haversine_metric)\n",
    "    \n",
    "    def calculate_cluster_diameter_fast(self, coords):\n",
    "        \"\"\"\n",
    "        Fast cluster diameter calculation with multiple optimization strategies.\n",
    "        \"\"\"\n",
    "        n_points = len(coords)\n",
    "        \n",
    "        if n_points <= 1:\n",
    "            return 0\n",
    "        \n",
    "        if n_points == 2:\n",
    "            return self.haversine_single_pair(coords[0], coords[1])\n",
    "        \n",
    "        # Use different strategies based on cluster size\n",
    "        if n_points <= 10:\n",
    "            # Small clusters: exact calculation\n",
    "            distances = self.haversine_pdist(coords)\n",
    "            return np.max(distances)\n",
    "        elif n_points <= 50:\n",
    "            # Medium clusters: vectorized calculation\n",
    "            if self.use_vectorized_distances:\n",
    "                distance_matrix = self.haversine_vectorized(coords)\n",
    "                return np.max(distance_matrix)\n",
    "            else:\n",
    "                distances = self.haversine_pdist(coords)\n",
    "                return np.max(distances)\n",
    "        else:\n",
    "            # Large clusters: smart sampling\n",
    "            return self._smart_diameter_estimation(coords)\n",
    "    \n",
    "    def _smart_diameter_estimation(self, coords):\n",
    "        \"\"\"\n",
    "        Improved diameter estimation using multiple sampling strategies.\n",
    "        \"\"\"\n",
    "        n_points = len(coords)\n",
    "        \n",
    "        # Strategy 1: Convex hull approximation\n",
    "        hull_diameter = self._convex_hull_diameter(coords)\n",
    "        \n",
    "        # Strategy 2: Grid-based sampling for large clusters\n",
    "        if n_points > 200:\n",
    "            grid_diameter = self._grid_based_diameter(coords)\n",
    "            return max(hull_diameter, grid_diameter)\n",
    "        \n",
    "        return hull_diameter\n",
    "    \n",
    "    def _convex_hull_diameter(self, coords):\n",
    "        \"\"\"Enhanced convex hull approximation.\"\"\"\n",
    "        lats, lons = coords[:, 0], coords[:, 1]\n",
    "        \n",
    "        # Get extreme points\n",
    "        extreme_indices = [\n",
    "            np.argmax(lats), np.argmin(lats),\n",
    "            np.argmax(lons), np.argmin(lons)\n",
    "        ]\n",
    "        \n",
    "        # Add points from different quadrants\n",
    "        lat_center, lon_center = np.mean(lats), np.mean(lons)\n",
    "        \n",
    "        quadrants = [\n",
    "            (lats >= lat_center) & (lons >= lon_center),  # NE\n",
    "            (lats >= lat_center) & (lons < lon_center),   # NW\n",
    "            (lats < lat_center) & (lons >= lon_center),   # SE\n",
    "            (lats < lat_center) & (lons < lon_center)     # SW\n",
    "        ]\n",
    "        \n",
    "        for quadrant in quadrants:\n",
    "            if np.any(quadrant):\n",
    "                quad_indices = np.where(quadrant)[0]\n",
    "                # Add furthest point from center in each quadrant\n",
    "                distances_from_center = np.sqrt(\n",
    "                    (lats[quad_indices] - lat_center)**2 + \n",
    "                    (lons[quad_indices] - lon_center)**2\n",
    "                )\n",
    "                furthest_idx = quad_indices[np.argmax(distances_from_center)]\n",
    "                extreme_indices.append(furthest_idx)\n",
    "        \n",
    "        # Add some random points\n",
    "        n_random = min(12, len(coords) - len(set(extreme_indices)))\n",
    "        if n_random > 0:\n",
    "            available_indices = list(set(range(len(coords))) - set(extreme_indices))\n",
    "            if available_indices:\n",
    "                random_indices = np.random.choice(available_indices, \n",
    "                                                min(n_random, len(available_indices)), \n",
    "                                                replace=False)\n",
    "                extreme_indices.extend(random_indices)\n",
    "        \n",
    "        # Get unique sample\n",
    "        sample_indices = list(set(extreme_indices))\n",
    "        sample_coords = coords[sample_indices]\n",
    "        \n",
    "        if len(sample_coords) <= 1:\n",
    "            return 0\n",
    "        \n",
    "        distances = self.haversine_pdist(sample_coords)\n",
    "        return np.max(distances)\n",
    "    \n",
    "    def _grid_based_diameter(self, coords):\n",
    "        \"\"\"Grid-based sampling for very large clusters.\"\"\"\n",
    "        # Create a grid and sample points from each grid cell\n",
    "        lats, lons = coords[:, 0], coords[:, 1]\n",
    "        \n",
    "        # Create 6x6 grid\n",
    "        lat_bins = np.linspace(lats.min(), lats.max(), 7)\n",
    "        lon_bins = np.linspace(lons.min(), lons.max(), 7)\n",
    "        \n",
    "        sample_indices = []\n",
    "        for i in range(len(lat_bins)-1):\n",
    "            for j in range(len(lon_bins)-1):\n",
    "                mask = ((lats >= lat_bins[i]) & (lats < lat_bins[i+1]) & \n",
    "                       (lons >= lon_bins[j]) & (lons < lon_bins[j+1]))\n",
    "                cell_indices = np.where(mask)[0]\n",
    "                if len(cell_indices) > 0:\n",
    "                    # Sample up to 2 points from each cell\n",
    "                    n_sample = min(2, len(cell_indices))\n",
    "                    sampled = np.random.choice(cell_indices, n_sample, replace=False)\n",
    "                    sample_indices.extend(sampled)\n",
    "        \n",
    "        if len(sample_indices) <= 1:\n",
    "            return 0\n",
    "        \n",
    "        sample_coords = coords[sample_indices]\n",
    "        distances = self.haversine_pdist(sample_coords)\n",
    "        return np.max(distances)\n",
    "    \n",
    "    def haversine_single_pair(self, coord1, coord2):\n",
    "        \"\"\"Calculate haversine distance between two points.\"\"\"\n",
    "        lat1, lon1 = np.radians(coord1)\n",
    "        lat2, lon2 = np.radians(coord2)\n",
    "        \n",
    "        dlat = lat2 - lat1\n",
    "        dlon = lon2 - lon1\n",
    "        \n",
    "        a = (np.sin(dlat / 2) ** 2 + \n",
    "             np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2)\n",
    "        c = 2 * np.arcsin(np.sqrt(np.clip(a, 0, 1)))\n",
    "        \n",
    "        return self.earth_radius_km * c\n",
    "    \n",
    "    def should_split_cluster(self, cluster_indices, coords_array):\n",
    "        \"\"\"Enhanced cluster splitting logic with load balancing.\"\"\"\n",
    "        cluster_size = len(cluster_indices)\n",
    "        \n",
    "        if cluster_size <= 2:\n",
    "            return False\n",
    "        \n",
    "        # Hard size constraint\n",
    "        if cluster_size > self.max_customers_per_cluster * 1.5:\n",
    "            return True\n",
    "        \n",
    "        # Soft size constraint with diameter check\n",
    "        if cluster_size > self.max_customers_per_cluster:\n",
    "            cluster_coords = coords_array[cluster_indices]\n",
    "            diameter = self.calculate_cluster_diameter_fast(cluster_coords)\n",
    "            return diameter > self.max_distance_km * 0.8  # More lenient for size\n",
    "        \n",
    "        # Diameter constraint\n",
    "        cluster_coords = coords_array[cluster_indices]\n",
    "        diameter = self.calculate_cluster_diameter_fast(cluster_coords)\n",
    "        \n",
    "        return diameter > self.max_distance_km\n",
    "    \n",
    "    def geographic_split(self, cluster_indices, coords_array):\n",
    "        \"\"\"\n",
    "        Improved geographic splitting with better load balancing.\n",
    "        \"\"\"\n",
    "        if len(cluster_indices) <= 2:\n",
    "            return [cluster_indices]\n",
    "        \n",
    "        cluster_coords = coords_array[cluster_indices]\n",
    "        n_points = len(cluster_coords)\n",
    "        \n",
    "        # For small clusters, use exact method\n",
    "        if n_points <= 50:\n",
    "            return self._exact_geographic_split(cluster_indices, cluster_coords)\n",
    "        \n",
    "        # For medium clusters, use K-means with geographic initialization\n",
    "        if n_points <= 200:\n",
    "            return self._kmeans_geographic_split(cluster_indices, cluster_coords)\n",
    "        \n",
    "        # For large clusters, use hierarchical approach\n",
    "        return self._hierarchical_geographic_split(cluster_indices, cluster_coords)\n",
    "    \n",
    "    def _exact_geographic_split(self, cluster_indices, cluster_coords):\n",
    "        \"\"\"Exact splitting for small clusters.\"\"\"\n",
    "        n_points = len(cluster_coords)\n",
    "        \n",
    "        # Find the two points that are farthest apart\n",
    "        distances = self.haversine_pdist(cluster_coords)\n",
    "        distance_matrix = squareform(distances)\n",
    "        max_idx = np.unravel_index(np.argmax(distance_matrix), distance_matrix.shape)\n",
    "        center1_idx, center2_idx = max_idx[0], max_idx[1]\n",
    "        \n",
    "        center1 = cluster_coords[center1_idx]\n",
    "        center2 = cluster_coords[center2_idx]\n",
    "        \n",
    "        # Assign points to closest center\n",
    "        distances_to_center1 = self.haversine_vectorized(cluster_coords, center1.reshape(1, -1))[:, 0]\n",
    "        distances_to_center2 = self.haversine_vectorized(cluster_coords, center2.reshape(1, -1))[:, 0]\n",
    "        \n",
    "        labels = (distances_to_center1 <= distances_to_center2).astype(int)\n",
    "        \n",
    "        return self._balance_split(cluster_indices, labels)\n",
    "    \n",
    "    def _kmeans_geographic_split(self, cluster_indices, cluster_coords):\n",
    "        \"\"\"K-means splitting with geographic initialization.\"\"\"\n",
    "        n_points = len(cluster_coords)\n",
    "        \n",
    "        # Initialize with farthest pair\n",
    "        center1_idx, center2_idx = self._find_approximate_farthest_pair(cluster_coords)\n",
    "        initial_centers = cluster_coords[[center1_idx, center2_idx]]\n",
    "        \n",
    "        # Apply K-means\n",
    "        kmeans = KMeans(n_clusters=2, init=initial_centers, n_init=1, random_state=42)\n",
    "        labels = kmeans.fit_predict(cluster_coords)\n",
    "        \n",
    "        return self._balance_split(cluster_indices, labels)\n",
    "    \n",
    "    def _hierarchical_geographic_split(self, cluster_indices, cluster_coords):\n",
    "        \"\"\"Hierarchical splitting for large clusters.\"\"\"\n",
    "        # Use linkage-based clustering for very large clusters\n",
    "        n_sample = min(100, len(cluster_coords))\n",
    "        sample_indices = np.random.choice(len(cluster_coords), n_sample, replace=False)\n",
    "        sample_coords = cluster_coords[sample_indices]\n",
    "        \n",
    "        # Compute linkage on sample\n",
    "        distances = self.haversine_pdist(sample_coords)\n",
    "        linkage_matrix = linkage(distances, method='ward')\n",
    "        sample_labels = fcluster(linkage_matrix, 2, criterion='maxclust') - 1\n",
    "        \n",
    "        # Assign all points based on closest sample point\n",
    "        center1_coords = sample_coords[sample_labels == 0]\n",
    "        center2_coords = sample_coords[sample_labels == 1]\n",
    "        \n",
    "        if len(center1_coords) == 0 or len(center2_coords) == 0:\n",
    "            # Fallback to farthest pair method\n",
    "            return self._exact_geographic_split(cluster_indices, cluster_coords)\n",
    "        \n",
    "        center1 = np.mean(center1_coords, axis=0)\n",
    "        center2 = np.mean(center2_coords, axis=0)\n",
    "        \n",
    "        distances_to_center1 = self.haversine_vectorized(cluster_coords, center1.reshape(1, -1))[:, 0]\n",
    "        distances_to_center2 = self.haversine_vectorized(cluster_coords, center2.reshape(1, -1))[:, 0]\n",
    "        \n",
    "        labels = (distances_to_center1 <= distances_to_center2).astype(int)\n",
    "        \n",
    "        return self._balance_split(cluster_indices, labels)\n",
    "    \n",
    "    def _balance_split(self, cluster_indices, labels):\n",
    "        \"\"\"Balance the split to avoid very uneven clusters.\"\"\"\n",
    "        cluster_0_indices = cluster_indices[labels == 0]\n",
    "        cluster_1_indices = cluster_indices[labels == 1]\n",
    "        \n",
    "        # Ensure no empty clusters\n",
    "        if len(cluster_0_indices) == 0:\n",
    "            cluster_0_indices = np.array([cluster_1_indices[0]])\n",
    "            cluster_1_indices = cluster_1_indices[1:]\n",
    "        elif len(cluster_1_indices) == 0:\n",
    "            cluster_1_indices = np.array([cluster_0_indices[0]])\n",
    "            cluster_0_indices = cluster_0_indices[1:]\n",
    "        \n",
    "        # Optional: Balance cluster sizes if one is much larger\n",
    "        if self.balance_clusters:\n",
    "            size_0, size_1 = len(cluster_0_indices), len(cluster_1_indices)\n",
    "            if size_0 > 3 * size_1 and size_1 > 0:\n",
    "                # Move some points from cluster 0 to cluster 1\n",
    "                n_move = (size_0 - size_1) // 4\n",
    "                move_indices = cluster_0_indices[:n_move]\n",
    "                cluster_0_indices = cluster_0_indices[n_move:]\n",
    "                cluster_1_indices = np.concatenate([cluster_1_indices, move_indices])\n",
    "            elif size_1 > 3 * size_0 and size_0 > 0:\n",
    "                # Move some points from cluster 1 to cluster 0\n",
    "                n_move = (size_1 - size_0) // 4\n",
    "                move_indices = cluster_1_indices[:n_move]\n",
    "                cluster_1_indices = cluster_1_indices[n_move:]\n",
    "                cluster_0_indices = np.concatenate([cluster_0_indices, move_indices])\n",
    "        \n",
    "        return [cluster_0_indices, cluster_1_indices]\n",
    "    \n",
    "    def _find_approximate_farthest_pair(self, coords):\n",
    "        \"\"\"Find approximate farthest pair for large clusters.\"\"\"\n",
    "        n_points = len(coords)\n",
    "        \n",
    "        if n_points <= 100:\n",
    "            # For moderate sizes, use exact calculation\n",
    "            distances = self.haversine_pdist(coords)\n",
    "            distance_matrix = squareform(distances)\n",
    "            max_idx = np.unravel_index(np.argmax(distance_matrix), distance_matrix.shape)\n",
    "            return max_idx[0], max_idx[1]\n",
    "        \n",
    "        # For large clusters, use sampling\n",
    "        sample_size = min(50, n_points)\n",
    "        sample_indices = np.random.choice(n_points, sample_size, replace=False)\n",
    "        sample_coords = coords[sample_indices]\n",
    "        \n",
    "        distances = self.haversine_pdist(sample_coords)\n",
    "        distance_matrix = squareform(distances)\n",
    "        max_idx = np.unravel_index(np.argmax(distance_matrix), distance_matrix.shape)\n",
    "        \n",
    "        return sample_indices[max_idx[0]], sample_indices[max_idx[1]]\n",
    "    \n",
    "    def divisive_clustering(self, customers_df):\n",
    "        \"\"\"Perform optimized divisive hierarchical clustering.\"\"\"\n",
    "        customers_df = customers_df.copy().reset_index(drop=True)\n",
    "        \n",
    "        # Validate input\n",
    "        if 'Latitude' not in customers_df.columns or 'Longitude' not in customers_df.columns:\n",
    "            raise ValueError(\"DataFrame must contain 'Latitude' and 'Longitude' columns\")\n",
    "        \n",
    "        coords_array = customers_df[['Latitude', 'Longitude']].values\n",
    "        n_customers = len(customers_df)\n",
    "        \n",
    "        if n_customers == 0:\n",
    "            customers_df['cluster'] = []\n",
    "            return customers_df\n",
    "        \n",
    "        if n_customers == 1:\n",
    "            customers_df['cluster'] = 1\n",
    "            return customers_df\n",
    "        \n",
    "        # Priority queue approach for better clustering\n",
    "        clusters_to_process = [(n_customers, np.arange(n_customers))]  # (size, indices)\n",
    "        final_clusters = []\n",
    "        \n",
    "        iteration_count = 0\n",
    "        max_iterations = n_customers * 2\n",
    "        \n",
    "        while clusters_to_process and iteration_count < max_iterations:\n",
    "            # Process largest cluster first\n",
    "            clusters_to_process.sort(key=lambda x: x[0], reverse=True)\n",
    "            current_size, current_cluster_indices = clusters_to_process.pop(0)\n",
    "            iteration_count += 1\n",
    "            \n",
    "            if self.should_split_cluster(current_cluster_indices, coords_array):\n",
    "                subclusters = self.geographic_split(current_cluster_indices, coords_array)\n",
    "                \n",
    "                for subcluster_indices in subclusters:\n",
    "                    if len(subcluster_indices) > 0:\n",
    "                        clusters_to_process.append((len(subcluster_indices), subcluster_indices))\n",
    "            else:\n",
    "                final_clusters.append(current_cluster_indices)\n",
    "        \n",
    "        # Handle remaining clusters\n",
    "        final_clusters.extend([indices for _, indices in clusters_to_process])\n",
    "        \n",
    "        # Create result DataFrame\n",
    "        result_df = customers_df.copy()\n",
    "        result_df['cluster'] = -1\n",
    "        \n",
    "        for cluster_id, cluster_indices in enumerate(final_clusters, 1):\n",
    "            result_df.loc[cluster_indices, 'cluster'] = cluster_id\n",
    "        \n",
    "        return result_df\n",
    "    \n",
    "    def get_cluster_stats(self, clustered_df):\n",
    "        \"\"\"Get comprehensive clustering statistics.\"\"\"\n",
    "        if 'cluster' not in clustered_df.columns:\n",
    "            raise ValueError(\"DataFrame must contain 'cluster' column\")\n",
    "        \n",
    "        stats = {}\n",
    "        cluster_sizes = []\n",
    "        cluster_diameters = []\n",
    "        \n",
    "        for cluster_id in clustered_df['cluster'].unique():\n",
    "            if cluster_id == -1:\n",
    "                continue\n",
    "                \n",
    "            cluster_data = clustered_df[clustered_df['cluster'] == cluster_id]\n",
    "            coords = cluster_data[['Latitude', 'Longitude']].values\n",
    "            \n",
    "            diameter = self.calculate_cluster_diameter_fast(coords)\n",
    "            cluster_sizes.append(len(cluster_data))\n",
    "            cluster_diameters.append(diameter)\n",
    "            \n",
    "            stats[cluster_id] = {\n",
    "                'size': len(cluster_data),\n",
    "                'diameter_km': diameter,\n",
    "                'centroid_lat': np.mean(coords[:, 0]),\n",
    "                'centroid_lon': np.mean(coords[:, 1]),\n",
    "                'meets_size_constraint': len(cluster_data) <= self.max_customers_per_cluster,\n",
    "                'meets_distance_constraint': diameter <= self.max_distance_km\n",
    "            }\n",
    "        \n",
    "        # Overall statistics\n",
    "        stats['summary'] = {\n",
    "            'total_clusters': len(stats) - 1,  # Excluding summary\n",
    "            'avg_cluster_size': np.mean(cluster_sizes),\n",
    "            'max_cluster_size': np.max(cluster_sizes),\n",
    "            'min_cluster_size': np.min(cluster_sizes),\n",
    "            'avg_diameter': np.mean(cluster_diameters),\n",
    "            'max_diameter': np.max(cluster_diameters),\n",
    "            'size_violations': sum(1 for size in cluster_sizes if size > self.max_customers_per_cluster),\n",
    "            'distance_violations': sum(1 for diameter in cluster_diameters if diameter > self.max_distance_km)\n",
    "        }\n",
    "        \n",
    "        return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d40e0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92b015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.cluster.hierarchy import fcluster, linkage\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from numba import jit, prange\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Fixed Enhanced Geographic Clustering\n",
    "class OptimizedDivisiveGeographicClustering_be:\n",
    "    def __init__(self, max_customers_per_cluster=20, max_distance_km=50, \n",
    "                 use_vectorized_distances=True, balance_clusters=False):\n",
    "        self.max_customers_per_cluster = max_customers_per_cluster\n",
    "        self.max_distance_km = max_distance_km\n",
    "        self.earth_radius_km = 6371.0\n",
    "        self.use_vectorized_distances = use_vectorized_distances\n",
    "        self.balance_clusters = balance_clusters\n",
    "        self._distance_cache = {}\n",
    "        \n",
    "    @staticmethod\n",
    "    @jit(nopython=True, fastmath=True, parallel=True)\n",
    "    def numba_haversine(coords1, coords2, radius):\n",
    "        \"\"\"JIT-optimized haversine distance calculation\"\"\"\n",
    "        n1 = coords1.shape[0]\n",
    "        n2 = coords2.shape[0] if coords2 is not None else n1\n",
    "        dists = np.empty((n1, n2), dtype=np.float64)\n",
    "        \n",
    "        for i in prange(n1):\n",
    "            lat1 = np.radians(coords1[i, 0])\n",
    "            lon1 = np.radians(coords1[i, 1])\n",
    "            \n",
    "            for j in range(n2):\n",
    "                if coords2 is None:\n",
    "                    lat2 = np.radians(coords1[j, 0])\n",
    "                    lon2 = np.radians(coords1[j, 1])\n",
    "                else:\n",
    "                    lat2 = np.radians(coords2[j, 0])\n",
    "                    lon2 = np.radians(coords2[j, 1])\n",
    "                    \n",
    "                dlat = lat2 - lat1\n",
    "                dlon = lon2 - lon1\n",
    "                \n",
    "                a = (np.sin(dlat/2)**2 + \n",
    "                     np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2)**2)\n",
    "                c = 2 * np.arcsin(np.sqrt(min(1.0, a)))\n",
    "                dists[i, j] = radius * c\n",
    "                \n",
    "        return dists\n",
    "\n",
    "    def haversine_vectorized(self, coords1, coords2=None, use_cache=False):\n",
    "        \"\"\"Optimized distance calculation with caching and Numba acceleration\"\"\"\n",
    "        cache_key = None\n",
    "        if use_cache and coords2 is None:\n",
    "            cache_key = tuple(map(tuple, coords1))\n",
    "            if cache_key in self._distance_cache:\n",
    "                return self._distance_cache[cache_key]\n",
    "        \n",
    "        if coords1.size < 500:  # Use Numba for smaller datasets\n",
    "            result = self.numba_haversine(coords1, coords2, self.earth_radius_km)\n",
    "        else:\n",
    "            # Use vectorized calculation for larger datasets\n",
    "            if coords2 is None:\n",
    "                coords_rad = np.radians(coords1)\n",
    "                lat = coords_rad[:, 0]\n",
    "                lon = coords_rad[:, 1]\n",
    "                dlat = lat[:, None] - lat\n",
    "                dlon = lon[:, None] - lon\n",
    "                \n",
    "                a = (np.sin(dlat/2)**2 + \n",
    "                     np.cos(lat[:, None]) * np.cos(lat) * np.sin(dlon/2)**2)\n",
    "            else:\n",
    "                coords1_rad = np.radians(coords1)\n",
    "                coords2_rad = np.radians(coords2)\n",
    "                dlat = coords1_rad[:, 0, None] - coords2_rad[:, 0]\n",
    "                dlon = coords1_rad[:, 1, None] - coords2_rad[:, 1]\n",
    "                \n",
    "                a = (np.sin(dlat/2)**2 + \n",
    "                     np.cos(coords1_rad[:, 0, None]) * \n",
    "                     np.cos(coords2_rad[:, 0]) * \n",
    "                     np.sin(dlon/2)**2)\n",
    "            \n",
    "            result = self.earth_radius_km * 2 * np.arcsin(np.sqrt(np.clip(a, 0, 1)))\n",
    "        \n",
    "        if cache_key is not None:\n",
    "            self._distance_cache[cache_key] = result\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    def haversine_single_pair(self, coord1, coord2):\n",
    "        \"\"\"Calculate haversine distance between two points.\"\"\"\n",
    "        lat1, lon1 = np.radians(coord1)\n",
    "        lat2, lon2 = np.radians(coord2)\n",
    "        \n",
    "        dlat = lat2 - lat1\n",
    "        dlon = lon2 - lon1\n",
    "        \n",
    "        a = (np.sin(dlat / 2) ** 2 + \n",
    "             np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2)\n",
    "        c = 2 * np.arcsin(np.sqrt(np.clip(a, 0, 1)))\n",
    "        \n",
    "        return self.earth_radius_km * c \n",
    "\n",
    "    def haversine_pdist(self, coords):\n",
    "        \"\"\"Calculate pairwise distances using scipy format\"\"\"\n",
    "        n = len(coords)\n",
    "        distances = []\n",
    "        for i in range(n):\n",
    "            for j in range(i + 1, n):\n",
    "                dist = self.haversine_single_pair(coords[i], coords[j])\n",
    "                distances.append(dist)\n",
    "        return np.array(distances)\n",
    "\n",
    "    def calculate_cluster_diameter_fast(self, coords):\n",
    "        \"\"\"Optimized diameter calculation with adaptive strategy\"\"\"\n",
    "        n = len(coords)\n",
    "        if n <= 1: \n",
    "            return 0\n",
    "        if n == 2:\n",
    "            return self.haversine_single_pair(coords[0], coords[1])\n",
    "        \n",
    "        # Use convex hull approximation for medium clusters\n",
    "        if n <= 100:\n",
    "            return self._convex_hull_diameter(coords)\n",
    "            \n",
    "        # Use grid-based sampling for large clusters\n",
    "        return self._grid_based_diameter(coords)\n",
    "\n",
    "    def _convex_hull_diameter(self, coords):\n",
    "        \"\"\"Calculate diameter using convex hull approximation\"\"\"\n",
    "        try:\n",
    "            from scipy.spatial import ConvexHull\n",
    "            if len(coords) < 3:\n",
    "                return max(self.haversine_single_pair(coords[i], coords[j]) \n",
    "                          for i in range(len(coords)) for j in range(i+1, len(coords)))\n",
    "            \n",
    "            hull = ConvexHull(coords)\n",
    "            hull_points = coords[hull.vertices]\n",
    "            \n",
    "            max_distance = 0\n",
    "            for i in range(len(hull_points)):\n",
    "                for j in range(i + 1, len(hull_points)):\n",
    "                    distance = self.haversine_single_pair(hull_points[i], hull_points[j])\n",
    "                    max_distance = max(max_distance, distance)\n",
    "            \n",
    "            return max_distance\n",
    "        except:\n",
    "            # Fallback to brute force for small clusters\n",
    "            return self._brute_force_diameter(coords)\n",
    "\n",
    "    def _grid_based_diameter(self, coords):\n",
    "        \"\"\"Use grid-based sampling for large clusters\"\"\"\n",
    "        n_sample = min(50, len(coords))\n",
    "        sample_indices = np.random.choice(len(coords), n_sample, replace=False)\n",
    "        sample_coords = coords[sample_indices]\n",
    "        return self._brute_force_diameter(sample_coords)\n",
    "\n",
    "    def _brute_force_diameter(self, coords):\n",
    "        \"\"\"Calculate exact diameter using brute force\"\"\"\n",
    "        max_distance = 0\n",
    "        n = len(coords)\n",
    "        for i in range(n):\n",
    "            for j in range(i + 1, n):\n",
    "                distance = self.haversine_single_pair(coords[i], coords[j])\n",
    "                max_distance = max(max_distance, distance)\n",
    "        return max_distance\n",
    "\n",
    "    def should_split_cluster(self, cluster_indices, coords_array):\n",
    "        \"\"\"Determine if a cluster should be split\"\"\"\n",
    "        n_points = len(cluster_indices)\n",
    "        \n",
    "        # Size constraint\n",
    "        if n_points <= self.max_customers_per_cluster:\n",
    "            return False\n",
    "        \n",
    "        # Distance constraint\n",
    "        cluster_coords = coords_array[cluster_indices]\n",
    "        diameter = self.calculate_cluster_diameter_fast(cluster_coords)\n",
    "        \n",
    "        if diameter <= self.max_distance_km:\n",
    "            return False\n",
    "            \n",
    "        return True\n",
    "\n",
    "    def geographic_split(self, cluster_indices, coords_array):\n",
    "        \"\"\"Enhanced splitting with DBSCAN for outlier handling\"\"\"\n",
    "        n_points = len(cluster_indices)\n",
    "        if n_points <= 2:\n",
    "            return [cluster_indices]\n",
    "            \n",
    "        cluster_coords = coords_array[cluster_indices]\n",
    "        \n",
    "        # Handle outliers with DBSCAN for large clusters\n",
    "        if n_points > 100:\n",
    "            try:\n",
    "                # Create distance matrix for DBSCAN\n",
    "                distances = self.haversine_vectorized(cluster_coords)\n",
    "                dbscan = DBSCAN(eps=self.max_distance_km/2, min_samples=3, \n",
    "                               metric='precomputed')\n",
    "                labels = dbscan.fit_predict(distances)\n",
    "                \n",
    "                if len(np.unique(labels[labels != -1])) > 1:\n",
    "                    return self._balance_split(cluster_indices, labels)\n",
    "            except:\n",
    "                pass  # Fall back to other methods\n",
    "        \n",
    "        # Small clusters: exact method\n",
    "        if n_points <= 50:\n",
    "            return self._exact_geographic_split(cluster_indices, cluster_coords)\n",
    "            \n",
    "        # Medium clusters: k-means with improved initialization\n",
    "        if n_points <= 200:\n",
    "            return self._kmeans_geographic_split(cluster_indices, cluster_coords)\n",
    "            \n",
    "        # Large clusters: hierarchical with complete linkage\n",
    "        return self._hierarchical_geographic_split(cluster_indices, cluster_coords)\n",
    "\n",
    "    def _exact_geographic_split(self, cluster_indices, cluster_coords):\n",
    "        \"\"\"Exact splitting for small clusters\"\"\"\n",
    "        if len(cluster_coords) <= 2:\n",
    "            return [cluster_indices]\n",
    "        \n",
    "        # Find the two points that are farthest apart\n",
    "        max_distance = 0\n",
    "        best_pair = (0, 1)\n",
    "        \n",
    "        for i in range(len(cluster_coords)):\n",
    "            for j in range(i + 1, len(cluster_coords)):\n",
    "                distance = self.haversine_single_pair(cluster_coords[i], cluster_coords[j])\n",
    "                if distance > max_distance:\n",
    "                    max_distance = distance\n",
    "                    best_pair = (i, j)\n",
    "        \n",
    "        # Assign points to the closer of the two centers\n",
    "        center1 = cluster_coords[best_pair[0]]\n",
    "        center2 = cluster_coords[best_pair[1]]\n",
    "        \n",
    "        labels = np.zeros(len(cluster_coords))\n",
    "        for i, coord in enumerate(cluster_coords):\n",
    "            dist1 = self.haversine_single_pair(coord, center1)\n",
    "            dist2 = self.haversine_single_pair(coord, center2)\n",
    "            labels[i] = 0 if dist1 <= dist2 else 1\n",
    "        \n",
    "        return self._balance_split(cluster_indices, labels)\n",
    "\n",
    "    def _kmeans_geographic_split(self, cluster_indices, cluster_coords):\n",
    "        \"\"\"K-means splitting for medium clusters\"\"\"\n",
    "        try:\n",
    "            # Use geographic coordinates directly for K-means\n",
    "            kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "            labels = kmeans.fit_predict(cluster_coords)\n",
    "            return self._balance_split(cluster_indices, labels)\n",
    "        except:\n",
    "            # Fallback to exact method\n",
    "            return self._exact_geographic_split(cluster_indices, cluster_coords)\n",
    "\n",
    "    def _hierarchical_geographic_split(self, cluster_indices, cluster_coords):\n",
    "        \"\"\"Improved hierarchical splitting with complete linkage\"\"\"\n",
    "        n_sample = min(150, len(cluster_coords))\n",
    "        sample_indices = np.random.choice(len(cluster_coords), n_sample, replace=False)\n",
    "        sample_coords = cluster_coords[sample_indices]\n",
    "        \n",
    "        distances = self.haversine_pdist(sample_coords)\n",
    "        linkage_matrix = linkage(distances, method='complete')\n",
    "        sample_labels = fcluster(linkage_matrix, 2, criterion='maxclust') - 1\n",
    "        \n",
    "        # Assign based on nearest cluster center\n",
    "        center1 = np.mean(sample_coords[sample_labels == 0], axis=0)\n",
    "        center2 = np.mean(sample_coords[sample_labels == 1], axis=0)\n",
    "        \n",
    "        dist_to_center1 = self.haversine_vectorized(cluster_coords, center1.reshape(1, -1))[:, 0]\n",
    "        dist_to_center2 = self.haversine_vectorized(cluster_coords, center2.reshape(1, -1))[:, 0]\n",
    "        labels = (dist_to_center1 <= dist_to_center2).astype(int)\n",
    "        \n",
    "        return self._balance_split(cluster_indices, labels)\n",
    "\n",
    "    def _balance_split(self, cluster_indices, labels):\n",
    "        \"\"\"Proximity-based balancing for spatial coherence\"\"\"\n",
    "        unique_labels = np.unique(labels)\n",
    "        if len(unique_labels) == 1:\n",
    "            # All points have same label, split arbitrarily\n",
    "            mid = len(cluster_indices) // 2\n",
    "            return [cluster_indices[:mid], cluster_indices[mid:]]\n",
    "        \n",
    "        # Handle noise points from DBSCAN (label -1)\n",
    "        if -1 in unique_labels:\n",
    "            noise_mask = labels == -1\n",
    "            valid_labels = labels[~noise_mask]\n",
    "            if len(np.unique(valid_labels)) == 0:\n",
    "                return [cluster_indices]\n",
    "            \n",
    "            # Assign noise points to nearest valid cluster\n",
    "            for i in np.where(noise_mask)[0]:\n",
    "                # Find nearest non-noise point\n",
    "                distances = []\n",
    "                for j in np.where(~noise_mask)[0]:\n",
    "                    dist = self.haversine_single_pair(\n",
    "                        self.full_coords_array[cluster_indices[i]], \n",
    "                        self.full_coords_array[cluster_indices[j]]\n",
    "                    )\n",
    "                    distances.append((dist, labels[j]))\n",
    "                \n",
    "                if distances:\n",
    "                    labels[i] = min(distances, key=lambda x: x[0])[1]\n",
    "        \n",
    "        # Create clusters based on labels\n",
    "        clusters = []\n",
    "        for label in np.unique(labels):\n",
    "            if label != -1:  # Skip noise label\n",
    "                cluster_mask = labels == label\n",
    "                cluster = cluster_indices[cluster_mask]\n",
    "                if len(cluster) > 0:\n",
    "                    clusters.append(cluster)\n",
    "        \n",
    "        if len(clusters) == 0:\n",
    "            return [cluster_indices]\n",
    "        elif len(clusters) == 1:\n",
    "            # Split the single cluster arbitrarily\n",
    "            cluster = clusters[0]\n",
    "            mid = len(cluster) // 2\n",
    "            return [cluster[:mid], cluster[mid:]]\n",
    "        else:\n",
    "            # Balance clusters if enabled\n",
    "            if self.balance_clusters and len(clusters) == 2:\n",
    "                return self._balance_two_clusters(clusters[0], clusters[1])\n",
    "            return clusters\n",
    "\n",
    "    def _balance_two_clusters(self, cluster_0, cluster_1):\n",
    "        \"\"\"Balance two clusters by size\"\"\"\n",
    "        size0, size1 = len(cluster_0), len(cluster_1)\n",
    "        \n",
    "        if size0 <= 2 * size1 and size1 <= 2 * size0:\n",
    "            return [cluster_0, cluster_1]\n",
    "        \n",
    "        coords0 = self.full_coords_array[cluster_0]\n",
    "        coords1 = self.full_coords_array[cluster_1]\n",
    "        \n",
    "        # Balance only when size difference is significant\n",
    "        if size0 > 2 * size1:\n",
    "            center1 = np.mean(coords1, axis=0)\n",
    "            dist_to_center1 = self.haversine_vectorized(coords0, center1.reshape(1, -1))[:, 0]\n",
    "            n_move = min((size0 - size1) // 2, max(1, size1))\n",
    "            move_idx = np.argsort(dist_to_center1)[:n_move]\n",
    "            cluster_1 = np.concatenate([cluster_1, cluster_0[move_idx]])\n",
    "            cluster_0 = np.delete(cluster_0, move_idx)\n",
    "            \n",
    "        elif size1 > 2 * size0:\n",
    "            center0 = np.mean(coords0, axis=0)\n",
    "            dist_to_center0 = self.haversine_vectorized(coords1, center0.reshape(1, -1))[:, 0]\n",
    "            n_move = min((size1 - size0) // 2, max(1, size0))\n",
    "            move_idx = np.argsort(dist_to_center0)[:n_move]\n",
    "            cluster_0 = np.concatenate([cluster_0, cluster_1[move_idx]])\n",
    "            cluster_1 = np.delete(cluster_1, move_idx)\n",
    "            \n",
    "        return [cluster_0, cluster_1]\n",
    "\n",
    "    def divisive_clustering(self, customers_df):\n",
    "        \"\"\"Main clustering with cache management\"\"\" \n",
    "        customers_df = customers_df.copy().reset_index(drop=True)\n",
    "        \n",
    "        # Validate input\n",
    "        if 'Latitude' not in customers_df.columns or 'Longitude' not in customers_df.columns:\n",
    "            raise ValueError(\"DataFrame must contain 'Latitude' and 'Longitude' columns\")\n",
    "        \n",
    "        coords_array = customers_df[['Latitude', 'Longitude']].values\n",
    "        n_customers = len(customers_df)\n",
    "        \n",
    "        self.full_coords_array = coords_array\n",
    "        self._distance_cache = {}  # Reset cache\n",
    "        \n",
    "        if n_customers == 0:\n",
    "            customers_df['cluster'] = []\n",
    "            return customers_df\n",
    "        \n",
    "        if n_customers == 1:\n",
    "            customers_df['cluster'] = 1\n",
    "            return customers_df\n",
    "        \n",
    "        # Priority queue approach for better clustering\n",
    "        clusters_to_process = [(n_customers, np.arange(n_customers))]  # (size, indices)\n",
    "        final_clusters = []\n",
    "        \n",
    "        iteration_count = 0\n",
    "        max_iterations = n_customers * 2\n",
    "        \n",
    "        while clusters_to_process and iteration_count < max_iterations:\n",
    "            # Process largest cluster first\n",
    "            clusters_to_process.sort(key=lambda x: x[0], reverse=True)\n",
    "            current_size, current_cluster_indices = clusters_to_process.pop(0)\n",
    "            iteration_count += 1\n",
    "            \n",
    "            if self.should_split_cluster(current_cluster_indices, coords_array):\n",
    "                subclusters = self.geographic_split(current_cluster_indices, coords_array)\n",
    "                \n",
    "                for subcluster_indices in subclusters:\n",
    "                    if len(subcluster_indices) > 0:\n",
    "                        clusters_to_process.append((len(subcluster_indices), subcluster_indices))\n",
    "            else:\n",
    "                final_clusters.append(current_cluster_indices)\n",
    "        \n",
    "        # Handle remaining clusters\n",
    "        final_clusters.extend([indices for _, indices in clusters_to_process])\n",
    "        \n",
    "        # Create result DataFrame\n",
    "        result_df = customers_df.copy()\n",
    "        result_df['cluster'] = -1\n",
    "        \n",
    "        for cluster_id, cluster_indices in enumerate(final_clusters, 1):\n",
    "            result_df.loc[cluster_indices, 'cluster'] = cluster_id\n",
    "        \n",
    "        # Clean up stored data\n",
    "        if hasattr(self, 'full_coords_array'):\n",
    "            del self.full_coords_array\n",
    "        self._distance_cache = {}\n",
    "\n",
    "        return result_df\n",
    "    \n",
    "    def get_cluster_stats(self, clustered_df):\n",
    "        \"\"\"Get comprehensive clustering statistics.\"\"\"\n",
    "        if 'cluster' not in clustered_df.columns:\n",
    "            raise ValueError(\"DataFrame must contain 'cluster' column\")\n",
    "        \n",
    "        stats = {}\n",
    "        cluster_sizes = []\n",
    "        cluster_diameters = []\n",
    "        \n",
    "        for cluster_id in clustered_df['cluster'].unique():\n",
    "            if cluster_id == -1:\n",
    "                continue\n",
    "                \n",
    "            cluster_data = clustered_df[clustered_df['cluster'] == cluster_id]\n",
    "            coords = cluster_data[['Latitude', 'Longitude']].values\n",
    "            \n",
    "            diameter = self.calculate_cluster_diameter_fast(coords)\n",
    "            cluster_sizes.append(len(cluster_data))\n",
    "            cluster_diameters.append(diameter)\n",
    "            \n",
    "            stats[cluster_id] = {\n",
    "                'size': len(cluster_data),\n",
    "                'diameter_km': diameter,\n",
    "                'centroid_lat': np.mean(coords[:, 0]),\n",
    "                'centroid_lon': np.mean(coords[:, 1]),\n",
    "                'meets_size_constraint': len(cluster_data) <= self.max_customers_per_cluster,\n",
    "                'meets_distance_constraint': diameter <= self.max_distance_km\n",
    "            }\n",
    "        \n",
    "        # Overall statistics\n",
    "        if cluster_sizes:  # Only calculate if there are clusters\n",
    "            stats['summary'] = {\n",
    "                'total_clusters': len(stats) - 1,  # Excluding summary key\n",
    "                'avg_cluster_size': np.mean(cluster_sizes),\n",
    "                'max_cluster_size': np.max(cluster_sizes),\n",
    "                'min_cluster_size': np.min(cluster_sizes),\n",
    "                'avg_diameter': np.mean(cluster_diameters),\n",
    "                'max_diameter': np.max(cluster_diameters),\n",
    "                'size_violations': sum(1 for size in cluster_sizes if size > self.max_customers_per_cluster),\n",
    "                'distance_violations': sum(1 for diameter in cluster_diameters if diameter > self.max_distance_km)\n",
    "            }\n",
    "        else:\n",
    "            stats['summary'] = {\n",
    "                'total_clusters': 0,\n",
    "                'avg_cluster_size': 0,\n",
    "                'max_cluster_size': 0,\n",
    "                'min_cluster_size': 0,\n",
    "                'avg_diameter': 0,\n",
    "                'max_diameter': 0,\n",
    "                'size_violations': 0,\n",
    "                'distance_violations': 0\n",
    "            }\n",
    "        \n",
    "        return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98368b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import numba\n",
    "\n",
    "### Fastest\n",
    "class OptimizedDivisiveGeographicClustering_fast:\n",
    "    def __init__(self, max_customers_per_cluster=20, max_distance_km=50):\n",
    "        self.max_customers_per_cluster = max_customers_per_cluster\n",
    "        self.max_distance_km = max_distance_km\n",
    "        self.earth_radius_km = 6371.0\n",
    "\n",
    "    @staticmethod\n",
    "    @numba.njit(fastmath=True)\n",
    "    def haversine_single_pair(lat1, lon1, lat2, lon2):\n",
    "        \"\"\"Numba-optimized haversine distance between two points.\"\"\"\n",
    "        lat1, lon1, lat2, lon2 = np.radians([lat1, lon1, lat2, lon2])\n",
    "        dlat = lat2 - lat1\n",
    "        dlon = lon2 - lon1\n",
    "        a = np.sin(dlat/2)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2)**2\n",
    "        return 6371.0 * 2 * np.arcsin(np.sqrt(min(1.0, a)))\n",
    "    \n",
    "    @staticmethod\n",
    "    @numba.njit(fastmath=True, parallel=True)\n",
    "    def haversine_vectorized(coord, coords):\n",
    "        \"\"\"Vectorized haversine distance from one point to many.\"\"\"\n",
    "        lat1, lon1 = np.radians(coord)\n",
    "        dists = np.empty(coords.shape[0])\n",
    "        for i in numba.prange(coords.shape[0]):\n",
    "            lat2, lon2 = np.radians(coords[i])\n",
    "            dlat = lat2 - lat1\n",
    "            dlon = lon2 - lon1\n",
    "            a = np.sin(dlat/2)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2)**2\n",
    "            dists[i] = 6371.0 * 2 * np.arcsin(np.sqrt(min(1.0, a)))\n",
    "        return dists\n",
    "\n",
    "    def compute_diameter_and_farthest_pair(self, coords):\n",
    "        \"\"\"Compute diameter and farthest pair with optimal strategy.\"\"\"\n",
    "        n = len(coords)\n",
    "        if n <= 100:  # Exact for small clusters\n",
    "            dists = self.haversine_pdist(coords)\n",
    "            dist_matrix = squareform(dists)\n",
    "            max_idx = np.unravel_index(np.argmax(dist_matrix), dist_matrix.shape)\n",
    "            return dist_matrix[max_idx], max_idx\n",
    "        else:  # Approximate for large clusters\n",
    "            return self._two_pass_approximation(coords)\n",
    "\n",
    "    def _two_pass_approximation(self, coords):\n",
    "        \"\"\"Two-pass algorithm for approximate diameter and farthest pair.\"\"\"\n",
    "        # First pass: random point to farthest point\n",
    "        idx0 = np.random.randint(len(coords))\n",
    "        dists = self.haversine_vectorized(coords[idx0], coords)\n",
    "        idx1 = np.argmax(dists)\n",
    "        \n",
    "        # Second pass: farthest point to its farthest point\n",
    "        dists = self.haversine_vectorized(coords[idx1], coords)\n",
    "        idx2 = np.argmax(dists)\n",
    "        diameter = dists[idx2]\n",
    "        \n",
    "        return diameter, (idx1, idx2)\n",
    "\n",
    "    def haversine_pdist(self, coords):\n",
    "        \"\"\"Optimized haversine pairwise distances using vectorization.\"\"\"\n",
    "        n = coords.shape[0]\n",
    "        dists = np.zeros(n*(n-1)//2)\n",
    "        k = 0\n",
    "        for i in range(n):\n",
    "            dists_i = self.haversine_vectorized(coords[i], coords[i+1:])\n",
    "            dists[k:k+len(dists_i)] = dists_i\n",
    "            k += len(dists_i)\n",
    "        return dists\n",
    "\n",
    "    def should_split_cluster(self, cluster_indices, coords_array):\n",
    "        \"\"\"Determine if cluster should be split with early termination.\"\"\"\n",
    "        cluster_size = len(cluster_indices)\n",
    "        \n",
    "        if cluster_size <= 1:\n",
    "            return False, None\n",
    "            \n",
    "        if cluster_size > self.max_customers_per_cluster:\n",
    "            return True, None  # Size violation\n",
    "        \n",
    "        # Check diameter constraint\n",
    "        cluster_coords = coords_array[cluster_indices]\n",
    "        diameter, farthest_pair = self.compute_diameter_and_farthest_pair(cluster_coords)\n",
    "        return diameter > self.max_distance_km, farthest_pair\n",
    "\n",
    "    def geographic_split(self, cluster_indices, coords_array, farthest_pair=None):\n",
    "        \"\"\"Efficient cluster splitting with optional precomputed centers.\"\"\"\n",
    "        cluster_coords = coords_array[cluster_indices]\n",
    "        n = len(cluster_coords)\n",
    "        \n",
    "        # Get or compute farthest pair\n",
    "        if farthest_pair is None:\n",
    "            if n <= 100:\n",
    "                _, farthest_pair = self.compute_diameter_and_farthest_pair(cluster_coords)\n",
    "            else:\n",
    "                _, farthest_pair = self._two_pass_approximation(cluster_coords)\n",
    "        \n",
    "        center1_idx, center2_idx = farthest_pair\n",
    "        center1 = cluster_coords[center1_idx]\n",
    "        center2 = cluster_coords[center2_idx]\n",
    "        \n",
    "        # Vectorized distance calculations\n",
    "        dists1 = self.haversine_vectorized(center1, cluster_coords)\n",
    "        dists2 = self.haversine_vectorized(center2, cluster_coords)\n",
    "        labels = (dists1 <= dists2).astype(int)\n",
    "        \n",
    "        # Create subclusters\n",
    "        mask = labels.astype(bool)\n",
    "        cluster_a = cluster_indices[mask]\n",
    "        cluster_b = cluster_indices[~mask]\n",
    "        \n",
    "        # Balance clusters if needed\n",
    "        if len(cluster_a) == 0 or len(cluster_b) == 0:\n",
    "            return self._split_fallback(cluster_indices, cluster_coords)\n",
    "            \n",
    "        return [cluster_a, cluster_b]\n",
    "\n",
    "    def _split_fallback(self, cluster_indices, cluster_coords):\n",
    "        \"\"\"Fallback split when primary method fails.\"\"\"\n",
    "        # Use longitude-based split as fallback\n",
    "        sorted_idx = np.argsort(cluster_coords[:, 1])\n",
    "        mid = len(sorted_idx) // 2\n",
    "        return [\n",
    "            cluster_indices[sorted_idx[:mid]],\n",
    "            cluster_indices[sorted_idx[mid:]]\n",
    "        ]\n",
    "\n",
    "    def divisive_clustering(self, customers_df):\n",
    "        \"\"\"Optimized divisive clustering with efficient diameter checks.\"\"\"\n",
    "        # Initialization and validation\n",
    "        if 'Latitude' not in customers_df or 'Longitude' not in customers_df:\n",
    "            raise ValueError(\"Missing Latitude/Longitude columns\")\n",
    "            \n",
    "        coords_array = customers_df[['Latitude', 'Longitude']].values\n",
    "        n = len(customers_df)\n",
    "        \n",
    "        # Edge cases\n",
    "        if n == 0:\n",
    "            return customers_df.assign(cluster=pd.Series(dtype=int))\n",
    "        if n == 1:\n",
    "            return customers_df.assign(cluster=1)\n",
    "        \n",
    "        # Initialize clustering\n",
    "        clusters_to_process = [np.arange(n)]\n",
    "        final_clusters = []\n",
    "        \n",
    "        # Process clusters\n",
    "        while clusters_to_process:\n",
    "            current = clusters_to_process.pop(0)\n",
    "            should_split, farthest_pair = self.should_split_cluster(current, coords_array)\n",
    "            \n",
    "            if should_split:\n",
    "                subclusters = self.geographic_split(\n",
    "                    current, coords_array, farthest_pair\n",
    "                )\n",
    "                clusters_to_process.extend(subclusters)\n",
    "            else:\n",
    "                final_clusters.append(current)\n",
    "        \n",
    "        # Assign cluster labels\n",
    "        cluster_labels = np.zeros(n, dtype=int)\n",
    "        for idx, cluster in enumerate(final_clusters, 1):\n",
    "            cluster_labels[cluster] = idx\n",
    "            \n",
    "        return customers_df.assign(cluster=cluster_labels)\n",
    "\n",
    "    def get_cluster_stats(self, clustered_df):\n",
    "        \"\"\"Get comprehensive clustering statistics.\"\"\"\n",
    "        if 'cluster' not in clustered_df.columns:\n",
    "            raise ValueError(\"DataFrame must contain 'cluster' column\")\n",
    "        \n",
    "        stats = {}\n",
    "        cluster_sizes = []\n",
    "        cluster_diameters = []\n",
    "        \n",
    "        for cluster_id in clustered_df['cluster'].unique():\n",
    "            if cluster_id == -1:\n",
    "                continue\n",
    "                \n",
    "            cluster_data = clustered_df[clustered_df['cluster'] == cluster_id]\n",
    "            coords = cluster_data[['Latitude', 'Longitude']].values\n",
    "            n_points = len(coords)\n",
    "            \n",
    "            # Handle diameter calculation efficiently\n",
    "            if n_points == 0:\n",
    "                diameter = 0.0\n",
    "            elif n_points == 1:\n",
    "                diameter = 0.0\n",
    "            else:\n",
    "                diameter, _ = self.compute_diameter_and_farthest_pair(coords)\n",
    "            \n",
    "            cluster_sizes.append(n_points)\n",
    "            cluster_diameters.append(diameter)\n",
    "            \n",
    "            stats[cluster_id] = {\n",
    "                'size': n_points,\n",
    "                'diameter_km': diameter,\n",
    "                'centroid_lat': np.mean(coords[:, 0]) if n_points > 0 else None,\n",
    "                'centroid_lon': np.mean(coords[:, 1]) if n_points > 0 else None,\n",
    "                'meets_size_constraint': n_points <= self.max_customers_per_cluster,\n",
    "                'meets_distance_constraint': diameter <= self.max_distance_km\n",
    "            }\n",
    "        \n",
    "        # Calculate overall statistics\n",
    "        total_clusters = len(stats)\n",
    "        size_violations = sum(1 for size in cluster_sizes if size > self.max_customers_per_cluster)\n",
    "        distance_violations = sum(1 for d in cluster_diameters if d > self.max_distance_km)\n",
    "        \n",
    "        # Handle empty case\n",
    "        summary = {\n",
    "            'total_clusters': total_clusters,\n",
    "            'size_violations': size_violations,\n",
    "            'distance_violations': distance_violations,\n",
    "        }\n",
    "        \n",
    "        # Add statistical measures only if clusters exist\n",
    "        if cluster_sizes:\n",
    "            summary.update({\n",
    "                'avg_cluster_size': np.mean(cluster_sizes),\n",
    "                'max_cluster_size': np.max(cluster_sizes),\n",
    "                'min_cluster_size': np.min(cluster_sizes),\n",
    "                'avg_diameter': np.mean(cluster_diameters),\n",
    "                'max_diameter': np.max(cluster_diameters),\n",
    "            })\n",
    "        else:\n",
    "            summary.update({\n",
    "                'avg_cluster_size': 0,\n",
    "                'max_cluster_size': 0,\n",
    "                'min_cluster_size': 0,\n",
    "                'avg_diameter': 0,\n",
    "                'max_diameter': 0,\n",
    "            })\n",
    "        \n",
    "        stats['summary'] = summary\n",
    "        return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f978e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2. DIVISIVE HIERARCHICAL CLUSTERING\n",
    "# =============================================================================\n",
    "\n",
    "from clustering.divisive_clustering import DivisiveGeographicClustering, OptimizedDivisiveGeographicClustering\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"2. DIVISIVE HIERARCHICAL CLUSTERING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# divisive_clusterer = OptimizedDivisiveGeographicClustering( # Rivers: Too Long --\n",
    "#     max_customers_per_cluster=20,  # REQUIRED\n",
    "#     max_distance_km=5            # REQUIRED  \n",
    "# ) \n",
    "\n",
    "divisive_clusterer = OptimizedDivisiveGeographicClustering_b( \n",
    "    # Rivers: Divisive clusters created: 48 || Silhouette Score: 0.54 || Constraint violations: Size=6, Distance=3\n",
    "    max_customers_per_cluster=20,  # REQUIRED\n",
    "    max_distance_km=5            # REQUIRED\n",
    "    ,use_vectorized_distances=True, balance_clusters=False\n",
    ")\n",
    "\n",
    "# divisive_clusterer = OptimizedDivisiveGeographicClustering_be( \n",
    "#     # Rivers: Divisive clusters created: 26 || Silhouette Score: 0.57 || Constraint violations: Size=9, Distance=6\n",
    "#     max_customers_per_cluster=20,  # REQUIRED\n",
    "#     max_distance_km=10            # REQUIRED\n",
    "#     ,use_vectorized_distances=True, balance_clusters=False\n",
    "# )\n",
    "\n",
    "# divisive_clusterer = OptimizedDivisiveGeographicClustering_bo( \n",
    "# # Rivers: Divisive clusters created: 60 || Silhouette Score: 0.58 || Constraint violations: Size=9, Distance=7\n",
    "#     max_customers_per_cluster=20,  # REQUIRED\n",
    "#     max_distance_km=5            # REQUIRED \n",
    "# ) \n",
    "\n",
    "# divisive_clusterer = OptimizedDivisiveGeographicClustering_fast(\n",
    "#     # Rivers: Divisive clusters created: 63 || Silhouette Score: 0.46 || Constraint violations: Size=0, Distance=0\n",
    "#     max_customers_per_cluster=20,  # REQUIRED\n",
    "#     max_distance_km=5            # REQUIRED\n",
    "# )\n",
    "\n",
    "# divisive_clusterer = OptimizedDivisiveGeographicClustering_Main( \n",
    "#     # Rivers: Divisive clusters created: 69 ||Silhouette Score: 0.41\n",
    "#     max_customers_per_cluster=20,  # REQUIRED\n",
    "#     max_distance_km=5            # REQUIRED \n",
    "# ) \n",
    "\n",
    "divisive_result = divisive_clusterer.divisive_clustering(df_all_cluster.copy())\n",
    "print(f\"\\nDivisive clusters created: {divisive_result['cluster'].nunique()}\")\n",
    "# print(f\"Cluster sizes: {divisive_result['cluster'].value_counts().sort_index().head()}\")\n",
    "_ = evaluate_unsupervised_clustering(divisive_result)\n",
    "\n",
    "# # Get detailed statistics\n",
    "stats = divisive_clusterer.get_cluster_stats(divisive_result)\n",
    "print(f\"Total clusters: {stats['summary']['total_clusters']}\")\n",
    "print(f\"Constraint violations: Size={stats['summary']['size_violations']}, Distance={stats['summary']['distance_violations']}\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ea47e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "divisive_result.cluster.value_counts().reset_index().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd968c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_and_save(df_routes = divisive_result,\n",
    "                 df_stockpoint = None,   \n",
    "                 filename=None,\n",
    "                 cluster_col = 'cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6a8784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.cluster.hierarchy import fcluster, linkage\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class BaseGeographicClustering:\n",
    "    \"\"\"\n",
    "    A base class containing common geographic utility methods\n",
    "    used by both Divisive and Agglomerative clustering implementations.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.earth_radius_km = 6371.0\n",
    "\n",
    "    def haversine_vectorized(self, coords1, coords2=None):\n",
    "        \"\"\"\n",
    "        Highly optimized vectorized haversine distance calculation.\n",
    "        If coords2 is None, calculates pairwise distances within coords1.\n",
    "        Assumes coords are [latitude, longitude].\n",
    "        \"\"\"\n",
    "        if coords2 is None:\n",
    "            # Pairwise distances within coords1 (NxN matrix)\n",
    "            coords1_rad = np.radians(coords1)\n",
    "            \n",
    "            lat1 = coords1_rad[:, 0]\n",
    "            lon1 = coords1_rad[:, 1]\n",
    "            \n",
    "            lat1_mesh, lat2_mesh = np.meshgrid(lat1, lat1)\n",
    "            lon1_mesh, lon2_mesh = np.meshgrid(lon1, lon1)\n",
    "            \n",
    "            dlat = lat2_mesh - lat1_mesh\n",
    "            dlon = lon2_mesh - lon1_mesh\n",
    "            \n",
    "            a = (np.sin(dlat / 2) ** 2 + \n",
    "                 np.cos(lat1_mesh) * np.cos(lat2_mesh) * np.sin(dlon / 2) ** 2)\n",
    "            c = 2 * np.arcsin(np.sqrt(np.clip(a, 0, 1)))\n",
    "            \n",
    "            return self.earth_radius_km * c\n",
    "        else:\n",
    "            # Distance from each point in coords1 to each point in coords2 (NxM matrix)\n",
    "            coords1_rad = np.radians(coords1)\n",
    "            coords2_rad = np.radians(coords2)\n",
    "            \n",
    "            lat1 = coords1_rad[:, 0][:, np.newaxis]\n",
    "            lon1 = coords1_rad[:, 1][:, np.newaxis]\n",
    "            lat2 = coords2_rad[:, 0][np.newaxis, :]\n",
    "            lon2 = coords2_rad[:, 1][np.newaxis, :]\n",
    "            \n",
    "            dlat = lat2 - lat1\n",
    "            dlon = lon2 - lon1\n",
    "            \n",
    "            a = (np.sin(dlat / 2) ** 2 + \n",
    "                 np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2)\n",
    "            c = 2 * np.arcsin(np.sqrt(np.clip(a, 0, 1)))\n",
    "            \n",
    "            return self.earth_radius_km * c\n",
    "    \n",
    "    def haversine_pdist(self, coords):\n",
    "        \"\"\"\n",
    "        Optimized haversine distance calculation for pdist, returning condensed distance matrix.\n",
    "        Assumes coords are [latitude, longitude].\n",
    "        \"\"\"\n",
    "        def haversine_metric(u, v):\n",
    "            lat1, lon1 = np.radians(u)\n",
    "            lat2, lon2 = np.radians(v)\n",
    "            \n",
    "            dlat = lat2 - lat1\n",
    "            dlon = lon2 - lon1\n",
    "            \n",
    "            a = (np.sin(dlat / 2) ** 2 + \n",
    "                 np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2)\n",
    "            c = 2 * np.arcsin(np.sqrt(np.clip(a, 0, 1)))\n",
    "            \n",
    "            return self.earth_radius_km * c\n",
    "        \n",
    "        return pdist(coords, metric=haversine_metric)\n",
    "    \n",
    "    def haversine_single_pair(self, coord1, coord2):\n",
    "        \"\"\"Calculate haversine distance between two points.\"\"\"\n",
    "        lat1, lon1 = np.radians(coord1)\n",
    "        lat2, lon2 = np.radians(coord2)\n",
    "        \n",
    "        dlat = lat2 - lat1\n",
    "        dlon = lon2 - lon1\n",
    "        \n",
    "        a = (np.sin(dlat / 2) ** 2 + \n",
    "             np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2)\n",
    "        c = 2 * np.arcsin(np.sqrt(np.clip(a, 0, 1)))\n",
    "        \n",
    "        return self.earth_radius_km * c\n",
    "\n",
    "    def _convex_hull_diameter(self, coords):\n",
    "        \"\"\"Enhanced convex hull approximation for diameter estimation.\"\"\"\n",
    "        lats, lons = coords[:, 0], coords[:, 1]\n",
    "        \n",
    "        # Get extreme points (min/max lat/lon)\n",
    "        extreme_indices = [\n",
    "            np.argmax(lats), np.argmin(lats),\n",
    "            np.argmax(lons), np.argmin(lons)\n",
    "        ]\n",
    "        \n",
    "        # Add points from different quadrants relative to the mean center\n",
    "        lat_center, lon_center = np.mean(lats), np.mean(lons)\n",
    "        \n",
    "        quadrants = [\n",
    "            (lats >= lat_center) & (lons >= lon_center),   # NE\n",
    "            (lats >= lat_center) & (lons < lon_center),    # NW\n",
    "            (lats < lat_center) & (lons >= lon_center),    # SE\n",
    "            (lats < lat_center) & (lons < lon_center)      # SW\n",
    "        ]\n",
    "        \n",
    "        for quadrant in quadrants:\n",
    "            if np.any(quadrant):\n",
    "                quad_indices = np.where(quadrant)[0]\n",
    "                # Add furthest point from center in each non-empty quadrant\n",
    "                distances_from_center = np.sqrt(\n",
    "                    (lats[quad_indices] - lat_center)**2 + \n",
    "                    (lons[quad_indices] - lon_center)**2\n",
    "                )\n",
    "                furthest_idx = quad_indices[np.argmax(distances_from_center)]\n",
    "                extreme_indices.append(furthest_idx)\n",
    "        \n",
    "        # Add some random points to further improve approximation for larger clusters\n",
    "        n_random = min(12, len(coords) - len(set(extreme_indices)))\n",
    "        if n_random > 0:\n",
    "            available_indices = list(set(range(len(coords))) - set(extreme_indices))\n",
    "            if available_indices:\n",
    "                random_indices = np.random.choice(available_indices, \n",
    "                                                  min(n_random, len(available_indices)), \n",
    "                                                  replace=False)\n",
    "                extreme_indices.extend(random_indices)\n",
    "        \n",
    "        # Get unique sample coordinates\n",
    "        sample_indices = list(set(extreme_indices))\n",
    "        sample_coords = coords[sample_indices]\n",
    "        \n",
    "        if len(sample_coords) <= 1:\n",
    "            return 0\n",
    "        \n",
    "        # Calculate max distance among the sampled points\n",
    "        distances = self.haversine_pdist(sample_coords)\n",
    "        return np.max(distances)\n",
    "    \n",
    "    def _grid_based_diameter(self, coords):\n",
    "        \"\"\"Grid-based sampling for very large clusters.\"\"\"\n",
    "        lats, lons = coords[:, 0], coords[:, 1]\n",
    "        \n",
    "        # Create 6x6 grid\n",
    "        lat_bins = np.linspace(lats.min(), lats.max(), 7)\n",
    "        lon_bins = np.linspace(lons.min(), lons.max(), 7)\n",
    "        \n",
    "        sample_indices = []\n",
    "        for i in range(len(lat_bins)-1):\n",
    "            for j in range(len(lon_bins)-1):\n",
    "                mask = ((lats >= lat_bins[i]) & (lats < lat_bins[i+1]) & \n",
    "                        (lons >= lon_bins[j]) & (lons < lon_bins[j+1]))\n",
    "                cell_indices = np.where(mask)[0]\n",
    "                if len(cell_indices) > 0:\n",
    "                    # Sample up to 2 points from each cell\n",
    "                    n_sample = min(2, len(cell_indices))\n",
    "                    sampled = np.random.choice(cell_indices, n_sample, replace=False)\n",
    "                    sample_indices.extend(sampled)\n",
    "        \n",
    "        if len(sample_indices) <= 1:\n",
    "            return 0\n",
    "        \n",
    "        sample_coords = coords[sample_indices]\n",
    "        distances = self.haversine_pdist(sample_coords)\n",
    "        return np.max(distances)\n",
    "    \n",
    "    def calculate_cluster_diameter_fast(self, coords):\n",
    "        \"\"\"\n",
    "        Fast cluster diameter calculation with multiple optimization strategies.\n",
    "        \"\"\"\n",
    "        n_points = len(coords)\n",
    "        \n",
    "        if n_points <= 1:\n",
    "            return 0\n",
    "        \n",
    "        if n_points == 2:\n",
    "            return self.haversine_single_pair(coords[0], coords[1])\n",
    "        \n",
    "        # Use different strategies based on cluster size\n",
    "        if n_points <= 10:\n",
    "            # Small clusters: exact calculation using pdist\n",
    "            distances = self.haversine_pdist(coords)\n",
    "            return np.max(distances)\n",
    "        elif n_points <= 50:\n",
    "            # Medium clusters: vectorized calculation or pdist\n",
    "            # Prioritize vectorized if available and faster for this range\n",
    "            distance_matrix = self.haversine_vectorized(coords)\n",
    "            # Ensure we're not taking max of diagonal (self-distances = 0)\n",
    "            return np.max(distance_matrix[np.triu_indices(n_points, k=1)])\n",
    "        else:\n",
    "            # Large clusters: smart sampling\n",
    "            return self._smart_diameter_estimation(coords)\n",
    "    \n",
    "    def _smart_diameter_estimation(self, coords):\n",
    "        \"\"\"\n",
    "        Improved diameter estimation using multiple sampling strategies.\n",
    "        \"\"\"\n",
    "        n_points = len(coords)\n",
    "        \n",
    "        # Strategy 1: Convex hull approximation\n",
    "        hull_diameter = self._convex_hull_diameter(coords)\n",
    "        \n",
    "        # Strategy 2: Grid-based sampling for very large clusters (higher confidence for max)\n",
    "        if n_points > 200: # Threshold for when grid sampling might be beneficial\n",
    "            grid_diameter = self._grid_based_diameter(coords)\n",
    "            return max(hull_diameter, grid_diameter)\n",
    "        \n",
    "        return hull_diameter\n",
    "\n",
    "    def _find_approximate_farthest_pair(self, coords):\n",
    "        \"\"\"Find approximate farthest pair for large clusters.\n",
    "           Moved from OptimizedDivisiveGeographicClustering to BaseGeographicClustering.\"\"\"\n",
    "        n_points = len(coords)\n",
    "        \n",
    "        if n_points <= 100:\n",
    "            # For moderate sizes, use exact calculation\n",
    "            distances = self.haversine_pdist(coords)\n",
    "            distance_matrix = squareform(distances)\n",
    "            max_idx = np.unravel_index(np.argmax(distance_matrix), distance_matrix.shape)\n",
    "            return max_idx[0], max_idx[1]\n",
    "        \n",
    "        # For large clusters, use sampling\n",
    "        sample_size = min(50, n_points)\n",
    "        sample_indices = np.random.choice(n_points, sample_size, replace=False)\n",
    "        sample_coords = coords[sample_indices]\n",
    "        \n",
    "        distances = self.haversine_pdist(sample_coords)\n",
    "        distance_matrix = squareform(distances)\n",
    "        max_idx = np.unravel_index(np.argmax(distance_matrix), distance_matrix.shape)\n",
    "        \n",
    "        return sample_indices[max_idx[0]], sample_indices[max_idx[1]]\n",
    "\n",
    "    def get_cluster_stats(self, clustered_df, max_customers_per_cluster, max_distance_km):\n",
    "        \"\"\"Get comprehensive clustering statistics.\"\"\"\n",
    "        if 'cluster' not in clustered_df.columns:\n",
    "            raise ValueError(\"DataFrame must contain 'cluster' column\")\n",
    "        \n",
    "        stats = {}\n",
    "        cluster_sizes = []\n",
    "        cluster_diameters = []\n",
    "        \n",
    "        for cluster_id in clustered_df['cluster'].unique():\n",
    "            if cluster_id == -1: # Unassigned points if any\n",
    "                continue\n",
    "            \n",
    "            cluster_data = clustered_df[clustered_df['cluster'] == cluster_id]\n",
    "            coords = cluster_data[['Latitude', 'Longitude']].values\n",
    "            \n",
    "            diameter = self.calculate_cluster_diameter_fast(coords)\n",
    "            cluster_sizes.append(len(cluster_data))\n",
    "            cluster_diameters.append(diameter)\n",
    "            \n",
    "            stats[cluster_id] = {\n",
    "                'size': len(cluster_data),\n",
    "                'diameter_km': diameter,\n",
    "                'centroid_lat': np.mean(coords[:, 0]),\n",
    "                'centroid_lon': np.mean(coords[:, 1]),\n",
    "                'meets_size_constraint': len(cluster_data) <= max_customers_per_cluster,\n",
    "                'meets_distance_constraint': diameter <= max_distance_km\n",
    "            }\n",
    "        \n",
    "        # Overall statistics\n",
    "        stats['summary'] = {\n",
    "            'total_clusters': len(stats), \n",
    "            'avg_cluster_size': np.mean(cluster_sizes) if cluster_sizes else 0,\n",
    "            'max_cluster_size': np.max(cluster_sizes) if cluster_sizes else 0,\n",
    "            'min_cluster_size': np.min(cluster_sizes) if cluster_sizes else 0,\n",
    "            'avg_diameter': np.mean(cluster_diameters) if cluster_diameters else 0,\n",
    "            'max_diameter': np.max(cluster_diameters) if cluster_diameters else 0,\n",
    "            'size_violations': sum(1 for size in cluster_sizes if size > max_customers_per_cluster),\n",
    "            'distance_violations': sum(1 for diameter in cluster_diameters if diameter > max_distance_km)\n",
    "        }\n",
    "        \n",
    "        return stats\n",
    "\n",
    "\n",
    "class AgglomerativeGeographicClustering(BaseGeographicClustering):\n",
    "    def __init__(self, max_customers_per_cluster=20, max_distance_km=50, \n",
    "                 linkage_method='ward', sub_cluster_if_oversized=True):\n",
    "        \"\"\"\n",
    "        Initializes the Agglomerative Geographic Clustering.\n",
    "\n",
    "        Args:\n",
    "            max_customers_per_cluster (int): Maximum number of customers allowed in a single cluster.\n",
    "            max_distance_km (float): Maximum diameter (distance between two farthest points)\n",
    "                                     allowed within a cluster in kilometers.\n",
    "            linkage_method (str): Method to use for calculating the distance between clusters\n",
    "                                  in hierarchical clustering. Options: 'ward', 'single', 'complete', 'average'.\n",
    "            sub_cluster_if_oversized (bool): If True, clusters that exceed max_customers_per_cluster\n",
    "                                             after distance-based cutting will be further sub-clustered\n",
    "                                             using K-Means.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.max_customers_per_cluster = max_customers_per_cluster\n",
    "        self.max_distance_km = max_distance_km\n",
    "        self.linkage_method = linkage_method\n",
    "        self.sub_cluster_if_oversized = sub_cluster_if_oversized\n",
    "\n",
    "    def agglomerative_clustering(self, customers_df):\n",
    "        \"\"\"\n",
    "        Performs agglomerative hierarchical clustering on geographic data\n",
    "        with constraints on cluster size and diameter.\n",
    "        \"\"\"\n",
    "        customers_df = customers_df.copy().reset_index(drop=True)\n",
    "        \n",
    "        if 'Latitude' not in customers_df.columns or 'Longitude' not in customers_df.columns:\n",
    "            raise ValueError(\"DataFrame must contain 'Latitude' and 'Longitude' columns\")\n",
    "        \n",
    "        coords_array = customers_df[['Latitude', 'Longitude']].values\n",
    "        n_customers = len(customers_df)\n",
    "        \n",
    "        if n_customers == 0:\n",
    "            customers_df['cluster'] = []\n",
    "            return customers_df\n",
    "        \n",
    "        if n_customers == 1:\n",
    "            customers_df['cluster'] = 1\n",
    "            return customers_df\n",
    "\n",
    "        # Step 1: Calculate pairwise Haversine distances\n",
    "        print(f\"Calculating {n_customers*(n_customers-1)//2} pairwise distances...\")\n",
    "        # Check if the number of points is too large for pdist to avoid MemoryError\n",
    "        # A rough heuristic: 5000 points * 5000 points / 2 * 8 bytes/float ~ 100MB\n",
    "        # For very large N, consider approximate methods if pdist is too slow/memory intensive\n",
    "        if n_customers > 2000 and self.linkage_method != 'ward': # Ward only works with Euclidean-like pdist\n",
    "             # For very large datasets, pdist might be too slow or memory intensive.\n",
    "             # In such cases, one might consider sampling or approximate hierarchical methods,\n",
    "             # or other clustering algorithms like DBSCAN that don't require a full distance matrix.\n",
    "             # For now, we proceed with pdist as it's standard for scipy.hierarchy.\n",
    "            print(\"Warning: Large dataset for pdist. This might take a while or consume a lot of memory.\")\n",
    "\n",
    "        distances = self.haversine_pdist(coords_array)\n",
    "        \n",
    "        # Step 2: Perform hierarchical clustering using linkage\n",
    "        print(f\"Performing linkage using '{self.linkage_method}' method...\")\n",
    "        linkage_matrix = linkage(distances, method=self.linkage_method)\n",
    "        \n",
    "        # Step 3: Cut the dendrogram based on max_distance_km\n",
    "        # This creates clusters where no two points are farther apart than max_distance_km\n",
    "        print(f\"Cutting dendrogram at max_distance_km={self.max_distance_km}...\")\n",
    "        initial_labels = fcluster(linkage_matrix, self.max_distance_km, criterion='distance')\n",
    "        \n",
    "        customers_df['cluster_temp'] = initial_labels\n",
    "        final_cluster_id = 0\n",
    "        final_clusters = {}\n",
    "\n",
    "        # Step 4: Post-process for max_customers_per_cluster constraint\n",
    "        print(f\"Post-processing clusters for size constraint (max {self.max_customers_per_cluster} customers)...\")\n",
    "        for current_cluster_label in sorted(customers_df['cluster_temp'].unique()):\n",
    "            cluster_indices = customers_df[customers_df['cluster_temp'] == current_cluster_label].index.values\n",
    "            current_coords = coords_array[cluster_indices]\n",
    "            \n",
    "            if len(cluster_indices) > self.max_customers_per_cluster and self.sub_cluster_if_oversized:\n",
    "                print(f\"  Cluster {current_cluster_label} (size {len(cluster_indices)}) is oversized. Sub-clustering...\")\n",
    "                # Sub-cluster using K-Means. Determine optimal k based on current size / max_customers_per_cluster\n",
    "                k_sub = int(np.ceil(len(cluster_indices) / self.max_customers_per_cluster))\n",
    "                k_sub = max(2, k_sub) # Ensure at least 2 clusters if splitting\n",
    "                \n",
    "                # Use approximate farthest pair for K-Means initialization\n",
    "                initial_centers_indices = self._find_approximate_farthest_pair(current_coords)\n",
    "                # Ensure initial_centers_indices has enough elements for k_sub.\n",
    "                # If k_sub > 2, KMeans++ initialization is generally more robust than a simple farthest pair.\n",
    "                if k_sub > 2:\n",
    "                    kmeans_sub = KMeans(n_clusters=k_sub, n_init=10, random_state=42) # Let KMeans find its own init\n",
    "                elif len(initial_centers_indices) >= 2: # k_sub = 2, use the farthest pair if available\n",
    "                    kmeans_sub = KMeans(n_clusters=k_sub, init=current_coords[[initial_centers_indices[0], initial_centers_indices[1]]], n_init=1, random_state=42)\n",
    "                else: # Fallback if initial_centers_indices is not sufficient for k_sub=2\n",
    "                    kmeans_sub = KMeans(n_clusters=k_sub, n_init=10, random_state=42)\n",
    "\n",
    "\n",
    "                sub_labels = kmeans_sub.fit_predict(current_coords)\n",
    "                \n",
    "                for sub_label in np.unique(sub_labels):\n",
    "                    final_cluster_id += 1\n",
    "                    sub_cluster_indices = cluster_indices[sub_labels == sub_label]\n",
    "                    final_clusters[final_cluster_id] = sub_cluster_indices\n",
    "            else:\n",
    "                final_cluster_id += 1\n",
    "                final_clusters[final_cluster_id] = cluster_indices\n",
    "        \n",
    "        # Assign final cluster labels to the DataFrame\n",
    "        result_df = customers_df.copy()\n",
    "        result_df['cluster'] = -1 # Initialize with unassigned\n",
    "\n",
    "        for cluster_id, indices in final_clusters.items():\n",
    "            result_df.loc[indices, 'cluster'] = cluster_id\n",
    "        \n",
    "        result_df = result_df.drop(columns=['cluster_temp'])\n",
    "        print(\"Agglomerative clustering completed.\\n\")\n",
    "        return result_df\n",
    "\n",
    "class OptimizedDivisiveGeographicClustering(BaseGeographicClustering):\n",
    "    \"\"\" Best - Fast and Accurate Divisive Geographic Clustering\n",
    "    \"\"\"\n",
    "    def __init__(self, max_customers_per_cluster=20, max_distance_km=50, \n",
    "                 use_vectorized_distances=True, balance_clusters=False):\n",
    "        super().__init__()\n",
    "        self.max_customers_per_cluster = max_customers_per_cluster\n",
    "        self.max_distance_km = max_distance_km\n",
    "        self.use_vectorized_distances = use_vectorized_distances\n",
    "        self.balance_clusters = balance_clusters\n",
    "        \n",
    "    def calculate_cluster_diameter_fast(self, coords): # Overrides Base class method\n",
    "        \"\"\"\n",
    "        Fast cluster diameter calculation with multiple optimization strategies.\n",
    "        \"\"\"\n",
    "        n_points = len(coords)\n",
    "        \n",
    "        if n_points <= 1:\n",
    "            return 0\n",
    "        \n",
    "        if n_points == 2:\n",
    "            return self.haversine_single_pair(coords[0], coords[1])\n",
    "        \n",
    "        # Use different strategies based on cluster size\n",
    "        if n_points <= 10:\n",
    "            # Small clusters: exact calculation\n",
    "            distances = self.haversine_pdist(coords)\n",
    "            return np.max(distances)\n",
    "        elif n_points <= 50:\n",
    "            # Medium clusters: vectorized calculation\n",
    "            if self.use_vectorized_distances:\n",
    "                distance_matrix = self.haversine_vectorized(coords)\n",
    "                return np.max(distance_matrix)\n",
    "            else:\n",
    "                distances = self.haversine_pdist(coords)\n",
    "                return np.max(distances)\n",
    "        else:\n",
    "            # Large clusters: smart sampling\n",
    "            return self._smart_diameter_estimation(coords)\n",
    "    \n",
    "    def _smart_diameter_estimation(self, coords): # Overrides Base class method\n",
    "        \"\"\"\n",
    "        Improved diameter estimation using multiple sampling strategies.\n",
    "        \"\"\"\n",
    "        n_points = len(coords)\n",
    "        \n",
    "        # Strategy 1: Convex hull approximation\n",
    "        hull_diameter = self._convex_hull_diameter(coords)\n",
    "        \n",
    "        # Strategy 2: Grid-based sampling for large clusters\n",
    "        if n_points > 200:\n",
    "            grid_diameter = self._grid_based_diameter(coords)\n",
    "            return max(hull_diameter, grid_diameter)\n",
    "        \n",
    "        return hull_diameter\n",
    "    \n",
    "    def should_split_cluster(self, cluster_indices, coords_array):\n",
    "        \"\"\"Enhanced cluster splitting logic with load balancing.\"\"\"\n",
    "        cluster_size = len(cluster_indices)\n",
    "        \n",
    "        if cluster_size <= 2:\n",
    "            return False\n",
    "        \n",
    "        # Hard size constraint\n",
    "        if cluster_size > self.max_customers_per_cluster * 1.5:\n",
    "            return True\n",
    "        \n",
    "        # Soft size constraint with diameter check\n",
    "        if cluster_size > self.max_customers_per_cluster:\n",
    "            cluster_coords = coords_array[cluster_indices]\n",
    "            diameter = self.calculate_cluster_diameter_fast(cluster_coords)\n",
    "            return diameter > self.max_distance_km * 0.8  # More lenient for size\n",
    "        \n",
    "        # Diameter constraint\n",
    "        cluster_coords = coords_array[cluster_indices]\n",
    "        diameter = self.calculate_cluster_diameter_fast(cluster_coords)\n",
    "        \n",
    "        return diameter > self.max_distance_km\n",
    "    \n",
    "    def geographic_split(self, cluster_indices, coords_array):\n",
    "        \"\"\"\n",
    "        Improved geographic splitting with better load balancing.\n",
    "        \"\"\"\n",
    "        if len(cluster_indices) <= 2:\n",
    "            return [cluster_indices]\n",
    "        \n",
    "        cluster_coords = coords_array[cluster_indices]\n",
    "        n_points = len(cluster_coords)\n",
    "        \n",
    "        # For small clusters, use exact method\n",
    "        if n_points <= 50:\n",
    "            return self._exact_geographic_split(cluster_indices, cluster_coords)\n",
    "        \n",
    "        # For medium clusters, use K-means with geographic initialization\n",
    "        if n_points <= 200:\n",
    "            return self._kmeans_geographic_split(cluster_indices, cluster_coords)\n",
    "        \n",
    "        # For large clusters, use hierarchical approach\n",
    "        return self._hierarchical_geographic_split(cluster_indices, cluster_coords)\n",
    "    \n",
    "    def _exact_geographic_split(self, cluster_indices, cluster_coords):\n",
    "        \"\"\"Exact splitting for small clusters.\"\"\"\n",
    "        n_points = len(cluster_coords)\n",
    "        \n",
    "        # Find the two points that are farthest apart\n",
    "        distances = self.haversine_pdist(cluster_coords)\n",
    "        distance_matrix = squareform(distances)\n",
    "        max_idx = np.unravel_index(np.argmax(distance_matrix), distance_matrix.shape)\n",
    "        center1_idx, center2_idx = max_idx[0], max_idx[1]\n",
    "        \n",
    "        center1 = cluster_coords[center1_idx]\n",
    "        center2 = cluster_coords[center2_idx]\n",
    "        \n",
    "        # Assign points to closest center\n",
    "        distances_to_center1 = self.haversine_vectorized(cluster_coords, center1.reshape(1, -1))[:, 0]\n",
    "        distances_to_center2 = self.haversine_vectorized(cluster_coords, center2.reshape(1, -1))[:, 0]\n",
    "        \n",
    "        labels = (distances_to_center1 <= distances_to_center2).astype(int)\n",
    "        \n",
    "        return self._balance_split(cluster_indices, labels)\n",
    "    \n",
    "    def _kmeans_geographic_split(self, cluster_indices, cluster_coords):\n",
    "        \"\"\"K-means splitting with geographic initialization.\"\"\"\n",
    "        n_points = len(cluster_coords)\n",
    "        \n",
    "        # Initialize with farthest pair\n",
    "        # This calls _find_approximate_farthest_pair from BaseGeographicClustering\n",
    "        center1_idx, center2_idx = self._find_approximate_farthest_pair(cluster_coords) \n",
    "        initial_centers = cluster_coords[[center1_idx, center2_idx]]\n",
    "        \n",
    "        # Apply K-means\n",
    "        kmeans = KMeans(n_clusters=2, init=initial_centers, n_init=1, random_state=42)\n",
    "        labels = kmeans.fit_predict(cluster_coords)\n",
    "        \n",
    "        return self._balance_split(cluster_indices, labels)\n",
    "    \n",
    "    def _hierarchical_geographic_split(self, cluster_indices, cluster_coords):\n",
    "        \"\"\"Hierarchical splitting for large clusters.\"\"\"\n",
    "        # Use linkage-based clustering for very large clusters\n",
    "        n_sample = min(100, len(cluster_coords))\n",
    "        sample_indices = np.random.choice(len(cluster_coords), n_sample, replace=False)\n",
    "        sample_coords = cluster_coords[sample_indices]\n",
    "        \n",
    "        # Compute linkage on sample\n",
    "        distances = self.haversine_pdist(sample_coords)\n",
    "        linkage_matrix = linkage(distances, method='ward')\n",
    "        sample_labels = fcluster(linkage_matrix, 2, criterion='maxclust') - 1\n",
    "        \n",
    "        # Ensure that both sub-clusters have points from the sample\n",
    "        center1_coords = sample_coords[sample_labels == 0]\n",
    "        center2_coords = sample_coords[sample_labels == 1]\n",
    "        \n",
    "        if len(center1_coords) == 0 or len(center2_coords) == 0:\n",
    "            # Fallback to exact split if hierarchical sample leads to empty sub-clusters\n",
    "            return self._exact_geographic_split(cluster_indices, cluster_coords)\n",
    "        \n",
    "        center1 = np.mean(center1_coords, axis=0)\n",
    "        center2 = np.mean(center2_coords, axis=0)\n",
    "        \n",
    "        distances_to_center1 = self.haversine_vectorized(cluster_coords, center1.reshape(1, -1))[:, 0]\n",
    "        distances_to_center2 = self.haversine_vectorized(cluster_coords, center2.reshape(1, -1))[:, 0]\n",
    "        \n",
    "        labels = (distances_to_center1 <= distances_to_center2).astype(int)\n",
    "        \n",
    "        return self._balance_split(cluster_indices, labels)\n",
    "    \n",
    "    def _balance_split(self, cluster_indices, labels):\n",
    "        \"\"\"Balance the split to avoid very uneven clusters.\"\"\"\n",
    "        cluster_0_indices = cluster_indices[labels == 0]\n",
    "        cluster_1_indices = cluster_indices[labels == 1]\n",
    "        \n",
    "        # Ensure no empty clusters (very important for recursive calls)\n",
    "        if len(cluster_0_indices) == 0:\n",
    "            # If one cluster is empty, move one point from the other to it.\n",
    "            # This handles edge cases but might lead to a single point cluster,\n",
    "            # which the should_split_cluster check will prevent further splitting if <= 2.\n",
    "            if len(cluster_1_indices) > 0:\n",
    "                cluster_0_indices = np.array([cluster_1_indices[0]])\n",
    "                cluster_1_indices = cluster_1_indices[1:]\n",
    "            else: # Both empty, should not happen if initial cluster_indices was not empty\n",
    "                return [np.array([]), np.array([])]\n",
    "        elif len(cluster_1_indices) == 0:\n",
    "            if len(cluster_0_indices) > 0:\n",
    "                cluster_1_indices = np.array([cluster_0_indices[0]])\n",
    "                cluster_0_indices = cluster_0_indices[1:]\n",
    "            else: # Both empty\n",
    "                return [np.array([]), np.array([])]\n",
    "        \n",
    "        # Optional: Balance cluster sizes if one is much larger\n",
    "        if self.balance_clusters:\n",
    "            size_0, size_1 = len(cluster_0_indices), len(cluster_1_indices)\n",
    "            if size_0 > 3 * size_1 and size_1 > 0: # If cluster 0 is significantly larger\n",
    "                n_move = (size_0 - size_1) // 4 # Move a quarter of the difference\n",
    "                move_indices = cluster_0_indices[:n_move]\n",
    "                cluster_0_indices = cluster_0_indices[n_move:]\n",
    "                cluster_1_indices = np.concatenate([cluster_1_indices, move_indices])\n",
    "            elif size_1 > 3 * size_0 and size_0 > 0: # If cluster 1 is significantly larger\n",
    "                n_move = (size_1 - size_0) // 4\n",
    "                move_indices = cluster_1_indices[:n_move]\n",
    "                cluster_1_indices = cluster_1_indices[n_move:]\n",
    "                cluster_0_indices = np.concatenate([cluster_0_indices, move_indices])\n",
    "        \n",
    "        return [cluster_0_indices, cluster_1_indices]\n",
    "    \n",
    "    def divisive_clustering(self, customers_df):\n",
    "        \"\"\"Perform optimized divisive hierarchical clustering.\"\"\"\n",
    "        customers_df = customers_df.copy().reset_index(drop=True)\n",
    "        \n",
    "        # Validate input\n",
    "        if 'Latitude' not in customers_df.columns or 'Longitude' not in customers_df.columns:\n",
    "            raise ValueError(\"DataFrame must contain 'Latitude' and 'Longitude' columns\")\n",
    "        \n",
    "        coords_array = customers_df[['Latitude', 'Longitude']].values\n",
    "        n_customers = len(customers_df)\n",
    "        \n",
    "        if n_customers == 0:\n",
    "            customers_df['cluster'] = []\n",
    "            return customers_df\n",
    "        \n",
    "        if n_customers == 1:\n",
    "            customers_df['cluster'] = 1\n",
    "            return customers_df\n",
    "        \n",
    "        # Priority queue approach for better clustering\n",
    "        clusters_to_process = [(n_customers, np.arange(n_customers))]   # (size, indices)\n",
    "        final_clusters = []\n",
    "        \n",
    "        iteration_count = 0\n",
    "        max_iterations = n_customers * 2 # Safety break to prevent infinite loops\n",
    "        \n",
    "        while clusters_to_process and iteration_count < max_iterations:\n",
    "            # Process largest cluster first to tackle the biggest problems\n",
    "            clusters_to_process.sort(key=lambda x: x[0], reverse=True)\n",
    "            current_size, current_cluster_indices = clusters_to_process.pop(0)\n",
    "            iteration_count += 1\n",
    "            \n",
    "            if self.should_split_cluster(current_cluster_indices, coords_array):\n",
    "                subclusters = self.geographic_split(current_cluster_indices, coords_array)\n",
    "                \n",
    "                for subcluster_indices in subclusters:\n",
    "                    if len(subcluster_indices) > 0:\n",
    "                        clusters_to_process.append((len(subcluster_indices), subcluster_indices))\n",
    "            else:\n",
    "                final_clusters.append(current_cluster_indices)\n",
    "        \n",
    "        # Handle any clusters remaining in `clusters_to_process` if max_iterations was hit\n",
    "        final_clusters.extend([indices for _, indices in clusters_to_process])\n",
    "        \n",
    "        # Create result DataFrame\n",
    "        result_df = customers_df.copy()\n",
    "        result_df['cluster'] = -1 # Initialize with -1 for unassigned\n",
    "        \n",
    "        for cluster_id, cluster_indices in enumerate(final_clusters, 1):\n",
    "            result_df.loc[cluster_indices, 'cluster'] = cluster_id\n",
    "        \n",
    "        return result_df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c64bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad756b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### My custom testing\n",
    "print(\"--- Running Agglomerative Clustering ---\")\n",
    "agg_clusterer = AgglomerativeGeographicClustering(\n",
    "    max_customers_per_cluster=20, # Aim for clusters of max 50 customers\n",
    "    max_distance_km=5.0,        # Max diameter of 5 km\n",
    "    linkage_method='ward',       # Common choice for compact clusters\n",
    "    sub_cluster_if_oversized=True\n",
    ")\n",
    "clustered_agg_df = agg_clusterer.agglomerative_clustering(df_all_cluster.copy())\n",
    "agg_stats = agg_clusterer.get_cluster_stats(clustered_agg_df, agg_clusterer.max_customers_per_cluster, agg_clusterer.max_distance_km)\n",
    "print(\"\\nAgglomerative Clustering Stats:\")\n",
    "for k, v in agg_stats['summary'].items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "print(\"\\nSample Agglomerative Cluster Details:\")\n",
    "for cluster_id, details in list(agg_stats.items())[:5]: # Show first 5 clusters\n",
    "    if cluster_id != 'summary':\n",
    "        print(f\"  Cluster {cluster_id}: Size={details['size']}, Diameter={details['diameter_km']:.2f} km, Size OK={details['meets_size_constraint']}, Distance OK={details['meets_distance_constraint']}\")\n",
    "\n",
    "\n",
    "_ = evaluate_unsupervised_clustering(clustered_agg_df)\n",
    "\n",
    "# # # Get detailed statistics\n",
    "stats = divisive_clusterer.get_cluster_stats(clustered_agg_df)\n",
    "print(f\"Total clusters: {stats['summary']['total_clusters']}\")\n",
    "print(f\"Constraint violations: Size={stats['summary']['size_violations']}, Distance={stats['summary']['distance_violations']}\")\n",
    " \n",
    "\n",
    " \n",
    "vis_and_save(df_routes = clustered_agg_df,\n",
    "                 df_stockpoint = None,   \n",
    "                 filename=None,\n",
    "                 cluster_col = 'cluster')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92bf2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### My custom testing\n",
    "print(\"\\n--- Running Divisive Clustering (for comparison) ---\")\n",
    "div_clusterer = OptimizedDivisiveGeographicClustering(\n",
    "    max_customers_per_cluster=50,\n",
    "    max_distance_km=5.0,\n",
    "    balance_clusters=True\n",
    ")\n",
    "clustered_div_df = div_clusterer.divisive_clustering(df_all_cluster.copy())\n",
    "div_stats = div_clusterer.get_cluster_stats(clustered_div_df, div_clusterer.max_customers_per_cluster, div_clusterer.max_distance_km) # Added missing arguments\n",
    "print(\"\\nDivisive Clustering Stats:\")\n",
    "for k, v in div_stats['summary'].items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "print(\"\\nSample Divisive Cluster Details:\")\n",
    "for cluster_id, details in list(div_stats.items())[:5]: # Show first 5 clusters\n",
    "    if cluster_id != 'summary':\n",
    "        print(f\"  Cluster {cluster_id}: Size={details['size']}, Diameter={details['diameter_km']:.2f} km, Size OK={details['meets_size_constraint']}, Distance OK={details['meets_distance_constraint']}\")\n",
    "\n",
    "\n",
    "_ = evaluate_unsupervised_clustering(clustered_div_df)\n",
    "\n",
    "# # # Get detailed statistics\n",
    "stats = divisive_clusterer.get_cluster_stats(clustered_div_df)\n",
    "print(f\"Total clusters: {stats['summary']['total_clusters']}\")\n",
    "print(f\"Constraint violations: Size={stats['summary']['size_violations']}, Distance={stats['summary']['distance_violations']}\")\n",
    "\n",
    "\n",
    "\n",
    "vis_and_save(df_routes = clustered_div_df,\n",
    "                df_stockpoint = None,   \n",
    "                filename=None,\n",
    "                cluster_col = 'cluster')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33c5c24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f57385",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Example Usage ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate some sample geographic data\n",
    "    np.random.seed(42)\n",
    "    num_customers = 500 # Testing with more customers for better demonstration\n",
    "    \n",
    "    # Simulate clusters\n",
    "    center1 = [6.5, 3.3] # Lagos area\n",
    "    center2 = [6.6, 3.4]\n",
    "    center3 = [6.4, 3.2]\n",
    "\n",
    "    customers_data = []\n",
    "    # Cluster 1 (dense)\n",
    "    for _ in range(200):\n",
    "        customers_data.append({\n",
    "            'CustomerID': f'C1_{_}',\n",
    "            'Latitude': center1[0] + np.random.randn() * 0.01,\n",
    "            'Longitude': center1[1] + np.random.randn() * 0.01\n",
    "        })\n",
    "    # Cluster 2 (dense)\n",
    "    for _ in range(150):\n",
    "        customers_data.append({\n",
    "            'CustomerID': f'C2_{_}',\n",
    "            'Latitude': center2[0] + np.random.randn() * 0.015,\n",
    "            'Longitude': center2[1] + np.random.randn() * 0.015\n",
    "        })\n",
    "    # Cluster 3 (sparse, might get split or remain single if large enough)\n",
    "    for _ in range(150):\n",
    "        customers_data.append({\n",
    "            'CustomerID': f'C3_{_}',\n",
    "            'Latitude': center3[0] + np.random.randn() * 0.02,\n",
    "            'Longitude': center3[1] + np.random.randn() * 0.02\n",
    "        })\n",
    "\n",
    "    customers_df = pd.DataFrame(customers_data)\n",
    "\n",
    "    print(\"--- Running Agglomerative Clustering ---\")\n",
    "    agg_clusterer = AgglomerativeGeographicClustering(\n",
    "        max_customers_per_cluster=50, # Aim for clusters of max 50 customers\n",
    "        max_distance_km=5.0,        # Max diameter of 5 km\n",
    "        linkage_method='ward',       # Common choice for compact clusters\n",
    "        sub_cluster_if_oversized=True\n",
    "    )\n",
    "    clustered_agg_df = agg_clusterer.agglomerative_clustering(customers_df.copy())\n",
    "    agg_stats = agg_clusterer.get_cluster_stats(clustered_agg_df, agg_clusterer.max_customers_per_cluster, agg_clusterer.max_distance_km)\n",
    "    print(\"\\nAgglomerative Clustering Stats:\")\n",
    "    for k, v in agg_stats['summary'].items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "    print(\"\\nSample Agglomerative Cluster Details:\")\n",
    "    for cluster_id, details in list(agg_stats.items())[:5]: # Show first 5 clusters\n",
    "        if cluster_id != 'summary':\n",
    "            print(f\"  Cluster {cluster_id}: Size={details['size']}, Diameter={details['diameter_km']:.2f} km, Size OK={details['meets_size_constraint']}, Distance OK={details['meets_distance_constraint']}\")\n",
    "\n",
    "    print(\"\\n--- Running Divisive Clustering (for comparison) ---\")\n",
    "    div_clusterer = OptimizedDivisiveGeographicClustering(\n",
    "        max_customers_per_cluster=50,\n",
    "        max_distance_km=5.0,\n",
    "        balance_clusters=True\n",
    "    )\n",
    "    clustered_div_df = div_clusterer.divisive_clustering(customers_df.copy())\n",
    "    div_stats = div_clusterer.get_cluster_stats(clustered_div_df, div_clusterer.max_customers_per_cluster, div_clusterer.max_distance_km) # Added missing arguments\n",
    "    print(\"\\nDivisive Clustering Stats:\")\n",
    "    for k, v in div_stats['summary'].items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "    print(\"\\nSample Divisive Cluster Details:\")\n",
    "    for cluster_id, details in list(div_stats.items())[:5]: # Show first 5 clusters\n",
    "        if cluster_id != 'summary':\n",
    "            print(f\"  Cluster {cluster_id}: Size={details['size']}, Diameter={details['diameter_km']:.2f} km, Size OK={details['meets_size_constraint']}, Distance OK={details['meets_distance_constraint']}\")\n",
    "\n",
    "    # --- Plotting the clusters (optional, requires matplotlib/folium) ---\n",
    "    # To visualize, you'd typically plot these clustered_agg_df or clustered_div_df\n",
    "    # on a map using Folium, similar to our routing visualization.\n",
    "    # For a quick visual check (requires matplotlib):\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        plt.figure(figsize=(15, 7))\n",
    "\n",
    "        # Plot Agglomerative Clusters\n",
    "        ax1 = plt.subplot(121)\n",
    "        for cluster_id in clustered_agg_df['cluster'].unique():\n",
    "            if cluster_id == -1: continue\n",
    "            cluster_points = clustered_agg_df[clustered_agg_df['cluster'] == cluster_id]\n",
    "            ax1.scatter(cluster_points['Longitude'], cluster_points['Latitude'], \n",
    "                        label=f'Agg C{cluster_id} (n={len(cluster_points)})', s=20, alpha=0.6)\n",
    "        ax1.set_title('Agglomerative Clusters')\n",
    "        ax1.set_xlabel('Longitude')\n",
    "        ax1.set_ylabel('Latitude')\n",
    "        ax1.grid(True)\n",
    "\n",
    "        # Plot Divisive Clusters\n",
    "        ax2 = plt.subplot(122)\n",
    "        for cluster_id in clustered_div_df['cluster'].unique():\n",
    "            if cluster_id == -1: continue\n",
    "            cluster_points = clustered_div_df[clustered_div_df['cluster'] == cluster_id]\n",
    "            ax2.scatter(cluster_points['Longitude'], cluster_points['Latitude'], \n",
    "                        label=f'Div C{cluster_id} (n={len(cluster_points)})', s=20, alpha=0.6)\n",
    "        ax2.set_title('Divisive Clusters')\n",
    "        ax2.set_xlabel('Longitude')\n",
    "        ax2.set_ylabel('Latitude')\n",
    "        ax2.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    except ImportError:\n",
    "        print(\"\\nMatplotlib not found. Skipping cluster visualization.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during plotting: {e}. Skipping cluster visualization.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da02ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
