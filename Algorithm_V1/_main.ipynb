{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14f01705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from src.get_data import get_data \n",
    "from src.get_data import get_connection\n",
    "from datetime import datetime, timedelta\n",
    "from routing.routing_optimizer import RouteOptimizer\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score \n",
    "import folium\n",
    "from clustering.plot_cluster import create_enhanced_cluster_map\n",
    "from routing.routing import get_valhalla_routes_info, plot_routes_on_map\n",
    "import openrouteservice as ors\n",
    "import math\n",
    "import numpy as np\n",
    "import os \n",
    "from routingpy import Valhalla\n",
    "# client = ors.Client(key='5b3ce3597851110001cf62485a415b103df64104ad2680c9210ef936') \n",
    "\n",
    "import logging\n",
    "import pandas as pd\n",
    "from pyodbc import Connection\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "# from src.route_optimization import run_route_optimizer\n",
    "\n",
    "\n",
    "VALHALLA_BASE_URL = \"http://localhost:8002\" # Pointing to your self-hosted Valhalla\n",
    "VALHALLA_API_KEY = \"\" # No API key needed for your self-hosted instance\n",
    "\n",
    "\n",
    "CURRENT_DATE  = datetime.today().date() + timedelta(days=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a4fa03",
   "metadata": {},
   "source": [
    "## **Utils**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75e2ca2",
   "metadata": {},
   "source": [
    "#### Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7cc1de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_invalid_coordinates_DEP(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Replaces invalid Latitude (< -90 or > 90) and Longitude (< -180 or > 180) values with 0.0.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame with 'Latitude' and 'Longitude' columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with corrected coordinate values.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    df.loc[(df['Latitude'] < -90) | (df['Latitude'] > 90), 'Latitude'] = 0.0\n",
    "    df.loc[(df['Longitude'] < -180) | (df['Longitude'] > 180), 'Longitude'] = 0.0\n",
    "\n",
    "\n",
    "    ### Nigeria \n",
    "    # ADD NIGERIA FILTER HERE\n",
    "    return df\n",
    "\n",
    "def clean_invalid_coordinates(df: pd.DataFrame, offset_degrees: float = 0.1) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Replaces invalid Latitude (< -90 or > 90) and Longitude (< -180 or > 180) values with 0.0.\n",
    "    Also replaces coordinates outside Nigeria's approximate boundaries (with an optional offset) with 0.0.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame with 'Latitude' and 'Longitude' columns.\n",
    "        offset_degrees (float): Degrees to add/subtract from the strict Nigeria boundary\n",
    "                                to expand the bounding box. Default is 0.1 degrees.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with corrected coordinate values.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Global invalid coordinate ranges\n",
    "    df.loc[(df['Latitude'] < -90) | (df['Latitude'] > 90), 'Latitude'] = 0.0\n",
    "    df.loc[(df['Longitude'] < -180) | (df['Longitude'] > 180), 'Longitude'] = 0.0\n",
    "\n",
    "    ### Nigeria Boundary Filter ###\n",
    "    # Approximate decimal degree boundaries for Nigeria\n",
    "    STRICT_NIGERIA_MIN_LAT = 4.10\n",
    "    STRICT_NIGERIA_MAX_LAT = 13.90\n",
    "    STRICT_NIGERIA_MIN_LON = 2.60\n",
    "    STRICT_NIGERIA_MAX_LON = 14.70\n",
    "\n",
    "    # Apply offset to expand the bounding box\n",
    "    NIGERIA_MIN_LAT = STRICT_NIGERIA_MIN_LAT - offset_degrees\n",
    "    NIGERIA_MAX_LAT = STRICT_NIGERIA_MAX_LAT + offset_degrees\n",
    "    NIGERIA_MIN_LON = STRICT_NIGERIA_MIN_LON - offset_degrees\n",
    "    NIGERIA_MAX_LON = STRICT_NIGERIA_MAX_LON + offset_degrees\n",
    "\n",
    "    # Identify coordinates outside Nigeria's expanded bounding box\n",
    "    # Condition for rows outside Nigeria's latitude range\n",
    "    outside_nigeria_lat = (df['Latitude'] < NIGERIA_MIN_LAT) | \\\n",
    "                          (df['Latitude'] > NIGERIA_MAX_LAT)\n",
    "\n",
    "    # Condition for rows outside Nigeria's longitude range\n",
    "    outside_nigeria_lon = (df['Longitude'] < NIGERIA_MIN_LON) | \\\n",
    "                          (df['Longitude'] > NIGERIA_MAX_LON)\n",
    "\n",
    "    # Combine conditions: if EITHER latitude OR longitude is outside Nigeria's expanded box,\n",
    "    # then set BOTH Latitude and Longitude for that row to 0.0.\n",
    "    # We apply this only to coordinates that are already globally valid (i.e., not 0.0).\n",
    "    df.loc[\n",
    "        (df['Latitude'] != 0.0) &\n",
    "        (df['Longitude'] != 0.0) &\n",
    "        (outside_nigeria_lat | outside_nigeria_lon),\n",
    "        ['Latitude', 'Longitude']\n",
    "    ] = 0.0\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589e0f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df_customer_sku_recommendation_raw, \n",
    "                      df_customer_dim_with_affinity_score_raw, \n",
    "                      df_stockpoint_dim_raw,\n",
    "                      df_customer_score,\n",
    "                      df_kyc_customer) :\n",
    "    \n",
    "    df_customer_sku_recommendation_raw['Stock_Point_ID'] = df_customer_sku_recommendation_raw['Stock_Point_ID'].astype(int)\n",
    "    df_customer_dim_with_affinity_score_raw['Stock_Point_ID'] = df_customer_dim_with_affinity_score_raw['Stock_Point_ID'].astype(int)\n",
    "    df_stockpoint_dim_raw['Stock_Point_ID'] = df_stockpoint_dim_raw['Stock_Point_ID'].astype(int)\n",
    "    df_customer_score = df_customer_score.rename(columns={'StockPointID':'Stock_Point_ID'})\n",
    "    df_customer_score['Stock_Point_ID'] = df_customer_score['Stock_Point_ID'].astype(int)\n",
    "\n",
    "\n",
    "    # ----------------- CUSTOMER DIM TABLE \n",
    "    col_sel_affinity = ['Region', 'Stock_Point_ID', 'CustomerID']\n",
    "\n",
    "    col_sel_kyc = ['CustomerID', 'ContactName', 'BusinessName', 'CustomerModeName',\n",
    "        'CustomerRef', 'ContactPhone', 'CustomerType', 'FullAddress', \n",
    "        'StateName', 'CityName', 'TownName', 'Latitude','Longitude', \n",
    "        'DistanceVarianceInMeter', 'IsLocationSubmitted',\n",
    "        'IsLocationCaptured', 'IsLocationVerified','CustomerStatus',\n",
    "        'RejectReason',  'KYC_Capture_Status',  'lastDelvDate', \n",
    "        # 'hasPOS','hasVAS', 'hasBNPL', 'lastDelvDate', \n",
    "        'isActive']\n",
    "\n",
    "    col_sel_score = ['Stock_Point_ID', 'CustomerID', 'composite_customer_score',\n",
    "        'percentile_rank', 'active_months_pct', 'avg_orders_per_active_month',\n",
    "        'avg_qty_per_month', 'avg_revenue_per_month', 'days_since_last_order']\n",
    "\n",
    "    df_master_customer_dim = (\n",
    "                df_customer_dim_with_affinity_score_raw[col_sel_affinity]\n",
    "                .merge(df_kyc_customer[col_sel_kyc], how='inner', on=['CustomerID'])\n",
    "                .merge(df_customer_score[col_sel_score], how='left', on=['Stock_Point_ID', 'CustomerID'])\n",
    "                .rename(columns = {'CityName':'LGA',\n",
    "                                'TownName':'LCDA'\n",
    "                                })\n",
    "\n",
    "            )\n",
    "\n",
    "    # df_master_customer_dim['CustomerPurchaseRecency'] =  df_master_customer_dim['days_since_last_order'].apply(lambda x: (datetime.now() - x).days)\n",
    "    df_master_customer_dim['CustomerPurchaseRecency'] =  df_master_customer_dim['lastDelvDate'].apply(lambda x: (datetime.now() - x).days)\n",
    "    df_master_customer_dim['CustomerPurchaseRecency'] = df_master_customer_dim['CustomerPurchaseRecency'].fillna(max(df_master_customer_dim['CustomerPurchaseRecency']))\n",
    "    df_master_customer_dim['KYC_Capture_Status'] = df_master_customer_dim['KYC_Capture_Status'].apply(lambda x: 'Yes' if x == 1 else 'No')\n",
    "\n",
    "    # Add to Score\n",
    "    # Fix Missing value -------------------------------------------\n",
    "    for col in ['BusinessName', 'CustomerModeName', 'FullAddress', 'LGA', 'LCDA']:\n",
    "        df_master_customer_dim[col] = df_master_customer_dim[col].fillna('')\n",
    "\n",
    "    for col in ['Latitude',  'Longitude', 'composite_customer_score',  \n",
    "                'percentile_rank',  'active_months_pct', 'avg_orders_per_active_month',  \n",
    "                'avg_qty_per_month',  'avg_revenue_per_month'\n",
    "                ]:\n",
    "        df_master_customer_dim[col] = pd.to_numeric(df_master_customer_dim[col], errors='coerce').fillna(0) \n",
    "\n",
    "    df_master_customer_dim = clean_invalid_coordinates(df_master_customer_dim)\n",
    "    \n",
    "    # Add to Score \n",
    "    # Boost composite score and percentile rank for customers with completed KYC\n",
    "    mask_kyc = df_master_customer_dim['KYC_Capture_Status'] == 'Yes'\n",
    "\n",
    "    df_master_customer_dim.loc[mask_kyc, 'composite_customer_score'] += 5\n",
    "    df_master_customer_dim.loc[mask_kyc, 'percentile_rank'] += 0.1 \n",
    "\n",
    "    # ----------------- RECOMMENDATION\n",
    "    col2 = ['EstimatedQuantity', 'CustomerSKUscore', 'CustomerSKUscoreStandardize', 'CustomerSKUscoreRank']\n",
    "    for col in col2: \n",
    "        df_customer_sku_recommendation_raw[col] = pd.to_numeric(df_customer_sku_recommendation_raw[col], errors='coerce')\n",
    "\n",
    "    df_customer_sku_recommendation_raw['LastDeliveredDate'] = pd.to_datetime(df_customer_sku_recommendation_raw['LastDeliveredDate'])\n",
    "    # Get today's date\n",
    "    today = pd.Timestamp.today()\n",
    "\n",
    "    df_customer_sku_recommendation_raw['Recency'] = df_customer_sku_recommendation_raw['LastDeliveredDate'].apply(lambda x: (datetime.now() - x).days)\n",
    "    df_customer_sku_recommendation_raw['Recency'] = df_customer_sku_recommendation_raw['Recency'].fillna(max(df_customer_sku_recommendation_raw['Recency']))\n",
    "    \n",
    "    # ----------------- STOCKPOINT\n",
    "    df_stockpoint_dim_raw.rename(columns={'lattitude':'Latitude', 'longitude':'Longitude'}, inplace=True) \n",
    "    col3 = ['Latitude', 'Longitude']\n",
    "    for col in col3: \n",
    "        df_stockpoint_dim_raw[col] = pd.to_numeric(df_stockpoint_dim_raw[col], errors='coerce').fillna(0)    \n",
    "\n",
    "    # Replace invalid latitude values with NaN\n",
    "    df_stockpoint_dim_raw = clean_invalid_coordinates(df_stockpoint_dim_raw)   \n",
    "    \n",
    "\n",
    "    return df_customer_sku_recommendation_raw, df_master_customer_dim, df_stockpoint_dim_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50d39f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_filter(df_customer_sku_recommendation, df_master_customer_dim, df_stockpoint_dim,\n",
    "                stockpoint_id,  sku_recency = 7, customer_recency = 90, number_recommendation = 5,\n",
    "                estimate_qty_scale_factor = .90, max_estimated_qty = 5, exclude_recency_customer = 4):\n",
    "    \n",
    "    df_customer_sku_recommendation = df_customer_sku_recommendation.copy().query(f'Stock_Point_ID == {stockpoint_id}')\n",
    "    # Filter Recommendation\n",
    "    df_customer_sku_recommendation = df_customer_sku_recommendation[df_customer_sku_recommendation['ProductTag'] != 'Standard-Inactive']\n",
    "    df_customer_sku_recommendation = df_customer_sku_recommendation[df_customer_sku_recommendation['Medium'] != 'Never Purchased']\n",
    "\n",
    "    # Filter customer base\n",
    "    df_master_customer_dim['valid_for_push'] = np.where(\n",
    "                                                    #  df_master_customer_dim['KYC_Capture_Status'] == 'Yes'   \n",
    "                                                    (\n",
    "                                                        (df_master_customer_dim['IsLocationCaptured'] == 'Yes') |\n",
    "                                                        (df_master_customer_dim['DistanceVarianceInMeter'] <= 150.0) |\n",
    "                                                        (df_master_customer_dim['KYC_Capture_Status'] == 'Yes') |\n",
    "                                                        (df_master_customer_dim['CustomerPurchaseRecency'] <= customer_recency)\n",
    "                                                    )\n",
    "                                                    ,1,0\n",
    "                                                )\n",
    "    # df_master_customer_dim = df_master_customer_dim[df_master_customer_dim['CustomerPurchaseRecency'] <= customer_recency]\n",
    "    df_master_customer_dim = df_master_customer_dim.query('valid_for_push == 1')  \n",
    "    # Exclude Customer with recent purchase of any SKU\n",
    "    df_master_customer_dim = df_master_customer_dim.query(f'CustomerPurchaseRecency > {exclude_recency_customer}')\n",
    "    # Customer with valid Location Coordination\n",
    "    df_master_customer_dim = df_master_customer_dim.query('Latitude != 0').reset_index(drop=True)\n",
    "    \n",
    "    # # Clipping Max Estimated Quantity to 10 qty\n",
    "    df_customer_sku_recommendation['EstimatedQuantity_bck'] = df_customer_sku_recommendation['EstimatedQuantity']\n",
    "    df_customer_sku_recommendation['EstimatedQuantity'] = df_customer_sku_recommendation['EstimatedQuantity'].apply(lambda x: max_estimated_qty if int((x*estimate_qty_scale_factor)) > max_estimated_qty else int((x*estimate_qty_scale_factor)) )\n",
    "\n",
    "\n",
    "    # Select top 10 SKU by SKURank per customer\n",
    "    df_customer_sku_recommendation = (\n",
    "        df_customer_sku_recommendation\n",
    "        .query('EstimatedQuantity > 1')\n",
    "        .sort_values(['CustomerID','CustomerSKUscoreRank'])\n",
    "        .groupby('CustomerID', group_keys=False)\n",
    "        .head(number_recommendation)\n",
    "        .reset_index(drop=True) \n",
    "    )\n",
    "\n",
    "    df_customer_sku_recommendation_ = df_master_customer_dim.merge(df_customer_sku_recommendation, how='inner', on = ['CustomerID','Stock_Point_ID'])  \n",
    "\n",
    "    df_stockpoint_dim = df_stockpoint_dim.query(f'Stock_Point_ID == {stockpoint_id}').reset_index(drop=True) \n",
    "    \n",
    "\n",
    "    df_customer_dim = df_master_customer_dim.merge(df_customer_sku_recommendation_['CustomerID'].drop_duplicates(), how='inner', on = 'CustomerID')\n",
    "    # df_customer_dim = df_customer_dim.merge(df_customer_dim_with_affinity_score[sel_cols], how='inner', on = 'CustomerID').reset_index(drop = True) \n",
    "    \n",
    "    print(f'Total Quantity before filter: {df_customer_sku_recommendation.query(f\"Stock_Point_ID == {stockpoint_id}\").EstimatedQuantity.sum():,}')\n",
    "    print(f'Total Quantity: {df_customer_sku_recommendation_.EstimatedQuantity.sum():,}')\n",
    "    print(f'Total Number of Customers before filter: {df_customer_sku_recommendation.query(f\"Stock_Point_ID == {stockpoint_id}\").CustomerID.nunique():,}')\n",
    "    print(f'Total Number of Customers: {df_customer_dim.CustomerID.nunique():,}')\n",
    "\n",
    " \n",
    "    return df_customer_sku_recommendation_, df_customer_dim,   df_stockpoint_dim  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b10555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a26754f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_data(\n",
    "        selected_trip,\n",
    "        all_push_recommendation,\n",
    "        cluster_summary,\n",
    "        stock_point_name\n",
    "    ): \n",
    "    dir_path = f'./recommendation_output/{CURRENT_DATE}'\n",
    "    \n",
    "    # Ensure directory exists\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    \n",
    "    file_path = f'{dir_path}/{stock_point_name}_{CURRENT_DATE}.xlsx'\n",
    "\n",
    "    with pd.ExcelWriter(file_path) as writer:\n",
    "        selected_trip.to_excel(writer, sheet_name='Selected Trip', index=False)\n",
    "        all_push_recommendation.to_excel(writer, sheet_name='All Recommendation', index=False)\n",
    "        cluster_summary.to_excel(writer, sheet_name='Recommendation Cluster Summary', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939127f3",
   "metadata": {},
   "source": [
    "#### Map-Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7525cc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_and_save(df_routes, \n",
    "                 df_stockpoint = None,   \n",
    "                 filename=None,\n",
    "                 cluster_col='cluster'):\n",
    "    \n",
    "    map_clusters = create_enhanced_cluster_map(\n",
    "        df_routes,\n",
    "        popup_cols=['CustomerID', 'LGA', 'LCDA'],\n",
    "        tooltip_cols=['LGA', 'LCDA'], \n",
    "        cluster_col = cluster_col,\n",
    "        zoom_start=10, \n",
    "        radius=8\n",
    "    )\n",
    "    \n",
    "    if df_stockpoint:\n",
    "        depot_location = [df_stockpoint.Latitude[0], df_stockpoint.Longitude[0]]\n",
    "        depot_name = df_stockpoint.Stock_point_Name[0]\n",
    "        map_clusters = map_clusters.add_child(folium.Marker(location=depot_location, \n",
    "                                size = 10, \n",
    "                                tooltip=depot_name, \n",
    "                                icon=folium.Icon(color=\"green\", \n",
    "                                icon=\"home\")))  \n",
    "    if filename:\n",
    "        map_clusters.save(filename)\n",
    "    return map_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ff9846",
   "metadata": {},
   "source": [
    "#### Cluster Summary Route-Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee878c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_unsupervised_clustering(df):\n",
    "    # Usage:\n",
    "    X = df[['Latitude', 'Longitude']].values\n",
    "    labels = df['cluster'].values\n",
    "    scores = {\n",
    "        \"Silhouette Score\":  silhouette_score(X, labels).round(2),\n",
    "        \"Davies-Bouldin Index\": davies_bouldin_score(X, labels).round(2),\n",
    "        \"Calinski-Harabasz Score\": calinski_harabasz_score(X, labels).round(2)\n",
    "    }\n",
    "\n",
    "    for key in scores:\n",
    "        print(f\"{key}: {scores[key]}\")\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b65cbb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stockpoint_dict(df_selected_trip, df_stockpoint_dim):\n",
    "    \"\"\"\n",
    "    Create a dictionary structure with stock point information and associated trips.\n",
    "    \n",
    "    Parameters:\n",
    "    df_selected_trip: DataFrame with columns ['StockPointID', 'StockPointName', 'TripID', 'CustomerID', 'Latitude', 'Longitude', 'EstimatedQuantity']\n",
    "    df_stockpoint_dim: DataFrame with columns ['Stock_Point_ID', 'Stock_point_Name', 'Latitude', 'Longitude']\n",
    "    \n",
    "    Returns:\n",
    "    dict: Dictionary with stock point information and trips\n",
    "    \"\"\"\n",
    "    if df_selected_trip.empty:\n",
    "        logger.info('Dataframe is empty')\n",
    "        return {}\n",
    "    \n",
    "    # Group by StockPointID to handle each stock point\n",
    "    stockpoint_groups = df_selected_trip.groupby('StockPointID')\n",
    "    \n",
    "    result = {}\n",
    "    \n",
    "    for stock_point_id, group in stockpoint_groups:\n",
    "        # Get stock point information from df_stockpoint_dim\n",
    "        stock_point_info = df_stockpoint_dim[df_stockpoint_dim['Stock_Point_ID'] == stock_point_id]\n",
    "        \n",
    "        if stock_point_info.empty:\n",
    "            # If stock point not found in dimension table, use info from selected_trip\n",
    "            stock_point_name = group['StockPointName'].iloc[0]\n",
    "            # Note: We'll need to get coordinates from somewhere since customer coordinates \n",
    "            # in df_selected_trip are for destinations, not stock points\n",
    "            stock_point_coord = [0, 0]  # Placeholder - you may need to adjust this\n",
    "        else:\n",
    "            stock_point_name = stock_point_info['Stock_point_Name'].iloc[0]\n",
    "            stock_point_coord = [\n",
    "                stock_point_info['Longitude'].iloc[0], \n",
    "                stock_point_info['Latitude'].iloc[0]\n",
    "            ]\n",
    "        \n",
    "        # Group by TripID to organize trips\n",
    "        trip_groups = group.groupby('TripID')\n",
    "        trips = []\n",
    "        \n",
    "        for trip_id, trip_group in trip_groups:\n",
    "            # Create destinations list for this trip\n",
    "            destinations = []\n",
    "            for _, row in trip_group.iterrows():\n",
    "                destination = {\n",
    "                    'CustomerID': row['CustomerID'],\n",
    "                    'Coordinate': [row['Longitude'], row['Latitude']]\n",
    "                }\n",
    "                destinations.append(destination)\n",
    "            \n",
    "            # Create trip dictionary\n",
    "            trip_dict = {\n",
    "                'TripID': trip_id,\n",
    "                'Destinations': destinations\n",
    "            }\n",
    "            trips.append(trip_dict)\n",
    "        \n",
    "        # Create the final dictionary structure for this stock point\n",
    "        result[stock_point_id] = {\n",
    "            'StockPointName': stock_point_name,\n",
    "            'StockPointID': stock_point_id,\n",
    "            'StockPointCoord': stock_point_coord,\n",
    "            'Trips': trips\n",
    "        }\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# Alternative version if you want a single dictionary (assuming only one stock point)\n",
    "def create_single_stockpoint_dict(df_selected_trip, df_stockpoint_dim):\n",
    "    \"\"\"\n",
    "    Create a single dictionary structure for one stock point.\n",
    "    \n",
    "    Parameters:\n",
    "    df_selected_trip: DataFrame with trip data for one stock point\n",
    "    df_stockpoint_dim: DataFrame with stock point dimension data\n",
    "    \n",
    "    Returns:\n",
    "    dict: Single dictionary with stock point information and trips\n",
    "    \"\"\"\n",
    "    if df_selected_trip.empty:\n",
    "        logger.info('Dataframe is empty')\n",
    "        return {}\n",
    "    \n",
    "    # Get the stock point ID (assuming all rows have the same stock point)\n",
    "    stock_point_id = df_selected_trip['StockPointID'].iloc[0]\n",
    "    \n",
    "    # Get stock point information from df_stockpoint_dim\n",
    "    stock_point_info = df_stockpoint_dim[df_stockpoint_dim['Stock_Point_ID'] == stock_point_id]\n",
    "    \n",
    "    if stock_point_info.empty:\n",
    "        stock_point_name = df_selected_trip['StockPointName'].iloc[0]\n",
    "        stock_point_coord = [0, 0]  # Placeholder\n",
    "    else:\n",
    "        stock_point_name = stock_point_info['Stock_point_Name'].iloc[0] \n",
    "        stock_point_coord = [\n",
    "            stock_point_info['Longitude'].iloc[0], \n",
    "            stock_point_info['Latitude'].iloc[0]\n",
    "        ]\n",
    "    \n",
    "    # Group by TripID\n",
    "    trip_groups = df_selected_trip.groupby('TripID')\n",
    "    trips = []\n",
    "    \n",
    "    for trip_id, trip_group in trip_groups:\n",
    "        destinations = []\n",
    "        for _, row in trip_group.iterrows():\n",
    "            destination = {\n",
    "                'CustomerID': row['CustomerID'],\n",
    "                'Coordinate': [row['Longitude'], row['Latitude']]\n",
    "            }\n",
    "            destinations.append(destination)\n",
    "        \n",
    "        trip_dict = {\n",
    "            'TripID': trip_id,\n",
    "            'Destinations': destinations\n",
    "        }\n",
    "        trips.append(trip_dict)\n",
    "    \n",
    "    # Return the final dictionary\n",
    "    return {\n",
    "        'StockPointName': stock_point_name,\n",
    "        'StockPointID': stock_point_id,\n",
    "        'StockPointCoord': stock_point_coord,\n",
    "        'Trips': trips\n",
    "    }\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# \"\"\"\n",
    "# # For multiple stock points:\n",
    "# result_dict = create_stockpoint_dict(df_selected_trip, df_stockpoint_dim)\n",
    "\n",
    "# # For a single stock point:\n",
    "# single_result = create_single_stockpoint_dict(df_selected_trip, df_stockpoint_dim)\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f4c7281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_route(df_selected_trip, df_stockpoint_dim):\n",
    "    # Path \n",
    "    main_dir = f'./recommendation_output/selected_trip_map/{CURRENT_DATE}' \n",
    "    os.makedirs(f'{main_dir}', exist_ok=True)\n",
    "\n",
    "\n",
    "    trip_dict = create_single_stockpoint_dict(df_selected_trip, df_stockpoint_dim) \n",
    "\n",
    "    if trip_dict == {}:\n",
    "        logger.info('Trip Data is empty')\n",
    "    else:\n",
    "        try:\n",
    "            StockPointID = trip_dict['StockPointID']\n",
    "            output_filename = f'{main_dir}/{StockPointID}.html'\n",
    "            # Step 1: Get route information for all trips\n",
    "            calculated_routes_info = get_valhalla_routes_info(trip_dict)\n",
    "\n",
    "            # Step 2: Plot all routes on a map\n",
    "            plot_routes_on_map(trip_data=trip_dict, routes_info=calculated_routes_info, output_filename = output_filename)\n",
    "        except Exception as e:\n",
    "            logger.warn(f'Some vital error occured while creating route {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dce62501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_route_optimizer(df_clustering, sel_cluster_tuple, df_stockpoint, \n",
    "                        stock_point_name,\n",
    "                        sel_total_customer_count, capacity_size = 20):\n",
    "     # ---- SETUP CLIENT\n",
    "     try:\n",
    "          client = Valhalla(base_url=VALHALLA_BASE_URL)\n",
    "          if VALHALLA_API_KEY:\n",
    "               client = Valhalla(base_url=VALHALLA_BASE_URL, api_key=VALHALLA_API_KEY)\n",
    "          \n",
    "          logger.info('Setting up routing client via LOCAL host Valhalla')\n",
    "     except Exception as e:\n",
    "          logger.warning('Setting up routing client via ORS')\n",
    "          client = ors.Client(key=os.getenv('ORS_KEY')) \n",
    "\n",
    "     # Select cluster 37\n",
    "     df_sel_clust = df_clustering.query(f'cluster in {sel_cluster_tuple}').query('Latitude > 0')\n",
    "\n",
    "     # Ensure coordinates are in [longitude, latitude] for ORS\n",
    "     coords = [[lon, lat] for lat, lon in zip(df_sel_clust.Latitude, df_sel_clust.Longitude)]\n",
    "     # Print number of jobs\n",
    "     print(\"Number of customer locations:\", len(coords))\n",
    "     # Convert depot_location to ORS format\n",
    "     # Assuming depot_location is [lat, lon], flip to [lon, lat]\n",
    "     vehicle_start = [df_stockpoint.Longitude[0], df_stockpoint.Latitude[0]]\n",
    "     num_vehicles = math.floor(sel_total_customer_count / capacity_size)\n",
    "     vehicles = [\n",
    "          ors.optimization.Vehicle(\n",
    "               id=i,\n",
    "               profile='driving-car',\n",
    "               start=vehicle_start,\n",
    "               end=vehicle_start,\n",
    "               capacity=[capacity_size]\n",
    "          ) for i in range(num_vehicles)\n",
    "     ]\n",
    "\n",
    "     # Define jobs (each customer gets amount=[1])\n",
    "     jobs = [ors.optimization.Job(id=index, location=coord, amount=[1]) for index, coord in enumerate(coords)]\n",
    "\n",
    "     # Call ORS optimization API\n",
    "     optimized = client.optimization(jobs=jobs, vehicles=vehicles, geometry=True)\n",
    "\n",
    "     #     ------ MAP\n",
    "     depot_location = [df_stockpoint.Latitude[0], df_stockpoint.Longitude[0]]\n",
    "     depot_name = df_stockpoint.Stock_point_Name[0]\n",
    "\n",
    "     map_clusters_route = create_enhanced_cluster_map(\n",
    "     df_sel_clust,\n",
    "     popup_cols=['CustomerID', 'LGA', 'LCDA'],\n",
    "     tooltip_cols=['LGA', 'LCDA'], \n",
    "     zoom_start=10, \n",
    "     radius=10\n",
    "     ).add_child(folium.Marker(location=depot_location, \n",
    "                         size = 10, \n",
    "                         tooltip=depot_name, \n",
    "                         icon=folium.Icon(color=\"green\", \n",
    "                         icon=\"home\")))\n",
    "\n",
    "     # line_colors = ['green', 'orange', 'blue', 'yellow']\n",
    "     separable_colors = [\n",
    "          \"#1f77b4\",  # blue\n",
    "          \"#ff7f0e\",  # orange\n",
    "          \"#2ca02c\",  # green\n",
    "          \"#d62728\",  # red\n",
    "          \"#9467bd\",  # purple\n",
    "          \"#8c564b\",  # brown\n",
    "          \"#e377c2\",  # pink\n",
    "          \"#7f7f7f\",  # gray\n",
    "          \"#bcbd22\",  # yellow-green\n",
    "          \"#17becf\",  # cyan\n",
    "          \"#aec7e8\",  # light blue\n",
    "          \"#ffbb78\",  # light orange\n",
    "          ]\n",
    "\n",
    "     line_colors = separable_colors[0:num_vehicles] #['green', 'orange', 'blue', 'yellow']\n",
    "     for route in optimized['routes']:\n",
    "          folium.PolyLine(locations=[list(reversed(coords)) for coords in ors.convert.decode_polyline(route['geometry'])['coordinates']], color=line_colors[route['vehicle']]).add_to(map_clusters_route)\n",
    "\n",
    "     #\n",
    "     selected_trip_map_path = f'./recommendation_output/selected_trip_map/{stock_point_name}_{CURRENT_DATE}.html' \n",
    "     map_clusters_route.save(selected_trip_map_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b107eaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_trip_route(df_sku_rec, \n",
    "                       df_customer_dim, \n",
    "                       df_stockpoint,\n",
    "                       stock_point_id,\n",
    "                       max_customers_per_route, \n",
    "                       max_volume_per_route,\n",
    "                       max_distance_km, \n",
    "                       clustering_method='divisive',\n",
    "                       skip_route_optimization = False):\n",
    "     \n",
    "\n",
    "    optimizer = RouteOptimizer(\n",
    "        max_customers_per_route=max_customers_per_route,\n",
    "        max_volume_per_route=max_volume_per_route,\n",
    "        max_distance_km = max_distance_km\n",
    "    )\n",
    "\n",
    "    optimizer.load_data(df_sku_rec, df_customer_dim, df_stockpoint)\n",
    "    print(\"✓ Route optimizer initialized\")\n",
    "\n",
    "    # STEP 3: Generate Routes for Stock Point 1647113\n",
    "    print(\"\\n3. Generating Optimized Routes...\")\n",
    "    print(\"-\" * 40) \n",
    "\n",
    "    stock_point = df_stockpoint[df_stockpoint['Stock_Point_ID'] == stock_point_id].reset_index(drop = True)\n",
    "    \n",
    "    stock_point_coords = (stock_point['Latitude'], stock_point['Longitude'])\n",
    "        \n",
    "    clustering_customers_df = optimizer.filter_customers_for_stockpoint(stock_point_id)\n",
    "\n",
    "    df_clustering, n_clusters = optimizer.create_geographic_clusters(clustering_customers_df, \n",
    "                                                                     clustering_method = clustering_method)\n",
    "\n",
    "    if skip_route_optimization == True:\n",
    "        routes = optimizer.generate_multi_trip_routes(stock_point_id, \n",
    "                                                    max_trips=5, \n",
    "                                                    clustering_method=clustering_method)\n",
    "        df_routes = pd.DataFrame(routes)\n",
    "    else:\n",
    "        df_routes = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "    # STEP 4: Analyze Results\n",
    "    print(\"\\n4. Route Analysis & Results...\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    push_recommendation = df_sku_rec.merge(df_clustering[['Stock_Point_ID','CustomerID', 'cluster']], \n",
    "                                           how='inner', on =['Stock_Point_ID','CustomerID'] )\n",
    "    \n",
    "    ### Cluster Evaluation\n",
    "    evaluate_unsupervised_clustering(df_clustering)\n",
    "\n",
    "    return push_recommendation, df_clustering, df_routes, stock_point_coords\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1bc8a429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_summary_and_selection(push_recommendation,\n",
    "                                  sel_trip_cluster,\n",
    "                                  min_ncust_per_cluster = 4\n",
    "                                  ):\n",
    "    ### Cluster Summary \n",
    "    cluster_summary = (\n",
    "        push_recommendation\n",
    "        .groupby('cluster').agg(\n",
    "            LGA_list = ('LGA', lambda x: x.unique().tolist()),\n",
    "            LCDA_List = ('LCDA', lambda x: x.unique().tolist()),\n",
    "            ncustomer = ('CustomerID','nunique'),\n",
    "            totalQty = ('EstimatedQuantity','sum'), \n",
    "            avg_customer_score = ('composite_customer_score','mean'),\n",
    "        )\n",
    "        .reset_index()\n",
    "        .sort_values(['avg_customer_score','ncustomer', 'totalQty'], \n",
    "                     ascending=[False, False, False])\n",
    "        )\n",
    "\n",
    "    ### Select Trip   \n",
    "    df_high_value_cluster_summary = (\n",
    "            cluster_summary\n",
    "            .query(f'ncustomer >= {min_ncust_per_cluster}')\n",
    "            .head(max(10, sel_trip_cluster))\n",
    "            .reset_index(drop = True)\n",
    "        )\n",
    "    sel_cluster_tuple = df_high_value_cluster_summary.cluster[0:sel_trip_cluster].to_list()\n",
    "    sel_total_customer_count = df_high_value_cluster_summary.head(sel_trip_cluster).ncustomer.sum()\n",
    "    print(f'''Select ClusterIDs: {sel_cluster_tuple}''')\n",
    "    print(f'''Total Number of Customers: {sel_total_customer_count}''')\n",
    "    print(df_high_value_cluster_summary.head(sel_trip_cluster))\n",
    "\n",
    "    return cluster_summary, df_high_value_cluster_summary, sel_cluster_tuple, sel_total_customer_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "171a5cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_selected_trip(push_recommendation, \n",
    "                       cluster_summary,\n",
    "                       df_master_customer_dim,  \n",
    "                       df_stockpoint,\n",
    "                       sel_cluster_tuple):\n",
    "    \n",
    "        \n",
    "\n",
    "    sel_columns = ['Stock_Point_ID', \n",
    "                'StateName', # 'Region', \n",
    "                'Latitude', 'Longitude', 'LGA', 'LCDA', 'cluster', \n",
    "                'CustomerID', 'SKUID', 'ProductName', 'Output',\n",
    "                'LastDeliveredDate', 'Recency', 'InventoryCheck', 'ProductTag', 'Medium',\n",
    "                'EstimatedQuantity', \n",
    "                # 'CustomerSKUscoreRank'\n",
    "                ]\n",
    "\n",
    "    sel_cols_cust= ['Stock_Point_ID', 'CustomerID', 'ContactName',  'CustomerModeName',   'ContactPhone', 'FullAddress', \n",
    "                    'composite_customer_score', 'percentile_rank',  'KYC_Capture_Status', 'CustomerPurchaseRecency']\n",
    "\n",
    "    final_cols = ['Stock_Point_ID', 'Stock_point_Name', 'TripID', 'LGA_list', 'LCDA_List', \n",
    "                  'ncustomer', 'totalQty','avg_customer_score', 'CustomerID', 'ContactName',  \n",
    "                  'CustomerModeName',   'ContactPhone', 'FullAddress', 'Latitude',\n",
    "                  'Longitude', 'LGA', 'LCDA', 'composite_customer_score', #, 'percentile_rank',  \n",
    "                  'KYC_Capture_Status', 'SKUID', 'ProductName', #'Output', 'LastDeliveredDate', \n",
    "                  'Recency','CustomerPurchaseRecency', 'InventoryCheck', 'ProductTag', 'Medium', 'EstimatedQuantity',\n",
    "                ]\n",
    "    \n",
    "    def _merge_select(df):\n",
    "        modified_df = (\n",
    "                        df[sel_columns]\n",
    "                        .merge(cluster_summary, how='left', on = 'cluster' )\n",
    "                        .merge(df_master_customer_dim[sel_cols_cust], how='left', on = ['Stock_Point_ID', 'CustomerID'])\n",
    "                        .merge(df_stockpoint[['Stock_Point_ID', 'Stock_point_Name']], how='left', on = ['Stock_Point_ID'])\n",
    "                        .rename(columns={'cluster':'TripID'})\n",
    "                        [final_cols]\n",
    "                        .rename(columns = {\n",
    "                                           'Stock_point_Name': 'StockPointName'\n",
    "                                           ,'Stock_Point_ID': 'StockPointID'\n",
    "                                           ,'ncustomer': 'TotalCustonerCount'\n",
    "                                           ,'totalQty': 'TripTotalQuantity'\n",
    "                                           ,'avg_customer_score': 'TripAvgCustomerScore'\n",
    "                                           ,'LastDeliveredDate': 'CustomerLastDeliveredDate'\n",
    "                                           ,'Medium': 'RecommendationType'\n",
    "                                           ,'Recency': 'SKUDaysSinceLastBuy'\n",
    "                                           ,'CustomerPurchaseRecency': 'CustomerDaysSinceLastBuy'\n",
    "                                           ,'composite_customer_score': 'CustomerScore'\n",
    "                                           ,'KYC_Capture_Status': 'kycCaptureStatus'\n",
    "                                           ,'LGA_list': 'ClusterLGAs'\n",
    "                                           ,'LCDA_List': 'ClusterLCDAs'\n",
    "                                           })\n",
    "                        )\n",
    "        return modified_df\n",
    "\n",
    "    df_selected_trip = push_recommendation[push_recommendation['cluster'].isin(sel_cluster_tuple)]\n",
    "    selected_push_recommendation_trip = _merge_select(df_selected_trip)\n",
    "    all_push_recommendation =  _merge_select(push_recommendation)\n",
    "    all_push_recommendation['isTripSelected'] = np.where(all_push_recommendation['TripID'].isin(sel_cluster_tuple) ,\n",
    "                                                    'Yes',\n",
    "                                                    'No'\n",
    "                                                )\n",
    "    \n",
    "\n",
    "    return selected_push_recommendation_trip, all_push_recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762d067f",
   "metadata": {},
   "source": [
    "### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd91edc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_push_recommendation(df_customer_sku_recommendation, \n",
    "                            df_master_customer_dim, \n",
    "                            df_stockpoint_dim, \n",
    "                            stock_point_id,\n",
    "                            stock_point_name,\n",
    "                            sku_recency = 7, \n",
    "                            customer_recency = 60, number_recommendation = 5, \n",
    "                            estimate_qty_scale_factor = 1, max_estimated_qty = 5, \n",
    "                            exclude_recency_customer = 4,\n",
    "                            max_customers_per_route=20,\n",
    "                            max_volume_per_route=300,\n",
    "                            max_distance_km = 40,\n",
    "                            sel_trip_cluster = 5,\n",
    "                            min_ncust_per_cluster = 5,\n",
    "                            clustering_method = 'divisive',\n",
    "                            skip_route_optimization = False):\n",
    "    \"\"\"\n",
    "    Main execution function demonstrating complete route optimization workflow\n",
    "    \"\"\" \n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\")\n",
    "    print(f\"StockPoint: {stock_point_name}, StockPointID: {stock_point_id},\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # STEP 1: Load or Generate Data\n",
    "    print(\"\\n1. Loading Data...\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    df_sku_rec, df_customer_dim, df_stockpoint  = data_filter(df_customer_sku_recommendation, \n",
    "                                                                df_master_customer_dim, \n",
    "                                                                df_stockpoint_dim, \n",
    "                                                                stockpoint_id = stock_point_id,  \n",
    "                                                                sku_recency = sku_recency, \n",
    "                                                                customer_recency = customer_recency, \n",
    "                                                                number_recommendation = number_recommendation,\n",
    "                                                                estimate_qty_scale_factor = estimate_qty_scale_factor, \n",
    "                                                                max_estimated_qty = max_estimated_qty,\n",
    "                                                                exclude_recency_customer = exclude_recency_customer)\n",
    "\n",
    "    if len(df_customer_dim) < min_ncust_per_cluster:\n",
    "        return {}\n",
    "    \n",
    "    print(f\"✓ Loaded {len(df_sku_rec)} SKU recommendations\")\n",
    "    print(f\"✓ Loaded {len(df_customer_dim)} customer records\")\n",
    "    print(f\"✓ Loaded {len(df_stockpoint)} stock points\")\n",
    "\n",
    "    push_recommendation, df_clustering, df_routes, stock_point_coords = cluster_trip_route(df_sku_rec, \n",
    "                                                                                            df_customer_dim, \n",
    "                                                                                            df_stockpoint,\n",
    "                                                                                            stock_point_id,\n",
    "                                                                                            max_customers_per_route, \n",
    "                                                                                            max_volume_per_route,\n",
    "                                                                                            max_distance_km,\n",
    "                                                                                            clustering_method,\n",
    "                                                                                            skip_route_optimization)\n",
    "\n",
    "    ### Cluster Evaluation\n",
    "    _ = evaluate_unsupervised_clustering(df_clustering) \n",
    "    \n",
    "    ### Cluster Summary \n",
    "    cluster_summary, df_high_value_cluster_summary, sel_cluster_tuple, sel_total_customer_count = cluster_summary_and_selection(\n",
    "                                                                                                        push_recommendation,\n",
    "                                                                                                        sel_trip_cluster,\n",
    "                                                                                                        min_ncust_per_cluster = min_ncust_per_cluster\n",
    "                                                                                                        )\n",
    "\n",
    "    ## Trip\n",
    "    selected_push_recommendation_trip, all_push_recommendation = prep_selected_trip(push_recommendation, \n",
    "                                                  cluster_summary, \n",
    "                                                  df_master_customer_dim,  \n",
    "                                                  df_stockpoint,\n",
    "                                                  sel_cluster_tuple)\n",
    "    \n",
    " \n",
    "    ### Trip Maps\n",
    "    if skip_route_optimization:\n",
    "        try:\n",
    "            df_selected_trip_summary =  selected_push_recommendation_trip.groupby(['StockPointID','TripID', \n",
    "                                                                                   'CustomerID', 'Latitude','Longitude',\n",
    "                                                                                   'LGA', 'LCDA','CustomerScore']).agg( \n",
    "                        TotalQuantity = ('EstimatedQuantity','sum')\n",
    "                        ,TotalSKU = ('SKUID','nunique')\n",
    "                    ).reset_index()\n",
    "            create_route(df_selected_trip_summary, df_stockpoint)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    else:\n",
    "        try:\n",
    "            trip_map_path = f'./recommendation_output/trip_map/{stock_point_name}_{CURRENT_DATE}.html' \n",
    "            map_clusters = vis_and_save(df_routes= (df_routes\n",
    "                                                .rename(columns={'cluster':'cluster_bck'})\n",
    "                                                .rename(columns={'TripNumber':'cluster'})\n",
    "                                                ), \n",
    "                                        df_stockpoint=df_stockpoint, \n",
    "                                        filename=trip_map_path)\n",
    "        except Exception as e:\n",
    "            print(f'Unable to save the generated map image: {e}')\n",
    "\n",
    "        try:\n",
    "            run_route_optimizer(df_clustering, sel_cluster_tuple, df_stockpoint, \n",
    "                            stock_point_name,\n",
    "                            sel_total_customer_count, \n",
    "                            capacity_size = 20)\n",
    "        except Exception as e:\n",
    "            print(f'Unable to generate route mapping using orc: {e}')       \n",
    "    \n",
    "\n",
    "    ### Export Data\n",
    "    try:\n",
    "        export_data(\n",
    "                selected_trip = selected_push_recommendation_trip,\n",
    "                all_push_recommendation = all_push_recommendation,\n",
    "                cluster_summary = cluster_summary,\n",
    "                stock_point_name = stock_point_name\n",
    "            )\n",
    "    except Exception as e:\n",
    "        print(f'Unable to generate route mapping using orc: {e}')\n",
    "\n",
    "    dict_ = {\n",
    "        'stock_point_name': stock_point_name,\n",
    "        'selected_trip': selected_push_recommendation_trip,\n",
    "        'all_push_recommendation': all_push_recommendation,\n",
    "        'cluster_summary': cluster_summary\n",
    "    }\n",
    "\n",
    "    return dict_\n",
    "    #push_recommendation, df_clustering, df_routes, trip_summary, stock_point_coords, df_stockpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44619d0",
   "metadata": {},
   "source": [
    "# Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8cc0a172",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Data\n",
    "df_customer_sku_recommendation_raw = pd.read_feather('./input/customer_sku_recommendation.feather').rename(columns={'FCID':'Stock_Point_ID','CustomerId':'CustomerID'})\n",
    "df_customer_dim_with_affinity_score_raw = pd.read_feather('./input/customer_dim_with_affinity_score.feather').rename(columns={'FCID':'Stock_Point_ID'})\n",
    "df_stockpoint_dim_raw = pd.read_feather('./input/stockpoint_dim.feather')\n",
    "df_kyc_customer = pd.read_feather('./input/kyc_customers.feather')\n",
    "df_customer_score = pd.read_feather('./input/df_customer_score.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1617177c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "df_customer_sku_recommendation, df_master_customer_dim, df_stockpoint_dim = preprocessing(df_customer_sku_recommendation_raw, \n",
    "                                                                                                        df_customer_dim_with_affinity_score_raw, \n",
    "                                                                                                        df_stockpoint_dim_raw,\n",
    "                                                                                                        df_customer_score,\n",
    "                                                                                                        df_kyc_customer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe979f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# causeway_customer_dim.query(\"days_since_last_order > 60\")[['KYC_Capture_Status']].value_counts()\n",
    "# causeway_customer_dim.query(\"KYC_Capture_Status == 'No'\")[['days_since_last_order']].hist()#.value_counts()#.reset_index().sort_values('days_since_last_order')\n",
    "# causeway_customer_dim.KYC_Capture_Status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904b1d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [col for col in df_stockpoint_dim.Stock_point_Name if 'C' in col] \n",
    "# test_sp = 'OmniHub Apapa Lagos - CAUSEWAY'\n",
    "# # # test_spid = 1647402\n",
    "# # test_sp = 'OmniHub Alimosho Lagos - Barka Agro Mix'\n",
    "# # test_spid = 1647345\n",
    "\n",
    "# df_stockpoint_dim[df_stockpoint_dim['Stock_point_Name'] == test_sp]\n",
    "# # # df_customer_sku_recommendation.query(f'Stock_Point_ID == {test_spid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518e3101",
   "metadata": {},
   "source": [
    "### Iterative Run - All SPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d43aaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Point ID: 1647128 || Stock Point Name: OmniHub Obio Akpor Rivers - Rivoc\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Obio Akpor Rivers - Rivoc, StockPointID: 1647128,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 50\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 1\n",
      "Total Number of Customers: 0\n",
      "Stock Point ID: 1647401 || Stock Point Name: OmniHub Ado Odo/Ota Ogun - Prince Tunadek\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ado Odo/Ota Ogun - Prince Tunadek, StockPointID: 1647401,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 254\n",
      "Total Quantity: 249\n",
      "Total Number of Customers before filter: 20\n",
      "Total Number of Customers: 19\n",
      "✓ Loaded 59 SKU recommendations\n",
      "✓ Loaded 19 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.55\n",
      "Davies-Bouldin Index: 0.73\n",
      "Calinski-Harabasz Score: 17.77\n",
      "Silhouette Score: 0.55\n",
      "Davies-Bouldin Index: 0.73\n",
      "Calinski-Harabasz Score: 17.77\n",
      "Select ClusterIDs: [1]\n",
      "Total Number of Customers: 9\n",
      "   cluster LGA_list       LCDA_List  ncustomer  totalQty  avg_customer_score\n",
      "0        1    [Ifo]  [, Ifo market]          9       122           31.943333\n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (10 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 18.16 km, Duration: 32.02 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1647401.html\n",
      "Unable to generate route mapping using orc: Cannot save file into a non-existent directory: 'recommendation_output/2025-06-26/OmniHub Ado Odo'\n",
      "Stock Point ID: 1647402 || Stock Point Name: OmniHub AMAC 1 Abuja - Elriah\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub AMAC 1 Abuja - Elriah, StockPointID: 1647402,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 96\n",
      "Total Quantity: 96\n",
      "Total Number of Customers before filter: 8\n",
      "Total Number of Customers: 8\n",
      "✓ Loaded 27 SKU recommendations\n",
      "✓ Loaded 8 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.49\n",
      "Davies-Bouldin Index: 0.31\n",
      "Calinski-Harabasz Score: 29.7\n",
      "Silhouette Score: 0.49\n",
      "Davies-Bouldin Index: 0.31\n",
      "Calinski-Harabasz Score: 29.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Dataframe is empty\n",
      "INFO:__main__:Trip Data is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select ClusterIDs: []\n",
      "Total Number of Customers: 0\n",
      "Empty DataFrame\n",
      "Columns: [cluster, LGA_list, LCDA_List, ncustomer, totalQty, avg_customer_score]\n",
      "Index: []\n",
      "Stock Point ID: 1647136 || Stock Point Name: OmniHub Tarauni Kano - Amjabil\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Tarauni Kano - Amjabil, StockPointID: 1647136,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 5\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 1\n",
      "Total Number of Customers: 0\n",
      "Stock Point ID: 1647076 || Stock Point Name: OmniHub Alimosho Lagos - Isukoshi MFC\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Alimosho Lagos - Isukoshi MFC, StockPointID: 1647076,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "Stock Point ID: 1647394 || Stock Point Name: OmniHub Port Harcourt Rivers - WCG 2\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Port Harcourt Rivers - WCG 2, StockPointID: 1647394,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 16,406\n",
      "Total Quantity: 13,303\n",
      "Total Number of Customers before filter: 476\n",
      "Total Number of Customers: 385\n",
      "✓ Loaded 3577 SKU recommendations\n",
      "✓ Loaded 385 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.55\n",
      "Davies-Bouldin Index: 0.63\n",
      "Calinski-Harabasz Score: 278.24\n",
      "Silhouette Score: 0.55\n",
      "Davies-Bouldin Index: 0.63\n",
      "Calinski-Harabasz Score: 278.24\n",
      "Select ClusterIDs: [17, 24, 9, 18]\n",
      "Total Number of Customers: 36\n",
      "   cluster                              LGA_list  \\\n",
      "0       17                          [Obio Akpor]   \n",
      "1       24                             [Ikwerre]   \n",
      "2        9  [Port Harcourt, Obio Akpor, Ikwerre]   \n",
      "3       18                               [Etche]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0                                       [Rukpokwu, ]          7       228   \n",
      "1                         [Igwuruta, , Igwuruta-Ali]          5       186   \n",
      "2  [Port Harcourt-Transamadi, Woji, Trans Amadi, ...         18       663   \n",
      "3                        [Igbo, , Eegelem, Chokocho]          6       194   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           44.313065  \n",
      "1           43.034286  \n",
      "2           42.639942  \n",
      "3           41.863396  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 9 (19 waypoints)...\n",
      "  Trip ID 9 calculated. Distance: 56.92 km, Duration: 77.83 min\n",
      "  Calculating route for Trip ID: 17 (8 waypoints)...\n",
      "  Trip ID 17 calculated. Distance: 25.02 km, Duration: 30.17 min\n",
      "  Calculating route for Trip ID: 18 (7 waypoints)...\n",
      "  Trip ID 18 calculated. Distance: 27.22 km, Duration: 26.55 min\n",
      "  Calculating route for Trip ID: 24 (6 waypoints)...\n",
      "  Trip ID 24 calculated. Distance: 30.52 km, Duration: 35.37 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1647394.html\n",
      "Stock Point ID: 1647396 || Stock Point Name: OmniHub Oshodi Isolo Lagos - Eloramore\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Oshodi Isolo Lagos - Eloramore, StockPointID: 1647396,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 3,383\n",
      "Total Quantity: 2,632\n",
      "Total Number of Customers before filter: 162\n",
      "Total Number of Customers: 127\n",
      "✓ Loaded 846 SKU recommendations\n",
      "✓ Loaded 127 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.26\n",
      "Davies-Bouldin Index: 0.79\n",
      "Calinski-Harabasz Score: 7756.95\n",
      "Silhouette Score: 0.26\n",
      "Davies-Bouldin Index: 0.79\n",
      "Calinski-Harabasz Score: 7756.95\n",
      "Select ClusterIDs: [2, 6, 3, 1]\n",
      "Total Number of Customers: 74\n",
      "   cluster          LGA_list  \\\n",
      "0        2  [Oshodi Isolo, ]   \n",
      "1        6    [Oshodi Isolo]   \n",
      "2        3    [Oshodi Isolo]   \n",
      "3        1  [, Oshodi Isolo]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [Oshodi Isolo - Shogunle, , Oshodi Isolo - Bol...         23       493   \n",
      "1  [, Oshodi Isolo - Ago Palace, Oshodi Isolo - O...         11       255   \n",
      "2  [, Oshodi Isolo - Okota, Oshodi Isolo - Orile,...         17       367   \n",
      "3  [, Oshodi Isolo - Isolo, Oshodi Isolo - Bolade...         23       428   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           42.449255  \n",
      "1           41.486750  \n",
      "2           37.239492  \n",
      "3           35.853706  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (24 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 56.53 km, Duration: 111.62 min\n",
      "  Calculating route for Trip ID: 2 (24 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 34.72 km, Duration: 86.48 min\n",
      "  Calculating route for Trip ID: 3 (18 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 33.99 km, Duration: 73.95 min\n",
      "  Calculating route for Trip ID: 6 (12 waypoints)...\n",
      "  Trip ID 6 calculated. Distance: 28.83 km, Duration: 54.47 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1647396.html\n",
      "Stock Point ID: 1647075 || Stock Point Name: OmniHub Dugbe Oyo - Derints Enterprises\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Dugbe Oyo - Derints Enterprises, StockPointID: 1647075,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "Stock Point ID: 1647077 || Stock Point Name: OmniHub Surulere Lagos - Platform Height MFC\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Surulere Lagos - Platform Height MFC, StockPointID: 1647077,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "Stock Point ID: 1647400 || Stock Point Name: OmniHub Eleme Rivers - Berclynv\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Eleme Rivers - Berclynv, StockPointID: 1647400,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 7,204\n",
      "Total Quantity: 5,759\n",
      "Total Number of Customers before filter: 290\n",
      "Total Number of Customers: 228\n",
      "✓ Loaded 1687 SKU recommendations\n",
      "✓ Loaded 228 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.64\n",
      "Davies-Bouldin Index: 0.47\n",
      "Calinski-Harabasz Score: 95964.16\n",
      "Silhouette Score: 0.64\n",
      "Davies-Bouldin Index: 0.47\n",
      "Calinski-Harabasz Score: 95964.16\n",
      "Select ClusterIDs: [5, 1, 2, 7]\n",
      "Total Number of Customers: 82\n",
      "   cluster  LGA_list                                          LCDA_List  \\\n",
      "0        5   [Eleme]  [Nichia-Eleme, Aleto, ELEME-ALETO, , Ogale, Ag...   \n",
      "1        1   [Eleme]                               [Onne, , ELEME-ONNE]   \n",
      "2        2  [Okrika]      [Okirika, Ogoloma, Abam – Ama Ii, , Okochiri]   \n",
      "3        7   [Eleme]        [, ELEME-NCHIA, Nichia-Eleme, Aleto, Ogale]   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0         17       417           40.181707  \n",
      "1         26       754           30.103151  \n",
      "2         24       605           29.392043  \n",
      "3         15       362           28.160187  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (27 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 11.32 km, Duration: 14.87 min\n",
      "  Calculating route for Trip ID: 2 (25 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 30.40 km, Duration: 46.45 min\n",
      "  Calculating route for Trip ID: 5 (18 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 10.82 km, Duration: 15.92 min\n",
      "  Calculating route for Trip ID: 7 (16 waypoints)...\n",
      "  Trip ID 7 calculated. Distance: 2.60 km, Duration: 3.60 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1647400.html\n",
      "Stock Point ID: 1647081 || Stock Point Name: OmniHub Alimosho Lagos - Barka-Agro and General Services MFC\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Alimosho Lagos - Barka-Agro and General Services MFC, StockPointID: 1647081,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 5,384\n",
      "Total Quantity: 3,736\n",
      "Total Number of Customers before filter: 205\n",
      "Total Number of Customers: 139\n",
      "✓ Loaded 1165 SKU recommendations\n",
      "✓ Loaded 139 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.34\n",
      "Davies-Bouldin Index: 0.63\n",
      "Calinski-Harabasz Score: 4167.14\n",
      "Silhouette Score: 0.34\n",
      "Davies-Bouldin Index: 0.63\n",
      "Calinski-Harabasz Score: 4167.14\n",
      "Select ClusterIDs: [2, 1, 8, 5]\n",
      "Total Number of Customers: 69\n",
      "   cluster                     LGA_list  \\\n",
      "0        2  [Alimosho, Push - Alimosho]   \n",
      "1        1                   [Alimosho]   \n",
      "2        8                   [Alimosho]   \n",
      "3        5                   [Alimosho]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [Alimosho - Iyana Ipaja (egbeda), Alimosho - I...         19       587   \n",
      "1  [, Alimosho - Iyana Ipaja (shasha), Alimosho -...         30       833   \n",
      "2                               [, Alimosho - Idimu]          5       125   \n",
      "3  [Alimosho - Iyana Ejigbo, Alimosho - Egbe/idim...         15       362   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           58.712156  \n",
      "1           47.426693  \n",
      "2           47.210455  \n",
      "3           40.047477  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (31 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 30.03 km, Duration: 93.03 min\n",
      "  Calculating route for Trip ID: 2 (20 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 18.73 km, Duration: 40.78 min\n",
      "  Calculating route for Trip ID: 5 (16 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 34.47 km, Duration: 55.55 min\n",
      "  Calculating route for Trip ID: 8 (6 waypoints)...\n",
      "  Trip ID 8 calculated. Distance: 17.14 km, Duration: 38.60 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1647081.html\n",
      "Stock Point ID: 1647398 || Stock Point Name: OmniHub Ifako Ijaiye Lagos - Bickson\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ifako Ijaiye Lagos - Bickson, StockPointID: 1647398,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 1,472\n",
      "Total Quantity: 1,331\n",
      "Total Number of Customers before filter: 87\n",
      "Total Number of Customers: 79\n",
      "✓ Loaded 392 SKU recommendations\n",
      "✓ Loaded 79 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.39\n",
      "Davies-Bouldin Index: 0.81\n",
      "Calinski-Harabasz Score: 95.64\n",
      "Silhouette Score: 0.39\n",
      "Davies-Bouldin Index: 0.81\n",
      "Calinski-Harabasz Score: 95.64\n",
      "Select ClusterIDs: [5, 6, 2, 4]\n",
      "Total Number of Customers: 46\n",
      "   cluster                             LGA_list  \\\n",
      "0        5  [Ifako Ijaiye, Agege, Ifako-Ijaiye]   \n",
      "1        6                       [Ifako Ijaiye]   \n",
      "2        2                       [Ifako Ijaiye]   \n",
      "3        4                [Agege, Ifako Ijaiye]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [Agege - Ajuwon Akute Road, , Ifako Ijaiye - O...         10       239   \n",
      "1  [Ifako Ijaiye - Ogba - Obawole, Ifako Ijaiye -...          8       152   \n",
      "2                         [Ifako Ijaiye - Ojokoro, ]         16       310   \n",
      "3                  [, Ifako Ijaiye - Ogba - Obawole]         12       166   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           62.873382  \n",
      "1           53.824792  \n",
      "2           46.546705  \n",
      "3           42.256596  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 2 (17 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 50.21 km, Duration: 102.03 min\n",
      "  Calculating route for Trip ID: 4 (13 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 38.85 km, Duration: 65.45 min\n",
      "  Calculating route for Trip ID: 5 (11 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 36.16 km, Duration: 95.73 min\n",
      "  Calculating route for Trip ID: 6 (9 waypoints)...\n",
      "  Trip ID 6 calculated. Distance: 15.56 km, Duration: 48.37 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1647398.html\n",
      "Stock Point ID: 1646941 || Stock Point Name: OmniHub Ido Oyo - CARESGATE AFRICA LTD\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ido Oyo - CARESGATE AFRICA LTD, StockPointID: 1646941,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 1,919\n",
      "Total Quantity: 1,573\n",
      "Total Number of Customers before filter: 101\n",
      "Total Number of Customers: 84\n",
      "✓ Loaded 423 SKU recommendations\n",
      "✓ Loaded 84 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.46\n",
      "Davies-Bouldin Index: 0.45\n",
      "Calinski-Harabasz Score: 1981.3\n",
      "Silhouette Score: 0.46\n",
      "Davies-Bouldin Index: 0.45\n",
      "Calinski-Harabasz Score: 1981.3\n",
      "Select ClusterIDs: [2, 4, 5, 1]\n",
      "Total Number of Customers: 52\n",
      "   cluster                    LGA_list                     LCDA_List  \\\n",
      "0        2  [Ibadan South West, Ido, ]  [, Apata, IBADAN-APATA, Ido]   \n",
      "1        4    [Ibadan South West, Ido]       [Apata, , IBADAN-APATA]   \n",
      "2        5         [Ibadan South West]                     [Apata, ]   \n",
      "3        1    [Ido, Ibadan South West]  [IBADAN-APATA, Apata, , Ido]   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0         18       314           33.411519  \n",
      "1         10       172           30.039796  \n",
      "2          6       131           26.604857  \n",
      "3         18       295           24.253733  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (19 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 29.37 km, Duration: 44.43 min\n",
      "  Calculating route for Trip ID: 2 (19 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 44.40 km, Duration: 61.60 min\n",
      "  Calculating route for Trip ID: 4 (11 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 32.30 km, Duration: 54.38 min\n",
      "  Calculating route for Trip ID: 5 (7 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 23.45 km, Duration: 23.17 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1646941.html\n",
      "Stock Point ID: 1646945 || Stock Point Name: OmniHub Ado Odo/Ota Ogun - RAZCO ENERGY\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ado Odo/Ota Ogun - RAZCO ENERGY, StockPointID: 1646945,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 20\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 1\n",
      "Total Number of Customers: 0\n",
      "Stock Point ID: 1646999 || Stock Point Name: OmniHub Eti Osa Lagos - Motomori\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Eti Osa Lagos - Motomori, StockPointID: 1646999,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 4,876\n",
      "Total Quantity: 4,028\n",
      "Total Number of Customers before filter: 162\n",
      "Total Number of Customers: 133\n",
      "✓ Loaded 1019 SKU recommendations\n",
      "✓ Loaded 133 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.41\n",
      "Davies-Bouldin Index: 0.68\n",
      "Calinski-Harabasz Score: 26.38\n",
      "Silhouette Score: 0.41\n",
      "Davies-Bouldin Index: 0.68\n",
      "Calinski-Harabasz Score: 26.38\n",
      "Select ClusterIDs: [8, 6, 5, 4]\n",
      "Total Number of Customers: 35\n",
      "   cluster   LGA_list                                          LCDA_List  \\\n",
      "0        8  [Eti Osa]  [Eti Osa - Lekki - Ajah (abraham Adesanya), , ...   \n",
      "1        6  [Eti Osa]  [Eti Osa - Ikoyi Mtn - Pickup Station, , Eti O...   \n",
      "2        5  [Eti Osa]  [, Eti Osa - Lekki - Ajah (abraham Adesanya), ...   \n",
      "3        4  [Eti Osa]  [, Eti Osa - Lekki - Ikota, Eti Osa - Lekki - ...   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0          7       212           59.692941  \n",
      "1          8       227           51.007931  \n",
      "2          9       317           43.869200  \n",
      "3         11       349           41.893736  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 4 (12 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 45.10 km, Duration: 55.25 min\n",
      "  Calculating route for Trip ID: 5 (10 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 26.09 km, Duration: 37.15 min\n",
      "  Calculating route for Trip ID: 6 (9 waypoints)...\n",
      "  Trip ID 6 calculated. Distance: 49.66 km, Duration: 60.77 min\n",
      "  Calculating route for Trip ID: 8 (8 waypoints)...\n",
      "  Trip ID 8 calculated. Distance: 16.60 km, Duration: 29.93 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1646999.html\n",
      "Stock Point ID: 1647010 || Stock Point Name: OmniHub Alimosho Lagos - LARDAMIC\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Alimosho Lagos - LARDAMIC, StockPointID: 1647010,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 2,032\n",
      "Total Quantity: 1,684\n",
      "Total Number of Customers before filter: 69\n",
      "Total Number of Customers: 57\n",
      "✓ Loaded 520 SKU recommendations\n",
      "✓ Loaded 57 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.32\n",
      "Davies-Bouldin Index: 0.78\n",
      "Calinski-Harabasz Score: 43.04\n",
      "Silhouette Score: 0.32\n",
      "Davies-Bouldin Index: 0.78\n",
      "Calinski-Harabasz Score: 43.04\n",
      "Select ClusterIDs: [3, 1, 2]\n",
      "Total Number of Customers: 46\n",
      "   cluster    LGA_list                                          LCDA_List  \\\n",
      "0        3  [Alimosho]  [Alimosho - Abule Egba (ajasa Command Rd), Ali...   \n",
      "1        1  [Alimosho]  [Alimosho - Iyana Ipaja (ikola Road), , Alimos...   \n",
      "2        2  [Alimosho]  [Alimosho - Abule Egba (ajasa Command Rd), Ali...   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0         12       413           63.614167  \n",
      "1         19       529           47.854146  \n",
      "2         15       443           47.264043  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (20 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 23.75 km, Duration: 54.65 min\n",
      "  Calculating route for Trip ID: 2 (16 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 28.23 km, Duration: 55.52 min\n",
      "  Calculating route for Trip ID: 3 (13 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 17.88 km, Duration: 25.30 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1647010.html\n",
      "Stock Point ID: 1646991 || Stock Point Name: OmniHub Badagry Lagos - STEAVESON\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Badagry Lagos - STEAVESON, StockPointID: 1646991,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 2,230\n",
      "Total Quantity: 1,576\n",
      "Total Number of Customers before filter: 122\n",
      "Total Number of Customers: 85\n",
      "✓ Loaded 403 SKU recommendations\n",
      "✓ Loaded 85 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.57\n",
      "Davies-Bouldin Index: 0.4\n",
      "Calinski-Harabasz Score: 36019.89\n",
      "Silhouette Score: 0.57\n",
      "Davies-Bouldin Index: 0.4\n",
      "Calinski-Harabasz Score: 36019.89\n",
      "Select ClusterIDs: [1, 2, 4, 3]\n",
      "Total Number of Customers: 55\n",
      "   cluster                   LGA_list  \\\n",
      "0        1                  [Badagry]   \n",
      "1        2                  [Badagry]   \n",
      "2        4                  [Badagry]   \n",
      "3        3  [Push - Badagry, Badagry]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [, Badagry - Oko-afor, Badagry - Ibereko, Bada...         26       606   \n",
      "1     [Badagry - Oko-afor, , Badagry - Ilogbo-eremi]         14       193   \n",
      "2  [Badagry - Ibereko, , Badagry - Badagry Town, ...          7       136   \n",
      "3                                 [, Badagry - Mowo]          8       143   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           63.100000  \n",
      "1           58.213200  \n",
      "2           55.121935  \n",
      "3           50.649048  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (27 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 16.86 km, Duration: 23.97 min\n",
      "  Calculating route for Trip ID: 2 (15 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 37.02 km, Duration: 44.33 min\n",
      "  Calculating route for Trip ID: 3 (9 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 16.05 km, Duration: 10.75 min\n",
      "  Calculating route for Trip ID: 4 (8 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 12.63 km, Duration: 19.38 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1646991.html\n",
      "Stock Point ID: 1647024 || Stock Point Name: OmniHub Oyigbo Rivers - LAMDA GLOBAL\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Oyigbo Rivers - LAMDA GLOBAL, StockPointID: 1647024,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 11,544\n",
      "Total Quantity: 9,200\n",
      "Total Number of Customers before filter: 307\n",
      "Total Number of Customers: 244\n",
      "✓ Loaded 2263 SKU recommendations\n",
      "✓ Loaded 244 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.33\n",
      "Davies-Bouldin Index: 0.57\n",
      "Calinski-Harabasz Score: 10518.91\n",
      "Silhouette Score: 0.33\n",
      "Davies-Bouldin Index: 0.57\n",
      "Calinski-Harabasz Score: 10518.91\n",
      "Select ClusterIDs: [7, 10, 3, 5]\n",
      "Total Number of Customers: 62\n",
      "   cluster           LGA_list  \\\n",
      "0        7           [Oyigbo]   \n",
      "1       10           [Oyigbo]   \n",
      "2        3    [Etche, Oyigbo]   \n",
      "3        5  [Oyigbo, Etche, ]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [Komkom, OYIGBO (DUPLICATE), PORTHARCOURT-OBIB...         10       357   \n",
      "1                     [OYIGBO (DUPLICATE), , Izuoma]          7       293   \n",
      "2     [Umuebulu, Obeama, Afam, , OYIGBO (DUPLICATE)]         25       913   \n",
      "3                               [Komkom, Umuebulu, ]         20       745   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           58.298632  \n",
      "1           47.452857  \n",
      "2           46.999339  \n",
      "3           43.861154  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 3 (26 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 39.63 km, Duration: 42.73 min\n",
      "  Calculating route for Trip ID: 5 (21 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 18.92 km, Duration: 16.80 min\n",
      "  Calculating route for Trip ID: 7 (11 waypoints)...\n",
      "  Trip ID 7 calculated. Distance: 17.71 km, Duration: 15.63 min\n",
      "  Calculating route for Trip ID: 10 (8 waypoints)...\n",
      "  Trip ID 10 calculated. Distance: 41.42 km, Duration: 49.77 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1647024.html\n",
      "Stock Point ID: 1646989 || Stock Point Name: OmniHub Amuwo Odofin Lagos - GOLDVIRTUES\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Amuwo Odofin Lagos - GOLDVIRTUES, StockPointID: 1646989,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "Stock Point ID: 1647033 || Stock Point Name: OmniHub Ilorin_East Kwara - REAL HEIGHT SERVICES\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ilorin_East Kwara - REAL HEIGHT SERVICES, StockPointID: 1647033,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 940\n",
      "Total Quantity: 725\n",
      "Total Number of Customers before filter: 82\n",
      "Total Number of Customers: 62\n",
      "✓ Loaded 166 SKU recommendations\n",
      "✓ Loaded 62 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.41\n",
      "Davies-Bouldin Index: 0.55\n",
      "Calinski-Harabasz Score: 51.54\n",
      "Silhouette Score: 0.41\n",
      "Davies-Bouldin Index: 0.55\n",
      "Calinski-Harabasz Score: 51.54\n",
      "Select ClusterIDs: [3, 5, 4, 1]\n",
      "Total Number of Customers: 39\n",
      "   cluster                                  LGA_list  \\\n",
      "0        3  [Ilorin South, Ilorin East, Ilorin West]   \n",
      "1        5  [Ilorin East, Ilorin South, Ilorin West]   \n",
      "2        4               [Ilorin East, Ilorin South]   \n",
      "3        1                [Ilorin West, Ilorin East]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [, Oja-Gboro, Offa Garage, General Hospital, G...         11       141   \n",
      "1          [Okelele, Idi-Ape, , Oja-Gboro, Agbo-Oba]          6        73   \n",
      "2              [Oja-Gboro, Kulende, , Maraba, Sango]          7        81   \n",
      "3  [Asa Dam, General Hospital, Agbo-Oba, Babaoko,...         15       176   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           54.724063  \n",
      "1           50.263000  \n",
      "2           40.943684  \n",
      "3           38.205000  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (16 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 32.85 km, Duration: 44.07 min\n",
      "  Calculating route for Trip ID: 3 (12 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 99.74 km, Duration: 705.35 min\n",
      "  Calculating route for Trip ID: 4 (8 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 26.56 km, Duration: 33.10 min\n",
      "  Calculating route for Trip ID: 5 (7 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 25.36 km, Duration: 27.70 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1647033.html\n",
      "Stock Point ID: 1646976 || Stock Point Name: \n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: , StockPointID: 1646976,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "Stock Point ID: 1646971 || Stock Point Name: OmniHub Abeokuta Ogun - Brooks\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Abeokuta Ogun - Brooks, StockPointID: 1646971,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 1,323\n",
      "Total Quantity: 1,017\n",
      "Total Number of Customers before filter: 86\n",
      "Total Number of Customers: 67\n",
      "✓ Loaded 302 SKU recommendations\n",
      "✓ Loaded 67 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.58\n",
      "Davies-Bouldin Index: 0.42\n",
      "Calinski-Harabasz Score: 633.09\n",
      "Silhouette Score: 0.58\n",
      "Davies-Bouldin Index: 0.42\n",
      "Calinski-Harabasz Score: 633.09\n",
      "Select ClusterIDs: [4, 3, 1, 5]\n",
      "Total Number of Customers: 44\n",
      "   cluster                          LGA_list  \\\n",
      "0        4           [Odeda, Abeokuta South]   \n",
      "1        3  [Abeokuta South, Abeokuta North]   \n",
      "2        1                  [Abeokuta North]   \n",
      "3        5  [Abeokuta South, Abeokuta North]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0                         [Eleweran, Aregbe, Adatan]          8       132   \n",
      "1                 [Adatan, , Iberekodo, Kuto, Elega]         11       176   \n",
      "2  [Iberekodo, Elega, Bode - Olude, Akomoje, Mokola]         19       270   \n",
      "3  [Gbokoniyi, Onikolobo, Totoro, Akinolugbade, I...          6        82   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           43.346429  \n",
      "1           41.671923  \n",
      "2           40.181220  \n",
      "3           36.608400  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (20 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 31.27 km, Duration: 68.23 min\n",
      "  Calculating route for Trip ID: 3 (12 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 32.02 km, Duration: 33.97 min\n",
      "  Calculating route for Trip ID: 4 (9 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 22.82 km, Duration: 34.00 min\n",
      "  Calculating route for Trip ID: 5 (7 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 19.56 km, Duration: 34.10 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1646971.html\n",
      "Stock Point ID: 1647011 || Stock Point Name: OmniHub Badagry Lagos - NEEMYGHT MULTI-VENTURE ENTERPRISES\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Badagry Lagos - NEEMYGHT MULTI-VENTURE ENTERPRISES, StockPointID: 1647011,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 1,157\n",
      "Total Quantity: 898\n",
      "Total Number of Customers before filter: 60\n",
      "Total Number of Customers: 46\n",
      "✓ Loaded 227 SKU recommendations\n",
      "✓ Loaded 46 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.77\n",
      "Davies-Bouldin Index: 0.18\n",
      "Calinski-Harabasz Score: 9893.4\n",
      "Silhouette Score: 0.77\n",
      "Davies-Bouldin Index: 0.18\n",
      "Calinski-Harabasz Score: 9893.4\n",
      "Select ClusterIDs: [3, 1, 2]\n",
      "Total Number of Customers: 35\n",
      "   cluster                   LGA_list  \\\n",
      "0        3                  [Badagry]   \n",
      "1        1  [Badagry, Push - Badagry]   \n",
      "2        2                  [Badagry]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [Badagry - Agbara (checking Point), Badagry - ...          7       122   \n",
      "1  [Badagry - Agbara (church Gate), , Badagry - A...         17       303   \n",
      "2  [, Badagry - Agbara (morogbo), Badagry - Agbar...         11       248   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           56.588148  \n",
      "1           41.478267  \n",
      "2           40.539194  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (18 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 0.00 km, Duration: 0.00 min\n",
      "  Calculating route for Trip ID: 2 (12 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 58.43 km, Duration: 47.22 min\n",
      "  Calculating route for Trip ID: 3 (8 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 48.95 km, Duration: 36.05 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1647011.html\n",
      "Stock Point ID: 1647050 || Stock Point Name: OMNIHUB-OREDO-EDO-AMA-PEE ENTERPRISE\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OMNIHUB-OREDO-EDO-AMA-PEE ENTERPRISE, StockPointID: 1647050,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 1,833\n",
      "Total Quantity: 1,317\n",
      "Total Number of Customers before filter: 187\n",
      "Total Number of Customers: 128\n",
      "✓ Loaded 307 SKU recommendations\n",
      "✓ Loaded 128 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.45\n",
      "Davies-Bouldin Index: 0.82\n",
      "Calinski-Harabasz Score: 828.98\n",
      "Silhouette Score: 0.45\n",
      "Davies-Bouldin Index: 0.82\n",
      "Calinski-Harabasz Score: 828.98\n",
      "Select ClusterIDs: [8, 2, 4, 9]\n",
      "Total Number of Customers: 35\n",
      "   cluster              LGA_list  \\\n",
      "0        8  [Oredo, Ikpoba Okha]   \n",
      "1        2  [Oredo, Ikpoba Okha]   \n",
      "2        4  [Ikpoba Okha, Oredo]   \n",
      "3        9  [Oredo, Ikpoba Okha]   \n",
      "\n",
      "                                       LCDA_List  ncustomer  totalQty  \\\n",
      "0                    [Benin, , Gorretti, Idogbo]          6        59   \n",
      "1  [, Gorretti, Benin, Etete, Obayantor, Idogbo]         16       160   \n",
      "2                   [Obayantor, Gorretti, Benin]          8        77   \n",
      "3                      [G.R.A, Benin, Obayantor]          5        68   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           59.324286  \n",
      "1           50.137949  \n",
      "2           50.021667  \n",
      "3           49.415625  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 2 (17 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 27.14 km, Duration: 41.03 min\n",
      "  Calculating route for Trip ID: 4 (9 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 22.83 km, Duration: 24.53 min\n",
      "  Calculating route for Trip ID: 8 (7 waypoints)...\n",
      "  Trip ID 8 calculated. Distance: 20.37 km, Duration: 25.38 min\n",
      "  Calculating route for Trip ID: 9 (6 waypoints)...\n",
      "  Trip ID 9 calculated. Distance: 67.31 km, Duration: 48.55 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1647050.html\n",
      "Stock Point ID: 1647006 || Stock Point Name: OmniHub Ogba/Egbema Ndoni Rivers - JIB\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ogba/Egbema Ndoni Rivers - JIB, StockPointID: 1647006,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "Stock Point ID: 1646995 || Stock Point Name: OmniHub Epe Lagos - WONUOLA SUPER STORE\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Epe Lagos - WONUOLA SUPER STORE, StockPointID: 1646995,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "Stock Point ID: 1647391 || Stock Point Name: OmniHub Ibeju Lekki Lagos - SI & A\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ibeju Lekki Lagos - SI & A, StockPointID: 1647391,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 713\n",
      "Total Quantity: 643\n",
      "Total Number of Customers before filter: 47\n",
      "Total Number of Customers: 42\n",
      "✓ Loaded 177 SKU recommendations\n",
      "✓ Loaded 42 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.41\n",
      "Davies-Bouldin Index: 0.52\n",
      "Calinski-Harabasz Score: 288.83\n",
      "Silhouette Score: 0.41\n",
      "Davies-Bouldin Index: 0.52\n",
      "Calinski-Harabasz Score: 288.83\n",
      "Select ClusterIDs: [1, 2, 3]\n",
      "Total Number of Customers: 30\n",
      "   cluster       LGA_list                                          LCDA_List  \\\n",
      "0        1  [Ibeju Lekki]  [Ibeju Lekki - Lakowe - School Gate, Ibeju Lek...   \n",
      "1        2  [Ibeju Lekki]  [Ibeju Lekki - Awoyaya - Container Bustop, Ibe...   \n",
      "2        3  [Ibeju Lekki]  [Ibeju Lekki - Igando - Oloja, Ibeju Lekki - E...   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0         18       328           42.798830  \n",
      "1          7        96           41.537037  \n",
      "2          5        57           33.084000  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (19 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 122.65 km, Duration: 144.22 min\n",
      "  Calculating route for Trip ID: 2 (8 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 44.95 km, Duration: 58.13 min\n",
      "  Calculating route for Trip ID: 3 (6 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 34.39 km, Duration: 31.83 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1647391.html\n",
      "Stock Point ID: 1647372 || Stock Point Name: OmniHub AMAC 1 Abuja - Roekwi\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub AMAC 1 Abuja - Roekwi, StockPointID: 1647372,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 2,094\n",
      "Total Quantity: 1,739\n",
      "Total Number of Customers before filter: 160\n",
      "Total Number of Customers: 134\n",
      "✓ Loaded 522 SKU recommendations\n",
      "✓ Loaded 134 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.62\n",
      "Davies-Bouldin Index: 0.49\n",
      "Calinski-Harabasz Score: 3150.87\n",
      "Silhouette Score: 0.62\n",
      "Davies-Bouldin Index: 0.49\n",
      "Calinski-Harabasz Score: 3150.87\n",
      "Select ClusterIDs: [6, 5, 2, 3]\n",
      "Total Number of Customers: 54\n",
      "   cluster                 LGA_list  \\\n",
      "0        6  [Kuje/Gwagwalada/Abaji]   \n",
      "1        5                 [AMAC 1]   \n",
      "2        2  [Kuje/Gwagwalada/Abaji]   \n",
      "3        3  [Kuje/Gwagwalada/Abaji]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [, Tungan Maje, ABUJA - TUNGA MAJE, ABUJA-GWAG...          6        75   \n",
      "1                              [Lugbe, Airport Road]          8       117   \n",
      "2           [ABUJA-KUJE, ABUJA - TUNGA MAJE, Pegi, ]         20       228   \n",
      "3                [ABUJA-GWAGWALADA, , Kutunku, Dobi]         20       249   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           53.565000  \n",
      "1           49.944474  \n",
      "2           38.548889  \n",
      "3           35.241370  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 2 (21 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 46.02 km, Duration: 57.73 min\n",
      "  Calculating route for Trip ID: 3 (21 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 104.08 km, Duration: 99.83 min\n",
      "  Calculating route for Trip ID: 5 (9 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 18.39 km, Duration: 31.78 min\n",
      "  Calculating route for Trip ID: 6 (7 waypoints)...\n",
      "  Trip ID 6 calculated. Distance: 57.85 km, Duration: 56.98 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1647372.html\n",
      "Stock Point ID: 1647377 || Stock Point Name: OmniHub Ikorodu Lagos - Sitrest\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ikorodu Lagos - Sitrest, StockPointID: 1647377,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 4,076\n",
      "Total Quantity: 3,766\n",
      "Total Number of Customers before filter: 152\n",
      "Total Number of Customers: 141\n",
      "✓ Loaded 1033 SKU recommendations\n",
      "✓ Loaded 141 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.45\n",
      "Davies-Bouldin Index: 0.68\n",
      "Calinski-Harabasz Score: 204.35\n",
      "Silhouette Score: 0.45\n",
      "Davies-Bouldin Index: 0.68\n",
      "Calinski-Harabasz Score: 204.35\n",
      "Select ClusterIDs: [5, 9, 3, 6]\n",
      "Total Number of Customers: 46\n",
      "   cluster   LGA_list                                          LCDA_List  \\\n",
      "0        5  [Ikorodu]  [Ikorodu - Offin, Ikorodu - Owode - Ibese, Iko...   \n",
      "1        9  [Ikorodu]      [Ikorodu - Igbogbo, , Ikorodu - Oreyo - Igbe]   \n",
      "2        3  [Ikorodu]  [Ikorodu - Bayeku, Ikorodu - Offin, Ikorodu - ...   \n",
      "3        6  [Ikorodu]  [, Ikorodu - Owode - Ibese, Ikorodu - Igbogbo,...   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0         13       333           39.402778  \n",
      "1          6       225           31.201429  \n",
      "2         16       496           28.822206  \n",
      "3         11       243           28.521714  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 3 (17 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 67.79 km, Duration: 82.35 min\n",
      "  Calculating route for Trip ID: 5 (14 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 85.22 km, Duration: 102.03 min\n",
      "  Calculating route for Trip ID: 6 (12 waypoints)...\n",
      "  Trip ID 6 calculated. Distance: 53.44 km, Duration: 59.97 min\n",
      "  Calculating route for Trip ID: 9 (7 waypoints)...\n",
      "  Trip ID 9 calculated. Distance: 46.55 km, Duration: 50.43 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1647377.html\n",
      "Stock Point ID: 1647387 || Stock Point Name: OmniHub Ogba/Egbema Ndoni Rivers - Nest-Och\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ogba/Egbema Ndoni Rivers - Nest-Och, StockPointID: 1647387,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 3,211\n",
      "Total Quantity: 3,052\n",
      "Total Number of Customers before filter: 155\n",
      "Total Number of Customers: 148\n",
      "✓ Loaded 875 SKU recommendations\n",
      "✓ Loaded 148 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.67\n",
      "Davies-Bouldin Index: 0.34\n",
      "Calinski-Harabasz Score: 24498.69\n",
      "Silhouette Score: 0.67\n",
      "Davies-Bouldin Index: 0.34\n",
      "Calinski-Harabasz Score: 24498.69\n",
      "Select ClusterIDs: [5, 6, 1, 2]\n",
      "Total Number of Customers: 79\n",
      "   cluster             LGA_list           LCDA_List  ncustomer  totalQty  \\\n",
      "0        5  [Ogba/Egbema Ndoni]      [Omoku, Ndoni]         10       268   \n",
      "1        6  [Ogba/Egbema Ndoni]           [Omoku, ]         10       255   \n",
      "2        1  [Ogba/Egbema Ndoni]  [Omoku, Usomini, ]         30       678   \n",
      "3        2  [Ogba/Egbema Ndoni]           [Omoku, ]         29       582   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           48.595395  \n",
      "1           48.048553  \n",
      "2           44.741026  \n",
      "3           43.717048  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (31 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 2.67 km, Duration: 3.90 min\n",
      "  Calculating route for Trip ID: 2 (30 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 12.88 km, Duration: 15.02 min\n",
      "  Calculating route for Trip ID: 5 (11 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 10.66 km, Duration: 12.82 min\n",
      "  Calculating route for Trip ID: 6 (11 waypoints)...\n",
      "  Trip ID 6 calculated. Distance: 2.22 km, Duration: 2.82 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1647387.html\n",
      "Unable to generate route mapping using orc: Cannot save file into a non-existent directory: 'recommendation_output/2025-06-26/OmniHub Ogba'\n",
      "Stock Point ID: 1647062 || Stock Point Name: OmniHub Kosofe Lagos - KOLF \n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Kosofe Lagos - KOLF , StockPointID: 1647062,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 6,987\n",
      "Total Quantity: 5,036\n",
      "Total Number of Customers before filter: 225\n",
      "Total Number of Customers: 160\n",
      "✓ Loaded 1486 SKU recommendations\n",
      "✓ Loaded 160 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.51\n",
      "Davies-Bouldin Index: 0.52\n",
      "Calinski-Harabasz Score: 15783.27\n",
      "Silhouette Score: 0.51\n",
      "Davies-Bouldin Index: 0.52\n",
      "Calinski-Harabasz Score: 15783.27\n",
      "Select ClusterIDs: [7, 2, 5, 1]\n",
      "Total Number of Customers: 85\n",
      "   cluster  LGA_list                                          LCDA_List  \\\n",
      "0        7  [Kosofe]   [Kosofe - Ketu - Ikosi Road, Kosofe - Mile 12, ]   \n",
      "1        2  [Kosofe]  [Kosofe - Mile 12, , Kosofe - Ketu - Alapere, ...   \n",
      "2        5  [Kosofe]                           [Kosofe - Oworonshoki, ]   \n",
      "3        1  [Kosofe]  [Kosofe - Ketu - Demurin, Kosofe - Ketu - Alap...   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0         12       407           56.166949  \n",
      "1         25       764           55.190796  \n",
      "2         20       695           55.006162  \n",
      "3         28       823           53.583571  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (29 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 46.98 km, Duration: 68.48 min\n",
      "  Calculating route for Trip ID: 2 (26 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 31.74 km, Duration: 58.02 min\n",
      "  Calculating route for Trip ID: 5 (21 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 52.78 km, Duration: 62.65 min\n",
      "  Calculating route for Trip ID: 7 (13 waypoints)...\n",
      "  Trip ID 7 calculated. Distance: 14.30 km, Duration: 23.82 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1647062.html\n",
      "Stock Point ID: 1647381 || Stock Point Name: OmniHub Ado Odo/Ota Ogun - Sam-Samron\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ado Odo/Ota Ogun - Sam-Samron, StockPointID: 1647381,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 64\n",
      "Total Quantity: 57\n",
      "Total Number of Customers before filter: 5\n",
      "Total Number of Customers: 4\n",
      "Stock Point ID: 1647345 || Stock Point Name: OmniHub Alimosho Lagos - Barka Agro Mix\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Alimosho Lagos - Barka Agro Mix, StockPointID: 1647345,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 3,597\n",
      "Total Quantity: 2,821\n",
      "Total Number of Customers before filter: 163\n",
      "Total Number of Customers: 130\n",
      "✓ Loaded 874 SKU recommendations\n",
      "✓ Loaded 130 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.27\n",
      "Davies-Bouldin Index: 0.65\n",
      "Calinski-Harabasz Score: 4263.81\n",
      "Silhouette Score: 0.27\n",
      "Davies-Bouldin Index: 0.65\n",
      "Calinski-Harabasz Score: 4263.81\n",
      "Select ClusterIDs: [3, 1, 8, 2]\n",
      "Total Number of Customers: 68\n",
      "   cluster                     LGA_list  \\\n",
      "0        3  [Alimosho, Push - Alimosho]   \n",
      "1        1                   [Alimosho]   \n",
      "2        8                   [Alimosho]   \n",
      "3        2                 [Alimosho, ]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [Alimosho - Ikotun, , Alimosho - Ijegun, Alimo...         15       432   \n",
      "1           [Alimosho - Ikotun, Alimosho - Ijegun, ]         24       564   \n",
      "2  [Alimosho - Ikotun, Alimosho - Ijegun-obadore ...          8       185   \n",
      "3    [, Alimosho - Ijegun, Alimosho - Ejigbo-ijegun]         21       287   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           47.337167  \n",
      "1           46.411856  \n",
      "2           43.614237  \n",
      "3           42.389794  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (25 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 57.81 km, Duration: 166.43 min\n",
      "  Calculating route for Trip ID: 2 (22 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 55.66 km, Duration: 144.72 min\n",
      "  Calculating route for Trip ID: 3 (16 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 71.72 km, Duration: 119.75 min\n",
      "  Calculating route for Trip ID: 8 (9 waypoints)...\n",
      "  Trip ID 8 calculated. Distance: 27.47 km, Duration: 74.97 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1647345.html\n",
      "Stock Point ID: 1647376 || Stock Point Name: OmniHub Ijebu Ode Ogun - WCG\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ijebu Ode Ogun - WCG, StockPointID: 1647376,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "Stock Point ID: 1647353 || Stock Point Name: OmniHub Yenagoa Bayelsa - Schist & Scoria\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Yenagoa Bayelsa - Schist & Scoria, StockPointID: 1647353,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 718\n",
      "Total Quantity: 507\n",
      "Total Number of Customers before filter: 86\n",
      "Total Number of Customers: 64\n",
      "✓ Loaded 113 SKU recommendations\n",
      "✓ Loaded 64 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.75\n",
      "Davies-Bouldin Index: 0.24\n",
      "Calinski-Harabasz Score: 601.24\n",
      "Silhouette Score: 0.75\n",
      "Davies-Bouldin Index: 0.24\n",
      "Calinski-Harabasz Score: 601.24\n",
      "Select ClusterIDs: [1, 3, 2]\n",
      "Total Number of Customers: 55\n",
      "   cluster   LGA_list                                          LCDA_List  \\\n",
      "0        1  [Yenagoa]  [Kpansia, Ekeki, Ovelemini, Atissa, Amarata, A...   \n",
      "1        3  [Yenagoa]                                [Tombia, Ovelemini]   \n",
      "2        2  [Yenagoa]  [Kpansia, Opolo, Tombia, Ekeki, Epie, Azikoro,...   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0         30       253           35.793889  \n",
      "1          7        64           34.876429  \n",
      "2         18       124           34.237143  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (31 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 38.42 km, Duration: 52.00 min\n",
      "  Calculating route for Trip ID: 2 (19 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 29.67 km, Duration: 41.92 min\n",
      "  Calculating route for Trip ID: 3 (8 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 9.20 km, Duration: 8.98 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1647353.html\n",
      "Stock Point ID: 1647347 || Stock Point Name: OmniHub Ikorodu Lagos - Pleck\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ikorodu Lagos - Pleck, StockPointID: 1647347,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 7,170\n",
      "Total Quantity: 5,073\n",
      "Total Number of Customers before filter: 249\n",
      "Total Number of Customers: 175\n",
      "✓ Loaded 1319 SKU recommendations\n",
      "✓ Loaded 175 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.54\n",
      "Davies-Bouldin Index: 0.57\n",
      "Calinski-Harabasz Score: 114.33\n",
      "Silhouette Score: 0.54\n",
      "Davies-Bouldin Index: 0.57\n",
      "Calinski-Harabasz Score: 114.33\n",
      "Select ClusterIDs: [9, 8, 4, 3]\n",
      "Total Number of Customers: 52\n",
      "   cluster   LGA_list                                LCDA_List  ncustomer  \\\n",
      "0        9  [Ikorodu]  [Ikorodu - Gberigbe, Ikorodu - Adamo, ]          7   \n",
      "1        8  [Ikorodu]   [Ikorodu - Itamaga, Ikorodu - Elepe, ]         12   \n",
      "2        4  [Ikorodu]                   [Ikorodu - Gberigbe, ]         16   \n",
      "3        3  [Ikorodu]                      [, Ikorodu - Adamo]         17   \n",
      "\n",
      "   totalQty  avg_customer_score  \n",
      "0       157           47.790952  \n",
      "1       409           43.273714  \n",
      "2       478           40.197480  \n",
      "3       469           36.359310  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 3 (18 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 40.70 km, Duration: 61.23 min\n",
      "  Calculating route for Trip ID: 4 (17 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 31.57 km, Duration: 41.85 min\n",
      "  Calculating route for Trip ID: 8 (13 waypoints)...\n",
      "  Trip ID 8 calculated. Distance: 8.62 km, Duration: 14.13 min\n",
      "  Calculating route for Trip ID: 9 (8 waypoints)...\n",
      "  Trip ID 9 calculated. Distance: 13.61 km, Duration: 19.07 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1647347.html\n",
      "Stock Point ID: 1647341 || Stock Point Name: OmniHub AMAC 3 Nasarawa - Utmaab Kurudu\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub AMAC 3 Nasarawa - Utmaab Kurudu, StockPointID: 1647341,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 3,643\n",
      "Total Quantity: 2,581\n",
      "Total Number of Customers before filter: 253\n",
      "Total Number of Customers: 181\n",
      "✓ Loaded 900 SKU recommendations\n",
      "✓ Loaded 181 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.73\n",
      "Davies-Bouldin Index: 0.41\n",
      "Calinski-Harabasz Score: 5552.62\n",
      "Silhouette Score: 0.73\n",
      "Davies-Bouldin Index: 0.41\n",
      "Calinski-Harabasz Score: 5552.62\n",
      "Select ClusterIDs: [8, 5, 3, 4]\n",
      "Total Number of Customers: 63\n",
      "   cluster                          LGA_list                LCDA_List  \\\n",
      "0        8                  [AMAC 3, AMAC 2]               [Karshi, ]   \n",
      "1        5                          [AMAC 3]           [Nyanya, Karu]   \n",
      "2        3  [AMAC 3, Push - Abuja Municipal]  [Orozo, Push - Orozo, ]   \n",
      "3        4                  [AMAC 3, AMAC 2]      [Jikwoyi, , Kurudu]   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0         12       209           56.781351  \n",
      "1         15       241           39.900000  \n",
      "2         19       217           39.621585  \n",
      "3         17       211           39.150000  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 3 (20 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 46.18 km, Duration: 52.67 min\n",
      "  Calculating route for Trip ID: 4 (18 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 33.42 km, Duration: 40.28 min\n",
      "  Calculating route for Trip ID: 5 (16 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 23.48 km, Duration: 21.60 min\n",
      "  Calculating route for Trip ID: 8 (13 waypoints)...\n",
      "  Trip ID 8 calculated. Distance: 24.50 km, Duration: 29.03 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1647341.html\n",
      "Stock Point ID: 1647350 || Stock Point Name: OmniHub OBI AKPOR Rivers - CHARRYSWIFT\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub OBI AKPOR Rivers - CHARRYSWIFT, StockPointID: 1647350,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 18,573\n",
      "Total Quantity: 15,116\n",
      "Total Number of Customers before filter: 512\n",
      "Total Number of Customers: 416\n",
      "✓ Loaded 3941 SKU recommendations\n",
      "✓ Loaded 416 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.54\n",
      "Davies-Bouldin Index: 0.55\n",
      "Calinski-Harabasz Score: 66329.11\n",
      "Silhouette Score: 0.54\n",
      "Davies-Bouldin Index: 0.55\n",
      "Calinski-Harabasz Score: 66329.11\n",
      "Select ClusterIDs: [12, 6, 23, 11]\n",
      "Total Number of Customers: 58\n",
      "   cluster                     LGA_list                   LCDA_List  \\\n",
      "0       12  [Port Harcourt, Obio Akpor]      [Diobu, , Rumuolumeni]   \n",
      "1        6                 [Obio Akpor]  [Rumuolumeni, Mgbuosimini]   \n",
      "2       23                 [Obio Akpor]               [Rumuolumeni]   \n",
      "3       11                 [Obio Akpor]  [Rumuolumeni, Rumuekini, ]   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0         15       541           55.881667  \n",
      "1         21       842           54.370097  \n",
      "2          6       239           51.146667  \n",
      "3         16       570           49.251184  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 6 (22 waypoints)...\n",
      "  Trip ID 6 calculated. Distance: 20.74 km, Duration: 34.80 min\n",
      "  Calculating route for Trip ID: 11 (17 waypoints)...\n",
      "  Trip ID 11 calculated. Distance: 8.76 km, Duration: 14.38 min\n",
      "  Calculating route for Trip ID: 12 (16 waypoints)...\n",
      "  Trip ID 12 calculated. Distance: 46.30 km, Duration: 66.45 min\n",
      "  Calculating route for Trip ID: 23 (7 waypoints)...\n",
      "  Trip ID 23 calculated. Distance: 13.78 km, Duration: 22.32 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1647350.html\n",
      "Stock Point ID: 1647125 || Stock Point Name: OmniHub Ikorodu Lagos - Mofaz\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ikorodu Lagos - Mofaz, StockPointID: 1647125,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 14,917\n",
      "Total Quantity: 9,802\n",
      "Total Number of Customers before filter: 560\n",
      "Total Number of Customers: 387\n",
      "✓ Loaded 2699 SKU recommendations\n",
      "✓ Loaded 387 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.33\n",
      "Davies-Bouldin Index: 0.65\n",
      "Calinski-Harabasz Score: 21755.85\n",
      "Silhouette Score: 0.33\n",
      "Davies-Bouldin Index: 0.65\n",
      "Calinski-Harabasz Score: 21755.85\n",
      "Select ClusterIDs: [13, 2, 17, 8]\n",
      "Total Number of Customers: 65\n",
      "   cluster           LGA_list  \\\n",
      "0       13  [Ikorodu, Kosofe]   \n",
      "1        2          [Ikorodu]   \n",
      "2       17          [Ikorodu]   \n",
      "3        8          [Ikorodu]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [Ikorodu - Irawo, Ikorodu - Agbede, Ikorodu - ...         10       247   \n",
      "1  [, Ikorodu - Ogolonto, Ikorodu - Agric, Ikorod...         28       639   \n",
      "2  [Ikorodu - Agric, Ikorodu - Odonla, Ikorodu - ...          8       202   \n",
      "3  [Ikorodu - Agric, Ikorodu - Eyita, Ikorodu - A...         19       398   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           63.275000  \n",
      "1           57.651067  \n",
      "2           53.592182  \n",
      "3           51.831802  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 2 (29 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 58.29 km, Duration: 65.08 min\n",
      "  Calculating route for Trip ID: 8 (20 waypoints)...\n",
      "  Trip ID 8 calculated. Distance: 40.49 km, Duration: 68.85 min\n",
      "  Calculating route for Trip ID: 13 (11 waypoints)...\n",
      "  Trip ID 13 calculated. Distance: 49.40 km, Duration: 50.28 min\n",
      "  Calculating route for Trip ID: 17 (9 waypoints)...\n",
      "  Trip ID 17 calculated. Distance: 33.56 km, Duration: 52.65 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1647125.html\n",
      "Stock Point ID: 1647120 || Stock Point Name: OmniHub Surulere Lagos - Jimoh Odutola\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Surulere Lagos - Jimoh Odutola, StockPointID: 1647120,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "Stock Point ID: 1647122 || Stock Point Name: OmniHub Egbeda Oyo - Vizazi\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Egbeda Oyo - Vizazi, StockPointID: 1647122,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 9,495\n",
      "Total Quantity: 6,488\n",
      "Total Number of Customers before filter: 340\n",
      "Total Number of Customers: 235\n",
      "✓ Loaded 1749 SKU recommendations\n",
      "✓ Loaded 235 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.51\n",
      "Davies-Bouldin Index: 0.57\n",
      "Calinski-Harabasz Score: 14432.64\n",
      "Silhouette Score: 0.51\n",
      "Davies-Bouldin Index: 0.57\n",
      "Calinski-Harabasz Score: 14432.64\n",
      "Select ClusterIDs: [11, 3, 10, 4]\n",
      "Total Number of Customers: 59\n",
      "   cluster          LGA_list  \\\n",
      "0       11         [Ona Ara]   \n",
      "1        3          [Egbeda]   \n",
      "2       10          [Egbeda]   \n",
      "3        4  [Lagelu, Egbeda]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0                    [Olorunsogo, Olunloyo, Ona Ara]          7       190   \n",
      "1  [IBADAN-NEW GBAGI MARKET, , Monatan, Academy, ...         23       769   \n",
      "2          [IBADAN-NEW GBAGI MARKET, , Old Ife Road]          7       219   \n",
      "3  [Iwo Road-Monantan, IBADAN-AKOBO, IYANA CHURCH...         22       597   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           51.140392  \n",
      "1           50.978436  \n",
      "2           49.477119  \n",
      "3           46.319608  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 3 (24 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 38.90 km, Duration: 51.98 min\n",
      "  Calculating route for Trip ID: 4 (23 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 45.42 km, Duration: 72.95 min\n",
      "  Calculating route for Trip ID: 10 (8 waypoints)...\n",
      "  Trip ID 10 calculated. Distance: 7.50 km, Duration: 11.15 min\n",
      "  Calculating route for Trip ID: 11 (8 waypoints)...\n",
      "  Trip ID 11 calculated. Distance: 28.61 km, Duration: 33.53 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1647122.html\n",
      "Stock Point ID: 1647112 || Stock Point Name: OmniHub Lagos - OmniHub Eti Osa Lagos - Jimbass\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Lagos - OmniHub Eti Osa Lagos - Jimbass, StockPointID: 1647112,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "Stock Point ID: 1647113 || Stock Point Name: OmniHub Apapa Lagos - CAUSEWAY\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Apapa Lagos - CAUSEWAY, StockPointID: 1647113,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 30,130\n",
      "Total Quantity: 21,744\n",
      "Total Number of Customers before filter: 1,064\n",
      "Total Number of Customers: 769\n",
      "✓ Loaded 6534 SKU recommendations\n",
      "✓ Loaded 769 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.31\n",
      "Davies-Bouldin Index: 0.82\n",
      "Calinski-Harabasz Score: 812.99\n",
      "Silhouette Score: 0.31\n",
      "Davies-Bouldin Index: 0.82\n",
      "Calinski-Harabasz Score: 812.99\n",
      "Select ClusterIDs: [28, 37, 38, 9]\n",
      "Total Number of Customers: 56\n",
      "   cluster                                 LGA_list  \\\n",
      "0       28                [Ajeromi Ifelodun, Apapa]   \n",
      "1       37                                 [Mushin]   \n",
      "2       38         [Lagos Island, Mushin, Surulere]   \n",
      "3        9  [Surulere, Mushin, Lagos Island, Apapa]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [Ajeromi Ifelodun - Boundary, , Ajeromi Ifelod...         16       492   \n",
      "1  [Mushin - Agege Motor Road, Mushin - Mushin Ma...          8       252   \n",
      "2    [Lagos Island - Sura, Mushin - Mushin Market, ]          8       253   \n",
      "3  [Surulere - Lawanson, Mushin - Palm Avenue, Mu...         24       725   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           58.291387  \n",
      "1           56.402222  \n",
      "2           56.364776  \n",
      "3           54.885463  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 9 (25 waypoints)...\n",
      "  Trip ID 9 calculated. Distance: 52.55 km, Duration: 121.45 min\n",
      "  Calculating route for Trip ID: 28 (17 waypoints)...\n",
      "  Trip ID 28 calculated. Distance: 19.29 km, Duration: 45.72 min\n",
      "  Calculating route for Trip ID: 37 (9 waypoints)...\n",
      "  Trip ID 37 calculated. Distance: 13.30 km, Duration: 19.13 min\n",
      "  Calculating route for Trip ID: 38 (9 waypoints)...\n",
      "  Trip ID 38 calculated. Distance: 9.89 km, Duration: 15.42 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1647113.html\n",
      "Stock Point ID: 1647132 || Stock Point Name: OmniHub Ibadan North Oyo - Eby 99\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ibadan North Oyo - Eby 99, StockPointID: 1647132,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 5,348\n",
      "Total Quantity: 4,205\n",
      "Total Number of Customers before filter: 243\n",
      "Total Number of Customers: 190\n",
      "✓ Loaded 1136 SKU recommendations\n",
      "✓ Loaded 190 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.53\n",
      "Davies-Bouldin Index: 0.66\n",
      "Calinski-Harabasz Score: 6067.13\n",
      "Silhouette Score: 0.53\n",
      "Davies-Bouldin Index: 0.66\n",
      "Calinski-Harabasz Score: 6067.13\n",
      "Select ClusterIDs: [3, 5, 10, 11]\n",
      "Total Number of Customers: 46\n",
      "   cluster                                LGA_list  \\\n",
      "0        3  [Ibadan North, Ibadan North West, Ido]   \n",
      "1        5                          [Ibadan North]   \n",
      "2       10                     [Ido, Ibadan North]   \n",
      "3       11           [Akinyele, Ibadan North, Ido]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [IBADAN-BODIJA, Bodija, Mokola, Poly Ibadan, S...         17       376   \n",
      "1  [Poly Ibadan, Eleyele, Bodija, Sango, , Total ...         14       328   \n",
      "2                             [, Poly Ibadan, Apete]          8       191   \n",
      "3            [Ojoo, Sango, Apete, , Bodija, Eleyele]          7       172   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           47.397526  \n",
      "1           45.907391  \n",
      "2           44.738431  \n",
      "3           40.953617  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 3 (18 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 22.16 km, Duration: 33.95 min\n",
      "  Calculating route for Trip ID: 5 (15 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 9.98 km, Duration: 12.72 min\n",
      "  Calculating route for Trip ID: 10 (9 waypoints)...\n",
      "  Trip ID 10 calculated. Distance: 16.48 km, Duration: 22.22 min\n",
      "  Calculating route for Trip ID: 11 (8 waypoints)...\n",
      "  Trip ID 11 calculated. Distance: 122.88 km, Duration: 110.02 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1647132.html\n",
      "Stock Point ID: 1647124 || Stock Point Name: OmniHub Ibadan South West Oyo - Cemalon\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ibadan South West Oyo - Cemalon, StockPointID: 1647124,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 2,696\n",
      "Total Quantity: 1,970\n",
      "Total Number of Customers before filter: 136\n",
      "Total Number of Customers: 102\n",
      "✓ Loaded 495 SKU recommendations\n",
      "✓ Loaded 102 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.24\n",
      "Davies-Bouldin Index: 0.59\n",
      "Calinski-Harabasz Score: 590.6\n",
      "Silhouette Score: 0.24\n",
      "Davies-Bouldin Index: 0.59\n",
      "Calinski-Harabasz Score: 590.6\n",
      "Select ClusterIDs: [5, 2, 3, 1]\n",
      "Total Number of Customers: 67\n",
      "   cluster                                         LGA_list  \\\n",
      "0        5           [Ibadan South West, Ibadan North West]   \n",
      "1        2                              [Ibadan South West]   \n",
      "2        3  [Ibadan North West, Ibadan South West, Oluyole]   \n",
      "3        1           [Ibadan North West, Ibadan South West]   \n",
      "\n",
      "                                  LCDA_List  ncustomer  totalQty  \\\n",
      "0                  [Agbeni, , IBADAN-DUGBE]          5       112   \n",
      "1               [Molete, , Agbeni, Oke Ado]         24       518   \n",
      "2  [, Agbeni, IBADAN-ODO-ONA ELEWE, Molete]          8       128   \n",
      "3                   [Agbeni, , Orita Merin]         30       553   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           40.778519  \n",
      "1           35.288293  \n",
      "2           30.187812  \n",
      "3           30.153309  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (31 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 1.76 km, Duration: 2.95 min\n",
      "  Calculating route for Trip ID: 2 (25 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 39.31 km, Duration: 52.35 min\n",
      "  Calculating route for Trip ID: 3 (9 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 23.14 km, Duration: 25.87 min\n",
      "  Calculating route for Trip ID: 5 (6 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 7.67 km, Duration: 10.82 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1647124.html\n",
      "Stock Point ID: 1647380 || Stock Point Name: OmniHub Owerri Municipal Imo - Bonaventure \n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Owerri Municipal Imo - Bonaventure , StockPointID: 1647380,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 235\n",
      "Total Quantity: 82\n",
      "Total Number of Customers before filter: 19\n",
      "Total Number of Customers: 10\n",
      "✓ Loaded 17 SKU recommendations\n",
      "✓ Loaded 10 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Dataframe is empty\n",
      "INFO:__main__:Trip Data is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.39\n",
      "Davies-Bouldin Index: 0.5\n",
      "Calinski-Harabasz Score: 15.71\n",
      "Silhouette Score: 0.39\n",
      "Davies-Bouldin Index: 0.5\n",
      "Calinski-Harabasz Score: 15.71\n",
      "Select ClusterIDs: []\n",
      "Total Number of Customers: 0\n",
      "Empty DataFrame\n",
      "Columns: [cluster, LGA_list, LCDA_List, ncustomer, totalQty, avg_customer_score]\n",
      "Index: []\n",
      "Stock Point ID: 1647126 || Stock Point Name: OmniHub Sagamu Ogun - Ajaka\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Sagamu Ogun - Ajaka, StockPointID: 1647126,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 78\n",
      "Total Quantity: 50\n",
      "Total Number of Customers before filter: 2\n",
      "Total Number of Customers: 1\n",
      "Stock Point ID: 1647109 || Stock Point Name: OmniHub Oluyole Oyo - Techcomserve\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Oluyole Oyo - Techcomserve, StockPointID: 1647109,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 302\n",
      "Total Quantity: 250\n",
      "Total Number of Customers before filter: 22\n",
      "Total Number of Customers: 18\n",
      "✓ Loaded 68 SKU recommendations\n",
      "✓ Loaded 18 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.56\n",
      "Davies-Bouldin Index: 0.45\n",
      "Calinski-Harabasz Score: 850.88\n",
      "Silhouette Score: 0.56\n",
      "Davies-Bouldin Index: 0.45\n",
      "Calinski-Harabasz Score: 850.88\n",
      "Select ClusterIDs: [1]\n",
      "Total Number of Customers: 11\n",
      "   cluster                      LGA_list  \\\n",
      "0        1  [Oluyole, Ibadan South West]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [Orita Challenge, Ringroad, IBADAN-ODO-ONA ELE...         11       144   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           39.522791  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (12 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 39.19 km, Duration: 58.55 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1647109.html\n",
      "Stock Point ID: 1647371 || Stock Point Name: OmniHub Alimosho Lagos - Demadek\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Alimosho Lagos - Demadek, StockPointID: 1647371,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 1,274\n",
      "Total Quantity: 958\n",
      "Total Number of Customers before filter: 64\n",
      "Total Number of Customers: 48\n",
      "✓ Loaded 291 SKU recommendations\n",
      "✓ Loaded 48 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.28\n",
      "Davies-Bouldin Index: 0.73\n",
      "Calinski-Harabasz Score: 21143.87\n",
      "Silhouette Score: 0.28\n",
      "Davies-Bouldin Index: 0.73\n",
      "Calinski-Harabasz Score: 21143.87\n",
      "Select ClusterIDs: [5, 1, 3, 2]\n",
      "Total Number of Customers: 39\n",
      "   cluster    LGA_list              LCDA_List  ncustomer  totalQty  \\\n",
      "0        5  [Alimosho]  [Alimosho - Igando, ]          5        90   \n",
      "1        1  [Alimosho]  [Alimosho - Igando, ]         16       290   \n",
      "2        3  [Alimosho]  [, Alimosho - Igando]          8       175   \n",
      "3        2  [Alimosho]  [, Alimosho - Igando]         10       238   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           39.688000  \n",
      "1           33.753023  \n",
      "2           30.344545  \n",
      "3           25.703768  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (17 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 53.33 km, Duration: 115.90 min\n",
      "  Calculating route for Trip ID: 2 (11 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 38.93 km, Duration: 89.82 min\n",
      "  Calculating route for Trip ID: 3 (9 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 18.33 km, Duration: 46.17 min\n",
      "  Calculating route for Trip ID: 5 (6 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 14.32 km, Duration: 51.03 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1647371.html\n",
      "Stock Point ID: 1647131 || Stock Point Name: OmniHub Alimosho Lagos - Pafeak\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Alimosho Lagos - Pafeak, StockPointID: 1647131,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 4,569\n",
      "Total Quantity: 3,127\n",
      "Total Number of Customers before filter: 171\n",
      "Total Number of Customers: 118\n",
      "✓ Loaded 1014 SKU recommendations\n",
      "✓ Loaded 118 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.32\n",
      "Davies-Bouldin Index: 0.78\n",
      "Calinski-Harabasz Score: 7046.82\n",
      "Silhouette Score: 0.32\n",
      "Davies-Bouldin Index: 0.78\n",
      "Calinski-Harabasz Score: 7046.82\n",
      "Select ClusterIDs: [1, 5, 3, 2]\n",
      "Total Number of Customers: 76\n",
      "   cluster                  LGA_list  \\\n",
      "0        1                [Alimosho]   \n",
      "1        5                [Alimosho]   \n",
      "2        3  [Alimosho, Ifako Ijaiye]   \n",
      "3        2                [Alimosho]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [Alimosho - Abule Egba (ekoro Road), Alimosho ...         29       751   \n",
      "1  [Alimosho - Abule Egba (meiran Road), Alimosho...          8       205   \n",
      "2  [, Alimosho - Abule Egba (agbado Ijaye Road), ...         18       509   \n",
      "3  [, Alimosho - Abule Egba (ekoro Road), Alimosh...         21       537   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           57.919578  \n",
      "1           53.403194  \n",
      "2           48.610932  \n",
      "3           44.993333  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (30 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 69.41 km, Duration: 116.43 min\n",
      "  Calculating route for Trip ID: 2 (22 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 56.16 km, Duration: 80.43 min\n",
      "  Calculating route for Trip ID: 3 (19 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 44.09 km, Duration: 128.45 min\n",
      "  Calculating route for Trip ID: 5 (9 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 30.79 km, Duration: 51.75 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1647131.html\n",
      "Stock Point ID: 1647110 || Stock Point Name: OmniHub Ado Odo/Ota Ogun - Hardej\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ado Odo/Ota Ogun - Hardej, StockPointID: 1647110,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 1,478\n",
      "Total Quantity: 1,123\n",
      "Total Number of Customers before filter: 104\n",
      "Total Number of Customers: 76\n",
      "✓ Loaded 268 SKU recommendations\n",
      "✓ Loaded 76 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.46\n",
      "Davies-Bouldin Index: 0.33\n",
      "Calinski-Harabasz Score: 12465.33\n",
      "Silhouette Score: 0.46\n",
      "Davies-Bouldin Index: 0.33\n",
      "Calinski-Harabasz Score: 12465.33\n",
      "Select ClusterIDs: [4, 2, 3, 1]\n",
      "Total Number of Customers: 51\n",
      "   cluster       LGA_list                  LCDA_List  ncustomer  totalQty  \\\n",
      "0        4  [Ado Odo/Ota]           [Sango-Ota, Ota]          5        71   \n",
      "1        2  [Ado Odo/Ota]           [Ota, Sango-Ota]         15       242   \n",
      "2        3  [Ado Odo/Ota]  [Sango-Ota, , Sango, Ota]         12       188   \n",
      "3        1  [Ado Odo/Ota]  [Ota, Sango-Ota, Oju ore]         19       285   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           59.515882  \n",
      "1           47.167705  \n",
      "2           40.834783  \n",
      "3           37.533030  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (20 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 80.44 km, Duration: 187.52 min\n",
      "  Calculating route for Trip ID: 2 (16 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 53.73 km, Duration: 86.17 min\n",
      "  Calculating route for Trip ID: 3 (13 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 23.25 km, Duration: 66.15 min\n",
      "  Calculating route for Trip ID: 4 (6 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 25.45 km, Duration: 47.12 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1647110.html\n",
      "Unable to generate route mapping using orc: Cannot save file into a non-existent directory: 'recommendation_output/2025-06-26/OmniHub Ado Odo'\n",
      "Stock Point ID: 1647137 || Stock Point Name: OmniHub Shomolu Lagos - Autograph\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Shomolu Lagos - Autograph, StockPointID: 1647137,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 12,227\n",
      "Total Quantity: 9,002\n",
      "Total Number of Customers before filter: 461\n",
      "Total Number of Customers: 339\n",
      "✓ Loaded 2917 SKU recommendations\n",
      "✓ Loaded 339 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.28\n",
      "Davies-Bouldin Index: 0.69\n",
      "Calinski-Harabasz Score: 10927.07\n",
      "Silhouette Score: 0.28\n",
      "Davies-Bouldin Index: 0.69\n",
      "Calinski-Harabasz Score: 10927.07\n",
      "Select ClusterIDs: [19, 14, 12, 2]\n",
      "Total Number of Customers: 62\n",
      "   cluster          LGA_list  \\\n",
      "0       19  [Lagos Mainland]   \n",
      "1       14         [Shomolu]   \n",
      "2       12  [Lagos Mainland]   \n",
      "3        2  [Lagos Mainland]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0                  [Lagos Mainland - Yaba - Oyingbo]          6       175   \n",
      "1                                 [Shomolu - Bariga]         12       303   \n",
      "2  [Lagos Mainland - Yaba - Oyingbo, Lagos Mainla...         14       352   \n",
      "3  [Lagos Mainland - Yaba - Oyingbo, Lagos Mainla...         30       815   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           52.398182  \n",
      "1           51.644000  \n",
      "2           44.985909  \n",
      "3           43.432610  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 2 (31 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 110.72 km, Duration: 187.65 min\n",
      "  Calculating route for Trip ID: 12 (15 waypoints)...\n",
      "  Trip ID 12 calculated. Distance: 16.65 km, Duration: 24.58 min\n",
      "  Calculating route for Trip ID: 14 (13 waypoints)...\n",
      "  Trip ID 14 calculated. Distance: 6.25 km, Duration: 13.35 min\n",
      "  Calculating route for Trip ID: 19 (7 waypoints)...\n",
      "  Trip ID 19 calculated. Distance: 29.22 km, Duration: 33.42 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1647137.html\n",
      "Stock Point ID: 1647106 || Stock Point Name: OmniHub Ikeja Lagos - Barka-Agro Food Ogba\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ikeja Lagos - Barka-Agro Food Ogba, StockPointID: 1647106,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 2,990\n",
      "Total Quantity: 1,917\n",
      "Total Number of Customers before filter: 194\n",
      "Total Number of Customers: 121\n",
      "✓ Loaded 536 SKU recommendations\n",
      "✓ Loaded 121 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.3\n",
      "Davies-Bouldin Index: 0.64\n",
      "Calinski-Harabasz Score: 17822.12\n",
      "Silhouette Score: 0.3\n",
      "Davies-Bouldin Index: 0.64\n",
      "Calinski-Harabasz Score: 17822.12\n",
      "Select ClusterIDs: [9, 8, 3, 7]\n",
      "Total Number of Customers: 38\n",
      "   cluster               LGA_list  \\\n",
      "0        9  [Agege, Ifako Ijaiye]   \n",
      "1        8                [Agege]   \n",
      "2        3  [Ifako Ijaiye, Ikeja]   \n",
      "3        7  [Ifako Ijaiye, Ikeja]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [Agege - Old Otta Road, Ifako Ijaiye - Ogba - ...          7       165   \n",
      "1  [Agege - Orile Agege, Agege - Ogba Akilo Road,...          8       157   \n",
      "2  [Ifako Ijaiye - Ogba - Oke Ira, Ifako Ijaiye -...         14       208   \n",
      "3  [Ifako Ijaiye - Ojokoro, , Ifako Ijaiye - Ogba...          9       185   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           70.750870  \n",
      "1           56.477917  \n",
      "2           49.819138  \n",
      "3           46.048627  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 3 (15 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 25.10 km, Duration: 73.73 min\n",
      "  Calculating route for Trip ID: 7 (10 waypoints)...\n",
      "  Trip ID 7 calculated. Distance: 26.90 km, Duration: 60.37 min\n",
      "  Calculating route for Trip ID: 8 (9 waypoints)...\n",
      "  Trip ID 8 calculated. Distance: 25.12 km, Duration: 42.93 min\n",
      "  Calculating route for Trip ID: 9 (8 waypoints)...\n",
      "  Trip ID 9 calculated. Distance: 25.47 km, Duration: 62.17 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1647106.html\n",
      "Stock Point ID: 1647115 || Stock Point Name: OmniHub Lagos - OmniHub Amuwo Odofin Lagos - EMPRESS KOT.\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Lagos - OmniHub Amuwo Odofin Lagos - EMPRESS KOT., StockPointID: 1647115,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "Stock Point ID: 1647424 || Stock Point Name: OmniHub Obafemi Owode Ogun - Favoured Goodness\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Obafemi Owode Ogun - Favoured Goodness, StockPointID: 1647424,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "Stock Point ID: 1647127 || Stock Point Name: OmniHub Obio Akpor Rivers - FHS\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Obio Akpor Rivers - FHS, StockPointID: 1647127,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 15,894\n",
      "Total Quantity: 12,529\n",
      "Total Number of Customers before filter: 420\n",
      "Total Number of Customers: 331\n",
      "✓ Loaded 3196 SKU recommendations\n",
      "✓ Loaded 331 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.42\n",
      "Davies-Bouldin Index: 0.7\n",
      "Calinski-Harabasz Score: 14991.01\n",
      "Silhouette Score: 0.42\n",
      "Davies-Bouldin Index: 0.7\n",
      "Calinski-Harabasz Score: 14991.01\n",
      "Select ClusterIDs: [16, 12, 9, 10]\n",
      "Total Number of Customers: 60\n",
      "   cluster      LGA_list                                          LCDA_List  \\\n",
      "0       16  [Obio Akpor]                          [Rumuaghaolu, Rumuigbo, ]   \n",
      "1       12  [Obio Akpor]                  [, Nkpelu, Rumuigbo, Rumuaghaolu]   \n",
      "2        9  [Obio Akpor]  [Rumuokoro, Rumuigbo, Rumuodomaya, Rumuaghaolu...   \n",
      "3       10  [Obio Akpor]  [Rumuokoro, Rumuigbo, Rumuodomaya, Rumuaghaolu, ]   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0          8       253           54.438608  \n",
      "1         16       642           52.094375  \n",
      "2         19       778           50.156467  \n",
      "3         17       671           48.442353  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 9 (20 waypoints)...\n",
      "  Trip ID 9 calculated. Distance: 46.50 km, Duration: 73.52 min\n",
      "  Calculating route for Trip ID: 10 (18 waypoints)...\n",
      "  Trip ID 10 calculated. Distance: 34.81 km, Duration: 48.45 min\n",
      "  Calculating route for Trip ID: 12 (17 waypoints)...\n",
      "  Trip ID 12 calculated. Distance: 18.69 km, Duration: 35.70 min\n",
      "  Calculating route for Trip ID: 16 (9 waypoints)...\n",
      "  Trip ID 16 calculated. Distance: 26.04 km, Duration: 33.88 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1647127.html\n",
      "Stock Point ID: 1647130 || Stock Point Name: OmniHub Abuja - OmniHub Bwari Abuja - NETLINK\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Abuja - OmniHub Bwari Abuja - NETLINK, StockPointID: 1647130,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 3,301\n",
      "Total Quantity: 2,268\n",
      "Total Number of Customers before filter: 277\n",
      "Total Number of Customers: 177\n",
      "✓ Loaded 705 SKU recommendations\n",
      "✓ Loaded 177 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.64\n",
      "Davies-Bouldin Index: 0.5\n",
      "Calinski-Harabasz Score: 7603.16\n",
      "Silhouette Score: 0.64\n",
      "Davies-Bouldin Index: 0.5\n",
      "Calinski-Harabasz Score: 7603.16\n",
      "Select ClusterIDs: [3, 7, 5, 8]\n",
      "Total Number of Customers: 57\n",
      "   cluster               LGA_list  \\\n",
      "0        3                [Bwari]   \n",
      "1        7  [Bwari, Push - Bwari]   \n",
      "2        5                [Bwari]   \n",
      "3        8  [Bwari, Push - Bwari]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0                     [Dutsen Alhaji, ABUJA-BWARI, ]         17       220   \n",
      "1  [ABUJA-MPAPE, Dutsen Alhaji, Push - Abuja-Mpap...         13       169   \n",
      "2  [Kubwa, ABUJA-BWARI, ABUJA-MPAPE, , Kogo, Duts...         15       166   \n",
      "3  [ABUJA-BWARI, Kogo, Dutsen Alhaji, Push - Abuj...         12       151   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           56.421449  \n",
      "1           49.393529  \n",
      "2           48.298400  \n",
      "3           48.011522  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 3 (18 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 45.82 km, Duration: 58.12 min\n",
      "  Calculating route for Trip ID: 5 (16 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 20.09 km, Duration: 18.28 min\n",
      "  Calculating route for Trip ID: 7 (14 waypoints)...\n",
      "  Trip ID 7 calculated. Distance: 74.09 km, Duration: 105.87 min\n",
      "  Calculating route for Trip ID: 8 (13 waypoints)...\n",
      "  Trip ID 8 calculated. Distance: 22.86 km, Duration: 28.28 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1647130.html\n",
      "Stock Point ID: 1647111 || Stock Point Name: OmniHub Bwari Abuja - BAFAL\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Bwari Abuja - BAFAL, StockPointID: 1647111,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 4,230\n",
      "Total Quantity: 3,311\n",
      "Total Number of Customers before filter: 438\n",
      "Total Number of Customers: 346\n",
      "✓ Loaded 1029 SKU recommendations\n",
      "✓ Loaded 346 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.54\n",
      "Davies-Bouldin Index: 0.6\n",
      "Calinski-Harabasz Score: 1980.67\n",
      "Silhouette Score: 0.54\n",
      "Davies-Bouldin Index: 0.6\n",
      "Calinski-Harabasz Score: 1980.67\n",
      "Select ClusterIDs: [8, 5, 20, 12]\n",
      "Total Number of Customers: 55\n",
      "   cluster         LGA_list                                     LCDA_List  \\\n",
      "0        8         [AMAC 1]                             [, Jabi, Dei Dei]   \n",
      "1        5  [AMAC 1, Bwari]  [Airport Road, Lugbe, Dei Dei, Katampe, Idu]   \n",
      "2       20         [AMAC 1]                                        [Jabi]   \n",
      "3       12         [AMAC 1]                                   [, Dei Dei]   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0         18       186           39.498814  \n",
      "1         22       224           39.265652  \n",
      "2          5        46           37.043750  \n",
      "3         10        82           33.798800  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 5 (23 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 57.92 km, Duration: 47.13 min\n",
      "  Calculating route for Trip ID: 8 (19 waypoints)...\n",
      "  Trip ID 8 calculated. Distance: 49.28 km, Duration: 56.10 min\n",
      "  Calculating route for Trip ID: 12 (11 waypoints)...\n",
      "  Trip ID 12 calculated. Distance: 56.43 km, Duration: 52.27 min\n",
      "  Calculating route for Trip ID: 20 (6 waypoints)...\n",
      "  Trip ID 20 calculated. Distance: 46.41 km, Duration: 47.73 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1647111.html\n",
      "Stock Point ID: 1647382 || Stock Point Name: OmniHub Port Harcourt Rivers - IFO\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Port Harcourt Rivers - IFO, StockPointID: 1647382,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 4,999\n",
      "Total Quantity: 4,605\n",
      "Total Number of Customers before filter: 170\n",
      "Total Number of Customers: 157\n",
      "✓ Loaded 1197 SKU recommendations\n",
      "✓ Loaded 157 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.48\n",
      "Davies-Bouldin Index: 0.83\n",
      "Calinski-Harabasz Score: 1169.32\n",
      "Silhouette Score: 0.48\n",
      "Davies-Bouldin Index: 0.83\n",
      "Calinski-Harabasz Score: 1169.32\n",
      "Select ClusterIDs: [7, 1, 3, 10]\n",
      "Total Number of Customers: 60\n",
      "   cluster         LGA_list  \\\n",
      "0        7  [Port Harcourt]   \n",
      "1        1  [Port Harcourt]   \n",
      "2        3  [Port Harcourt]   \n",
      "3       10  [Port Harcourt]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0                                         [Borokiri]          7       218   \n",
      "1                        [Diobu, PORTHARCOURT-DIOBU]         29       892   \n",
      "2  [PORTHARCOURT-DIOBU, Diobu, D-Line, PORTHARCOU...         19       526   \n",
      "3                              [Diobu, Eagle Island]          5       150   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           56.052982  \n",
      "1           46.950756  \n",
      "2           40.337254  \n",
      "3           40.114000  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (30 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 31.81 km, Duration: 47.05 min\n",
      "  Calculating route for Trip ID: 3 (20 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 37.83 km, Duration: 51.62 min\n",
      "  Calculating route for Trip ID: 7 (8 waypoints)...\n",
      "  Trip ID 7 calculated. Distance: 29.19 km, Duration: 34.32 min\n",
      "  Calculating route for Trip ID: 10 (6 waypoints)...\n",
      "  Trip ID 10 calculated. Distance: 17.92 km, Duration: 23.15 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1647382.html\n",
      "Stock Point ID: 1647108 || Stock Point Name: OmniHub AMAC 2 Abuja - PearlCity Maraba\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub AMAC 2 Abuja - PearlCity Maraba, StockPointID: 1647108,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 9,407\n",
      "Total Quantity: 6,851\n",
      "Total Number of Customers before filter: 569\n",
      "Total Number of Customers: 409\n",
      "✓ Loaded 2408 SKU recommendations\n",
      "✓ Loaded 409 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.42\n",
      "Davies-Bouldin Index: 0.37\n",
      "Calinski-Harabasz Score: 3524.18\n",
      "Silhouette Score: 0.42\n",
      "Davies-Bouldin Index: 0.37\n",
      "Calinski-Harabasz Score: 3524.18\n",
      "Select ClusterIDs: [14, 3, 10, 11]\n",
      "Total Number of Customers: 60\n",
      "   cluster        LGA_list                                          LCDA_List  \\\n",
      "0       14        [AMAC 3]                                            [Maska]   \n",
      "1        3  [AMAC 3, Karu]  [Durumi, , One Man Village, Maska, Mararaba, A...   \n",
      "2       10        [AMAC 3]                                            [Maska]   \n",
      "3       11        [AMAC 3]                           [, Durumi, Apo, Garki 2]   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0          9       195           68.059403  \n",
      "1         30       475           50.531053  \n",
      "2         11       204           47.843485  \n",
      "3         10       143           47.522857  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 3 (31 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 102.87 km, Duration: 78.15 min\n",
      "  Calculating route for Trip ID: 10 (12 waypoints)...\n",
      "  Trip ID 10 calculated. Distance: 42.92 km, Duration: 40.17 min\n",
      "  Calculating route for Trip ID: 11 (11 waypoints)...\n",
      "  Trip ID 11 calculated. Distance: 16.59 km, Duration: 23.15 min\n",
      "  Calculating route for Trip ID: 14 (10 waypoints)...\n",
      "  Trip ID 14 calculated. Distance: 34.10 km, Duration: 27.10 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1647108.html\n",
      "Stock Point ID: 1647141 || Stock Point Name: OmniHub Ojo Lagos - Mas Global\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ojo Lagos - Mas Global, StockPointID: 1647141,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 8,599\n",
      "Total Quantity: 7,087\n",
      "Total Number of Customers before filter: 494\n",
      "Total Number of Customers: 403\n",
      "✓ Loaded 1807 SKU recommendations\n",
      "✓ Loaded 403 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.34\n",
      "Davies-Bouldin Index: 0.44\n",
      "Calinski-Harabasz Score: 16533.61\n",
      "Silhouette Score: 0.34\n",
      "Davies-Bouldin Index: 0.44\n",
      "Calinski-Harabasz Score: 16533.61\n",
      "Select ClusterIDs: [17, 5, 4, 7]\n",
      "Total Number of Customers: 78\n",
      "   cluster             LGA_list  \\\n",
      "0       17  [Ojo, Amuwo Odofin]   \n",
      "1        5       [Amuwo Odofin]   \n",
      "2        4                [Ojo]   \n",
      "3        7                [Ojo]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [, Ojo - Iyana Iba, Ojo - Lasu, Ojo - Agric, O...         10       189   \n",
      "1  [, Amuwo Odofin - Festac (1st Avenue), Amuwo O...         21       355   \n",
      "2  [, Ojo - Iba Housing Area, Ojo - Iyana Iba, Oj...         27       503   \n",
      "3     [Ojo - Okokomaiko, OKOKOMAIKO, Ojo - Aka Road]         20       382   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           53.068000  \n",
      "1           52.536947  \n",
      "2           47.005037  \n",
      "3           46.521809  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 4 (28 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 75.97 km, Duration: 154.72 min\n",
      "  Calculating route for Trip ID: 5 (22 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 86.40 km, Duration: 136.70 min\n",
      "  Calculating route for Trip ID: 7 (21 waypoints)...\n",
      "  Trip ID 7 calculated. Distance: 7.30 km, Duration: 20.25 min\n",
      "  Calculating route for Trip ID: 17 (11 waypoints)...\n",
      "  Trip ID 17 calculated. Distance: 52.02 km, Duration: 89.65 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1647141.html\n",
      "Stock Point ID: 1647187 || Stock Point Name: OmniHub Calabar Municipal Cross River - Eyong Obot\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Calabar Municipal Cross River - Eyong Obot, StockPointID: 1647187,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 1,741\n",
      "Total Quantity: 1,575\n",
      "Total Number of Customers before filter: 205\n",
      "Total Number of Customers: 184\n",
      "✓ Loaded 413 SKU recommendations\n",
      "✓ Loaded 184 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.46\n",
      "Davies-Bouldin Index: 0.57\n",
      "Calinski-Harabasz Score: 111166.08\n",
      "Silhouette Score: 0.46\n",
      "Davies-Bouldin Index: 0.57\n",
      "Calinski-Harabasz Score: 111166.08\n",
      "Select ClusterIDs: [3, 7, 10, 8]\n",
      "Total Number of Customers: 63\n",
      "   cluster                            LGA_list  \\\n",
      "0        3                   [Calabar South, ]   \n",
      "1        7                     [Calabar South]   \n",
      "2       10  [Calabar South, Calabar Municipal]   \n",
      "3        8                     [Calabar South]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [Watt Market, GOLDIE, Etim Edem Street., EGERT...         24       225   \n",
      "1  [EGERTON, Chambley Street., MAYNE AVENUE, MBUK...         14       112   \n",
      "2  [GOLDIE, EGERTON, Airport Road., Calabar Road....         11       103   \n",
      "3      [Bogobiri Street., Etim Edem Street., GOLDIE]         14       128   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           56.660984  \n",
      "1           52.026129  \n",
      "2           50.386000  \n",
      "3           49.679032  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 3 (25 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 5.69 km, Duration: 10.97 min\n",
      "  Calculating route for Trip ID: 7 (15 waypoints)...\n",
      "  Trip ID 7 calculated. Distance: 6.65 km, Duration: 9.85 min\n",
      "  Calculating route for Trip ID: 8 (15 waypoints)...\n",
      "  Trip ID 8 calculated. Distance: 7.45 km, Duration: 13.18 min\n",
      "  Calculating route for Trip ID: 10 (12 waypoints)...\n",
      "  Trip ID 10 calculated. Distance: 36.18 km, Duration: 54.85 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1647187.html\n",
      "Stock Point ID: 1647403 || Stock Point Name: OmniHub Calabar Municipal Cross River - Alpha Grafix\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Calabar Municipal Cross River - Alpha Grafix, StockPointID: 1647403,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 732\n",
      "Total Quantity: 650\n",
      "Total Number of Customers before filter: 84\n",
      "Total Number of Customers: 73\n",
      "✓ Loaded 147 SKU recommendations\n",
      "✓ Loaded 73 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.6\n",
      "Davies-Bouldin Index: 0.35\n",
      "Calinski-Harabasz Score: 74701.94\n",
      "Silhouette Score: 0.6\n",
      "Davies-Bouldin Index: 0.35\n",
      "Calinski-Harabasz Score: 74701.94\n",
      "Select ClusterIDs: [5, 3, 2, 1]\n",
      "Total Number of Customers: 63\n",
      "   cluster                            LGA_list  \\\n",
      "0        5  [Calabar Municipal, Calabar South]   \n",
      "1        3                 [Calabar Municipal]   \n",
      "2        2                 [Calabar Municipal]   \n",
      "3        1                 [Calabar Municipal]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [Ekpo Abasi Lane Ln., MAYNE AVENUE, Afokang St...          6        46   \n",
      "1  [, Abang Asang Street., Esuk Atu Road., Nyok E...         13       121   \n",
      "2  [Esuk Atu Road., Atimbo Ln., Abang Asang Stree...         16       151   \n",
      "3  [Mcc Road., Old Odukpani Road., Marian Road., ...         28       251   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           25.113636  \n",
      "1           17.411786  \n",
      "2           14.979394  \n",
      "3           13.943684  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (29 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 38.26 km, Duration: 51.30 min\n",
      "  Calculating route for Trip ID: 2 (17 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 28.80 km, Duration: 40.73 min\n",
      "  Calculating route for Trip ID: 3 (14 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 24.61 km, Duration: 33.78 min\n",
      "  Calculating route for Trip ID: 5 (7 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 29.32 km, Duration: 39.82 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-26/1647403.html\n",
      "Stock Point ID: 1647419 || Stock Point Name: OmniHub Alimosho Lagos - Kay24\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Alimosho Lagos - Kay24, StockPointID: 1647419,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 206\n",
      "Total Quantity: 133\n",
      "Total Number of Customers before filter: 13\n",
      "Total Number of Customers: 9\n",
      "✓ Loaded 39 SKU recommendations\n",
      "✓ Loaded 9 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Dataframe is empty\n",
      "INFO:__main__:Trip Data is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.47\n",
      "Davies-Bouldin Index: 0.3\n",
      "Calinski-Harabasz Score: 77.34\n",
      "Silhouette Score: 0.47\n",
      "Davies-Bouldin Index: 0.3\n",
      "Calinski-Harabasz Score: 77.34\n",
      "Select ClusterIDs: []\n",
      "Total Number of Customers: 0\n",
      "Empty DataFrame\n",
      "Columns: [cluster, LGA_list, LCDA_List, ncustomer, totalQty, avg_customer_score]\n",
      "Index: []\n",
      "Stock Point ID: 1647420 || Stock Point Name: OmniHub Ojo Lagos - Barka Agro 3\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ojo Lagos - Barka Agro 3, StockPointID: 1647420,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "Stock Point ID: 1647421 || Stock Point Name: OmniHub Ikpoba Okha Edo - Real Care\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ikpoba Okha Edo - Real Care, StockPointID: 1647421,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "Stock Point ID: 1647422 || Stock Point Name: OmniHub Oshodi Isolo Lagos - Fabb\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Oshodi Isolo Lagos - Fabb, StockPointID: 1647422,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "Stock Point ID: 1647425 || Stock Point Name: OmniHub Keffi Nasarawa - Donsam\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Keffi Nasarawa - Donsam, StockPointID: 1647425,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "Stock Point ID: 1647434 || Stock Point Name: OmniHub Kuje/Gwagwalada/Abaji Abuja - Deschek\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Kuje/Gwagwalada/Abaji Abuja - Deschek, StockPointID: 1647434,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n"
     ]
    }
   ],
   "source": [
    "ALL_STOCKPOINTS_RESULT = {}\n",
    "for index, row in df_stockpoint_dim.iterrows():\n",
    "    # if index == 12:\n",
    "    # if index == 5:\n",
    "    stock_point_id =  row['Stock_Point_ID']\n",
    "    stock_point_name = row['Stock_point_Name']\n",
    "    print(f'Stock Point ID: {stock_point_id} || Stock Point Name: {stock_point_name}')  # Access by column name\n",
    "\n",
    "    res_dict = run_push_recommendation(df_customer_sku_recommendation, \n",
    "                                df_master_customer_dim, \n",
    "                                df_stockpoint_dim, \n",
    "                                stock_point_id,\n",
    "                                stock_point_name,\n",
    "                                sku_recency = 7, \n",
    "                                customer_recency = 60, number_recommendation = 10, \n",
    "                                estimate_qty_scale_factor = 1, max_estimated_qty = 5, \n",
    "                                exclude_recency_customer = 3,\n",
    "                                max_customers_per_route=20,\n",
    "                                max_volume_per_route=300,\n",
    "                                max_distance_km = 5,\n",
    "                                sel_trip_cluster = 4,\n",
    "                                min_ncust_per_cluster = 5,\n",
    "                                clustering_method = 'divisive',\n",
    "                                skip_route_optimization = True)\n",
    "    \n",
    "    ALL_STOCKPOINTS_RESULT[stock_point_name] = res_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d067f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res_dict.keys())\n",
    "# [col  for col in res_dict['all_push_recommendation'].columns if 'KYC_Capture_Status' in col]\n",
    "# res_dict['cluster_summary'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6f9cbb",
   "metadata": {},
   "source": [
    "## Routing 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04decfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = ALL_STOCKPOINTS_RESULT['OmniHub Apapa Lagos - CAUSEWAY'] \n",
    "df_selected_trip = df_test['selected_trip']\n",
    "print(df_selected_trip.TripID.nunique())\n",
    "# dict_keys(['stock_point_name', 'selected_trip', 'all_push_recommendation', 'cluster_summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5b661f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected_trip_summary =  df_selected_trip.groupby(['StockPointID','TripID', \n",
    "                                                                                   'CustomerID', 'Latitude','Longitude',\n",
    "                                                                                   'LGA', 'LCDA','CustomerScore']).agg( \n",
    "                        TotalQuantity = ('EstimatedQuantity','sum')\n",
    "                        ,TotalSKU = ('SKUID','nunique')\n",
    "                    ).reset_index() \n",
    "# trip_dict = create_single_stockpoint_dict(df_selected_trip_summary, df_stockpoint_dim) \n",
    "# route_info = calculated_routes_info = get_valhalla_routes_info(trip_dict)\n",
    "# route_info[0].keys()\n",
    "# len(trip_dict['Trips'][0]['Destinations'])\n",
    "create_route(df_selected_trip_summary, df_stockpoint_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889871c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_route(df_selected_trip_summary, df_stockpoint_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b199e2",
   "metadata": {},
   "source": [
    "# Data Export to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea7a9217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL_STOCKPOINTS_RESULT.keys()\n",
    "# # ALL_STOCKPOINTS_RESULT['OmniHub Obio Akpor Rivers - Rivoc']\n",
    "# ALL_STOCKPOINTS_RESULT['OmniHub Ado Odo/Ota Ogun - Prince Tunadek']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "58bc8c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_ALL_RECOMMENDATION = pd.DataFrame() \n",
    "for key in ALL_STOCKPOINTS_RESULT.keys():\n",
    "    dict_f = ALL_STOCKPOINTS_RESULT[key]\n",
    "    if dict_f != {}:\n",
    "        df_ = dict_f['all_push_recommendation']\n",
    "    \n",
    "        if len(df_) > 0:\n",
    "            df_['ClusterLGAs'] = df_['ClusterLGAs'].apply(str)\n",
    "            df_['ClusterLCDAs'] = df_['ClusterLCDAs'].apply(str)\n",
    "            DF_ALL_RECOMMENDATION = pd.concat([DF_ALL_RECOMMENDATION, df_])\n",
    "            DF_ALL_RECOMMENDATION['ModifiedDate'] = CURRENT_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f705d251",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_summary = ['StockPointID', 'StockPointName', 'TripID', 'ClusterLGAs', 'ClusterLCDAs', 'TotalCustonerCount', 'TripTotalQuantity','TripAvgCustomerScore', 'ModifiedDate']  \n",
    "DF_CLUSTER_SUMMARY = DF_ALL_RECOMMENDATION[cols_summary].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2d60a7d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StockPointID</th>\n",
       "      <th>StockPointName</th>\n",
       "      <th>TripID</th>\n",
       "      <th>ClusterLGAs</th>\n",
       "      <th>ClusterLCDAs</th>\n",
       "      <th>TotalCustonerCount</th>\n",
       "      <th>TripTotalQuantity</th>\n",
       "      <th>TripAvgCustomerScore</th>\n",
       "      <th>ModifiedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>1647122</td>\n",
       "      <td>OmniHub Egbeda Oyo - Vizazi</td>\n",
       "      <td>10</td>\n",
       "      <td>['Egbeda']</td>\n",
       "      <td>['IBADAN-NEW GBAGI MARKET', '', 'Old Ife Road']</td>\n",
       "      <td>7</td>\n",
       "      <td>219</td>\n",
       "      <td>49.477119</td>\n",
       "      <td>2025-06-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     StockPointID               StockPointName  TripID ClusterLGAs  \\\n",
       "574       1647122  OmniHub Egbeda Oyo - Vizazi      10  ['Egbeda']   \n",
       "\n",
       "                                        ClusterLCDAs  TotalCustonerCount  \\\n",
       "574  ['IBADAN-NEW GBAGI MARKET', '', 'Old Ife Road']                   7   \n",
       "\n",
       "     TripTotalQuantity  TripAvgCustomerScore ModifiedDate  \n",
       "574                219             49.477119   2025-06-26  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "# DF_ALL_RECOMMENDATION.sample(1)\n",
    "DF_CLUSTER_SUMMARY.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "605ba250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_lengths = DF_ALL_RECOMMENDATION.astype(str).applymap(len).max().reset_index(name = 'max_length')\n",
    "# print(max_lengths)\n",
    "# print(DF_ALL_RECOMMENDATION.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "15686f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsert_dataframe(df, table_name, conn, match_cols, update_cols, batch_size = 2000, fast_executemany = True):\n",
    "    # Input validation\n",
    "    if df.empty:\n",
    "        raise ValueError(\"DataFrame is empty.\")\n",
    "    if not match_cols or not update_cols:\n",
    "        raise ValueError(\"match_cols and update_cols cannot be empty.\")\n",
    "    if not all(col in df.columns for col in match_cols + update_cols):\n",
    "        raise ValueError(\"Some match_cols or update_cols are not in the DataFrame.\")\n",
    "    if not table_name.strip() or any(c in table_name for c in \".;[]\"):\n",
    "        raise ValueError(\"Invalid table_name.\")\n",
    "\n",
    "    cursor = None\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.fast_executemany = fast_executemany \n",
    "\n",
    "        staging_table = f\"#{table_name}_staging\"\n",
    "        cols = df.columns.tolist()\n",
    "        col_list = ', '.join(f\"[{col}]\" for col in cols)\n",
    "        placeholders = ', '.join(['?'] * len(cols))\n",
    "\n",
    "        # Step 1: Create staging table from real schema\n",
    "        create_staging_sql = f\"\"\"\n",
    "        SELECT TOP 0 {col_list}\n",
    "        INTO {staging_table}\n",
    "        FROM {table_name}\n",
    "        WHERE 1 = 0;\n",
    "        \"\"\"\n",
    "        cursor.execute(create_staging_sql)\n",
    "\n",
    "        # Step 2: Bulk insert into staging table using fast_executemany\n",
    "        insert_sql = f\"INSERT INTO {staging_table} ({col_list}) VALUES ({placeholders})\"\n",
    "        cursor.executemany(insert_sql, df[cols].values.tolist())\n",
    "        conn.commit()\n",
    "\n",
    "        # insert_sql = f\"INSERT INTO {staging_table} ({col_list}) VALUES ({placeholders})\"\n",
    "        # data = df[cols].values.tolist()\n",
    "        # for i in range(0, len(data), batch_size):\n",
    "        #     cursor.executemany(insert_sql, data[i:i+batch_size])\n",
    "        # conn.commit()\n",
    "\n",
    "        # Step 3: MERGE for upsert\n",
    "        on_clause = ' AND '.join([f\"TARGET.[{col}] = SOURCE.[{col}]\" for col in match_cols])\n",
    "        update_clause = ', '.join([f\"TARGET.[{col}] = SOURCE.[{col}]\" for col in update_cols])\n",
    "        insert_cols = ', '.join([f\"[{col}]\" for col in cols])\n",
    "        insert_values = ', '.join([f\"SOURCE.[{col}]\" for col in cols])\n",
    "\n",
    "        merge_sql = f\"\"\"\n",
    "        MERGE {table_name} AS TARGET\n",
    "        USING {staging_table} AS SOURCE\n",
    "        ON {on_clause}\n",
    "        WHEN MATCHED THEN\n",
    "            UPDATE SET {update_clause}\n",
    "        WHEN NOT MATCHED THEN\n",
    "            INSERT ({insert_cols})\n",
    "            VALUES ({insert_values});\n",
    "        \"\"\"\n",
    "        cursor.execute(merge_sql)\n",
    "        conn.commit()\n",
    "    except Exception as e:\n",
    "        if conn:\n",
    "            conn.rollback()\n",
    "        logger.error(f\"Upsert failed for table {table_name}: {e}\")\n",
    "        raise Exception(f\"Upsert failed for table {table_name}: {e}\") from e\n",
    "    finally:\n",
    "        if cursor:\n",
    "            cursor.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "605c6399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "df_insert = DF_ALL_RECOMMENDATION.drop(columns=['ClusterLGAs',\t'ClusterLCDAs']).reset_index(drop=True)\n",
    "match_cols = ['StockPointID', 'CustomerID', 'SKUID', 'ModifiedDate']\n",
    "update_cols = list(set(df_insert.columns) - set(match_cols))\n",
    "\n",
    "conn = get_connection()\n",
    "upsert_dataframe(\n",
    "    df=df_insert,\n",
    "    table_name='dailyPredictedPull',\n",
    "    conn=conn,\n",
    "    match_cols=match_cols,\n",
    "    update_cols=update_cols   \n",
    ") \n",
    " \n",
    "print(conn.closed)\n",
    "conn.close()\n",
    "print(conn.closed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5e9d8104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "df = DF_CLUSTER_SUMMARY.copy() \n",
    "\n",
    "df['ClusterLGAs'] = df['ClusterLGAs'].astype(str).str.slice(0, 500)\n",
    "df['ClusterLCDAs'] = df['ClusterLCDAs'].astype(str).str.slice(0, 500)\n",
    "\n",
    "\n",
    "match_cols = ['StockPointID', 'TripID', 'ModifiedDate']\n",
    "update_cols = list(set(df.columns) - set(match_cols))\n",
    "\n",
    "conn = get_connection()\n",
    "upsert_dataframe(\n",
    "    df=df,\n",
    "    table_name='dailyPredictedPullClusterSummary',\n",
    "    conn=conn,\n",
    "    match_cols=match_cols,\n",
    "    update_cols=update_cols ,\n",
    "    fast_executemany = False  \n",
    ")\n",
    "\n",
    "print(conn.closed)\n",
    "conn.close()\n",
    "print(conn.closed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9fa188a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c3d7a360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pd.set_option('display.width', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# res_dict['all_push_recommendation'].sample(1)\n",
    "# # res_dict['cluster_summary'].sort_values('ncustomer', ascending = False)\n",
    "# from collections import Counter\n",
    "# Counter(res_dict['all_push_recommendation'].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d210a690",
   "metadata": {},
   "source": [
    "# Case Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cced9601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Filter - Testing \n",
    "causeway, causeway_customer_dim, causeway_stockpoint, = data_filter(df_customer_sku_recommendation, \n",
    "                                                                    df_master_customer_dim, \n",
    "                                                                    df_stockpoint_dim, \n",
    "                                                                    stockpoint_id = 1647394,  \n",
    "                                                                    # stockpoint_id = 1647113,  \n",
    "                                                                    sku_recency = 7, customer_recency = 60, number_recommendation = 10,\n",
    "                                                                    estimate_qty_scale_factor = 1, max_estimated_qty = 5, \n",
    "                                                                    exclude_recency_customer = 4)\n",
    "\n",
    "# Total Number of Customers: 905 || 901\n",
    "\n",
    "df_all_cluster = causeway_customer_dim[['CustomerID', 'Latitude','Longitude']].drop_duplicates()\n",
    "df_all_cluster.shape\n",
    "# df_all_cluster = res_dict['all_push_recommendation'][['CustomerID','TripID', 'Latitude','Longitude']].drop_duplicates().rename(columns={'TripID':'cluster'})\n",
    "\n",
    "\n",
    "# vis_and_save(df_routes = df_all_cluster,\n",
    "#                  df_stockpoint = None,   \n",
    "#                  filename=None,\n",
    "#                  cluster_col = 'cluster')\n",
    "\n",
    "# 459"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb813416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_cluster.Latitude.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a397ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = ['CustomerID', 'SKUID', 'Medium','CustomerPurchaseRecency']\n",
    "# causeway[cols].query('(CustomerID == 5271729) or (CustomerID ==  5266873)')\n",
    "# causeway.groupby(['CustomerPurchaseRecency'])['CustomerID'].nunique().reset_index().sort_values('CustomerID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee26108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# causeway.columns\n",
    "# causeway['Medium'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b73d94d",
   "metadata": {},
   "source": [
    "### Test New Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee242d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clustering.divisive_clustering import DivisiveGeographicClustering, OptimizedDivisiveGeographicClustering\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"2. DIVISIVE HIERARCHICAL CLUSTERING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "divisive_clusterer = OptimizedDivisiveGeographicClustering( \n",
    "    # Rivers: Divisive clusters created: 48 || Silhouette Score: 0.54 || Constraint violations: Size=6, Distance=3\n",
    "    max_customers_per_cluster=30,  # REQUIRED\n",
    "    max_distance_km=5            # REQUIRED\n",
    "    ,use_vectorized_distances=True, balance_clusters=False\n",
    ")\n",
    "\n",
    "divisive_result = divisive_clusterer.divisive_clustering(df_all_cluster.copy())\n",
    "print(f\"\\nDivisive clusters created: {divisive_result['cluster'].nunique()}\")\n",
    "# print(f\"Cluster sizes: {divisive_result['cluster'].value_counts().sort_index().head()}\")\n",
    "_ = evaluate_unsupervised_clustering(divisive_result)\n",
    "\n",
    "# # Get detailed statistics\n",
    "stats = divisive_clusterer.get_cluster_stats(divisive_result)\n",
    "print(f\"Total clusters: {stats['summary']['total_clusters']}\")\n",
    "print(f\"Constraint violations: Size={stats['summary']['size_violations']}, Distance={stats['summary']['distance_violations']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc977318",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clustering.agglomerative_clustering import AgglomerativeGeographicClustering\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"2. AGGLOMERATIVE CLUSTERING\")\n",
    "print(\"=\"*60)\n",
    " \n",
    "agg_clusterer = AgglomerativeGeographicClustering(\n",
    "    max_customers_per_cluster=30, # Aim for clusters of max 50 customers\n",
    "    max_distance_km=5.0,        # Max diameter of 5 km\n",
    "    linkage_method='ward',       # Common choice for compact clusters\n",
    "    sub_cluster_if_oversized=True\n",
    ")\n",
    "clustered_agg_df = agg_clusterer.agglomerative_clustering(df_all_cluster.copy())\n",
    "\n",
    "# print(\"\\nAgglomerative Clustering Stats:\")\n",
    "# for k, v in agg_stats['summary'].items():\n",
    "#     print(f\"  {k}: {v}\")\n",
    "# print(\"\\nSample Agglomerative Cluster Details:\")\n",
    "# for cluster_id, details in list(agg_stats.items())[:5]: # Show first 5 clusters\n",
    "#     if cluster_id != 'summary':\n",
    "#         print(f\"  Cluster {cluster_id}: Size={details['size']}, Diameter={details['diameter_km']:.2f} km, Size OK={details['meets_size_constraint']}, Distance OK={details['meets_distance_constraint']}\")\n",
    "\n",
    "\n",
    "_ = evaluate_unsupervised_clustering(clustered_agg_df)\n",
    "\n",
    "\n",
    "stats = agg_clusterer.get_cluster_stats(clustered_agg_df, agg_clusterer.max_customers_per_cluster, agg_clusterer.max_distance_km) \n",
    "print(f\"Total clusters: {stats['summary']['total_clusters']}\")\n",
    "print(f\"Constraint violations: Size={stats['summary']['size_violations']}, Distance={stats['summary']['distance_violations']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd35595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_and_save(df_routes = clustered_agg_df,\n",
    "                 df_stockpoint = None,   \n",
    "                 filename='agglomerative-clustering-test.html',\n",
    "                 cluster_col = 'cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a73b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_and_save(df_routes = divisive_result,\n",
    "                 df_stockpoint = None,   \n",
    "                 filename='divisive-clustering-test.html',\n",
    "                 cluster_col = 'cluster')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08980d8e",
   "metadata": {},
   "source": [
    "### New Clustering Algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2266ee03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.cluster.hierarchy import fcluster, linkage\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "## Best\n",
    "class OptimizedDivisiveGeographicClustering_b:\n",
    "    def __init__(self, max_customers_per_cluster=20, max_distance_km=50, \n",
    "                 use_vectorized_distances=True, balance_clusters=False):\n",
    "        self.max_customers_per_cluster = max_customers_per_cluster\n",
    "        self.max_distance_km = max_distance_km\n",
    "        self.earth_radius_km = 6371.0\n",
    "        self.use_vectorized_distances = use_vectorized_distances\n",
    "        self.balance_clusters = balance_clusters\n",
    "        \n",
    "    def haversine_vectorized(self, coords1, coords2=None):\n",
    "        \"\"\"\n",
    "        Highly optimized vectorized haversine distance calculation.\n",
    "        If coords2 is None, calculates pairwise distances within coords1.\n",
    "        \"\"\"\n",
    "        if coords2 is None:\n",
    "            # Pairwise distances within coords1\n",
    "            coords1_rad = np.radians(coords1)\n",
    "            n = len(coords1)\n",
    "            \n",
    "            # Create meshgrids for vectorized calculation\n",
    "            lat1 = coords1_rad[:, 0]\n",
    "            lon1 = coords1_rad[:, 1]\n",
    "            \n",
    "            lat1_mesh, lat2_mesh = np.meshgrid(lat1, lat1)\n",
    "            lon1_mesh, lon2_mesh = np.meshgrid(lon1, lon1)\n",
    "            \n",
    "            dlat = lat2_mesh - lat1_mesh\n",
    "            dlon = lon2_mesh - lon1_mesh\n",
    "            \n",
    "            a = (np.sin(dlat / 2) ** 2 + \n",
    "                 np.cos(lat1_mesh) * np.cos(lat2_mesh) * np.sin(dlon / 2) ** 2)\n",
    "            c = 2 * np.arcsin(np.sqrt(np.clip(a, 0, 1)))\n",
    "            \n",
    "            return self.earth_radius_km * c\n",
    "        else:\n",
    "            # Distance from each point in coords1 to each point in coords2\n",
    "            coords1_rad = np.radians(coords1)\n",
    "            coords2_rad = np.radians(coords2)\n",
    "            \n",
    "            lat1 = coords1_rad[:, 0][:, np.newaxis]\n",
    "            lon1 = coords1_rad[:, 1][:, np.newaxis]\n",
    "            lat2 = coords2_rad[:, 0][np.newaxis, :]\n",
    "            lon2 = coords2_rad[:, 1][np.newaxis, :]\n",
    "            \n",
    "            dlat = lat2 - lat1\n",
    "            dlon = lon2 - lon1\n",
    "            \n",
    "            a = (np.sin(dlat / 2) ** 2 + \n",
    "                 np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2)\n",
    "            c = 2 * np.arcsin(np.sqrt(np.clip(a, 0, 1)))\n",
    "            \n",
    "            return self.earth_radius_km * c\n",
    "    \n",
    "    def haversine_pdist(self, coords):\n",
    "        \"\"\"\n",
    "        Optimized haversine distance calculation using scipy's pdist.\n",
    "        \"\"\"\n",
    "        def haversine_metric(u, v):\n",
    "            lat1, lon1 = np.radians(u)\n",
    "            lat2, lon2 = np.radians(v)\n",
    "            \n",
    "            dlat = lat2 - lat1\n",
    "            dlon = lon2 - lon1\n",
    "            \n",
    "            a = (np.sin(dlat / 2) ** 2 + \n",
    "                 np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2)\n",
    "            c = 2 * np.arcsin(np.sqrt(np.clip(a, 0, 1)))\n",
    "            \n",
    "            return self.earth_radius_km * c\n",
    "        \n",
    "        return pdist(coords, metric=haversine_metric)\n",
    "    \n",
    "    def calculate_cluster_diameter_fast(self, coords):\n",
    "        \"\"\"\n",
    "        Fast cluster diameter calculation with multiple optimization strategies.\n",
    "        \"\"\"\n",
    "        n_points = len(coords)\n",
    "        \n",
    "        if n_points <= 1:\n",
    "            return 0\n",
    "        \n",
    "        if n_points == 2:\n",
    "            return self.haversine_single_pair(coords[0], coords[1])\n",
    "        \n",
    "        # Use different strategies based on cluster size\n",
    "        if n_points <= 10:\n",
    "            # Small clusters: exact calculation\n",
    "            distances = self.haversine_pdist(coords)\n",
    "            return np.max(distances)\n",
    "        elif n_points <= 50:\n",
    "            # Medium clusters: vectorized calculation\n",
    "            if self.use_vectorized_distances:\n",
    "                distance_matrix = self.haversine_vectorized(coords)\n",
    "                return np.max(distance_matrix)\n",
    "            else:\n",
    "                distances = self.haversine_pdist(coords)\n",
    "                return np.max(distances)\n",
    "        else:\n",
    "            # Large clusters: smart sampling\n",
    "            return self._smart_diameter_estimation(coords)\n",
    "    \n",
    "    def _smart_diameter_estimation(self, coords):\n",
    "        \"\"\"\n",
    "        Improved diameter estimation using multiple sampling strategies.\n",
    "        \"\"\"\n",
    "        n_points = len(coords)\n",
    "        \n",
    "        # Strategy 1: Convex hull approximation\n",
    "        hull_diameter = self._convex_hull_diameter(coords)\n",
    "        \n",
    "        # Strategy 2: Grid-based sampling for large clusters\n",
    "        if n_points > 200:\n",
    "            grid_diameter = self._grid_based_diameter(coords)\n",
    "            return max(hull_diameter, grid_diameter)\n",
    "        \n",
    "        return hull_diameter\n",
    "    \n",
    "    def _convex_hull_diameter(self, coords):\n",
    "        \"\"\"Enhanced convex hull approximation.\"\"\"\n",
    "        lats, lons = coords[:, 0], coords[:, 1]\n",
    "        \n",
    "        # Get extreme points\n",
    "        extreme_indices = [\n",
    "            np.argmax(lats), np.argmin(lats),\n",
    "            np.argmax(lons), np.argmin(lons)\n",
    "        ]\n",
    "        \n",
    "        # Add points from different quadrants\n",
    "        lat_center, lon_center = np.mean(lats), np.mean(lons)\n",
    "        \n",
    "        quadrants = [\n",
    "            (lats >= lat_center) & (lons >= lon_center),  # NE\n",
    "            (lats >= lat_center) & (lons < lon_center),   # NW\n",
    "            (lats < lat_center) & (lons >= lon_center),   # SE\n",
    "            (lats < lat_center) & (lons < lon_center)     # SW\n",
    "        ]\n",
    "        \n",
    "        for quadrant in quadrants:\n",
    "            if np.any(quadrant):\n",
    "                quad_indices = np.where(quadrant)[0]\n",
    "                # Add furthest point from center in each quadrant\n",
    "                distances_from_center = np.sqrt(\n",
    "                    (lats[quad_indices] - lat_center)**2 + \n",
    "                    (lons[quad_indices] - lon_center)**2\n",
    "                )\n",
    "                furthest_idx = quad_indices[np.argmax(distances_from_center)]\n",
    "                extreme_indices.append(furthest_idx)\n",
    "        \n",
    "        # Add some random points\n",
    "        n_random = min(12, len(coords) - len(set(extreme_indices)))\n",
    "        if n_random > 0:\n",
    "            available_indices = list(set(range(len(coords))) - set(extreme_indices))\n",
    "            if available_indices:\n",
    "                random_indices = np.random.choice(available_indices, \n",
    "                                                min(n_random, len(available_indices)), \n",
    "                                                replace=False)\n",
    "                extreme_indices.extend(random_indices)\n",
    "        \n",
    "        # Get unique sample\n",
    "        sample_indices = list(set(extreme_indices))\n",
    "        sample_coords = coords[sample_indices]\n",
    "        \n",
    "        if len(sample_coords) <= 1:\n",
    "            return 0\n",
    "        \n",
    "        distances = self.haversine_pdist(sample_coords)\n",
    "        return np.max(distances)\n",
    "    \n",
    "    def _grid_based_diameter(self, coords):\n",
    "        \"\"\"Grid-based sampling for very large clusters.\"\"\"\n",
    "        # Create a grid and sample points from each grid cell\n",
    "        lats, lons = coords[:, 0], coords[:, 1]\n",
    "        \n",
    "        # Create 6x6 grid\n",
    "        lat_bins = np.linspace(lats.min(), lats.max(), 7)\n",
    "        lon_bins = np.linspace(lons.min(), lons.max(), 7)\n",
    "        \n",
    "        sample_indices = []\n",
    "        for i in range(len(lat_bins)-1):\n",
    "            for j in range(len(lon_bins)-1):\n",
    "                mask = ((lats >= lat_bins[i]) & (lats < lat_bins[i+1]) & \n",
    "                       (lons >= lon_bins[j]) & (lons < lon_bins[j+1]))\n",
    "                cell_indices = np.where(mask)[0]\n",
    "                if len(cell_indices) > 0:\n",
    "                    # Sample up to 2 points from each cell\n",
    "                    n_sample = min(2, len(cell_indices))\n",
    "                    sampled = np.random.choice(cell_indices, n_sample, replace=False)\n",
    "                    sample_indices.extend(sampled)\n",
    "        \n",
    "        if len(sample_indices) <= 1:\n",
    "            return 0\n",
    "        \n",
    "        sample_coords = coords[sample_indices]\n",
    "        distances = self.haversine_pdist(sample_coords)\n",
    "        return np.max(distances)\n",
    "    \n",
    "    def haversine_single_pair(self, coord1, coord2):\n",
    "        \"\"\"Calculate haversine distance between two points.\"\"\"\n",
    "        lat1, lon1 = np.radians(coord1)\n",
    "        lat2, lon2 = np.radians(coord2)\n",
    "        \n",
    "        dlat = lat2 - lat1\n",
    "        dlon = lon2 - lon1\n",
    "        \n",
    "        a = (np.sin(dlat / 2) ** 2 + \n",
    "             np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2)\n",
    "        c = 2 * np.arcsin(np.sqrt(np.clip(a, 0, 1)))\n",
    "        \n",
    "        return self.earth_radius_km * c\n",
    "    \n",
    "    def should_split_cluster(self, cluster_indices, coords_array):\n",
    "        \"\"\"Enhanced cluster splitting logic with load balancing.\"\"\"\n",
    "        cluster_size = len(cluster_indices)\n",
    "        \n",
    "        if cluster_size <= 2:\n",
    "            return False\n",
    "        \n",
    "        # Hard size constraint\n",
    "        if cluster_size > self.max_customers_per_cluster * 1.5:\n",
    "            return True\n",
    "        \n",
    "        # Soft size constraint with diameter check\n",
    "        if cluster_size > self.max_customers_per_cluster:\n",
    "            cluster_coords = coords_array[cluster_indices]\n",
    "            diameter = self.calculate_cluster_diameter_fast(cluster_coords)\n",
    "            return diameter > self.max_distance_km * 0.8  # More lenient for size\n",
    "        \n",
    "        # Diameter constraint\n",
    "        cluster_coords = coords_array[cluster_indices]\n",
    "        diameter = self.calculate_cluster_diameter_fast(cluster_coords)\n",
    "        \n",
    "        return diameter > self.max_distance_km\n",
    "    \n",
    "    def geographic_split(self, cluster_indices, coords_array):\n",
    "        \"\"\"\n",
    "        Improved geographic splitting with better load balancing.\n",
    "        \"\"\"\n",
    "        if len(cluster_indices) <= 2:\n",
    "            return [cluster_indices]\n",
    "        \n",
    "        cluster_coords = coords_array[cluster_indices]\n",
    "        n_points = len(cluster_coords)\n",
    "        \n",
    "        # For small clusters, use exact method\n",
    "        if n_points <= 50:\n",
    "            return self._exact_geographic_split(cluster_indices, cluster_coords)\n",
    "        \n",
    "        # For medium clusters, use K-means with geographic initialization\n",
    "        if n_points <= 200:\n",
    "            return self._kmeans_geographic_split(cluster_indices, cluster_coords)\n",
    "        \n",
    "        # For large clusters, use hierarchical approach\n",
    "        return self._hierarchical_geographic_split(cluster_indices, cluster_coords)\n",
    "    \n",
    "    def _exact_geographic_split(self, cluster_indices, cluster_coords):\n",
    "        \"\"\"Exact splitting for small clusters.\"\"\"\n",
    "        n_points = len(cluster_coords)\n",
    "        \n",
    "        # Find the two points that are farthest apart\n",
    "        distances = self.haversine_pdist(cluster_coords)\n",
    "        distance_matrix = squareform(distances)\n",
    "        max_idx = np.unravel_index(np.argmax(distance_matrix), distance_matrix.shape)\n",
    "        center1_idx, center2_idx = max_idx[0], max_idx[1]\n",
    "        \n",
    "        center1 = cluster_coords[center1_idx]\n",
    "        center2 = cluster_coords[center2_idx]\n",
    "        \n",
    "        # Assign points to closest center\n",
    "        distances_to_center1 = self.haversine_vectorized(cluster_coords, center1.reshape(1, -1))[:, 0]\n",
    "        distances_to_center2 = self.haversine_vectorized(cluster_coords, center2.reshape(1, -1))[:, 0]\n",
    "        \n",
    "        labels = (distances_to_center1 <= distances_to_center2).astype(int)\n",
    "        \n",
    "        return self._balance_split(cluster_indices, labels)\n",
    "    \n",
    "    def _kmeans_geographic_split(self, cluster_indices, cluster_coords):\n",
    "        \"\"\"K-means splitting with geographic initialization.\"\"\"\n",
    "        n_points = len(cluster_coords)\n",
    "        \n",
    "        # Initialize with farthest pair\n",
    "        center1_idx, center2_idx = self._find_approximate_farthest_pair(cluster_coords)\n",
    "        initial_centers = cluster_coords[[center1_idx, center2_idx]]\n",
    "        \n",
    "        # Apply K-means\n",
    "        kmeans = KMeans(n_clusters=2, init=initial_centers, n_init=1, random_state=42)\n",
    "        labels = kmeans.fit_predict(cluster_coords)\n",
    "        \n",
    "        return self._balance_split(cluster_indices, labels)\n",
    "    \n",
    "    def _hierarchical_geographic_split(self, cluster_indices, cluster_coords):\n",
    "        \"\"\"Hierarchical splitting for large clusters.\"\"\"\n",
    "        # Use linkage-based clustering for very large clusters\n",
    "        n_sample = min(100, len(cluster_coords))\n",
    "        sample_indices = np.random.choice(len(cluster_coords), n_sample, replace=False)\n",
    "        sample_coords = cluster_coords[sample_indices]\n",
    "        \n",
    "        # Compute linkage on sample\n",
    "        distances = self.haversine_pdist(sample_coords)\n",
    "        linkage_matrix = linkage(distances, method='ward')\n",
    "        sample_labels = fcluster(linkage_matrix, 2, criterion='maxclust') - 1\n",
    "        \n",
    "        # Assign all points based on closest sample point\n",
    "        center1_coords = sample_coords[sample_labels == 0]\n",
    "        center2_coords = sample_coords[sample_labels == 1]\n",
    "        \n",
    "        if len(center1_coords) == 0 or len(center2_coords) == 0:\n",
    "            # Fallback to farthest pair method\n",
    "            return self._exact_geographic_split(cluster_indices, cluster_coords)\n",
    "        \n",
    "        center1 = np.mean(center1_coords, axis=0)\n",
    "        center2 = np.mean(center2_coords, axis=0)\n",
    "        \n",
    "        distances_to_center1 = self.haversine_vectorized(cluster_coords, center1.reshape(1, -1))[:, 0]\n",
    "        distances_to_center2 = self.haversine_vectorized(cluster_coords, center2.reshape(1, -1))[:, 0]\n",
    "        \n",
    "        labels = (distances_to_center1 <= distances_to_center2).astype(int)\n",
    "        \n",
    "        return self._balance_split(cluster_indices, labels)\n",
    "    \n",
    "    def _balance_split(self, cluster_indices, labels):\n",
    "        \"\"\"Balance the split to avoid very uneven clusters.\"\"\"\n",
    "        cluster_0_indices = cluster_indices[labels == 0]\n",
    "        cluster_1_indices = cluster_indices[labels == 1]\n",
    "        \n",
    "        # Ensure no empty clusters\n",
    "        if len(cluster_0_indices) == 0:\n",
    "            cluster_0_indices = np.array([cluster_1_indices[0]])\n",
    "            cluster_1_indices = cluster_1_indices[1:]\n",
    "        elif len(cluster_1_indices) == 0:\n",
    "            cluster_1_indices = np.array([cluster_0_indices[0]])\n",
    "            cluster_0_indices = cluster_0_indices[1:]\n",
    "        \n",
    "        # Optional: Balance cluster sizes if one is much larger\n",
    "        if self.balance_clusters:\n",
    "            size_0, size_1 = len(cluster_0_indices), len(cluster_1_indices)\n",
    "            if size_0 > 3 * size_1 and size_1 > 0:\n",
    "                # Move some points from cluster 0 to cluster 1\n",
    "                n_move = (size_0 - size_1) // 4\n",
    "                move_indices = cluster_0_indices[:n_move]\n",
    "                cluster_0_indices = cluster_0_indices[n_move:]\n",
    "                cluster_1_indices = np.concatenate([cluster_1_indices, move_indices])\n",
    "            elif size_1 > 3 * size_0 and size_0 > 0:\n",
    "                # Move some points from cluster 1 to cluster 0\n",
    "                n_move = (size_1 - size_0) // 4\n",
    "                move_indices = cluster_1_indices[:n_move]\n",
    "                cluster_1_indices = cluster_1_indices[n_move:]\n",
    "                cluster_0_indices = np.concatenate([cluster_0_indices, move_indices])\n",
    "        \n",
    "        return [cluster_0_indices, cluster_1_indices]\n",
    "    \n",
    "    def _find_approximate_farthest_pair(self, coords):\n",
    "        \"\"\"Find approximate farthest pair for large clusters.\"\"\"\n",
    "        n_points = len(coords)\n",
    "        \n",
    "        if n_points <= 100:\n",
    "            # For moderate sizes, use exact calculation\n",
    "            distances = self.haversine_pdist(coords)\n",
    "            distance_matrix = squareform(distances)\n",
    "            max_idx = np.unravel_index(np.argmax(distance_matrix), distance_matrix.shape)\n",
    "            return max_idx[0], max_idx[1]\n",
    "        \n",
    "        # For large clusters, use sampling\n",
    "        sample_size = min(50, n_points)\n",
    "        sample_indices = np.random.choice(n_points, sample_size, replace=False)\n",
    "        sample_coords = coords[sample_indices]\n",
    "        \n",
    "        distances = self.haversine_pdist(sample_coords)\n",
    "        distance_matrix = squareform(distances)\n",
    "        max_idx = np.unravel_index(np.argmax(distance_matrix), distance_matrix.shape)\n",
    "        \n",
    "        return sample_indices[max_idx[0]], sample_indices[max_idx[1]]\n",
    "    \n",
    "    def divisive_clustering(self, customers_df):\n",
    "        \"\"\"Perform optimized divisive hierarchical clustering.\"\"\"\n",
    "        customers_df = customers_df.copy().reset_index(drop=True)\n",
    "        \n",
    "        # Validate input\n",
    "        if 'Latitude' not in customers_df.columns or 'Longitude' not in customers_df.columns:\n",
    "            raise ValueError(\"DataFrame must contain 'Latitude' and 'Longitude' columns\")\n",
    "        \n",
    "        coords_array = customers_df[['Latitude', 'Longitude']].values\n",
    "        n_customers = len(customers_df)\n",
    "        \n",
    "        if n_customers == 0:\n",
    "            customers_df['cluster'] = []\n",
    "            return customers_df\n",
    "        \n",
    "        if n_customers == 1:\n",
    "            customers_df['cluster'] = 1\n",
    "            return customers_df\n",
    "        \n",
    "        # Priority queue approach for better clustering\n",
    "        clusters_to_process = [(n_customers, np.arange(n_customers))]  # (size, indices)\n",
    "        final_clusters = []\n",
    "        \n",
    "        iteration_count = 0\n",
    "        max_iterations = n_customers * 2\n",
    "        \n",
    "        while clusters_to_process and iteration_count < max_iterations:\n",
    "            # Process largest cluster first\n",
    "            clusters_to_process.sort(key=lambda x: x[0], reverse=True)\n",
    "            current_size, current_cluster_indices = clusters_to_process.pop(0)\n",
    "            iteration_count += 1\n",
    "            \n",
    "            if self.should_split_cluster(current_cluster_indices, coords_array):\n",
    "                subclusters = self.geographic_split(current_cluster_indices, coords_array)\n",
    "                \n",
    "                for subcluster_indices in subclusters:\n",
    "                    if len(subcluster_indices) > 0:\n",
    "                        clusters_to_process.append((len(subcluster_indices), subcluster_indices))\n",
    "            else:\n",
    "                final_clusters.append(current_cluster_indices)\n",
    "        \n",
    "        # Handle remaining clusters\n",
    "        final_clusters.extend([indices for _, indices in clusters_to_process])\n",
    "        \n",
    "        # Create result DataFrame\n",
    "        result_df = customers_df.copy()\n",
    "        result_df['cluster'] = -1\n",
    "        \n",
    "        for cluster_id, cluster_indices in enumerate(final_clusters, 1):\n",
    "            result_df.loc[cluster_indices, 'cluster'] = cluster_id\n",
    "        \n",
    "        return result_df\n",
    "    \n",
    "    def get_cluster_stats(self, clustered_df):\n",
    "        \"\"\"Get comprehensive clustering statistics.\"\"\"\n",
    "        if 'cluster' not in clustered_df.columns:\n",
    "            raise ValueError(\"DataFrame must contain 'cluster' column\")\n",
    "        \n",
    "        stats = {}\n",
    "        cluster_sizes = []\n",
    "        cluster_diameters = []\n",
    "        \n",
    "        for cluster_id in clustered_df['cluster'].unique():\n",
    "            if cluster_id == -1:\n",
    "                continue\n",
    "                \n",
    "            cluster_data = clustered_df[clustered_df['cluster'] == cluster_id]\n",
    "            coords = cluster_data[['Latitude', 'Longitude']].values\n",
    "            \n",
    "            diameter = self.calculate_cluster_diameter_fast(coords)\n",
    "            cluster_sizes.append(len(cluster_data))\n",
    "            cluster_diameters.append(diameter)\n",
    "            \n",
    "            stats[cluster_id] = {\n",
    "                'size': len(cluster_data),\n",
    "                'diameter_km': diameter,\n",
    "                'centroid_lat': np.mean(coords[:, 0]),\n",
    "                'centroid_lon': np.mean(coords[:, 1]),\n",
    "                'meets_size_constraint': len(cluster_data) <= self.max_customers_per_cluster,\n",
    "                'meets_distance_constraint': diameter <= self.max_distance_km\n",
    "            }\n",
    "        \n",
    "        # Overall statistics\n",
    "        stats['summary'] = {\n",
    "            'total_clusters': len(stats) - 1,  # Excluding summary\n",
    "            'avg_cluster_size': np.mean(cluster_sizes),\n",
    "            'max_cluster_size': np.max(cluster_sizes),\n",
    "            'min_cluster_size': np.min(cluster_sizes),\n",
    "            'avg_diameter': np.mean(cluster_diameters),\n",
    "            'max_diameter': np.max(cluster_diameters),\n",
    "            'size_violations': sum(1 for size in cluster_sizes if size > self.max_customers_per_cluster),\n",
    "            'distance_violations': sum(1 for diameter in cluster_diameters if diameter > self.max_distance_km)\n",
    "        }\n",
    "        \n",
    "        return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d40e0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92b015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.cluster.hierarchy import fcluster, linkage\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from numba import jit, prange\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Fixed Enhanced Geographic Clustering\n",
    "class OptimizedDivisiveGeographicClustering_be:\n",
    "    def __init__(self, max_customers_per_cluster=20, max_distance_km=50, \n",
    "                 use_vectorized_distances=True, balance_clusters=False):\n",
    "        self.max_customers_per_cluster = max_customers_per_cluster\n",
    "        self.max_distance_km = max_distance_km\n",
    "        self.earth_radius_km = 6371.0\n",
    "        self.use_vectorized_distances = use_vectorized_distances\n",
    "        self.balance_clusters = balance_clusters\n",
    "        self._distance_cache = {}\n",
    "        \n",
    "    @staticmethod\n",
    "    @jit(nopython=True, fastmath=True, parallel=True)\n",
    "    def numba_haversine(coords1, coords2, radius):\n",
    "        \"\"\"JIT-optimized haversine distance calculation\"\"\"\n",
    "        n1 = coords1.shape[0]\n",
    "        n2 = coords2.shape[0] if coords2 is not None else n1\n",
    "        dists = np.empty((n1, n2), dtype=np.float64)\n",
    "        \n",
    "        for i in prange(n1):\n",
    "            lat1 = np.radians(coords1[i, 0])\n",
    "            lon1 = np.radians(coords1[i, 1])\n",
    "            \n",
    "            for j in range(n2):\n",
    "                if coords2 is None:\n",
    "                    lat2 = np.radians(coords1[j, 0])\n",
    "                    lon2 = np.radians(coords1[j, 1])\n",
    "                else:\n",
    "                    lat2 = np.radians(coords2[j, 0])\n",
    "                    lon2 = np.radians(coords2[j, 1])\n",
    "                    \n",
    "                dlat = lat2 - lat1\n",
    "                dlon = lon2 - lon1\n",
    "                \n",
    "                a = (np.sin(dlat/2)**2 + \n",
    "                     np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2)**2)\n",
    "                c = 2 * np.arcsin(np.sqrt(min(1.0, a)))\n",
    "                dists[i, j] = radius * c\n",
    "                \n",
    "        return dists\n",
    "\n",
    "    def haversine_vectorized(self, coords1, coords2=None, use_cache=False):\n",
    "        \"\"\"Optimized distance calculation with caching and Numba acceleration\"\"\"\n",
    "        cache_key = None\n",
    "        if use_cache and coords2 is None:\n",
    "            cache_key = tuple(map(tuple, coords1))\n",
    "            if cache_key in self._distance_cache:\n",
    "                return self._distance_cache[cache_key]\n",
    "        \n",
    "        if coords1.size < 500:  # Use Numba for smaller datasets\n",
    "            result = self.numba_haversine(coords1, coords2, self.earth_radius_km)\n",
    "        else:\n",
    "            # Use vectorized calculation for larger datasets\n",
    "            if coords2 is None:\n",
    "                coords_rad = np.radians(coords1)\n",
    "                lat = coords_rad[:, 0]\n",
    "                lon = coords_rad[:, 1]\n",
    "                dlat = lat[:, None] - lat\n",
    "                dlon = lon[:, None] - lon\n",
    "                \n",
    "                a = (np.sin(dlat/2)**2 + \n",
    "                     np.cos(lat[:, None]) * np.cos(lat) * np.sin(dlon/2)**2)\n",
    "            else:\n",
    "                coords1_rad = np.radians(coords1)\n",
    "                coords2_rad = np.radians(coords2)\n",
    "                dlat = coords1_rad[:, 0, None] - coords2_rad[:, 0]\n",
    "                dlon = coords1_rad[:, 1, None] - coords2_rad[:, 1]\n",
    "                \n",
    "                a = (np.sin(dlat/2)**2 + \n",
    "                     np.cos(coords1_rad[:, 0, None]) * \n",
    "                     np.cos(coords2_rad[:, 0]) * \n",
    "                     np.sin(dlon/2)**2)\n",
    "            \n",
    "            result = self.earth_radius_km * 2 * np.arcsin(np.sqrt(np.clip(a, 0, 1)))\n",
    "        \n",
    "        if cache_key is not None:\n",
    "            self._distance_cache[cache_key] = result\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    def haversine_single_pair(self, coord1, coord2):\n",
    "        \"\"\"Calculate haversine distance between two points.\"\"\"\n",
    "        lat1, lon1 = np.radians(coord1)\n",
    "        lat2, lon2 = np.radians(coord2)\n",
    "        \n",
    "        dlat = lat2 - lat1\n",
    "        dlon = lon2 - lon1\n",
    "        \n",
    "        a = (np.sin(dlat / 2) ** 2 + \n",
    "             np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2)\n",
    "        c = 2 * np.arcsin(np.sqrt(np.clip(a, 0, 1)))\n",
    "        \n",
    "        return self.earth_radius_km * c \n",
    "\n",
    "    def haversine_pdist(self, coords):\n",
    "        \"\"\"Calculate pairwise distances using scipy format\"\"\"\n",
    "        n = len(coords)\n",
    "        distances = []\n",
    "        for i in range(n):\n",
    "            for j in range(i + 1, n):\n",
    "                dist = self.haversine_single_pair(coords[i], coords[j])\n",
    "                distances.append(dist)\n",
    "        return np.array(distances)\n",
    "\n",
    "    def calculate_cluster_diameter_fast(self, coords):\n",
    "        \"\"\"Optimized diameter calculation with adaptive strategy\"\"\"\n",
    "        n = len(coords)\n",
    "        if n <= 1: \n",
    "            return 0\n",
    "        if n == 2:\n",
    "            return self.haversine_single_pair(coords[0], coords[1])\n",
    "        \n",
    "        # Use convex hull approximation for medium clusters\n",
    "        if n <= 100:\n",
    "            return self._convex_hull_diameter(coords)\n",
    "            \n",
    "        # Use grid-based sampling for large clusters\n",
    "        return self._grid_based_diameter(coords)\n",
    "\n",
    "    def _convex_hull_diameter(self, coords):\n",
    "        \"\"\"Calculate diameter using convex hull approximation\"\"\"\n",
    "        try:\n",
    "            from scipy.spatial import ConvexHull\n",
    "            if len(coords) < 3:\n",
    "                return max(self.haversine_single_pair(coords[i], coords[j]) \n",
    "                          for i in range(len(coords)) for j in range(i+1, len(coords)))\n",
    "            \n",
    "            hull = ConvexHull(coords)\n",
    "            hull_points = coords[hull.vertices]\n",
    "            \n",
    "            max_distance = 0\n",
    "            for i in range(len(hull_points)):\n",
    "                for j in range(i + 1, len(hull_points)):\n",
    "                    distance = self.haversine_single_pair(hull_points[i], hull_points[j])\n",
    "                    max_distance = max(max_distance, distance)\n",
    "            \n",
    "            return max_distance\n",
    "        except:\n",
    "            # Fallback to brute force for small clusters\n",
    "            return self._brute_force_diameter(coords)\n",
    "\n",
    "    def _grid_based_diameter(self, coords):\n",
    "        \"\"\"Use grid-based sampling for large clusters\"\"\"\n",
    "        n_sample = min(50, len(coords))\n",
    "        sample_indices = np.random.choice(len(coords), n_sample, replace=False)\n",
    "        sample_coords = coords[sample_indices]\n",
    "        return self._brute_force_diameter(sample_coords)\n",
    "\n",
    "    def _brute_force_diameter(self, coords):\n",
    "        \"\"\"Calculate exact diameter using brute force\"\"\"\n",
    "        max_distance = 0\n",
    "        n = len(coords)\n",
    "        for i in range(n):\n",
    "            for j in range(i + 1, n):\n",
    "                distance = self.haversine_single_pair(coords[i], coords[j])\n",
    "                max_distance = max(max_distance, distance)\n",
    "        return max_distance\n",
    "\n",
    "    def should_split_cluster(self, cluster_indices, coords_array):\n",
    "        \"\"\"Determine if a cluster should be split\"\"\"\n",
    "        n_points = len(cluster_indices)\n",
    "        \n",
    "        # Size constraint\n",
    "        if n_points <= self.max_customers_per_cluster:\n",
    "            return False\n",
    "        \n",
    "        # Distance constraint\n",
    "        cluster_coords = coords_array[cluster_indices]\n",
    "        diameter = self.calculate_cluster_diameter_fast(cluster_coords)\n",
    "        \n",
    "        if diameter <= self.max_distance_km:\n",
    "            return False\n",
    "            \n",
    "        return True\n",
    "\n",
    "    def geographic_split(self, cluster_indices, coords_array):\n",
    "        \"\"\"Enhanced splitting with DBSCAN for outlier handling\"\"\"\n",
    "        n_points = len(cluster_indices)\n",
    "        if n_points <= 2:\n",
    "            return [cluster_indices]\n",
    "            \n",
    "        cluster_coords = coords_array[cluster_indices]\n",
    "        \n",
    "        # Handle outliers with DBSCAN for large clusters\n",
    "        if n_points > 100:\n",
    "            try:\n",
    "                # Create distance matrix for DBSCAN\n",
    "                distances = self.haversine_vectorized(cluster_coords)\n",
    "                dbscan = DBSCAN(eps=self.max_distance_km/2, min_samples=3, \n",
    "                               metric='precomputed')\n",
    "                labels = dbscan.fit_predict(distances)\n",
    "                \n",
    "                if len(np.unique(labels[labels != -1])) > 1:\n",
    "                    return self._balance_split(cluster_indices, labels)\n",
    "            except:\n",
    "                pass  # Fall back to other methods\n",
    "        \n",
    "        # Small clusters: exact method\n",
    "        if n_points <= 50:\n",
    "            return self._exact_geographic_split(cluster_indices, cluster_coords)\n",
    "            \n",
    "        # Medium clusters: k-means with improved initialization\n",
    "        if n_points <= 200:\n",
    "            return self._kmeans_geographic_split(cluster_indices, cluster_coords)\n",
    "            \n",
    "        # Large clusters: hierarchical with complete linkage\n",
    "        return self._hierarchical_geographic_split(cluster_indices, cluster_coords)\n",
    "\n",
    "    def _exact_geographic_split(self, cluster_indices, cluster_coords):\n",
    "        \"\"\"Exact splitting for small clusters\"\"\"\n",
    "        if len(cluster_coords) <= 2:\n",
    "            return [cluster_indices]\n",
    "        \n",
    "        # Find the two points that are farthest apart\n",
    "        max_distance = 0\n",
    "        best_pair = (0, 1)\n",
    "        \n",
    "        for i in range(len(cluster_coords)):\n",
    "            for j in range(i + 1, len(cluster_coords)):\n",
    "                distance = self.haversine_single_pair(cluster_coords[i], cluster_coords[j])\n",
    "                if distance > max_distance:\n",
    "                    max_distance = distance\n",
    "                    best_pair = (i, j)\n",
    "        \n",
    "        # Assign points to the closer of the two centers\n",
    "        center1 = cluster_coords[best_pair[0]]\n",
    "        center2 = cluster_coords[best_pair[1]]\n",
    "        \n",
    "        labels = np.zeros(len(cluster_coords))\n",
    "        for i, coord in enumerate(cluster_coords):\n",
    "            dist1 = self.haversine_single_pair(coord, center1)\n",
    "            dist2 = self.haversine_single_pair(coord, center2)\n",
    "            labels[i] = 0 if dist1 <= dist2 else 1\n",
    "        \n",
    "        return self._balance_split(cluster_indices, labels)\n",
    "\n",
    "    def _kmeans_geographic_split(self, cluster_indices, cluster_coords):\n",
    "        \"\"\"K-means splitting for medium clusters\"\"\"\n",
    "        try:\n",
    "            # Use geographic coordinates directly for K-means\n",
    "            kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "            labels = kmeans.fit_predict(cluster_coords)\n",
    "            return self._balance_split(cluster_indices, labels)\n",
    "        except:\n",
    "            # Fallback to exact method\n",
    "            return self._exact_geographic_split(cluster_indices, cluster_coords)\n",
    "\n",
    "    def _hierarchical_geographic_split(self, cluster_indices, cluster_coords):\n",
    "        \"\"\"Improved hierarchical splitting with complete linkage\"\"\"\n",
    "        n_sample = min(150, len(cluster_coords))\n",
    "        sample_indices = np.random.choice(len(cluster_coords), n_sample, replace=False)\n",
    "        sample_coords = cluster_coords[sample_indices]\n",
    "        \n",
    "        distances = self.haversine_pdist(sample_coords)\n",
    "        linkage_matrix = linkage(distances, method='complete')\n",
    "        sample_labels = fcluster(linkage_matrix, 2, criterion='maxclust') - 1\n",
    "        \n",
    "        # Assign based on nearest cluster center\n",
    "        center1 = np.mean(sample_coords[sample_labels == 0], axis=0)\n",
    "        center2 = np.mean(sample_coords[sample_labels == 1], axis=0)\n",
    "        \n",
    "        dist_to_center1 = self.haversine_vectorized(cluster_coords, center1.reshape(1, -1))[:, 0]\n",
    "        dist_to_center2 = self.haversine_vectorized(cluster_coords, center2.reshape(1, -1))[:, 0]\n",
    "        labels = (dist_to_center1 <= dist_to_center2).astype(int)\n",
    "        \n",
    "        return self._balance_split(cluster_indices, labels)\n",
    "\n",
    "    def _balance_split(self, cluster_indices, labels):\n",
    "        \"\"\"Proximity-based balancing for spatial coherence\"\"\"\n",
    "        unique_labels = np.unique(labels)\n",
    "        if len(unique_labels) == 1:\n",
    "            # All points have same label, split arbitrarily\n",
    "            mid = len(cluster_indices) // 2\n",
    "            return [cluster_indices[:mid], cluster_indices[mid:]]\n",
    "        \n",
    "        # Handle noise points from DBSCAN (label -1)\n",
    "        if -1 in unique_labels:\n",
    "            noise_mask = labels == -1\n",
    "            valid_labels = labels[~noise_mask]\n",
    "            if len(np.unique(valid_labels)) == 0:\n",
    "                return [cluster_indices]\n",
    "            \n",
    "            # Assign noise points to nearest valid cluster\n",
    "            for i in np.where(noise_mask)[0]:\n",
    "                # Find nearest non-noise point\n",
    "                distances = []\n",
    "                for j in np.where(~noise_mask)[0]:\n",
    "                    dist = self.haversine_single_pair(\n",
    "                        self.full_coords_array[cluster_indices[i]], \n",
    "                        self.full_coords_array[cluster_indices[j]]\n",
    "                    )\n",
    "                    distances.append((dist, labels[j]))\n",
    "                \n",
    "                if distances:\n",
    "                    labels[i] = min(distances, key=lambda x: x[0])[1]\n",
    "        \n",
    "        # Create clusters based on labels\n",
    "        clusters = []\n",
    "        for label in np.unique(labels):\n",
    "            if label != -1:  # Skip noise label\n",
    "                cluster_mask = labels == label\n",
    "                cluster = cluster_indices[cluster_mask]\n",
    "                if len(cluster) > 0:\n",
    "                    clusters.append(cluster)\n",
    "        \n",
    "        if len(clusters) == 0:\n",
    "            return [cluster_indices]\n",
    "        elif len(clusters) == 1:\n",
    "            # Split the single cluster arbitrarily\n",
    "            cluster = clusters[0]\n",
    "            mid = len(cluster) // 2\n",
    "            return [cluster[:mid], cluster[mid:]]\n",
    "        else:\n",
    "            # Balance clusters if enabled\n",
    "            if self.balance_clusters and len(clusters) == 2:\n",
    "                return self._balance_two_clusters(clusters[0], clusters[1])\n",
    "            return clusters\n",
    "\n",
    "    def _balance_two_clusters(self, cluster_0, cluster_1):\n",
    "        \"\"\"Balance two clusters by size\"\"\"\n",
    "        size0, size1 = len(cluster_0), len(cluster_1)\n",
    "        \n",
    "        if size0 <= 2 * size1 and size1 <= 2 * size0:\n",
    "            return [cluster_0, cluster_1]\n",
    "        \n",
    "        coords0 = self.full_coords_array[cluster_0]\n",
    "        coords1 = self.full_coords_array[cluster_1]\n",
    "        \n",
    "        # Balance only when size difference is significant\n",
    "        if size0 > 2 * size1:\n",
    "            center1 = np.mean(coords1, axis=0)\n",
    "            dist_to_center1 = self.haversine_vectorized(coords0, center1.reshape(1, -1))[:, 0]\n",
    "            n_move = min((size0 - size1) // 2, max(1, size1))\n",
    "            move_idx = np.argsort(dist_to_center1)[:n_move]\n",
    "            cluster_1 = np.concatenate([cluster_1, cluster_0[move_idx]])\n",
    "            cluster_0 = np.delete(cluster_0, move_idx)\n",
    "            \n",
    "        elif size1 > 2 * size0:\n",
    "            center0 = np.mean(coords0, axis=0)\n",
    "            dist_to_center0 = self.haversine_vectorized(coords1, center0.reshape(1, -1))[:, 0]\n",
    "            n_move = min((size1 - size0) // 2, max(1, size0))\n",
    "            move_idx = np.argsort(dist_to_center0)[:n_move]\n",
    "            cluster_0 = np.concatenate([cluster_0, cluster_1[move_idx]])\n",
    "            cluster_1 = np.delete(cluster_1, move_idx)\n",
    "            \n",
    "        return [cluster_0, cluster_1]\n",
    "\n",
    "    def divisive_clustering(self, customers_df):\n",
    "        \"\"\"Main clustering with cache management\"\"\" \n",
    "        customers_df = customers_df.copy().reset_index(drop=True)\n",
    "        \n",
    "        # Validate input\n",
    "        if 'Latitude' not in customers_df.columns or 'Longitude' not in customers_df.columns:\n",
    "            raise ValueError(\"DataFrame must contain 'Latitude' and 'Longitude' columns\")\n",
    "        \n",
    "        coords_array = customers_df[['Latitude', 'Longitude']].values\n",
    "        n_customers = len(customers_df)\n",
    "        \n",
    "        self.full_coords_array = coords_array\n",
    "        self._distance_cache = {}  # Reset cache\n",
    "        \n",
    "        if n_customers == 0:\n",
    "            customers_df['cluster'] = []\n",
    "            return customers_df\n",
    "        \n",
    "        if n_customers == 1:\n",
    "            customers_df['cluster'] = 1\n",
    "            return customers_df\n",
    "        \n",
    "        # Priority queue approach for better clustering\n",
    "        clusters_to_process = [(n_customers, np.arange(n_customers))]  # (size, indices)\n",
    "        final_clusters = []\n",
    "        \n",
    "        iteration_count = 0\n",
    "        max_iterations = n_customers * 2\n",
    "        \n",
    "        while clusters_to_process and iteration_count < max_iterations:\n",
    "            # Process largest cluster first\n",
    "            clusters_to_process.sort(key=lambda x: x[0], reverse=True)\n",
    "            current_size, current_cluster_indices = clusters_to_process.pop(0)\n",
    "            iteration_count += 1\n",
    "            \n",
    "            if self.should_split_cluster(current_cluster_indices, coords_array):\n",
    "                subclusters = self.geographic_split(current_cluster_indices, coords_array)\n",
    "                \n",
    "                for subcluster_indices in subclusters:\n",
    "                    if len(subcluster_indices) > 0:\n",
    "                        clusters_to_process.append((len(subcluster_indices), subcluster_indices))\n",
    "            else:\n",
    "                final_clusters.append(current_cluster_indices)\n",
    "        \n",
    "        # Handle remaining clusters\n",
    "        final_clusters.extend([indices for _, indices in clusters_to_process])\n",
    "        \n",
    "        # Create result DataFrame\n",
    "        result_df = customers_df.copy()\n",
    "        result_df['cluster'] = -1\n",
    "        \n",
    "        for cluster_id, cluster_indices in enumerate(final_clusters, 1):\n",
    "            result_df.loc[cluster_indices, 'cluster'] = cluster_id\n",
    "        \n",
    "        # Clean up stored data\n",
    "        if hasattr(self, 'full_coords_array'):\n",
    "            del self.full_coords_array\n",
    "        self._distance_cache = {}\n",
    "\n",
    "        return result_df\n",
    "    \n",
    "    def get_cluster_stats(self, clustered_df):\n",
    "        \"\"\"Get comprehensive clustering statistics.\"\"\"\n",
    "        if 'cluster' not in clustered_df.columns:\n",
    "            raise ValueError(\"DataFrame must contain 'cluster' column\")\n",
    "        \n",
    "        stats = {}\n",
    "        cluster_sizes = []\n",
    "        cluster_diameters = []\n",
    "        \n",
    "        for cluster_id in clustered_df['cluster'].unique():\n",
    "            if cluster_id == -1:\n",
    "                continue\n",
    "                \n",
    "            cluster_data = clustered_df[clustered_df['cluster'] == cluster_id]\n",
    "            coords = cluster_data[['Latitude', 'Longitude']].values\n",
    "            \n",
    "            diameter = self.calculate_cluster_diameter_fast(coords)\n",
    "            cluster_sizes.append(len(cluster_data))\n",
    "            cluster_diameters.append(diameter)\n",
    "            \n",
    "            stats[cluster_id] = {\n",
    "                'size': len(cluster_data),\n",
    "                'diameter_km': diameter,\n",
    "                'centroid_lat': np.mean(coords[:, 0]),\n",
    "                'centroid_lon': np.mean(coords[:, 1]),\n",
    "                'meets_size_constraint': len(cluster_data) <= self.max_customers_per_cluster,\n",
    "                'meets_distance_constraint': diameter <= self.max_distance_km\n",
    "            }\n",
    "        \n",
    "        # Overall statistics\n",
    "        if cluster_sizes:  # Only calculate if there are clusters\n",
    "            stats['summary'] = {\n",
    "                'total_clusters': len(stats) - 1,  # Excluding summary key\n",
    "                'avg_cluster_size': np.mean(cluster_sizes),\n",
    "                'max_cluster_size': np.max(cluster_sizes),\n",
    "                'min_cluster_size': np.min(cluster_sizes),\n",
    "                'avg_diameter': np.mean(cluster_diameters),\n",
    "                'max_diameter': np.max(cluster_diameters),\n",
    "                'size_violations': sum(1 for size in cluster_sizes if size > self.max_customers_per_cluster),\n",
    "                'distance_violations': sum(1 for diameter in cluster_diameters if diameter > self.max_distance_km)\n",
    "            }\n",
    "        else:\n",
    "            stats['summary'] = {\n",
    "                'total_clusters': 0,\n",
    "                'avg_cluster_size': 0,\n",
    "                'max_cluster_size': 0,\n",
    "                'min_cluster_size': 0,\n",
    "                'avg_diameter': 0,\n",
    "                'max_diameter': 0,\n",
    "                'size_violations': 0,\n",
    "                'distance_violations': 0\n",
    "            }\n",
    "        \n",
    "        return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98368b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import numba\n",
    "\n",
    "### Fastest\n",
    "class OptimizedDivisiveGeographicClustering_fast:\n",
    "    def __init__(self, max_customers_per_cluster=20, max_distance_km=50):\n",
    "        self.max_customers_per_cluster = max_customers_per_cluster\n",
    "        self.max_distance_km = max_distance_km\n",
    "        self.earth_radius_km = 6371.0\n",
    "\n",
    "    @staticmethod\n",
    "    @numba.njit(fastmath=True)\n",
    "    def haversine_single_pair(lat1, lon1, lat2, lon2):\n",
    "        \"\"\"Numba-optimized haversine distance between two points.\"\"\"\n",
    "        lat1, lon1, lat2, lon2 = np.radians([lat1, lon1, lat2, lon2])\n",
    "        dlat = lat2 - lat1\n",
    "        dlon = lon2 - lon1\n",
    "        a = np.sin(dlat/2)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2)**2\n",
    "        return 6371.0 * 2 * np.arcsin(np.sqrt(min(1.0, a)))\n",
    "    \n",
    "    @staticmethod\n",
    "    @numba.njit(fastmath=True, parallel=True)\n",
    "    def haversine_vectorized(coord, coords):\n",
    "        \"\"\"Vectorized haversine distance from one point to many.\"\"\"\n",
    "        lat1, lon1 = np.radians(coord)\n",
    "        dists = np.empty(coords.shape[0])\n",
    "        for i in numba.prange(coords.shape[0]):\n",
    "            lat2, lon2 = np.radians(coords[i])\n",
    "            dlat = lat2 - lat1\n",
    "            dlon = lon2 - lon1\n",
    "            a = np.sin(dlat/2)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2)**2\n",
    "            dists[i] = 6371.0 * 2 * np.arcsin(np.sqrt(min(1.0, a)))\n",
    "        return dists\n",
    "\n",
    "    def compute_diameter_and_farthest_pair(self, coords):\n",
    "        \"\"\"Compute diameter and farthest pair with optimal strategy.\"\"\"\n",
    "        n = len(coords)\n",
    "        if n <= 100:  # Exact for small clusters\n",
    "            dists = self.haversine_pdist(coords)\n",
    "            dist_matrix = squareform(dists)\n",
    "            max_idx = np.unravel_index(np.argmax(dist_matrix), dist_matrix.shape)\n",
    "            return dist_matrix[max_idx], max_idx\n",
    "        else:  # Approximate for large clusters\n",
    "            return self._two_pass_approximation(coords)\n",
    "\n",
    "    def _two_pass_approximation(self, coords):\n",
    "        \"\"\"Two-pass algorithm for approximate diameter and farthest pair.\"\"\"\n",
    "        # First pass: random point to farthest point\n",
    "        idx0 = np.random.randint(len(coords))\n",
    "        dists = self.haversine_vectorized(coords[idx0], coords)\n",
    "        idx1 = np.argmax(dists)\n",
    "        \n",
    "        # Second pass: farthest point to its farthest point\n",
    "        dists = self.haversine_vectorized(coords[idx1], coords)\n",
    "        idx2 = np.argmax(dists)\n",
    "        diameter = dists[idx2]\n",
    "        \n",
    "        return diameter, (idx1, idx2)\n",
    "\n",
    "    def haversine_pdist(self, coords):\n",
    "        \"\"\"Optimized haversine pairwise distances using vectorization.\"\"\"\n",
    "        n = coords.shape[0]\n",
    "        dists = np.zeros(n*(n-1)//2)\n",
    "        k = 0\n",
    "        for i in range(n):\n",
    "            dists_i = self.haversine_vectorized(coords[i], coords[i+1:])\n",
    "            dists[k:k+len(dists_i)] = dists_i\n",
    "            k += len(dists_i)\n",
    "        return dists\n",
    "\n",
    "    def should_split_cluster(self, cluster_indices, coords_array):\n",
    "        \"\"\"Determine if cluster should be split with early termination.\"\"\"\n",
    "        cluster_size = len(cluster_indices)\n",
    "        \n",
    "        if cluster_size <= 1:\n",
    "            return False, None\n",
    "            \n",
    "        if cluster_size > self.max_customers_per_cluster:\n",
    "            return True, None  # Size violation\n",
    "        \n",
    "        # Check diameter constraint\n",
    "        cluster_coords = coords_array[cluster_indices]\n",
    "        diameter, farthest_pair = self.compute_diameter_and_farthest_pair(cluster_coords)\n",
    "        return diameter > self.max_distance_km, farthest_pair\n",
    "\n",
    "    def geographic_split(self, cluster_indices, coords_array, farthest_pair=None):\n",
    "        \"\"\"Efficient cluster splitting with optional precomputed centers.\"\"\"\n",
    "        cluster_coords = coords_array[cluster_indices]\n",
    "        n = len(cluster_coords)\n",
    "        \n",
    "        # Get or compute farthest pair\n",
    "        if farthest_pair is None:\n",
    "            if n <= 100:\n",
    "                _, farthest_pair = self.compute_diameter_and_farthest_pair(cluster_coords)\n",
    "            else:\n",
    "                _, farthest_pair = self._two_pass_approximation(cluster_coords)\n",
    "        \n",
    "        center1_idx, center2_idx = farthest_pair\n",
    "        center1 = cluster_coords[center1_idx]\n",
    "        center2 = cluster_coords[center2_idx]\n",
    "        \n",
    "        # Vectorized distance calculations\n",
    "        dists1 = self.haversine_vectorized(center1, cluster_coords)\n",
    "        dists2 = self.haversine_vectorized(center2, cluster_coords)\n",
    "        labels = (dists1 <= dists2).astype(int)\n",
    "        \n",
    "        # Create subclusters\n",
    "        mask = labels.astype(bool)\n",
    "        cluster_a = cluster_indices[mask]\n",
    "        cluster_b = cluster_indices[~mask]\n",
    "        \n",
    "        # Balance clusters if needed\n",
    "        if len(cluster_a) == 0 or len(cluster_b) == 0:\n",
    "            return self._split_fallback(cluster_indices, cluster_coords)\n",
    "            \n",
    "        return [cluster_a, cluster_b]\n",
    "\n",
    "    def _split_fallback(self, cluster_indices, cluster_coords):\n",
    "        \"\"\"Fallback split when primary method fails.\"\"\"\n",
    "        # Use longitude-based split as fallback\n",
    "        sorted_idx = np.argsort(cluster_coords[:, 1])\n",
    "        mid = len(sorted_idx) // 2\n",
    "        return [\n",
    "            cluster_indices[sorted_idx[:mid]],\n",
    "            cluster_indices[sorted_idx[mid:]]\n",
    "        ]\n",
    "\n",
    "    def divisive_clustering(self, customers_df):\n",
    "        \"\"\"Optimized divisive clustering with efficient diameter checks.\"\"\"\n",
    "        # Initialization and validation\n",
    "        if 'Latitude' not in customers_df or 'Longitude' not in customers_df:\n",
    "            raise ValueError(\"Missing Latitude/Longitude columns\")\n",
    "            \n",
    "        coords_array = customers_df[['Latitude', 'Longitude']].values\n",
    "        n = len(customers_df)\n",
    "        \n",
    "        # Edge cases\n",
    "        if n == 0:\n",
    "            return customers_df.assign(cluster=pd.Series(dtype=int))\n",
    "        if n == 1:\n",
    "            return customers_df.assign(cluster=1)\n",
    "        \n",
    "        # Initialize clustering\n",
    "        clusters_to_process = [np.arange(n)]\n",
    "        final_clusters = []\n",
    "        \n",
    "        # Process clusters\n",
    "        while clusters_to_process:\n",
    "            current = clusters_to_process.pop(0)\n",
    "            should_split, farthest_pair = self.should_split_cluster(current, coords_array)\n",
    "            \n",
    "            if should_split:\n",
    "                subclusters = self.geographic_split(\n",
    "                    current, coords_array, farthest_pair\n",
    "                )\n",
    "                clusters_to_process.extend(subclusters)\n",
    "            else:\n",
    "                final_clusters.append(current)\n",
    "        \n",
    "        # Assign cluster labels\n",
    "        cluster_labels = np.zeros(n, dtype=int)\n",
    "        for idx, cluster in enumerate(final_clusters, 1):\n",
    "            cluster_labels[cluster] = idx\n",
    "            \n",
    "        return customers_df.assign(cluster=cluster_labels)\n",
    "\n",
    "    def get_cluster_stats(self, clustered_df):\n",
    "        \"\"\"Get comprehensive clustering statistics.\"\"\"\n",
    "        if 'cluster' not in clustered_df.columns:\n",
    "            raise ValueError(\"DataFrame must contain 'cluster' column\")\n",
    "        \n",
    "        stats = {}\n",
    "        cluster_sizes = []\n",
    "        cluster_diameters = []\n",
    "        \n",
    "        for cluster_id in clustered_df['cluster'].unique():\n",
    "            if cluster_id == -1:\n",
    "                continue\n",
    "                \n",
    "            cluster_data = clustered_df[clustered_df['cluster'] == cluster_id]\n",
    "            coords = cluster_data[['Latitude', 'Longitude']].values\n",
    "            n_points = len(coords)\n",
    "            \n",
    "            # Handle diameter calculation efficiently\n",
    "            if n_points == 0:\n",
    "                diameter = 0.0\n",
    "            elif n_points == 1:\n",
    "                diameter = 0.0\n",
    "            else:\n",
    "                diameter, _ = self.compute_diameter_and_farthest_pair(coords)\n",
    "            \n",
    "            cluster_sizes.append(n_points)\n",
    "            cluster_diameters.append(diameter)\n",
    "            \n",
    "            stats[cluster_id] = {\n",
    "                'size': n_points,\n",
    "                'diameter_km': diameter,\n",
    "                'centroid_lat': np.mean(coords[:, 0]) if n_points > 0 else None,\n",
    "                'centroid_lon': np.mean(coords[:, 1]) if n_points > 0 else None,\n",
    "                'meets_size_constraint': n_points <= self.max_customers_per_cluster,\n",
    "                'meets_distance_constraint': diameter <= self.max_distance_km\n",
    "            }\n",
    "        \n",
    "        # Calculate overall statistics\n",
    "        total_clusters = len(stats)\n",
    "        size_violations = sum(1 for size in cluster_sizes if size > self.max_customers_per_cluster)\n",
    "        distance_violations = sum(1 for d in cluster_diameters if d > self.max_distance_km)\n",
    "        \n",
    "        # Handle empty case\n",
    "        summary = {\n",
    "            'total_clusters': total_clusters,\n",
    "            'size_violations': size_violations,\n",
    "            'distance_violations': distance_violations,\n",
    "        }\n",
    "        \n",
    "        # Add statistical measures only if clusters exist\n",
    "        if cluster_sizes:\n",
    "            summary.update({\n",
    "                'avg_cluster_size': np.mean(cluster_sizes),\n",
    "                'max_cluster_size': np.max(cluster_sizes),\n",
    "                'min_cluster_size': np.min(cluster_sizes),\n",
    "                'avg_diameter': np.mean(cluster_diameters),\n",
    "                'max_diameter': np.max(cluster_diameters),\n",
    "            })\n",
    "        else:\n",
    "            summary.update({\n",
    "                'avg_cluster_size': 0,\n",
    "                'max_cluster_size': 0,\n",
    "                'min_cluster_size': 0,\n",
    "                'avg_diameter': 0,\n",
    "                'max_diameter': 0,\n",
    "            })\n",
    "        \n",
    "        stats['summary'] = summary\n",
    "        return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f978e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2. DIVISIVE HIERARCHICAL CLUSTERING\n",
    "# =============================================================================\n",
    "\n",
    "from clustering.divisive_clustering import DivisiveGeographicClustering, OptimizedDivisiveGeographicClustering\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"2. DIVISIVE HIERARCHICAL CLUSTERING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# divisive_clusterer = OptimizedDivisiveGeographicClustering( # Rivers: Too Long --\n",
    "#     max_customers_per_cluster=20,  # REQUIRED\n",
    "#     max_distance_km=5            # REQUIRED  \n",
    "# ) \n",
    "\n",
    "divisive_clusterer = OptimizedDivisiveGeographicClustering_b( \n",
    "    # Rivers: Divisive clusters created: 48 || Silhouette Score: 0.54 || Constraint violations: Size=6, Distance=3\n",
    "    max_customers_per_cluster=20,  # REQUIRED\n",
    "    max_distance_km=5            # REQUIRED\n",
    "    ,use_vectorized_distances=True, balance_clusters=False\n",
    ")\n",
    "\n",
    "# divisive_clusterer = OptimizedDivisiveGeographicClustering_be( \n",
    "#     # Rivers: Divisive clusters created: 26 || Silhouette Score: 0.57 || Constraint violations: Size=9, Distance=6\n",
    "#     max_customers_per_cluster=20,  # REQUIRED\n",
    "#     max_distance_km=10            # REQUIRED\n",
    "#     ,use_vectorized_distances=True, balance_clusters=False\n",
    "# )\n",
    "\n",
    "# divisive_clusterer = OptimizedDivisiveGeographicClustering_bo( \n",
    "# # Rivers: Divisive clusters created: 60 || Silhouette Score: 0.58 || Constraint violations: Size=9, Distance=7\n",
    "#     max_customers_per_cluster=20,  # REQUIRED\n",
    "#     max_distance_km=5            # REQUIRED \n",
    "# ) \n",
    "\n",
    "# divisive_clusterer = OptimizedDivisiveGeographicClustering_fast(\n",
    "#     # Rivers: Divisive clusters created: 63 || Silhouette Score: 0.46 || Constraint violations: Size=0, Distance=0\n",
    "#     max_customers_per_cluster=20,  # REQUIRED\n",
    "#     max_distance_km=5            # REQUIRED\n",
    "# )\n",
    "\n",
    "# divisive_clusterer = OptimizedDivisiveGeographicClustering_Main( \n",
    "#     # Rivers: Divisive clusters created: 69 ||Silhouette Score: 0.41\n",
    "#     max_customers_per_cluster=20,  # REQUIRED\n",
    "#     max_distance_km=5            # REQUIRED \n",
    "# ) \n",
    "\n",
    "divisive_result = divisive_clusterer.divisive_clustering(df_all_cluster.copy())\n",
    "print(f\"\\nDivisive clusters created: {divisive_result['cluster'].nunique()}\")\n",
    "# print(f\"Cluster sizes: {divisive_result['cluster'].value_counts().sort_index().head()}\")\n",
    "_ = evaluate_unsupervised_clustering(divisive_result)\n",
    "\n",
    "# # Get detailed statistics\n",
    "stats = divisive_clusterer.get_cluster_stats(divisive_result)\n",
    "print(f\"Total clusters: {stats['summary']['total_clusters']}\")\n",
    "print(f\"Constraint violations: Size={stats['summary']['size_violations']}, Distance={stats['summary']['distance_violations']}\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ea47e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "divisive_result.cluster.value_counts().reset_index().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd968c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_and_save(df_routes = divisive_result,\n",
    "                 df_stockpoint = None,   \n",
    "                 filename=None,\n",
    "                 cluster_col = 'cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6a8784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.cluster.hierarchy import fcluster, linkage\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class BaseGeographicClustering:\n",
    "    \"\"\"\n",
    "    A base class containing common geographic utility methods\n",
    "    used by both Divisive and Agglomerative clustering implementations.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.earth_radius_km = 6371.0\n",
    "\n",
    "    def haversine_vectorized(self, coords1, coords2=None):\n",
    "        \"\"\"\n",
    "        Highly optimized vectorized haversine distance calculation.\n",
    "        If coords2 is None, calculates pairwise distances within coords1.\n",
    "        Assumes coords are [latitude, longitude].\n",
    "        \"\"\"\n",
    "        if coords2 is None:\n",
    "            # Pairwise distances within coords1 (NxN matrix)\n",
    "            coords1_rad = np.radians(coords1)\n",
    "            \n",
    "            lat1 = coords1_rad[:, 0]\n",
    "            lon1 = coords1_rad[:, 1]\n",
    "            \n",
    "            lat1_mesh, lat2_mesh = np.meshgrid(lat1, lat1)\n",
    "            lon1_mesh, lon2_mesh = np.meshgrid(lon1, lon1)\n",
    "            \n",
    "            dlat = lat2_mesh - lat1_mesh\n",
    "            dlon = lon2_mesh - lon1_mesh\n",
    "            \n",
    "            a = (np.sin(dlat / 2) ** 2 + \n",
    "                 np.cos(lat1_mesh) * np.cos(lat2_mesh) * np.sin(dlon / 2) ** 2)\n",
    "            c = 2 * np.arcsin(np.sqrt(np.clip(a, 0, 1)))\n",
    "            \n",
    "            return self.earth_radius_km * c\n",
    "        else:\n",
    "            # Distance from each point in coords1 to each point in coords2 (NxM matrix)\n",
    "            coords1_rad = np.radians(coords1)\n",
    "            coords2_rad = np.radians(coords2)\n",
    "            \n",
    "            lat1 = coords1_rad[:, 0][:, np.newaxis]\n",
    "            lon1 = coords1_rad[:, 1][:, np.newaxis]\n",
    "            lat2 = coords2_rad[:, 0][np.newaxis, :]\n",
    "            lon2 = coords2_rad[:, 1][np.newaxis, :]\n",
    "            \n",
    "            dlat = lat2 - lat1\n",
    "            dlon = lon2 - lon1\n",
    "            \n",
    "            a = (np.sin(dlat / 2) ** 2 + \n",
    "                 np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2)\n",
    "            c = 2 * np.arcsin(np.sqrt(np.clip(a, 0, 1)))\n",
    "            \n",
    "            return self.earth_radius_km * c\n",
    "    \n",
    "    def haversine_pdist(self, coords):\n",
    "        \"\"\"\n",
    "        Optimized haversine distance calculation for pdist, returning condensed distance matrix.\n",
    "        Assumes coords are [latitude, longitude].\n",
    "        \"\"\"\n",
    "        def haversine_metric(u, v):\n",
    "            lat1, lon1 = np.radians(u)\n",
    "            lat2, lon2 = np.radians(v)\n",
    "            \n",
    "            dlat = lat2 - lat1\n",
    "            dlon = lon2 - lon1\n",
    "            \n",
    "            a = (np.sin(dlat / 2) ** 2 + \n",
    "                 np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2)\n",
    "            c = 2 * np.arcsin(np.sqrt(np.clip(a, 0, 1)))\n",
    "            \n",
    "            return self.earth_radius_km * c\n",
    "        \n",
    "        return pdist(coords, metric=haversine_metric)\n",
    "    \n",
    "    def haversine_single_pair(self, coord1, coord2):\n",
    "        \"\"\"Calculate haversine distance between two points.\"\"\"\n",
    "        lat1, lon1 = np.radians(coord1)\n",
    "        lat2, lon2 = np.radians(coord2)\n",
    "        \n",
    "        dlat = lat2 - lat1\n",
    "        dlon = lon2 - lon1\n",
    "        \n",
    "        a = (np.sin(dlat / 2) ** 2 + \n",
    "             np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2)\n",
    "        c = 2 * np.arcsin(np.sqrt(np.clip(a, 0, 1)))\n",
    "        \n",
    "        return self.earth_radius_km * c\n",
    "\n",
    "    def _convex_hull_diameter(self, coords):\n",
    "        \"\"\"Enhanced convex hull approximation for diameter estimation.\"\"\"\n",
    "        lats, lons = coords[:, 0], coords[:, 1]\n",
    "        \n",
    "        # Get extreme points (min/max lat/lon)\n",
    "        extreme_indices = [\n",
    "            np.argmax(lats), np.argmin(lats),\n",
    "            np.argmax(lons), np.argmin(lons)\n",
    "        ]\n",
    "        \n",
    "        # Add points from different quadrants relative to the mean center\n",
    "        lat_center, lon_center = np.mean(lats), np.mean(lons)\n",
    "        \n",
    "        quadrants = [\n",
    "            (lats >= lat_center) & (lons >= lon_center),   # NE\n",
    "            (lats >= lat_center) & (lons < lon_center),    # NW\n",
    "            (lats < lat_center) & (lons >= lon_center),    # SE\n",
    "            (lats < lat_center) & (lons < lon_center)      # SW\n",
    "        ]\n",
    "        \n",
    "        for quadrant in quadrants:\n",
    "            if np.any(quadrant):\n",
    "                quad_indices = np.where(quadrant)[0]\n",
    "                # Add furthest point from center in each non-empty quadrant\n",
    "                distances_from_center = np.sqrt(\n",
    "                    (lats[quad_indices] - lat_center)**2 + \n",
    "                    (lons[quad_indices] - lon_center)**2\n",
    "                )\n",
    "                furthest_idx = quad_indices[np.argmax(distances_from_center)]\n",
    "                extreme_indices.append(furthest_idx)\n",
    "        \n",
    "        # Add some random points to further improve approximation for larger clusters\n",
    "        n_random = min(12, len(coords) - len(set(extreme_indices)))\n",
    "        if n_random > 0:\n",
    "            available_indices = list(set(range(len(coords))) - set(extreme_indices))\n",
    "            if available_indices:\n",
    "                random_indices = np.random.choice(available_indices, \n",
    "                                                  min(n_random, len(available_indices)), \n",
    "                                                  replace=False)\n",
    "                extreme_indices.extend(random_indices)\n",
    "        \n",
    "        # Get unique sample coordinates\n",
    "        sample_indices = list(set(extreme_indices))\n",
    "        sample_coords = coords[sample_indices]\n",
    "        \n",
    "        if len(sample_coords) <= 1:\n",
    "            return 0\n",
    "        \n",
    "        # Calculate max distance among the sampled points\n",
    "        distances = self.haversine_pdist(sample_coords)\n",
    "        return np.max(distances)\n",
    "    \n",
    "    def _grid_based_diameter(self, coords):\n",
    "        \"\"\"Grid-based sampling for very large clusters.\"\"\"\n",
    "        lats, lons = coords[:, 0], coords[:, 1]\n",
    "        \n",
    "        # Create 6x6 grid\n",
    "        lat_bins = np.linspace(lats.min(), lats.max(), 7)\n",
    "        lon_bins = np.linspace(lons.min(), lons.max(), 7)\n",
    "        \n",
    "        sample_indices = []\n",
    "        for i in range(len(lat_bins)-1):\n",
    "            for j in range(len(lon_bins)-1):\n",
    "                mask = ((lats >= lat_bins[i]) & (lats < lat_bins[i+1]) & \n",
    "                        (lons >= lon_bins[j]) & (lons < lon_bins[j+1]))\n",
    "                cell_indices = np.where(mask)[0]\n",
    "                if len(cell_indices) > 0:\n",
    "                    # Sample up to 2 points from each cell\n",
    "                    n_sample = min(2, len(cell_indices))\n",
    "                    sampled = np.random.choice(cell_indices, n_sample, replace=False)\n",
    "                    sample_indices.extend(sampled)\n",
    "        \n",
    "        if len(sample_indices) <= 1:\n",
    "            return 0\n",
    "        \n",
    "        sample_coords = coords[sample_indices]\n",
    "        distances = self.haversine_pdist(sample_coords)\n",
    "        return np.max(distances)\n",
    "    \n",
    "    def calculate_cluster_diameter_fast(self, coords):\n",
    "        \"\"\"\n",
    "        Fast cluster diameter calculation with multiple optimization strategies.\n",
    "        \"\"\"\n",
    "        n_points = len(coords)\n",
    "        \n",
    "        if n_points <= 1:\n",
    "            return 0\n",
    "        \n",
    "        if n_points == 2:\n",
    "            return self.haversine_single_pair(coords[0], coords[1])\n",
    "        \n",
    "        # Use different strategies based on cluster size\n",
    "        if n_points <= 10:\n",
    "            # Small clusters: exact calculation using pdist\n",
    "            distances = self.haversine_pdist(coords)\n",
    "            return np.max(distances)\n",
    "        elif n_points <= 50:\n",
    "            # Medium clusters: vectorized calculation or pdist\n",
    "            # Prioritize vectorized if available and faster for this range\n",
    "            distance_matrix = self.haversine_vectorized(coords)\n",
    "            # Ensure we're not taking max of diagonal (self-distances = 0)\n",
    "            return np.max(distance_matrix[np.triu_indices(n_points, k=1)])\n",
    "        else:\n",
    "            # Large clusters: smart sampling\n",
    "            return self._smart_diameter_estimation(coords)\n",
    "    \n",
    "    def _smart_diameter_estimation(self, coords):\n",
    "        \"\"\"\n",
    "        Improved diameter estimation using multiple sampling strategies.\n",
    "        \"\"\"\n",
    "        n_points = len(coords)\n",
    "        \n",
    "        # Strategy 1: Convex hull approximation\n",
    "        hull_diameter = self._convex_hull_diameter(coords)\n",
    "        \n",
    "        # Strategy 2: Grid-based sampling for very large clusters (higher confidence for max)\n",
    "        if n_points > 200: # Threshold for when grid sampling might be beneficial\n",
    "            grid_diameter = self._grid_based_diameter(coords)\n",
    "            return max(hull_diameter, grid_diameter)\n",
    "        \n",
    "        return hull_diameter\n",
    "\n",
    "    def _find_approximate_farthest_pair(self, coords):\n",
    "        \"\"\"Find approximate farthest pair for large clusters.\n",
    "           Moved from OptimizedDivisiveGeographicClustering to BaseGeographicClustering.\"\"\"\n",
    "        n_points = len(coords)\n",
    "        \n",
    "        if n_points <= 100:\n",
    "            # For moderate sizes, use exact calculation\n",
    "            distances = self.haversine_pdist(coords)\n",
    "            distance_matrix = squareform(distances)\n",
    "            max_idx = np.unravel_index(np.argmax(distance_matrix), distance_matrix.shape)\n",
    "            return max_idx[0], max_idx[1]\n",
    "        \n",
    "        # For large clusters, use sampling\n",
    "        sample_size = min(50, n_points)\n",
    "        sample_indices = np.random.choice(n_points, sample_size, replace=False)\n",
    "        sample_coords = coords[sample_indices]\n",
    "        \n",
    "        distances = self.haversine_pdist(sample_coords)\n",
    "        distance_matrix = squareform(distances)\n",
    "        max_idx = np.unravel_index(np.argmax(distance_matrix), distance_matrix.shape)\n",
    "        \n",
    "        return sample_indices[max_idx[0]], sample_indices[max_idx[1]]\n",
    "\n",
    "    def get_cluster_stats(self, clustered_df, max_customers_per_cluster, max_distance_km):\n",
    "        \"\"\"Get comprehensive clustering statistics.\"\"\"\n",
    "        if 'cluster' not in clustered_df.columns:\n",
    "            raise ValueError(\"DataFrame must contain 'cluster' column\")\n",
    "        \n",
    "        stats = {}\n",
    "        cluster_sizes = []\n",
    "        cluster_diameters = []\n",
    "        \n",
    "        for cluster_id in clustered_df['cluster'].unique():\n",
    "            if cluster_id == -1: # Unassigned points if any\n",
    "                continue\n",
    "            \n",
    "            cluster_data = clustered_df[clustered_df['cluster'] == cluster_id]\n",
    "            coords = cluster_data[['Latitude', 'Longitude']].values\n",
    "            \n",
    "            diameter = self.calculate_cluster_diameter_fast(coords)\n",
    "            cluster_sizes.append(len(cluster_data))\n",
    "            cluster_diameters.append(diameter)\n",
    "            \n",
    "            stats[cluster_id] = {\n",
    "                'size': len(cluster_data),\n",
    "                'diameter_km': diameter,\n",
    "                'centroid_lat': np.mean(coords[:, 0]),\n",
    "                'centroid_lon': np.mean(coords[:, 1]),\n",
    "                'meets_size_constraint': len(cluster_data) <= max_customers_per_cluster,\n",
    "                'meets_distance_constraint': diameter <= max_distance_km\n",
    "            }\n",
    "        \n",
    "        # Overall statistics\n",
    "        stats['summary'] = {\n",
    "            'total_clusters': len(stats), \n",
    "            'avg_cluster_size': np.mean(cluster_sizes) if cluster_sizes else 0,\n",
    "            'max_cluster_size': np.max(cluster_sizes) if cluster_sizes else 0,\n",
    "            'min_cluster_size': np.min(cluster_sizes) if cluster_sizes else 0,\n",
    "            'avg_diameter': np.mean(cluster_diameters) if cluster_diameters else 0,\n",
    "            'max_diameter': np.max(cluster_diameters) if cluster_diameters else 0,\n",
    "            'size_violations': sum(1 for size in cluster_sizes if size > max_customers_per_cluster),\n",
    "            'distance_violations': sum(1 for diameter in cluster_diameters if diameter > max_distance_km)\n",
    "        }\n",
    "        \n",
    "        return stats\n",
    "\n",
    "\n",
    "class AgglomerativeGeographicClustering(BaseGeographicClustering):\n",
    "    def __init__(self, max_customers_per_cluster=20, max_distance_km=50, \n",
    "                 linkage_method='ward', sub_cluster_if_oversized=True):\n",
    "        \"\"\"\n",
    "        Initializes the Agglomerative Geographic Clustering.\n",
    "\n",
    "        Args:\n",
    "            max_customers_per_cluster (int): Maximum number of customers allowed in a single cluster.\n",
    "            max_distance_km (float): Maximum diameter (distance between two farthest points)\n",
    "                                     allowed within a cluster in kilometers.\n",
    "            linkage_method (str): Method to use for calculating the distance between clusters\n",
    "                                  in hierarchical clustering. Options: 'ward', 'single', 'complete', 'average'.\n",
    "            sub_cluster_if_oversized (bool): If True, clusters that exceed max_customers_per_cluster\n",
    "                                             after distance-based cutting will be further sub-clustered\n",
    "                                             using K-Means.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.max_customers_per_cluster = max_customers_per_cluster\n",
    "        self.max_distance_km = max_distance_km\n",
    "        self.linkage_method = linkage_method\n",
    "        self.sub_cluster_if_oversized = sub_cluster_if_oversized\n",
    "\n",
    "    def agglomerative_clustering(self, customers_df):\n",
    "        \"\"\"\n",
    "        Performs agglomerative hierarchical clustering on geographic data\n",
    "        with constraints on cluster size and diameter.\n",
    "        \"\"\"\n",
    "        customers_df = customers_df.copy().reset_index(drop=True)\n",
    "        \n",
    "        if 'Latitude' not in customers_df.columns or 'Longitude' not in customers_df.columns:\n",
    "            raise ValueError(\"DataFrame must contain 'Latitude' and 'Longitude' columns\")\n",
    "        \n",
    "        coords_array = customers_df[['Latitude', 'Longitude']].values\n",
    "        n_customers = len(customers_df)\n",
    "        \n",
    "        if n_customers == 0:\n",
    "            customers_df['cluster'] = []\n",
    "            return customers_df\n",
    "        \n",
    "        if n_customers == 1:\n",
    "            customers_df['cluster'] = 1\n",
    "            return customers_df\n",
    "\n",
    "        # Step 1: Calculate pairwise Haversine distances\n",
    "        print(f\"Calculating {n_customers*(n_customers-1)//2} pairwise distances...\")\n",
    "        # Check if the number of points is too large for pdist to avoid MemoryError\n",
    "        # A rough heuristic: 5000 points * 5000 points / 2 * 8 bytes/float ~ 100MB\n",
    "        # For very large N, consider approximate methods if pdist is too slow/memory intensive\n",
    "        if n_customers > 2000 and self.linkage_method != 'ward': # Ward only works with Euclidean-like pdist\n",
    "             # For very large datasets, pdist might be too slow or memory intensive.\n",
    "             # In such cases, one might consider sampling or approximate hierarchical methods,\n",
    "             # or other clustering algorithms like DBSCAN that don't require a full distance matrix.\n",
    "             # For now, we proceed with pdist as it's standard for scipy.hierarchy.\n",
    "            print(\"Warning: Large dataset for pdist. This might take a while or consume a lot of memory.\")\n",
    "\n",
    "        distances = self.haversine_pdist(coords_array)\n",
    "        \n",
    "        # Step 2: Perform hierarchical clustering using linkage\n",
    "        print(f\"Performing linkage using '{self.linkage_method}' method...\")\n",
    "        linkage_matrix = linkage(distances, method=self.linkage_method)\n",
    "        \n",
    "        # Step 3: Cut the dendrogram based on max_distance_km\n",
    "        # This creates clusters where no two points are farther apart than max_distance_km\n",
    "        print(f\"Cutting dendrogram at max_distance_km={self.max_distance_km}...\")\n",
    "        initial_labels = fcluster(linkage_matrix, self.max_distance_km, criterion='distance')\n",
    "        \n",
    "        customers_df['cluster_temp'] = initial_labels\n",
    "        final_cluster_id = 0\n",
    "        final_clusters = {}\n",
    "\n",
    "        # Step 4: Post-process for max_customers_per_cluster constraint\n",
    "        print(f\"Post-processing clusters for size constraint (max {self.max_customers_per_cluster} customers)...\")\n",
    "        for current_cluster_label in sorted(customers_df['cluster_temp'].unique()):\n",
    "            cluster_indices = customers_df[customers_df['cluster_temp'] == current_cluster_label].index.values\n",
    "            current_coords = coords_array[cluster_indices]\n",
    "            \n",
    "            if len(cluster_indices) > self.max_customers_per_cluster and self.sub_cluster_if_oversized:\n",
    "                print(f\"  Cluster {current_cluster_label} (size {len(cluster_indices)}) is oversized. Sub-clustering...\")\n",
    "                # Sub-cluster using K-Means. Determine optimal k based on current size / max_customers_per_cluster\n",
    "                k_sub = int(np.ceil(len(cluster_indices) / self.max_customers_per_cluster))\n",
    "                k_sub = max(2, k_sub) # Ensure at least 2 clusters if splitting\n",
    "                \n",
    "                # Use approximate farthest pair for K-Means initialization\n",
    "                initial_centers_indices = self._find_approximate_farthest_pair(current_coords)\n",
    "                # Ensure initial_centers_indices has enough elements for k_sub.\n",
    "                # If k_sub > 2, KMeans++ initialization is generally more robust than a simple farthest pair.\n",
    "                if k_sub > 2:\n",
    "                    kmeans_sub = KMeans(n_clusters=k_sub, n_init=10, random_state=42) # Let KMeans find its own init\n",
    "                elif len(initial_centers_indices) >= 2: # k_sub = 2, use the farthest pair if available\n",
    "                    kmeans_sub = KMeans(n_clusters=k_sub, init=current_coords[[initial_centers_indices[0], initial_centers_indices[1]]], n_init=1, random_state=42)\n",
    "                else: # Fallback if initial_centers_indices is not sufficient for k_sub=2\n",
    "                    kmeans_sub = KMeans(n_clusters=k_sub, n_init=10, random_state=42)\n",
    "\n",
    "\n",
    "                sub_labels = kmeans_sub.fit_predict(current_coords)\n",
    "                \n",
    "                for sub_label in np.unique(sub_labels):\n",
    "                    final_cluster_id += 1\n",
    "                    sub_cluster_indices = cluster_indices[sub_labels == sub_label]\n",
    "                    final_clusters[final_cluster_id] = sub_cluster_indices\n",
    "            else:\n",
    "                final_cluster_id += 1\n",
    "                final_clusters[final_cluster_id] = cluster_indices\n",
    "        \n",
    "        # Assign final cluster labels to the DataFrame\n",
    "        result_df = customers_df.copy()\n",
    "        result_df['cluster'] = -1 # Initialize with unassigned\n",
    "\n",
    "        for cluster_id, indices in final_clusters.items():\n",
    "            result_df.loc[indices, 'cluster'] = cluster_id\n",
    "        \n",
    "        result_df = result_df.drop(columns=['cluster_temp'])\n",
    "        print(\"Agglomerative clustering completed.\\n\")\n",
    "        return result_df\n",
    "\n",
    "class OptimizedDivisiveGeographicClustering(BaseGeographicClustering):\n",
    "    \"\"\" Best - Fast and Accurate Divisive Geographic Clustering\n",
    "    \"\"\"\n",
    "    def __init__(self, max_customers_per_cluster=20, max_distance_km=50, \n",
    "                 use_vectorized_distances=True, balance_clusters=False):\n",
    "        super().__init__()\n",
    "        self.max_customers_per_cluster = max_customers_per_cluster\n",
    "        self.max_distance_km = max_distance_km\n",
    "        self.use_vectorized_distances = use_vectorized_distances\n",
    "        self.balance_clusters = balance_clusters\n",
    "        \n",
    "    def calculate_cluster_diameter_fast(self, coords): # Overrides Base class method\n",
    "        \"\"\"\n",
    "        Fast cluster diameter calculation with multiple optimization strategies.\n",
    "        \"\"\"\n",
    "        n_points = len(coords)\n",
    "        \n",
    "        if n_points <= 1:\n",
    "            return 0\n",
    "        \n",
    "        if n_points == 2:\n",
    "            return self.haversine_single_pair(coords[0], coords[1])\n",
    "        \n",
    "        # Use different strategies based on cluster size\n",
    "        if n_points <= 10:\n",
    "            # Small clusters: exact calculation\n",
    "            distances = self.haversine_pdist(coords)\n",
    "            return np.max(distances)\n",
    "        elif n_points <= 50:\n",
    "            # Medium clusters: vectorized calculation\n",
    "            if self.use_vectorized_distances:\n",
    "                distance_matrix = self.haversine_vectorized(coords)\n",
    "                return np.max(distance_matrix)\n",
    "            else:\n",
    "                distances = self.haversine_pdist(coords)\n",
    "                return np.max(distances)\n",
    "        else:\n",
    "            # Large clusters: smart sampling\n",
    "            return self._smart_diameter_estimation(coords)\n",
    "    \n",
    "    def _smart_diameter_estimation(self, coords): # Overrides Base class method\n",
    "        \"\"\"\n",
    "        Improved diameter estimation using multiple sampling strategies.\n",
    "        \"\"\"\n",
    "        n_points = len(coords)\n",
    "        \n",
    "        # Strategy 1: Convex hull approximation\n",
    "        hull_diameter = self._convex_hull_diameter(coords)\n",
    "        \n",
    "        # Strategy 2: Grid-based sampling for large clusters\n",
    "        if n_points > 200:\n",
    "            grid_diameter = self._grid_based_diameter(coords)\n",
    "            return max(hull_diameter, grid_diameter)\n",
    "        \n",
    "        return hull_diameter\n",
    "    \n",
    "    def should_split_cluster(self, cluster_indices, coords_array):\n",
    "        \"\"\"Enhanced cluster splitting logic with load balancing.\"\"\"\n",
    "        cluster_size = len(cluster_indices)\n",
    "        \n",
    "        if cluster_size <= 2:\n",
    "            return False\n",
    "        \n",
    "        # Hard size constraint\n",
    "        if cluster_size > self.max_customers_per_cluster * 1.5:\n",
    "            return True\n",
    "        \n",
    "        # Soft size constraint with diameter check\n",
    "        if cluster_size > self.max_customers_per_cluster:\n",
    "            cluster_coords = coords_array[cluster_indices]\n",
    "            diameter = self.calculate_cluster_diameter_fast(cluster_coords)\n",
    "            return diameter > self.max_distance_km * 0.8  # More lenient for size\n",
    "        \n",
    "        # Diameter constraint\n",
    "        cluster_coords = coords_array[cluster_indices]\n",
    "        diameter = self.calculate_cluster_diameter_fast(cluster_coords)\n",
    "        \n",
    "        return diameter > self.max_distance_km\n",
    "    \n",
    "    def geographic_split(self, cluster_indices, coords_array):\n",
    "        \"\"\"\n",
    "        Improved geographic splitting with better load balancing.\n",
    "        \"\"\"\n",
    "        if len(cluster_indices) <= 2:\n",
    "            return [cluster_indices]\n",
    "        \n",
    "        cluster_coords = coords_array[cluster_indices]\n",
    "        n_points = len(cluster_coords)\n",
    "        \n",
    "        # For small clusters, use exact method\n",
    "        if n_points <= 50:\n",
    "            return self._exact_geographic_split(cluster_indices, cluster_coords)\n",
    "        \n",
    "        # For medium clusters, use K-means with geographic initialization\n",
    "        if n_points <= 200:\n",
    "            return self._kmeans_geographic_split(cluster_indices, cluster_coords)\n",
    "        \n",
    "        # For large clusters, use hierarchical approach\n",
    "        return self._hierarchical_geographic_split(cluster_indices, cluster_coords)\n",
    "    \n",
    "    def _exact_geographic_split(self, cluster_indices, cluster_coords):\n",
    "        \"\"\"Exact splitting for small clusters.\"\"\"\n",
    "        n_points = len(cluster_coords)\n",
    "        \n",
    "        # Find the two points that are farthest apart\n",
    "        distances = self.haversine_pdist(cluster_coords)\n",
    "        distance_matrix = squareform(distances)\n",
    "        max_idx = np.unravel_index(np.argmax(distance_matrix), distance_matrix.shape)\n",
    "        center1_idx, center2_idx = max_idx[0], max_idx[1]\n",
    "        \n",
    "        center1 = cluster_coords[center1_idx]\n",
    "        center2 = cluster_coords[center2_idx]\n",
    "        \n",
    "        # Assign points to closest center\n",
    "        distances_to_center1 = self.haversine_vectorized(cluster_coords, center1.reshape(1, -1))[:, 0]\n",
    "        distances_to_center2 = self.haversine_vectorized(cluster_coords, center2.reshape(1, -1))[:, 0]\n",
    "        \n",
    "        labels = (distances_to_center1 <= distances_to_center2).astype(int)\n",
    "        \n",
    "        return self._balance_split(cluster_indices, labels)\n",
    "    \n",
    "    def _kmeans_geographic_split(self, cluster_indices, cluster_coords):\n",
    "        \"\"\"K-means splitting with geographic initialization.\"\"\"\n",
    "        n_points = len(cluster_coords)\n",
    "        \n",
    "        # Initialize with farthest pair\n",
    "        # This calls _find_approximate_farthest_pair from BaseGeographicClustering\n",
    "        center1_idx, center2_idx = self._find_approximate_farthest_pair(cluster_coords) \n",
    "        initial_centers = cluster_coords[[center1_idx, center2_idx]]\n",
    "        \n",
    "        # Apply K-means\n",
    "        kmeans = KMeans(n_clusters=2, init=initial_centers, n_init=1, random_state=42)\n",
    "        labels = kmeans.fit_predict(cluster_coords)\n",
    "        \n",
    "        return self._balance_split(cluster_indices, labels)\n",
    "    \n",
    "    def _hierarchical_geographic_split(self, cluster_indices, cluster_coords):\n",
    "        \"\"\"Hierarchical splitting for large clusters.\"\"\"\n",
    "        # Use linkage-based clustering for very large clusters\n",
    "        n_sample = min(100, len(cluster_coords))\n",
    "        sample_indices = np.random.choice(len(cluster_coords), n_sample, replace=False)\n",
    "        sample_coords = cluster_coords[sample_indices]\n",
    "        \n",
    "        # Compute linkage on sample\n",
    "        distances = self.haversine_pdist(sample_coords)\n",
    "        linkage_matrix = linkage(distances, method='ward')\n",
    "        sample_labels = fcluster(linkage_matrix, 2, criterion='maxclust') - 1\n",
    "        \n",
    "        # Ensure that both sub-clusters have points from the sample\n",
    "        center1_coords = sample_coords[sample_labels == 0]\n",
    "        center2_coords = sample_coords[sample_labels == 1]\n",
    "        \n",
    "        if len(center1_coords) == 0 or len(center2_coords) == 0:\n",
    "            # Fallback to exact split if hierarchical sample leads to empty sub-clusters\n",
    "            return self._exact_geographic_split(cluster_indices, cluster_coords)\n",
    "        \n",
    "        center1 = np.mean(center1_coords, axis=0)\n",
    "        center2 = np.mean(center2_coords, axis=0)\n",
    "        \n",
    "        distances_to_center1 = self.haversine_vectorized(cluster_coords, center1.reshape(1, -1))[:, 0]\n",
    "        distances_to_center2 = self.haversine_vectorized(cluster_coords, center2.reshape(1, -1))[:, 0]\n",
    "        \n",
    "        labels = (distances_to_center1 <= distances_to_center2).astype(int)\n",
    "        \n",
    "        return self._balance_split(cluster_indices, labels)\n",
    "    \n",
    "    def _balance_split(self, cluster_indices, labels):\n",
    "        \"\"\"Balance the split to avoid very uneven clusters.\"\"\"\n",
    "        cluster_0_indices = cluster_indices[labels == 0]\n",
    "        cluster_1_indices = cluster_indices[labels == 1]\n",
    "        \n",
    "        # Ensure no empty clusters (very important for recursive calls)\n",
    "        if len(cluster_0_indices) == 0:\n",
    "            # If one cluster is empty, move one point from the other to it.\n",
    "            # This handles edge cases but might lead to a single point cluster,\n",
    "            # which the should_split_cluster check will prevent further splitting if <= 2.\n",
    "            if len(cluster_1_indices) > 0:\n",
    "                cluster_0_indices = np.array([cluster_1_indices[0]])\n",
    "                cluster_1_indices = cluster_1_indices[1:]\n",
    "            else: # Both empty, should not happen if initial cluster_indices was not empty\n",
    "                return [np.array([]), np.array([])]\n",
    "        elif len(cluster_1_indices) == 0:\n",
    "            if len(cluster_0_indices) > 0:\n",
    "                cluster_1_indices = np.array([cluster_0_indices[0]])\n",
    "                cluster_0_indices = cluster_0_indices[1:]\n",
    "            else: # Both empty\n",
    "                return [np.array([]), np.array([])]\n",
    "        \n",
    "        # Optional: Balance cluster sizes if one is much larger\n",
    "        if self.balance_clusters:\n",
    "            size_0, size_1 = len(cluster_0_indices), len(cluster_1_indices)\n",
    "            if size_0 > 3 * size_1 and size_1 > 0: # If cluster 0 is significantly larger\n",
    "                n_move = (size_0 - size_1) // 4 # Move a quarter of the difference\n",
    "                move_indices = cluster_0_indices[:n_move]\n",
    "                cluster_0_indices = cluster_0_indices[n_move:]\n",
    "                cluster_1_indices = np.concatenate([cluster_1_indices, move_indices])\n",
    "            elif size_1 > 3 * size_0 and size_0 > 0: # If cluster 1 is significantly larger\n",
    "                n_move = (size_1 - size_0) // 4\n",
    "                move_indices = cluster_1_indices[:n_move]\n",
    "                cluster_1_indices = cluster_1_indices[n_move:]\n",
    "                cluster_0_indices = np.concatenate([cluster_0_indices, move_indices])\n",
    "        \n",
    "        return [cluster_0_indices, cluster_1_indices]\n",
    "    \n",
    "    def divisive_clustering(self, customers_df):\n",
    "        \"\"\"Perform optimized divisive hierarchical clustering.\"\"\"\n",
    "        customers_df = customers_df.copy().reset_index(drop=True)\n",
    "        \n",
    "        # Validate input\n",
    "        if 'Latitude' not in customers_df.columns or 'Longitude' not in customers_df.columns:\n",
    "            raise ValueError(\"DataFrame must contain 'Latitude' and 'Longitude' columns\")\n",
    "        \n",
    "        coords_array = customers_df[['Latitude', 'Longitude']].values\n",
    "        n_customers = len(customers_df)\n",
    "        \n",
    "        if n_customers == 0:\n",
    "            customers_df['cluster'] = []\n",
    "            return customers_df\n",
    "        \n",
    "        if n_customers == 1:\n",
    "            customers_df['cluster'] = 1\n",
    "            return customers_df\n",
    "        \n",
    "        # Priority queue approach for better clustering\n",
    "        clusters_to_process = [(n_customers, np.arange(n_customers))]   # (size, indices)\n",
    "        final_clusters = []\n",
    "        \n",
    "        iteration_count = 0\n",
    "        max_iterations = n_customers * 2 # Safety break to prevent infinite loops\n",
    "        \n",
    "        while clusters_to_process and iteration_count < max_iterations:\n",
    "            # Process largest cluster first to tackle the biggest problems\n",
    "            clusters_to_process.sort(key=lambda x: x[0], reverse=True)\n",
    "            current_size, current_cluster_indices = clusters_to_process.pop(0)\n",
    "            iteration_count += 1\n",
    "            \n",
    "            if self.should_split_cluster(current_cluster_indices, coords_array):\n",
    "                subclusters = self.geographic_split(current_cluster_indices, coords_array)\n",
    "                \n",
    "                for subcluster_indices in subclusters:\n",
    "                    if len(subcluster_indices) > 0:\n",
    "                        clusters_to_process.append((len(subcluster_indices), subcluster_indices))\n",
    "            else:\n",
    "                final_clusters.append(current_cluster_indices)\n",
    "        \n",
    "        # Handle any clusters remaining in `clusters_to_process` if max_iterations was hit\n",
    "        final_clusters.extend([indices for _, indices in clusters_to_process])\n",
    "        \n",
    "        # Create result DataFrame\n",
    "        result_df = customers_df.copy()\n",
    "        result_df['cluster'] = -1 # Initialize with -1 for unassigned\n",
    "        \n",
    "        for cluster_id, cluster_indices in enumerate(final_clusters, 1):\n",
    "            result_df.loc[cluster_indices, 'cluster'] = cluster_id\n",
    "        \n",
    "        return result_df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c64bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad756b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### My custom testing\n",
    "print(\"--- Running Agglomerative Clustering ---\")\n",
    "agg_clusterer = AgglomerativeGeographicClustering(\n",
    "    max_customers_per_cluster=20, # Aim for clusters of max 50 customers\n",
    "    max_distance_km=5.0,        # Max diameter of 5 km\n",
    "    linkage_method='ward',       # Common choice for compact clusters\n",
    "    sub_cluster_if_oversized=True\n",
    ")\n",
    "clustered_agg_df = agg_clusterer.agglomerative_clustering(df_all_cluster.copy())\n",
    "agg_stats = agg_clusterer.get_cluster_stats(clustered_agg_df, agg_clusterer.max_customers_per_cluster, agg_clusterer.max_distance_km)\n",
    "print(\"\\nAgglomerative Clustering Stats:\")\n",
    "for k, v in agg_stats['summary'].items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "print(\"\\nSample Agglomerative Cluster Details:\")\n",
    "for cluster_id, details in list(agg_stats.items())[:5]: # Show first 5 clusters\n",
    "    if cluster_id != 'summary':\n",
    "        print(f\"  Cluster {cluster_id}: Size={details['size']}, Diameter={details['diameter_km']:.2f} km, Size OK={details['meets_size_constraint']}, Distance OK={details['meets_distance_constraint']}\")\n",
    "\n",
    "\n",
    "_ = evaluate_unsupervised_clustering(clustered_agg_df)\n",
    "\n",
    "# # # Get detailed statistics\n",
    "stats = divisive_clusterer.get_cluster_stats(clustered_agg_df)\n",
    "print(f\"Total clusters: {stats['summary']['total_clusters']}\")\n",
    "print(f\"Constraint violations: Size={stats['summary']['size_violations']}, Distance={stats['summary']['distance_violations']}\")\n",
    " \n",
    "\n",
    " \n",
    "vis_and_save(df_routes = clustered_agg_df,\n",
    "                 df_stockpoint = None,   \n",
    "                 filename=None,\n",
    "                 cluster_col = 'cluster')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92bf2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### My custom testing\n",
    "print(\"\\n--- Running Divisive Clustering (for comparison) ---\")\n",
    "div_clusterer = OptimizedDivisiveGeographicClustering(\n",
    "    max_customers_per_cluster=50,\n",
    "    max_distance_km=5.0,\n",
    "    balance_clusters=True\n",
    ")\n",
    "clustered_div_df = div_clusterer.divisive_clustering(df_all_cluster.copy())\n",
    "div_stats = div_clusterer.get_cluster_stats(clustered_div_df, div_clusterer.max_customers_per_cluster, div_clusterer.max_distance_km) # Added missing arguments\n",
    "print(\"\\nDivisive Clustering Stats:\")\n",
    "for k, v in div_stats['summary'].items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "print(\"\\nSample Divisive Cluster Details:\")\n",
    "for cluster_id, details in list(div_stats.items())[:5]: # Show first 5 clusters\n",
    "    if cluster_id != 'summary':\n",
    "        print(f\"  Cluster {cluster_id}: Size={details['size']}, Diameter={details['diameter_km']:.2f} km, Size OK={details['meets_size_constraint']}, Distance OK={details['meets_distance_constraint']}\")\n",
    "\n",
    "\n",
    "_ = evaluate_unsupervised_clustering(clustered_div_df)\n",
    "\n",
    "# # # Get detailed statistics\n",
    "stats = divisive_clusterer.get_cluster_stats(clustered_div_df)\n",
    "print(f\"Total clusters: {stats['summary']['total_clusters']}\")\n",
    "print(f\"Constraint violations: Size={stats['summary']['size_violations']}, Distance={stats['summary']['distance_violations']}\")\n",
    "\n",
    "\n",
    "\n",
    "vis_and_save(df_routes = clustered_div_df,\n",
    "                df_stockpoint = None,   \n",
    "                filename=None,\n",
    "                cluster_col = 'cluster')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33c5c24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f57385",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Example Usage ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate some sample geographic data\n",
    "    np.random.seed(42)\n",
    "    num_customers = 500 # Testing with more customers for better demonstration\n",
    "    \n",
    "    # Simulate clusters\n",
    "    center1 = [6.5, 3.3] # Lagos area\n",
    "    center2 = [6.6, 3.4]\n",
    "    center3 = [6.4, 3.2]\n",
    "\n",
    "    customers_data = []\n",
    "    # Cluster 1 (dense)\n",
    "    for _ in range(200):\n",
    "        customers_data.append({\n",
    "            'CustomerID': f'C1_{_}',\n",
    "            'Latitude': center1[0] + np.random.randn() * 0.01,\n",
    "            'Longitude': center1[1] + np.random.randn() * 0.01\n",
    "        })\n",
    "    # Cluster 2 (dense)\n",
    "    for _ in range(150):\n",
    "        customers_data.append({\n",
    "            'CustomerID': f'C2_{_}',\n",
    "            'Latitude': center2[0] + np.random.randn() * 0.015,\n",
    "            'Longitude': center2[1] + np.random.randn() * 0.015\n",
    "        })\n",
    "    # Cluster 3 (sparse, might get split or remain single if large enough)\n",
    "    for _ in range(150):\n",
    "        customers_data.append({\n",
    "            'CustomerID': f'C3_{_}',\n",
    "            'Latitude': center3[0] + np.random.randn() * 0.02,\n",
    "            'Longitude': center3[1] + np.random.randn() * 0.02\n",
    "        })\n",
    "\n",
    "    customers_df = pd.DataFrame(customers_data)\n",
    "\n",
    "    print(\"--- Running Agglomerative Clustering ---\")\n",
    "    agg_clusterer = AgglomerativeGeographicClustering(\n",
    "        max_customers_per_cluster=50, # Aim for clusters of max 50 customers\n",
    "        max_distance_km=5.0,        # Max diameter of 5 km\n",
    "        linkage_method='ward',       # Common choice for compact clusters\n",
    "        sub_cluster_if_oversized=True\n",
    "    )\n",
    "    clustered_agg_df = agg_clusterer.agglomerative_clustering(customers_df.copy())\n",
    "    agg_stats = agg_clusterer.get_cluster_stats(clustered_agg_df, agg_clusterer.max_customers_per_cluster, agg_clusterer.max_distance_km)\n",
    "    print(\"\\nAgglomerative Clustering Stats:\")\n",
    "    for k, v in agg_stats['summary'].items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "    print(\"\\nSample Agglomerative Cluster Details:\")\n",
    "    for cluster_id, details in list(agg_stats.items())[:5]: # Show first 5 clusters\n",
    "        if cluster_id != 'summary':\n",
    "            print(f\"  Cluster {cluster_id}: Size={details['size']}, Diameter={details['diameter_km']:.2f} km, Size OK={details['meets_size_constraint']}, Distance OK={details['meets_distance_constraint']}\")\n",
    "\n",
    "    print(\"\\n--- Running Divisive Clustering (for comparison) ---\")\n",
    "    div_clusterer = OptimizedDivisiveGeographicClustering(\n",
    "        max_customers_per_cluster=50,\n",
    "        max_distance_km=5.0,\n",
    "        balance_clusters=True\n",
    "    )\n",
    "    clustered_div_df = div_clusterer.divisive_clustering(customers_df.copy())\n",
    "    div_stats = div_clusterer.get_cluster_stats(clustered_div_df, div_clusterer.max_customers_per_cluster, div_clusterer.max_distance_km) # Added missing arguments\n",
    "    print(\"\\nDivisive Clustering Stats:\")\n",
    "    for k, v in div_stats['summary'].items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "    print(\"\\nSample Divisive Cluster Details:\")\n",
    "    for cluster_id, details in list(div_stats.items())[:5]: # Show first 5 clusters\n",
    "        if cluster_id != 'summary':\n",
    "            print(f\"  Cluster {cluster_id}: Size={details['size']}, Diameter={details['diameter_km']:.2f} km, Size OK={details['meets_size_constraint']}, Distance OK={details['meets_distance_constraint']}\")\n",
    "\n",
    "    # --- Plotting the clusters (optional, requires matplotlib/folium) ---\n",
    "    # To visualize, you'd typically plot these clustered_agg_df or clustered_div_df\n",
    "    # on a map using Folium, similar to our routing visualization.\n",
    "    # For a quick visual check (requires matplotlib):\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        plt.figure(figsize=(15, 7))\n",
    "\n",
    "        # Plot Agglomerative Clusters\n",
    "        ax1 = plt.subplot(121)\n",
    "        for cluster_id in clustered_agg_df['cluster'].unique():\n",
    "            if cluster_id == -1: continue\n",
    "            cluster_points = clustered_agg_df[clustered_agg_df['cluster'] == cluster_id]\n",
    "            ax1.scatter(cluster_points['Longitude'], cluster_points['Latitude'], \n",
    "                        label=f'Agg C{cluster_id} (n={len(cluster_points)})', s=20, alpha=0.6)\n",
    "        ax1.set_title('Agglomerative Clusters')\n",
    "        ax1.set_xlabel('Longitude')\n",
    "        ax1.set_ylabel('Latitude')\n",
    "        ax1.grid(True)\n",
    "\n",
    "        # Plot Divisive Clusters\n",
    "        ax2 = plt.subplot(122)\n",
    "        for cluster_id in clustered_div_df['cluster'].unique():\n",
    "            if cluster_id == -1: continue\n",
    "            cluster_points = clustered_div_df[clustered_div_df['cluster'] == cluster_id]\n",
    "            ax2.scatter(cluster_points['Longitude'], cluster_points['Latitude'], \n",
    "                        label=f'Div C{cluster_id} (n={len(cluster_points)})', s=20, alpha=0.6)\n",
    "        ax2.set_title('Divisive Clusters')\n",
    "        ax2.set_xlabel('Longitude')\n",
    "        ax2.set_ylabel('Latitude')\n",
    "        ax2.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    except ImportError:\n",
    "        print(\"\\nMatplotlib not found. Skipping cluster visualization.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during plotting: {e}. Skipping cluster visualization.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da02ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
