{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "14f01705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from src.get_data import get_data \n",
    "from src.get_data import get_connection\n",
    "from datetime import datetime, timedelta\n",
    "from routing.routing_optimizer import RouteOptimizer\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score \n",
    "import folium\n",
    "from clustering.plot_cluster import create_enhanced_cluster_map\n",
    "from routing.routing import get_valhalla_routes_info, plot_routes_on_map\n",
    "import openrouteservice as ors\n",
    "import math\n",
    "import numpy as np\n",
    "import os \n",
    "from routingpy import Valhalla\n",
    "# client = ors.Client(key='5b3ce3597851110001cf62485a415b103df64104ad2680c9210ef936') \n",
    "\n",
    "import logging\n",
    "import pandas as pd\n",
    "from pyodbc import Connection\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "# from src.route_optimization import run_route_optimizer\n",
    "\n",
    "\n",
    "VALHALLA_BASE_URL = \"http://localhost:8002\" # Pointing to your self-hosted Valhalla\n",
    "VALHALLA_API_KEY = \"\" # No API key needed for your self-hosted instance\n",
    "\n",
    "\n",
    "CURRENT_DATE  = datetime.today().date() + timedelta(days=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a4fa03",
   "metadata": {},
   "source": [
    "## **Utils**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75e2ca2",
   "metadata": {},
   "source": [
    "#### Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d7cc1de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_invalid_coordinates_DEP(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Replaces invalid Latitude (< -90 or > 90) and Longitude (< -180 or > 180) values with 0.0.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame with 'Latitude' and 'Longitude' columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with corrected coordinate values.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    df.loc[(df['Latitude'] < -90) | (df['Latitude'] > 90), 'Latitude'] = 0.0\n",
    "    df.loc[(df['Longitude'] < -180) | (df['Longitude'] > 180), 'Longitude'] = 0.0\n",
    "\n",
    "\n",
    "    ### Nigeria \n",
    "    # ADD NIGERIA FILTER HERE\n",
    "    return df\n",
    "\n",
    "def clean_invalid_coordinates(df: pd.DataFrame, offset_degrees: float = 0.1) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Replaces invalid Latitude (< -90 or > 90) and Longitude (< -180 or > 180) values with 0.0.\n",
    "    Also replaces coordinates outside Nigeria's approximate boundaries (with an optional offset) with 0.0.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame with 'Latitude' and 'Longitude' columns.\n",
    "        offset_degrees (float): Degrees to add/subtract from the strict Nigeria boundary\n",
    "                                to expand the bounding box. Default is 0.1 degrees.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with corrected coordinate values.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Global invalid coordinate ranges\n",
    "    df.loc[(df['Latitude'] < -90) | (df['Latitude'] > 90), 'Latitude'] = 0.0\n",
    "    df.loc[(df['Longitude'] < -180) | (df['Longitude'] > 180), 'Longitude'] = 0.0\n",
    "\n",
    "    ### Nigeria Boundary Filter ###\n",
    "    # Approximate decimal degree boundaries for Nigeria\n",
    "    STRICT_NIGERIA_MIN_LAT = 4.10\n",
    "    STRICT_NIGERIA_MAX_LAT = 13.90\n",
    "    STRICT_NIGERIA_MIN_LON = 2.60\n",
    "    STRICT_NIGERIA_MAX_LON = 14.70\n",
    "\n",
    "    # Apply offset to expand the bounding box\n",
    "    NIGERIA_MIN_LAT = STRICT_NIGERIA_MIN_LAT - offset_degrees\n",
    "    NIGERIA_MAX_LAT = STRICT_NIGERIA_MAX_LAT + offset_degrees\n",
    "    NIGERIA_MIN_LON = STRICT_NIGERIA_MIN_LON - offset_degrees\n",
    "    NIGERIA_MAX_LON = STRICT_NIGERIA_MAX_LON + offset_degrees\n",
    "\n",
    "    # Identify coordinates outside Nigeria's expanded bounding box\n",
    "    # Condition for rows outside Nigeria's latitude range\n",
    "    outside_nigeria_lat = (df['Latitude'] < NIGERIA_MIN_LAT) | \\\n",
    "                          (df['Latitude'] > NIGERIA_MAX_LAT)\n",
    "\n",
    "    # Condition for rows outside Nigeria's longitude range\n",
    "    outside_nigeria_lon = (df['Longitude'] < NIGERIA_MIN_LON) | \\\n",
    "                          (df['Longitude'] > NIGERIA_MAX_LON)\n",
    "\n",
    "    # Combine conditions: if EITHER latitude OR longitude is outside Nigeria's expanded box,\n",
    "    # then set BOTH Latitude and Longitude for that row to 0.0.\n",
    "    # We apply this only to coordinates that are already globally valid (i.e., not 0.0).\n",
    "    df.loc[\n",
    "        (df['Latitude'] != 0.0) &\n",
    "        (df['Longitude'] != 0.0) &\n",
    "        (outside_nigeria_lat | outside_nigeria_lon),\n",
    "        ['Latitude', 'Longitude']\n",
    "    ] = 0.0\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "589e0f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df_customer_sku_recommendation_raw, \n",
    "                      df_customer_dim_with_affinity_score_raw, \n",
    "                      df_stockpoint_dim_raw,\n",
    "                      df_customer_score,\n",
    "                      df_kyc_customer) :\n",
    "    \n",
    "    df_customer_sku_recommendation_raw['Stock_Point_ID'] = df_customer_sku_recommendation_raw['Stock_Point_ID'].astype(int)\n",
    "    df_customer_dim_with_affinity_score_raw['Stock_Point_ID'] = df_customer_dim_with_affinity_score_raw['Stock_Point_ID'].astype(int)\n",
    "    df_stockpoint_dim_raw['Stock_Point_ID'] = df_stockpoint_dim_raw['Stock_Point_ID'].astype(int)\n",
    "    df_customer_score = df_customer_score.rename(columns={'StockPointID':'Stock_Point_ID'})\n",
    "    df_customer_score['Stock_Point_ID'] = df_customer_score['Stock_Point_ID'].astype(int)\n",
    "\n",
    "\n",
    "    # ----------------- CUSTOMER DIM TABLE \n",
    "    col_sel_affinity = ['Region', 'Stock_Point_ID', 'CustomerID']\n",
    "\n",
    "    col_sel_kyc = ['CustomerID', 'ContactName', 'BusinessName', 'CustomerModeName',\n",
    "        'CustomerRef', 'ContactPhone', 'CustomerType', 'FullAddress', \n",
    "        'StateName', 'CityName', 'TownName', 'Latitude','Longitude', \n",
    "        'DistanceVarianceInMeter', 'IsLocationSubmitted',\n",
    "        'IsLocationCaptured', 'IsLocationVerified','CustomerStatus',\n",
    "        'RejectReason',  'KYC_Capture_Status',  'lastDelvDate', \n",
    "        # 'hasPOS','hasVAS', 'hasBNPL', 'lastDelvDate', \n",
    "        'isActive']\n",
    "\n",
    "    col_sel_score = ['Stock_Point_ID', 'CustomerID', 'composite_customer_score',\n",
    "        'percentile_rank', 'active_months_pct', 'avg_orders_per_active_month',\n",
    "        'avg_qty_per_month', 'avg_revenue_per_month', 'days_since_last_order']\n",
    "\n",
    "    df_master_customer_dim = (\n",
    "                df_customer_dim_with_affinity_score_raw[col_sel_affinity]\n",
    "                .merge(df_kyc_customer[col_sel_kyc], how='inner', on=['CustomerID'])\n",
    "                .merge(df_customer_score[col_sel_score], how='left', on=['Stock_Point_ID', 'CustomerID'])\n",
    "                .rename(columns = {'CityName':'LGA',\n",
    "                                'TownName':'LCDA'\n",
    "                                })\n",
    "\n",
    "            )\n",
    "\n",
    "    # Change CustomerPurchaseRecency from lastDelvDate to days since last order (order creation date)\n",
    "    df_master_customer_dim['CustomerPurchaseRecency'] =  df_master_customer_dim['days_since_last_order']\n",
    "    # df_master_customer_dim['CustomerPurchaseRecency'] =  df_master_customer_dim['lastDelvDate'].apply(lambda x: (datetime.now() - x).days)\n",
    "    df_master_customer_dim['CustomerPurchaseRecency'] = df_master_customer_dim['CustomerPurchaseRecency'].fillna(max(df_master_customer_dim['CustomerPurchaseRecency']))\n",
    "    df_master_customer_dim['KYC_Capture_Status'] = df_master_customer_dim['KYC_Capture_Status'].apply(lambda x: 'Yes' if x == 1 else 'No')\n",
    "\n",
    "    # Add to Score\n",
    "    # Fix Missing value -------------------------------------------\n",
    "    for col in ['BusinessName', 'CustomerModeName', 'FullAddress', 'LGA', 'LCDA']:\n",
    "        df_master_customer_dim[col] = df_master_customer_dim[col].fillna('')\n",
    "\n",
    "    for col in ['Latitude',  'Longitude', 'composite_customer_score',  \n",
    "                'percentile_rank',  'active_months_pct', 'avg_orders_per_active_month',  \n",
    "                'avg_qty_per_month',  'avg_revenue_per_month'\n",
    "                ]:\n",
    "        df_master_customer_dim[col] = pd.to_numeric(df_master_customer_dim[col], errors='coerce').fillna(0) \n",
    "\n",
    "    df_master_customer_dim = clean_invalid_coordinates(df_master_customer_dim)\n",
    "    \n",
    "    # Add to Score \n",
    "    # Boost composite score and percentile rank for customers with completed KYC\n",
    "    mask_kyc = df_master_customer_dim['KYC_Capture_Status'] == 'Yes'\n",
    "\n",
    "    df_master_customer_dim.loc[mask_kyc, 'composite_customer_score'] += 5\n",
    "    df_master_customer_dim.loc[mask_kyc, 'percentile_rank'] += 0.1 \n",
    "\n",
    "    # ----------------- RECOMMENDATION\n",
    "    col2 = ['EstimatedQuantity', 'CustomerSKUscore', 'CustomerSKUscoreStandardize', 'CustomerSKUscoreRank']\n",
    "    for col in col2: \n",
    "        df_customer_sku_recommendation_raw[col] = pd.to_numeric(df_customer_sku_recommendation_raw[col], errors='coerce')\n",
    "\n",
    "    df_customer_sku_recommendation_raw['LastDeliveredDate'] = pd.to_datetime(df_customer_sku_recommendation_raw['LastDeliveredDate'])\n",
    "    # Get today's date\n",
    "    today = pd.Timestamp.today()\n",
    "\n",
    "    df_customer_sku_recommendation_raw['Recency'] = df_customer_sku_recommendation_raw['LastDeliveredDate'].apply(lambda x: (datetime.now() - x).days)\n",
    "    df_customer_sku_recommendation_raw['Recency'] = df_customer_sku_recommendation_raw['Recency'].fillna(max(df_customer_sku_recommendation_raw['Recency']))\n",
    "    \n",
    "    # ----------------- STOCKPOINT\n",
    "    df_stockpoint_dim_raw.rename(columns={'lattitude':'Latitude', 'longitude':'Longitude'}, inplace=True) \n",
    "    col3 = ['Latitude', 'Longitude']\n",
    "    for col in col3: \n",
    "        df_stockpoint_dim_raw[col] = pd.to_numeric(df_stockpoint_dim_raw[col], errors='coerce').fillna(0)    \n",
    "\n",
    "    # Replace invalid latitude values with NaN\n",
    "    df_stockpoint_dim_raw = clean_invalid_coordinates(df_stockpoint_dim_raw)   \n",
    "    \n",
    "\n",
    "    return df_customer_sku_recommendation_raw, df_master_customer_dim, df_stockpoint_dim_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "50d39f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_filter(df_customer_sku_recommendation, df_master_customer_dim, df_stockpoint_dim,\n",
    "                stockpoint_id,  sku_recency = 7, customer_recency = 90, number_recommendation = 5,\n",
    "                estimate_qty_scale_factor = .90, max_estimated_qty = 5, exclude_recency_customer = 4):\n",
    "    \n",
    "    df_customer_sku_recommendation = df_customer_sku_recommendation.copy().query(f'Stock_Point_ID == {stockpoint_id}')\n",
    "    # Filter Recommendation\n",
    "    df_customer_sku_recommendation = df_customer_sku_recommendation[df_customer_sku_recommendation['ProductTag'] != 'Standard-Inactive']\n",
    "    df_customer_sku_recommendation = df_customer_sku_recommendation[df_customer_sku_recommendation['Medium'] != 'Never Purchased']\n",
    "\n",
    "    # Filter customer base\n",
    "    df_master_customer_dim['valid_for_push'] = np.where(\n",
    "                                                    #  df_master_customer_dim['KYC_Capture_Status'] == 'Yes'   \n",
    "                                                    (\n",
    "                                                        (df_master_customer_dim['IsLocationCaptured'] == 'Yes') |\n",
    "                                                        (df_master_customer_dim['DistanceVarianceInMeter'] <= 150.0) |\n",
    "                                                        (df_master_customer_dim['KYC_Capture_Status'] == 'Yes') |\n",
    "                                                        (df_master_customer_dim['CustomerPurchaseRecency'] <= customer_recency)\n",
    "                                                    )\n",
    "                                                    ,1,0\n",
    "                                                )\n",
    "    # df_master_customer_dim = df_master_customer_dim[df_master_customer_dim['CustomerPurchaseRecency'] <= customer_recency]\n",
    "    df_master_customer_dim = df_master_customer_dim.query('valid_for_push == 1')  \n",
    "    # Exclude Customer with recent purchase of any SKU\n",
    "    df_master_customer_dim = df_master_customer_dim.query(f'CustomerPurchaseRecency > {exclude_recency_customer}')\n",
    "    # Customer with valid Location Coordination\n",
    "    df_master_customer_dim = df_master_customer_dim.query('Latitude != 0').reset_index(drop=True)\n",
    "    \n",
    "    # # Clipping Max Estimated Quantity to 10 qty\n",
    "    df_customer_sku_recommendation['EstimatedQuantity_bck'] = df_customer_sku_recommendation['EstimatedQuantity']\n",
    "    df_customer_sku_recommendation['EstimatedQuantity'] = df_customer_sku_recommendation['EstimatedQuantity'].apply(lambda x: max_estimated_qty if int((x*estimate_qty_scale_factor)) > max_estimated_qty else int((x*estimate_qty_scale_factor)) )\n",
    "\n",
    "\n",
    "    # Select top 10 SKU by SKURank per customer\n",
    "    df_customer_sku_recommendation = (\n",
    "        df_customer_sku_recommendation\n",
    "        .query('EstimatedQuantity > 1')\n",
    "        .sort_values(['CustomerID','CustomerSKUscoreRank'])\n",
    "        .groupby('CustomerID', group_keys=False)\n",
    "        .head(number_recommendation)\n",
    "        .reset_index(drop=True) \n",
    "    )\n",
    "\n",
    "    df_customer_sku_recommendation_ = df_master_customer_dim.merge(df_customer_sku_recommendation, how='inner', on = ['CustomerID','Stock_Point_ID'])  \n",
    "\n",
    "    df_stockpoint_dim = df_stockpoint_dim.query(f'Stock_Point_ID == {stockpoint_id}').reset_index(drop=True) \n",
    "    \n",
    "\n",
    "    df_customer_dim = df_master_customer_dim.merge(df_customer_sku_recommendation_['CustomerID'].drop_duplicates(), how='inner', on = 'CustomerID')\n",
    "    # df_customer_dim = df_customer_dim.merge(df_customer_dim_with_affinity_score[sel_cols], how='inner', on = 'CustomerID').reset_index(drop = True) \n",
    "    \n",
    "    print(f'Total Quantity before filter: {df_customer_sku_recommendation.query(f\"Stock_Point_ID == {stockpoint_id}\").EstimatedQuantity.sum():,}')\n",
    "    print(f'Total Quantity: {df_customer_sku_recommendation_.EstimatedQuantity.sum():,}')\n",
    "    print(f'Total Number of Customers before filter: {df_customer_sku_recommendation.query(f\"Stock_Point_ID == {stockpoint_id}\").CustomerID.nunique():,}')\n",
    "    print(f'Total Number of Customers: {df_customer_dim.CustomerID.nunique():,}')\n",
    "\n",
    " \n",
    "    return df_customer_sku_recommendation_, df_customer_dim,   df_stockpoint_dim  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b10555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a26754f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_data(\n",
    "        selected_trip,\n",
    "        all_push_recommendation,\n",
    "        cluster_summary,\n",
    "        stock_point_name\n",
    "    ): \n",
    "    dir_path = f'./recommendation_output/{CURRENT_DATE}'\n",
    "    \n",
    "    # Ensure directory exists\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    \n",
    "    file_path = f'{dir_path}/{stock_point_name}_{CURRENT_DATE}.xlsx'\n",
    "\n",
    "    with pd.ExcelWriter(file_path) as writer:\n",
    "        selected_trip.to_excel(writer, sheet_name='Selected Trip', index=False)\n",
    "        all_push_recommendation.to_excel(writer, sheet_name='All Recommendation', index=False)\n",
    "        cluster_summary.to_excel(writer, sheet_name='Recommendation Cluster Summary', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939127f3",
   "metadata": {},
   "source": [
    "#### Map-Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7525cc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_and_save(df_routes, \n",
    "                 df_stockpoint = None,   \n",
    "                 filename=None,\n",
    "                 cluster_col='cluster'):\n",
    "    \n",
    "    map_clusters = create_enhanced_cluster_map(\n",
    "        df_routes,\n",
    "        popup_cols=['CustomerID', 'LGA', 'LCDA'],\n",
    "        tooltip_cols=['LGA', 'LCDA'], \n",
    "        cluster_col = cluster_col,\n",
    "        zoom_start=10, \n",
    "        radius=8\n",
    "    )\n",
    "    \n",
    "    if df_stockpoint:\n",
    "        depot_location = [df_stockpoint.Latitude[0], df_stockpoint.Longitude[0]]\n",
    "        depot_name = df_stockpoint.Stock_point_Name[0]\n",
    "        map_clusters = map_clusters.add_child(folium.Marker(location=depot_location, \n",
    "                                size = 10, \n",
    "                                tooltip=depot_name, \n",
    "                                icon=folium.Icon(color=\"green\", \n",
    "                                icon=\"home\")))  \n",
    "    if filename:\n",
    "        map_clusters.save(filename)\n",
    "    return map_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ff9846",
   "metadata": {},
   "source": [
    "#### Cluster Summary Route-Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ee878c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_unsupervised_clustering(df):\n",
    "    # Usage:\n",
    "    X = df[['Latitude', 'Longitude']].values\n",
    "    labels = df['cluster'].values\n",
    "    scores = {\n",
    "        \"Silhouette Score\":  silhouette_score(X, labels).round(2),\n",
    "        \"Davies-Bouldin Index\": davies_bouldin_score(X, labels).round(2),\n",
    "        \"Calinski-Harabasz Score\": calinski_harabasz_score(X, labels).round(2)\n",
    "    }\n",
    "\n",
    "    for key in scores:\n",
    "        print(f\"{key}: {scores[key]}\")\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b65cbb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stockpoint_dict(df_selected_trip, df_stockpoint_dim):\n",
    "    \"\"\"\n",
    "    Create a dictionary structure with stock point information and associated trips.\n",
    "    \n",
    "    Parameters:\n",
    "    df_selected_trip: DataFrame with columns ['StockPointID', 'StockPointName', 'TripID', 'CustomerID', 'Latitude', 'Longitude', 'EstimatedQuantity']\n",
    "    df_stockpoint_dim: DataFrame with columns ['Stock_Point_ID', 'Stock_point_Name', 'Latitude', 'Longitude']\n",
    "    \n",
    "    Returns:\n",
    "    dict: Dictionary with stock point information and trips\n",
    "    \"\"\"\n",
    "    if df_selected_trip.empty:\n",
    "        logger.info('Dataframe is empty')\n",
    "        return {}\n",
    "    \n",
    "    # Group by StockPointID to handle each stock point\n",
    "    stockpoint_groups = df_selected_trip.groupby('StockPointID')\n",
    "    \n",
    "    result = {}\n",
    "    \n",
    "    for stock_point_id, group in stockpoint_groups:\n",
    "        # Get stock point information from df_stockpoint_dim\n",
    "        stock_point_info = df_stockpoint_dim[df_stockpoint_dim['Stock_Point_ID'] == stock_point_id]\n",
    "        \n",
    "        if stock_point_info.empty:\n",
    "            # If stock point not found in dimension table, use info from selected_trip\n",
    "            stock_point_name = group['StockPointName'].iloc[0]\n",
    "            # Note: We'll need to get coordinates from somewhere since customer coordinates \n",
    "            # in df_selected_trip are for destinations, not stock points\n",
    "            stock_point_coord = [0, 0]  # Placeholder - you may need to adjust this\n",
    "        else:\n",
    "            stock_point_name = stock_point_info['Stock_point_Name'].iloc[0]\n",
    "            stock_point_coord = [\n",
    "                stock_point_info['Longitude'].iloc[0], \n",
    "                stock_point_info['Latitude'].iloc[0]\n",
    "            ]\n",
    "        \n",
    "        # Group by TripID to organize trips\n",
    "        trip_groups = group.groupby('TripID')\n",
    "        trips = []\n",
    "        \n",
    "        for trip_id, trip_group in trip_groups:\n",
    "            # Create destinations list for this trip\n",
    "            destinations = []\n",
    "            for _, row in trip_group.iterrows():\n",
    "                destination = {\n",
    "                    'CustomerID': row['CustomerID'],\n",
    "                    'Coordinate': [row['Longitude'], row['Latitude']]\n",
    "                }\n",
    "                destinations.append(destination)\n",
    "            \n",
    "            # Create trip dictionary\n",
    "            trip_dict = {\n",
    "                'TripID': trip_id,\n",
    "                'Destinations': destinations\n",
    "            }\n",
    "            trips.append(trip_dict)\n",
    "        \n",
    "        # Create the final dictionary structure for this stock point\n",
    "        result[stock_point_id] = {\n",
    "            'StockPointName': stock_point_name,\n",
    "            'StockPointID': stock_point_id,\n",
    "            'StockPointCoord': stock_point_coord,\n",
    "            'Trips': trips\n",
    "        }\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# Alternative version if you want a single dictionary (assuming only one stock point)\n",
    "def create_single_stockpoint_dict(df_selected_trip, df_stockpoint_dim):\n",
    "    \"\"\"\n",
    "    Create a single dictionary structure for one stock point.\n",
    "    \n",
    "    Parameters:\n",
    "    df_selected_trip: DataFrame with trip data for one stock point\n",
    "    df_stockpoint_dim: DataFrame with stock point dimension data\n",
    "    \n",
    "    Returns:\n",
    "    dict: Single dictionary with stock point information and trips\n",
    "    \"\"\"\n",
    "    if df_selected_trip.empty:\n",
    "        logger.info('Dataframe is empty')\n",
    "        return {}\n",
    "    \n",
    "    # Get the stock point ID (assuming all rows have the same stock point)\n",
    "    stock_point_id = df_selected_trip['StockPointID'].iloc[0]\n",
    "    \n",
    "    # Get stock point information from df_stockpoint_dim\n",
    "    stock_point_info = df_stockpoint_dim[df_stockpoint_dim['Stock_Point_ID'] == stock_point_id]\n",
    "    \n",
    "    if stock_point_info.empty:\n",
    "        stock_point_name = df_selected_trip['StockPointName'].iloc[0]\n",
    "        stock_point_coord = [0, 0]  # Placeholder\n",
    "    else:\n",
    "        stock_point_name = stock_point_info['Stock_point_Name'].iloc[0] \n",
    "        stock_point_coord = [\n",
    "            stock_point_info['Longitude'].iloc[0], \n",
    "            stock_point_info['Latitude'].iloc[0]\n",
    "        ]\n",
    "    \n",
    "    # Group by TripID\n",
    "    trip_groups = df_selected_trip.groupby('TripID')\n",
    "    trips = []\n",
    "    \n",
    "    for trip_id, trip_group in trip_groups:\n",
    "        destinations = []\n",
    "        for _, row in trip_group.iterrows():\n",
    "            destination = {\n",
    "                'CustomerID': row['CustomerID'],\n",
    "                'Coordinate': [row['Longitude'], row['Latitude']]\n",
    "            }\n",
    "            destinations.append(destination)\n",
    "        \n",
    "        trip_dict = {\n",
    "            'TripID': trip_id,\n",
    "            'Destinations': destinations\n",
    "        }\n",
    "        trips.append(trip_dict)\n",
    "    \n",
    "    # Return the final dictionary\n",
    "    return {\n",
    "        'StockPointName': stock_point_name,\n",
    "        'StockPointID': stock_point_id,\n",
    "        'StockPointCoord': stock_point_coord,\n",
    "        'Trips': trips\n",
    "    }\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# \"\"\"\n",
    "# # For multiple stock points:\n",
    "# result_dict = create_stockpoint_dict(df_selected_trip, df_stockpoint_dim)\n",
    "\n",
    "# # For a single stock point:\n",
    "# single_result = create_single_stockpoint_dict(df_selected_trip, df_stockpoint_dim)\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7f4c7281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_route(df_selected_trip, df_stockpoint_dim):\n",
    "    # Path \n",
    "    main_dir = f'./recommendation_output/selected_trip_map/{CURRENT_DATE}' \n",
    "    os.makedirs(f'{main_dir}', exist_ok=True)\n",
    "\n",
    "\n",
    "    trip_dict = create_single_stockpoint_dict(df_selected_trip, df_stockpoint_dim) \n",
    "\n",
    "    if trip_dict == {}:\n",
    "        logger.info('Trip Data is empty')\n",
    "    else:\n",
    "        try:\n",
    "            StockPointID = trip_dict['StockPointID']\n",
    "            output_filename = f'{main_dir}/{StockPointID}.html'\n",
    "            # Step 1: Get route information for all trips\n",
    "            calculated_routes_info = get_valhalla_routes_info(trip_dict)\n",
    "\n",
    "            # Step 2: Plot all routes on a map\n",
    "            plot_routes_on_map(trip_data=trip_dict, routes_info=calculated_routes_info, output_filename = output_filename)\n",
    "        except Exception as e:\n",
    "            logger.warn(f'Some vital error occured while creating route {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dce62501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_route_optimizer(df_clustering, sel_cluster_tuple, df_stockpoint, \n",
    "                        stock_point_name,\n",
    "                        sel_total_customer_count, capacity_size = 20):\n",
    "     # ---- SETUP CLIENT\n",
    "     try:\n",
    "          client = Valhalla(base_url=VALHALLA_BASE_URL)\n",
    "          if VALHALLA_API_KEY:\n",
    "               client = Valhalla(base_url=VALHALLA_BASE_URL, api_key=VALHALLA_API_KEY)\n",
    "          \n",
    "          logger.info('Setting up routing client via LOCAL host Valhalla')\n",
    "     except Exception as e:\n",
    "          logger.warning('Setting up routing client via ORS')\n",
    "          client = ors.Client(key=os.getenv('ORS_KEY')) \n",
    "\n",
    "     # Select cluster 37\n",
    "     df_sel_clust = df_clustering.query(f'cluster in {sel_cluster_tuple}').query('Latitude > 0')\n",
    "\n",
    "     # Ensure coordinates are in [longitude, latitude] for ORS\n",
    "     coords = [[lon, lat] for lat, lon in zip(df_sel_clust.Latitude, df_sel_clust.Longitude)]\n",
    "     # Print number of jobs\n",
    "     print(\"Number of customer locations:\", len(coords))\n",
    "     # Convert depot_location to ORS format\n",
    "     # Assuming depot_location is [lat, lon], flip to [lon, lat]\n",
    "     vehicle_start = [df_stockpoint.Longitude[0], df_stockpoint.Latitude[0]]\n",
    "     num_vehicles = math.floor(sel_total_customer_count / capacity_size)\n",
    "     vehicles = [\n",
    "          ors.optimization.Vehicle(\n",
    "               id=i,\n",
    "               profile='driving-car',\n",
    "               start=vehicle_start,\n",
    "               end=vehicle_start,\n",
    "               capacity=[capacity_size]\n",
    "          ) for i in range(num_vehicles)\n",
    "     ]\n",
    "\n",
    "     # Define jobs (each customer gets amount=[1])\n",
    "     jobs = [ors.optimization.Job(id=index, location=coord, amount=[1]) for index, coord in enumerate(coords)]\n",
    "\n",
    "     # Call ORS optimization API\n",
    "     optimized = client.optimization(jobs=jobs, vehicles=vehicles, geometry=True)\n",
    "\n",
    "     #     ------ MAP\n",
    "     depot_location = [df_stockpoint.Latitude[0], df_stockpoint.Longitude[0]]\n",
    "     depot_name = df_stockpoint.Stock_point_Name[0]\n",
    "\n",
    "     map_clusters_route = create_enhanced_cluster_map(\n",
    "     df_sel_clust,\n",
    "     popup_cols=['CustomerID', 'LGA', 'LCDA'],\n",
    "     tooltip_cols=['LGA', 'LCDA'], \n",
    "     zoom_start=10, \n",
    "     radius=10\n",
    "     ).add_child(folium.Marker(location=depot_location, \n",
    "                         size = 10, \n",
    "                         tooltip=depot_name, \n",
    "                         icon=folium.Icon(color=\"green\", \n",
    "                         icon=\"home\")))\n",
    "\n",
    "     # line_colors = ['green', 'orange', 'blue', 'yellow']\n",
    "     separable_colors = [\n",
    "          \"#1f77b4\",  # blue\n",
    "          \"#ff7f0e\",  # orange\n",
    "          \"#2ca02c\",  # green\n",
    "          \"#d62728\",  # red\n",
    "          \"#9467bd\",  # purple\n",
    "          \"#8c564b\",  # brown\n",
    "          \"#e377c2\",  # pink\n",
    "          \"#7f7f7f\",  # gray\n",
    "          \"#bcbd22\",  # yellow-green\n",
    "          \"#17becf\",  # cyan\n",
    "          \"#aec7e8\",  # light blue\n",
    "          \"#ffbb78\",  # light orange\n",
    "          ]\n",
    "\n",
    "     line_colors = separable_colors[0:num_vehicles] #['green', 'orange', 'blue', 'yellow']\n",
    "     for route in optimized['routes']:\n",
    "          folium.PolyLine(locations=[list(reversed(coords)) for coords in ors.convert.decode_polyline(route['geometry'])['coordinates']], color=line_colors[route['vehicle']]).add_to(map_clusters_route)\n",
    "\n",
    "     #\n",
    "     selected_trip_map_path = f'./recommendation_output/selected_trip_map/{stock_point_name}_{CURRENT_DATE}.html' \n",
    "     map_clusters_route.save(selected_trip_map_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b107eaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_trip_route(df_sku_rec, \n",
    "                       df_customer_dim, \n",
    "                       df_stockpoint,\n",
    "                       stock_point_id,\n",
    "                       max_customers_per_route, \n",
    "                       max_volume_per_route,\n",
    "                       max_distance_km, \n",
    "                       clustering_method='divisive',\n",
    "                       skip_route_optimization = False):\n",
    "     \n",
    "\n",
    "    optimizer = RouteOptimizer(\n",
    "        max_customers_per_route=max_customers_per_route,\n",
    "        max_volume_per_route=max_volume_per_route,\n",
    "        max_distance_km = max_distance_km\n",
    "    )\n",
    "\n",
    "    optimizer.load_data(df_sku_rec, df_customer_dim, df_stockpoint)\n",
    "    print(\"✓ Route optimizer initialized\")\n",
    "\n",
    "    # STEP 3: Generate Routes for Stock Point 1647113\n",
    "    print(\"\\n3. Generating Optimized Routes...\")\n",
    "    print(\"-\" * 40) \n",
    "\n",
    "    stock_point = df_stockpoint[df_stockpoint['Stock_Point_ID'] == stock_point_id].reset_index(drop = True)\n",
    "    \n",
    "    stock_point_coords = (stock_point['Latitude'], stock_point['Longitude'])\n",
    "        \n",
    "    clustering_customers_df = optimizer.filter_customers_for_stockpoint(stock_point_id)\n",
    "\n",
    "    df_clustering, n_clusters = optimizer.create_geographic_clusters(clustering_customers_df, \n",
    "                                                                     clustering_method = clustering_method)\n",
    "\n",
    "    if skip_route_optimization == True:\n",
    "        routes = optimizer.generate_multi_trip_routes(stock_point_id, \n",
    "                                                    max_trips=5, \n",
    "                                                    clustering_method=clustering_method)\n",
    "        df_routes = pd.DataFrame(routes)\n",
    "    else:\n",
    "        df_routes = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "    # STEP 4: Analyze Results\n",
    "    print(\"\\n4. Route Analysis & Results...\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    push_recommendation = df_sku_rec.merge(df_clustering[['Stock_Point_ID','CustomerID', 'cluster']], \n",
    "                                           how='inner', on =['Stock_Point_ID','CustomerID'] )\n",
    "    \n",
    "    ### Cluster Evaluation\n",
    "    try:\n",
    "        evaluate_unsupervised_clustering(df_clustering)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return push_recommendation, df_clustering, df_routes, stock_point_coords\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1bc8a429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_summary_and_selection(push_recommendation,\n",
    "                                  sel_trip_cluster,\n",
    "                                  min_ncust_per_cluster = 4\n",
    "                                  ):\n",
    "    ### Cluster Summary \n",
    "    cluster_summary = (\n",
    "        push_recommendation\n",
    "        .groupby('cluster').agg(\n",
    "            LGA_list = ('LGA', lambda x: x.unique().tolist()),\n",
    "            LCDA_List = ('LCDA', lambda x: x.unique().tolist()),\n",
    "            ncustomer = ('CustomerID','nunique'),\n",
    "            totalQty = ('EstimatedQuantity','sum'), \n",
    "            avg_customer_score = ('composite_customer_score','mean'),\n",
    "        )\n",
    "        .reset_index()\n",
    "        .sort_values(['avg_customer_score','ncustomer', 'totalQty'], \n",
    "                     ascending=[False, False, False])\n",
    "        )\n",
    "\n",
    "    ### Select Trip   \n",
    "    df_high_value_cluster_summary = (\n",
    "            cluster_summary\n",
    "            .query(f'ncustomer >= {min_ncust_per_cluster}')\n",
    "            .head(max(10, sel_trip_cluster))\n",
    "            .reset_index(drop = True)\n",
    "        )\n",
    "    sel_cluster_tuple = df_high_value_cluster_summary.cluster[0:sel_trip_cluster].to_list()\n",
    "    sel_total_customer_count = df_high_value_cluster_summary.head(sel_trip_cluster).ncustomer.sum()\n",
    "    print(f'''Select ClusterIDs: {sel_cluster_tuple}''')\n",
    "    print(f'''Total Number of Customers: {sel_total_customer_count}''')\n",
    "    print(df_high_value_cluster_summary.head(sel_trip_cluster))\n",
    "\n",
    "    return cluster_summary, df_high_value_cluster_summary, sel_cluster_tuple, sel_total_customer_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "171a5cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_selected_trip(push_recommendation, \n",
    "                       cluster_summary,\n",
    "                       df_master_customer_dim,  \n",
    "                       df_stockpoint,\n",
    "                       sel_cluster_tuple):\n",
    "    \n",
    "        \n",
    "\n",
    "    sel_columns = ['Stock_Point_ID', \n",
    "                'StateName', # 'Region', \n",
    "                'Latitude', 'Longitude', 'LGA', 'LCDA', 'cluster', \n",
    "                'CustomerID', 'SKUID', 'ProductName', 'Output',\n",
    "                'LastDeliveredDate', 'Recency', 'InventoryCheck', 'ProductTag', 'Medium',\n",
    "                'EstimatedQuantity', \n",
    "                # 'CustomerSKUscoreRank'\n",
    "                ]\n",
    "\n",
    "    sel_cols_cust= ['Stock_Point_ID', 'CustomerID', 'ContactName',  'CustomerModeName',   'ContactPhone', 'FullAddress', \n",
    "                    'composite_customer_score', 'percentile_rank',  'KYC_Capture_Status', 'CustomerPurchaseRecency']\n",
    "\n",
    "    final_cols = ['Stock_Point_ID', 'Stock_point_Name', 'TripID', 'LGA_list', 'LCDA_List', \n",
    "                  'ncustomer', 'totalQty','avg_customer_score', 'CustomerID', 'ContactName',  \n",
    "                  'CustomerModeName',   'ContactPhone', 'FullAddress', 'Latitude',\n",
    "                  'Longitude', 'LGA', 'LCDA', 'composite_customer_score', #, 'percentile_rank',  \n",
    "                  'KYC_Capture_Status', 'SKUID', 'ProductName', #'Output', 'LastDeliveredDate', \n",
    "                  'Recency','CustomerPurchaseRecency', 'InventoryCheck', 'ProductTag', 'Medium', 'EstimatedQuantity',\n",
    "                ]\n",
    "    \n",
    "    def _merge_select(df):\n",
    "        modified_df = (\n",
    "                        df[sel_columns]\n",
    "                        .merge(cluster_summary, how='left', on = 'cluster' )\n",
    "                        .merge(df_master_customer_dim[sel_cols_cust], how='left', on = ['Stock_Point_ID', 'CustomerID'])\n",
    "                        .merge(df_stockpoint[['Stock_Point_ID', 'Stock_point_Name']], how='left', on = ['Stock_Point_ID'])\n",
    "                        .rename(columns={'cluster':'TripID'})\n",
    "                        [final_cols]\n",
    "                        .rename(columns = {\n",
    "                                           'Stock_point_Name': 'StockPointName'\n",
    "                                           ,'Stock_Point_ID': 'StockPointID'\n",
    "                                           ,'ncustomer': 'TotalCustonerCount'\n",
    "                                           ,'totalQty': 'TripTotalQuantity'\n",
    "                                           ,'avg_customer_score': 'TripAvgCustomerScore'\n",
    "                                           ,'LastDeliveredDate': 'CustomerLastDeliveredDate'\n",
    "                                           ,'Medium': 'RecommendationType'\n",
    "                                           ,'Recency': 'SKUDaysSinceLastBuy'\n",
    "                                           ,'CustomerPurchaseRecency': 'CustomerDaysSinceLastBuy'\n",
    "                                           ,'composite_customer_score': 'CustomerScore'\n",
    "                                           ,'KYC_Capture_Status': 'kycCaptureStatus'\n",
    "                                           ,'LGA_list': 'ClusterLGAs'\n",
    "                                           ,'LCDA_List': 'ClusterLCDAs'\n",
    "                                           })\n",
    "                        )\n",
    "        return modified_df\n",
    "\n",
    "    df_selected_trip = push_recommendation[push_recommendation['cluster'].isin(sel_cluster_tuple)]\n",
    "    selected_push_recommendation_trip = _merge_select(df_selected_trip)\n",
    "    all_push_recommendation =  _merge_select(push_recommendation)\n",
    "    all_push_recommendation['isTripSelected'] = np.where(all_push_recommendation['TripID'].isin(sel_cluster_tuple) ,\n",
    "                                                    'Yes',\n",
    "                                                    'No'\n",
    "                                                )\n",
    "    \n",
    "\n",
    "    return selected_push_recommendation_trip, all_push_recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762d067f",
   "metadata": {},
   "source": [
    "### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bd91edc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_push_recommendation(df_customer_sku_recommendation, \n",
    "                            df_master_customer_dim, \n",
    "                            df_stockpoint_dim, \n",
    "                            stock_point_id,\n",
    "                            stock_point_name,\n",
    "                            sku_recency = 7, \n",
    "                            customer_recency = 60, number_recommendation = 5, \n",
    "                            estimate_qty_scale_factor = 1, max_estimated_qty = 5, \n",
    "                            exclude_recency_customer = 4,\n",
    "                            max_customers_per_route=20,\n",
    "                            max_volume_per_route=300,\n",
    "                            max_distance_km = 40,\n",
    "                            sel_trip_cluster = 5,\n",
    "                            min_ncust_per_cluster = 5,\n",
    "                            clustering_method = 'divisive',\n",
    "                            skip_route_optimization = False):\n",
    "    \"\"\"\n",
    "    Main execution function demonstrating complete route optimization workflow\n",
    "    \"\"\" \n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\")\n",
    "    print(f\"StockPoint: {stock_point_name}, StockPointID: {stock_point_id},\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # STEP 1: Load or Generate Data\n",
    "    print(\"\\n1. Loading Data...\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    df_sku_rec, df_customer_dim, df_stockpoint  = data_filter(df_customer_sku_recommendation, \n",
    "                                                                df_master_customer_dim, \n",
    "                                                                df_stockpoint_dim, \n",
    "                                                                stockpoint_id = stock_point_id,  \n",
    "                                                                sku_recency = sku_recency, \n",
    "                                                                customer_recency = customer_recency, \n",
    "                                                                number_recommendation = number_recommendation,\n",
    "                                                                estimate_qty_scale_factor = estimate_qty_scale_factor, \n",
    "                                                                max_estimated_qty = max_estimated_qty,\n",
    "                                                                exclude_recency_customer = exclude_recency_customer)\n",
    "\n",
    "    if len(df_customer_dim) < min_ncust_per_cluster:\n",
    "        return {}\n",
    "    \n",
    "    print(f\"✓ Loaded {len(df_sku_rec)} SKU recommendations\")\n",
    "    print(f\"✓ Loaded {len(df_customer_dim)} customer records\")\n",
    "    print(f\"✓ Loaded {len(df_stockpoint)} stock points\")\n",
    "\n",
    "    push_recommendation, df_clustering, df_routes, stock_point_coords = cluster_trip_route(df_sku_rec, \n",
    "                                                                                            df_customer_dim, \n",
    "                                                                                            df_stockpoint,\n",
    "                                                                                            stock_point_id,\n",
    "                                                                                            max_customers_per_route, \n",
    "                                                                                            max_volume_per_route,\n",
    "                                                                                            max_distance_km,\n",
    "                                                                                            clustering_method,\n",
    "                                                                                            skip_route_optimization)\n",
    "\n",
    "    ### Cluster Evaluation\n",
    "    try:\n",
    "        evaluate_unsupervised_clustering(df_clustering)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    ### Cluster Summary \n",
    "    cluster_summary, df_high_value_cluster_summary, sel_cluster_tuple, sel_total_customer_count = cluster_summary_and_selection(\n",
    "                                                                                                        push_recommendation,\n",
    "                                                                                                        sel_trip_cluster,\n",
    "                                                                                                        min_ncust_per_cluster = min_ncust_per_cluster\n",
    "                                                                                                        )\n",
    "\n",
    "    ## Trip\n",
    "    selected_push_recommendation_trip, all_push_recommendation = prep_selected_trip(push_recommendation, \n",
    "                                                  cluster_summary, \n",
    "                                                  df_master_customer_dim,  \n",
    "                                                  df_stockpoint,\n",
    "                                                  sel_cluster_tuple)\n",
    "    \n",
    " \n",
    "    ### Trip Maps\n",
    "    if skip_route_optimization:\n",
    "        try:\n",
    "            df_selected_trip_summary =  selected_push_recommendation_trip.groupby(['StockPointID','TripID', \n",
    "                                                                                   'CustomerID', 'Latitude','Longitude',\n",
    "                                                                                   'LGA', 'LCDA','CustomerScore']).agg( \n",
    "                        TotalQuantity = ('EstimatedQuantity','sum')\n",
    "                        ,TotalSKU = ('SKUID','nunique')\n",
    "                    ).reset_index()\n",
    "            create_route(df_selected_trip_summary, df_stockpoint)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    else:\n",
    "        try:\n",
    "            trip_map_path = f'./recommendation_output/trip_map/{stock_point_name}_{CURRENT_DATE}.html' \n",
    "            map_clusters = vis_and_save(df_routes= (df_routes\n",
    "                                                .rename(columns={'cluster':'cluster_bck'})\n",
    "                                                .rename(columns={'TripNumber':'cluster'})\n",
    "                                                ), \n",
    "                                        df_stockpoint=df_stockpoint, \n",
    "                                        filename=trip_map_path)\n",
    "        except Exception as e:\n",
    "            print(f'Unable to save the generated map image: {e}')\n",
    "\n",
    "        try:\n",
    "            run_route_optimizer(df_clustering, sel_cluster_tuple, df_stockpoint, \n",
    "                            stock_point_name,\n",
    "                            sel_total_customer_count, \n",
    "                            capacity_size = 20)\n",
    "        except Exception as e:\n",
    "            print(f'Unable to generate route mapping using orc: {e}')       \n",
    "    \n",
    "\n",
    "    ### Export Data\n",
    "    try:\n",
    "        export_data(\n",
    "                selected_trip = selected_push_recommendation_trip,\n",
    "                all_push_recommendation = all_push_recommendation,\n",
    "                cluster_summary = cluster_summary,\n",
    "                stock_point_name = stock_point_name\n",
    "            )\n",
    "    except Exception as e:\n",
    "        print(f'Unable to generate route mapping using orc: {e}')\n",
    "\n",
    "    dict_ = {\n",
    "        'stock_point_name': stock_point_name,\n",
    "        'selected_trip': selected_push_recommendation_trip,\n",
    "        'all_push_recommendation': all_push_recommendation,\n",
    "        'cluster_summary': cluster_summary\n",
    "    }\n",
    "\n",
    "    return dict_\n",
    "    #push_recommendation, df_clustering, df_routes, trip_summary, stock_point_coords, df_stockpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44619d0",
   "metadata": {},
   "source": [
    "# Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8cc0a172",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Data\n",
    "df_customer_sku_recommendation_raw = pd.read_feather('./input/customer_sku_recommendation.feather').rename(columns={'FCID':'Stock_Point_ID','CustomerId':'CustomerID'})\n",
    "df_customer_dim_with_affinity_score_raw = pd.read_feather('./input/customer_dim_with_affinity_score.feather').rename(columns={'FCID':'Stock_Point_ID'})\n",
    "df_stockpoint_dim_raw = pd.read_feather('./input/stockpoint_dim.feather')\n",
    "df_kyc_customer = pd.read_feather('./input/kyc_customers.feather')\n",
    "df_customer_score = pd.read_feather('./input/df_customer_score.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1617177c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "df_customer_sku_recommendation, df_master_customer_dim, df_stockpoint_dim = preprocessing(df_customer_sku_recommendation_raw, \n",
    "                                                                                                        df_customer_dim_with_affinity_score_raw, \n",
    "                                                                                                        df_stockpoint_dim_raw,\n",
    "                                                                                                        df_customer_score,\n",
    "                                                                                                        df_kyc_customer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fe979f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# causeway_customer_dim.query(\"days_since_last_order > 60\")[['KYC_Capture_Status']].value_counts()\n",
    "# causeway_customer_dim.query(\"KYC_Capture_Status == 'No'\")[['days_since_last_order']].hist()#.value_counts()#.reset_index().sort_values('days_since_last_order')\n",
    "# causeway_customer_dim.KYC_Capture_Status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "904b1d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [col for col in df_stockpoint_dim.Stock_point_Name if 'C' in col] \n",
    "# test_sp = 'OmniHub Apapa Lagos - CAUSEWAY'\n",
    "# # # test_spid = 1647402\n",
    "# # test_sp = 'OmniHub Alimosho Lagos - Barka Agro Mix'\n",
    "# # test_spid = 1647345\n",
    "\n",
    "# df_stockpoint_dim[df_stockpoint_dim['Stock_point_Name'] == test_sp]\n",
    "# # # df_customer_sku_recommendation.query(f'Stock_Point_ID == {test_spid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518e3101",
   "metadata": {},
   "source": [
    "### Iterative Run - All SPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6d43aaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/70 \n",
      "Stock Point ID: 1647128 || Stock Point Name: OmniHub Obio Akpor Rivers - Rivoc\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Obio Akpor Rivers - Rivoc, StockPointID: 1647128,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 50\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 1\n",
      "Total Number of Customers: 0\n",
      "1/70 \n",
      "Stock Point ID: 1647401 || Stock Point Name: OmniHub Ado Odo/Ota Ogun - Prince Tunadek\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ado Odo/Ota Ogun - Prince Tunadek, StockPointID: 1647401,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 218\n",
      "Total Quantity: 67\n",
      "Total Number of Customers before filter: 19\n",
      "Total Number of Customers: 4\n",
      "2/70 \n",
      "Stock Point ID: 1647402 || Stock Point Name: OmniHub AMAC 1 Abuja - Elriah\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub AMAC 1 Abuja - Elriah, StockPointID: 1647402,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 96\n",
      "Total Quantity: 53\n",
      "Total Number of Customers before filter: 8\n",
      "Total Number of Customers: 4\n",
      "3/70 \n",
      "Stock Point ID: 1647136 || Stock Point Name: OmniHub Tarauni Kano - Amjabil\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Tarauni Kano - Amjabil, StockPointID: 1647136,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 5\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 1\n",
      "Total Number of Customers: 0\n",
      "4/70 \n",
      "Stock Point ID: 1647076 || Stock Point Name: OmniHub Alimosho Lagos - Isukoshi MFC\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Alimosho Lagos - Isukoshi MFC, StockPointID: 1647076,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "5/70 \n",
      "Stock Point ID: 1647394 || Stock Point Name: OmniHub Port Harcourt Rivers - WCG 2\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Port Harcourt Rivers - WCG 2, StockPointID: 1647394,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 16,300\n",
      "Total Quantity: 11,203\n",
      "Total Number of Customers before filter: 476\n",
      "Total Number of Customers: 326\n",
      "✓ Loaded 3019 SKU recommendations\n",
      "✓ Loaded 326 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.53\n",
      "Davies-Bouldin Index: 0.61\n",
      "Calinski-Harabasz Score: 272.2\n",
      "Silhouette Score: 0.53\n",
      "Davies-Bouldin Index: 0.61\n",
      "Calinski-Harabasz Score: 272.2\n",
      "Select ClusterIDs: [5, 12, 17, 7]\n",
      "Total Number of Customers: 59\n",
      "   cluster                              LGA_list  \\\n",
      "0        5  [Obio Akpor, Port Harcourt, Ikwerre]   \n",
      "1       12                 [Obio Akpor, Ikwerre]   \n",
      "2       17  [Obio Akpor, Ikwerre, Port Harcourt]   \n",
      "3        7                             [Ikwerre]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [Woji, Oginigba, PORTHARCOURT-PETER ODILLI ROA...         20       721   \n",
      "1                             [Rukpokwu, Igwuruta, ]         13       472   \n",
      "2                    [Rukpokwu, Omagwa, , Amadi Ama]          6       208   \n",
      "3                         [Igwuruta, , Igwuruta-Ali]         20       743   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           41.393927  \n",
      "1           37.598443  \n",
      "2           37.112807  \n",
      "3           37.101224  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 5 (21 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 58.63 km, Duration: 80.08 min\n",
      "  Calculating route for Trip ID: 7 (21 waypoints)...\n",
      "  Trip ID 7 calculated. Distance: 85.88 km, Duration: 98.93 min\n",
      "  Calculating route for Trip ID: 12 (14 waypoints)...\n",
      "  Trip ID 12 calculated. Distance: 49.53 km, Duration: 59.82 min\n",
      "  Calculating route for Trip ID: 17 (7 waypoints)...\n",
      "  Trip ID 17 calculated. Distance: 28.36 km, Duration: 35.08 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647394.html\n",
      "6/70 \n",
      "Stock Point ID: 1647396 || Stock Point Name: OmniHub Oshodi Isolo Lagos - Eloramore\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Oshodi Isolo Lagos - Eloramore, StockPointID: 1647396,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 3,332\n",
      "Total Quantity: 2,058\n",
      "Total Number of Customers before filter: 162\n",
      "Total Number of Customers: 102\n",
      "✓ Loaded 660 SKU recommendations\n",
      "✓ Loaded 102 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.27\n",
      "Davies-Bouldin Index: 0.83\n",
      "Calinski-Harabasz Score: 8683.49\n",
      "Silhouette Score: 0.27\n",
      "Davies-Bouldin Index: 0.83\n",
      "Calinski-Harabasz Score: 8683.49\n",
      "Select ClusterIDs: [1, 4, 6, 2]\n",
      "Total Number of Customers: 58\n",
      "   cluster                         LGA_list  \\\n",
      "0        1                 [Oshodi Isolo, ]   \n",
      "1        4  [Oshodi Isolo, Push - Alimosho]   \n",
      "2        6                   [Oshodi Isolo]   \n",
      "3        2                 [Oshodi Isolo, ]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [Oshodi Isolo - Isolo, Oshodi Isolo - Ejigbo -...         21       387   \n",
      "1  [, Oshodi Isolo - Ago Palace, Push - Alimosho ...         12       273   \n",
      "2  [Oshodi Isolo - Shogunle, Oshodi Isolo - Ago P...          8       185   \n",
      "3  [, Oshodi Isolo - Shogunle, Oshodi Isolo - Bol...         17       338   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           30.972800  \n",
      "1           30.525341  \n",
      "2           28.409167  \n",
      "3           28.320631  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (22 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 52.97 km, Duration: 99.43 min\n",
      "  Calculating route for Trip ID: 2 (18 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 46.22 km, Duration: 99.33 min\n",
      "  Calculating route for Trip ID: 4 (13 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 34.53 km, Duration: 84.25 min\n",
      "  Calculating route for Trip ID: 6 (9 waypoints)...\n",
      "  Trip ID 6 calculated. Distance: 21.86 km, Duration: 41.73 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647396.html\n",
      "7/70 \n",
      "Stock Point ID: 1647075 || Stock Point Name: OmniHub Dugbe Oyo - Derints Enterprises\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Dugbe Oyo - Derints Enterprises, StockPointID: 1647075,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "8/70 \n",
      "Stock Point ID: 1647077 || Stock Point Name: OmniHub Surulere Lagos - Platform Height MFC\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Surulere Lagos - Platform Height MFC, StockPointID: 1647077,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "9/70 \n",
      "Stock Point ID: 1647400 || Stock Point Name: OmniHub Eleme Rivers - Berclynv\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Eleme Rivers - Berclynv, StockPointID: 1647400,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 7,098\n",
      "Total Quantity: 4,088\n",
      "Total Number of Customers before filter: 290\n",
      "Total Number of Customers: 159\n",
      "✓ Loaded 1192 SKU recommendations\n",
      "✓ Loaded 159 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.59\n",
      "Davies-Bouldin Index: 0.44\n",
      "Calinski-Harabasz Score: 57624.53\n",
      "Silhouette Score: 0.59\n",
      "Davies-Bouldin Index: 0.44\n",
      "Calinski-Harabasz Score: 57624.53\n",
      "Select ClusterIDs: [5, 4, 2, 1]\n",
      "Total Number of Customers: 87\n",
      "   cluster  LGA_list                                          LCDA_List  \\\n",
      "0        5   [Eleme]  [ELEME-ALETO, Aleto, , Alese, ELEME-AGBONCHIA,...   \n",
      "1        4  [Okrika]      [Ogoloma, Okirika, , Okochiri, Abam – Ama Ii]   \n",
      "2        2   [Eleme]  [Alese, Aleto, Nichia-Eleme, , Ebubu, ELEME-AL...   \n",
      "3        1   [Eleme]                               [Onne, , ELEME-ONNE]   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0         15       383           39.155182  \n",
      "1         18       475           31.815068  \n",
      "2         25       603           30.663810  \n",
      "3         29       784           28.478289  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (30 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 26.20 km, Duration: 39.95 min\n",
      "  Calculating route for Trip ID: 2 (26 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 10.19 km, Duration: 13.18 min\n",
      "  Calculating route for Trip ID: 4 (19 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 24.89 km, Duration: 36.70 min\n",
      "  Calculating route for Trip ID: 5 (16 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 13.28 km, Duration: 16.17 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647400.html\n",
      "10/70 \n",
      "Stock Point ID: 1647081 || Stock Point Name: OmniHub Alimosho Lagos - Barka-Agro and General Services MFC\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Alimosho Lagos - Barka-Agro and General Services MFC, StockPointID: 1647081,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 5,354\n",
      "Total Quantity: 3,443\n",
      "Total Number of Customers before filter: 205\n",
      "Total Number of Customers: 128\n",
      "✓ Loaded 1075 SKU recommendations\n",
      "✓ Loaded 128 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.32\n",
      "Davies-Bouldin Index: 0.77\n",
      "Calinski-Harabasz Score: 3837.94\n",
      "Silhouette Score: 0.32\n",
      "Davies-Bouldin Index: 0.77\n",
      "Calinski-Harabasz Score: 3837.94\n",
      "Select ClusterIDs: [1, 6, 2, 3]\n",
      "Total Number of Customers: 82\n",
      "   cluster           LGA_list  \\\n",
      "0        1         [Alimosho]   \n",
      "1        6         [Alimosho]   \n",
      "2        2  [Alimosho, Agege]   \n",
      "3        3         [Alimosho]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [Alimosho - Iyana Ipaja (egbeda), , Alimosho -...         30       857   \n",
      "1         [Alimosho - Egbe/idimu, Alimosho - Ijegun]          6       154   \n",
      "2  [Alimosho - Iyana Ipaja (egbeda), , Alimosho -...         26       735   \n",
      "3  [Alimosho - Iyana Ipaja (egbeda), Alimosho - I...         20       556   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           52.363504  \n",
      "1           45.216735  \n",
      "2           41.759829  \n",
      "3           40.645174  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (31 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 31.38 km, Duration: 71.95 min\n",
      "  Calculating route for Trip ID: 2 (27 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 59.28 km, Duration: 103.20 min\n",
      "  Calculating route for Trip ID: 3 (21 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 34.16 km, Duration: 90.58 min\n",
      "  Calculating route for Trip ID: 6 (7 waypoints)...\n",
      "  Trip ID 6 calculated. Distance: 29.87 km, Duration: 49.53 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647081.html\n",
      "11/70 \n",
      "Stock Point ID: 1647398 || Stock Point Name: OmniHub Ifako Ijaiye Lagos - Bickson\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ifako Ijaiye Lagos - Bickson, StockPointID: 1647398,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 1,459\n",
      "Total Quantity: 913\n",
      "Total Number of Customers before filter: 87\n",
      "Total Number of Customers: 58\n",
      "✓ Loaded 266 SKU recommendations\n",
      "✓ Loaded 58 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.41\n",
      "Davies-Bouldin Index: 0.72\n",
      "Calinski-Harabasz Score: 70.52\n",
      "Silhouette Score: 0.41\n",
      "Davies-Bouldin Index: 0.72\n",
      "Calinski-Harabasz Score: 70.52\n",
      "Select ClusterIDs: [2, 5, 3, 4]\n",
      "Total Number of Customers: 37\n",
      "   cluster                                    LGA_list  \\\n",
      "0        2  [Ifako Ijaiye, Push - Ifako Ijaiye, Agege]   \n",
      "1        5                       [Agege, Ifako Ijaiye]   \n",
      "2        3                              [Ifako Ijaiye]   \n",
      "3        4                              [Ifako Ijaiye]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [, Ifako Ijaiye - Ojokoro, Agege - Iju Road, P...         11       198   \n",
      "1                      [, Agege - Ajuwon Akute Road]          5        99   \n",
      "2  [Ifako Ijaiye - Ojokoro, Ifako Ijaiye - Ogba -...         11       168   \n",
      "3                         [Ifako Ijaiye - Ojokoro, ]         10       190   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           50.223276  \n",
      "1           47.246207  \n",
      "2           39.790370  \n",
      "3           38.532075  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 2 (12 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 14.30 km, Duration: 45.87 min\n",
      "  Calculating route for Trip ID: 3 (12 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 31.66 km, Duration: 93.68 min\n",
      "  Calculating route for Trip ID: 4 (11 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 38.20 km, Duration: 64.73 min\n",
      "  Calculating route for Trip ID: 5 (6 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 17.20 km, Duration: 44.57 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647398.html\n",
      "12/70 \n",
      "Stock Point ID: 1646941 || Stock Point Name: OmniHub Ido Oyo - CARESGATE AFRICA LTD\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ido Oyo - CARESGATE AFRICA LTD, StockPointID: 1646941,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 1,917\n",
      "Total Quantity: 1,119\n",
      "Total Number of Customers before filter: 101\n",
      "Total Number of Customers: 58\n",
      "✓ Loaded 299 SKU recommendations\n",
      "✓ Loaded 58 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.32\n",
      "Davies-Bouldin Index: 0.51\n",
      "Calinski-Harabasz Score: 1468.64\n",
      "Silhouette Score: 0.32\n",
      "Davies-Bouldin Index: 0.51\n",
      "Calinski-Harabasz Score: 1468.64\n",
      "Select ClusterIDs: [2, 1, 3, 4]\n",
      "Total Number of Customers: 40\n",
      "   cluster                    LGA_list                     LCDA_List  \\\n",
      "0        2  [Ido, Ibadan South West, ]  [IBADAN-APATA, Apata, , Ido]   \n",
      "1        1    [Ibadan South West, Ido]       [Apata, , IBADAN-APATA]   \n",
      "2        3    [Ido, Ibadan South West]           [Apete, Apata, Ido]   \n",
      "3        4    [Ibadan South West, Ido]             [, Apata, Agbeni]   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0         12       220           27.144151  \n",
      "1         14       256           25.290725  \n",
      "2          8       190           23.430769  \n",
      "3          6       116           22.840333  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (15 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 26.52 km, Duration: 40.73 min\n",
      "  Calculating route for Trip ID: 2 (13 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 30.44 km, Duration: 40.85 min\n",
      "  Calculating route for Trip ID: 3 (9 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 35.61 km, Duration: 40.63 min\n",
      "  Calculating route for Trip ID: 4 (7 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 40.98 km, Duration: 45.85 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1646941.html\n",
      "13/70 \n",
      "Stock Point ID: 1646945 || Stock Point Name: OmniHub Ado Odo/Ota Ogun - RAZCO ENERGY\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ado Odo/Ota Ogun - RAZCO ENERGY, StockPointID: 1646945,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 20\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 1\n",
      "Total Number of Customers: 0\n",
      "14/70 \n",
      "Stock Point ID: 1646999 || Stock Point Name: OmniHub Eti Osa Lagos - Motomori\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Eti Osa Lagos - Motomori, StockPointID: 1646999,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 4,859\n",
      "Total Quantity: 3,091\n",
      "Total Number of Customers before filter: 162\n",
      "Total Number of Customers: 102\n",
      "✓ Loaded 781 SKU recommendations\n",
      "✓ Loaded 102 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.47\n",
      "Davies-Bouldin Index: 0.63\n",
      "Calinski-Harabasz Score: 26.82\n",
      "Silhouette Score: 0.47\n",
      "Davies-Bouldin Index: 0.63\n",
      "Calinski-Harabasz Score: 26.82\n",
      "Select ClusterIDs: [7, 1, 6, 2]\n",
      "Total Number of Customers: 60\n",
      "   cluster   LGA_list                                          LCDA_List  \\\n",
      "0        7  [Eti Osa]  [Eti Osa - Victoria Island (ahmed Bello Way), ...   \n",
      "1        1  [Eti Osa]  [, Eti Osa - Ajah (lekki), Eti Osa - Lekki - A...   \n",
      "2        6  [Eti Osa]  [, Eti Osa - Lekki - Ajah (sangotedo), Eti Osa...   \n",
      "3        2  [Eti Osa]  [Eti Osa - Ajah (lekki), , Eti Osa - Lekki - A...   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0          7       191           44.749796  \n",
      "1         29       771           37.101084  \n",
      "2          7       242           37.077377  \n",
      "3         17       487           36.832093  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (30 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 82.71 km, Duration: 111.42 min\n",
      "  Calculating route for Trip ID: 2 (18 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 53.38 km, Duration: 77.35 min\n",
      "  Calculating route for Trip ID: 6 (8 waypoints)...\n",
      "  Trip ID 6 calculated. Distance: 25.58 km, Duration: 26.05 min\n",
      "  Calculating route for Trip ID: 7 (8 waypoints)...\n",
      "  Trip ID 7 calculated. Distance: 47.78 km, Duration: 52.50 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1646999.html\n",
      "15/70 \n",
      "Stock Point ID: 1647010 || Stock Point Name: OmniHub Alimosho Lagos - LARDAMIC\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Alimosho Lagos - LARDAMIC, StockPointID: 1647010,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 2,011\n",
      "Total Quantity: 1,376\n",
      "Total Number of Customers before filter: 69\n",
      "Total Number of Customers: 48\n",
      "✓ Loaded 430 SKU recommendations\n",
      "✓ Loaded 48 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.39\n",
      "Davies-Bouldin Index: 0.62\n",
      "Calinski-Harabasz Score: 36.87\n",
      "Silhouette Score: 0.39\n",
      "Davies-Bouldin Index: 0.62\n",
      "Calinski-Harabasz Score: 36.87\n",
      "Select ClusterIDs: [1, 2]\n",
      "Total Number of Customers: 41\n",
      "   cluster    LGA_list                                          LCDA_List  \\\n",
      "0        1  [Alimosho]  [Alimosho - Iyana Ipaja (ikola Road), Alimosho...   \n",
      "1        2  [Alimosho]  [Alimosho - Iyana Ipaja (ikola Road), , Alimos...   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0         26       769           46.126109  \n",
      "1         15       416           45.374769  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (27 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 60.39 km, Duration: 110.00 min\n",
      "  Calculating route for Trip ID: 2 (16 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 25.69 km, Duration: 57.80 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647010.html\n",
      "16/70 \n",
      "Stock Point ID: 1646991 || Stock Point Name: OmniHub Badagry Lagos - STEAVESON\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Badagry Lagos - STEAVESON, StockPointID: 1646991,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 2,225\n",
      "Total Quantity: 1,407\n",
      "Total Number of Customers before filter: 122\n",
      "Total Number of Customers: 74\n",
      "✓ Loaded 356 SKU recommendations\n",
      "✓ Loaded 74 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.57\n",
      "Davies-Bouldin Index: 0.34\n",
      "Calinski-Harabasz Score: 36597.64\n",
      "Silhouette Score: 0.57\n",
      "Davies-Bouldin Index: 0.34\n",
      "Calinski-Harabasz Score: 36597.64\n",
      "Select ClusterIDs: [1, 2, 3, 4]\n",
      "Total Number of Customers: 48\n",
      "   cluster                   LGA_list  \\\n",
      "0        1                  [Badagry]   \n",
      "1        2                  [Badagry]   \n",
      "2        3                  [Badagry]   \n",
      "3        4  [Badagry, Push - Badagry]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [Badagry - Agbalata, , Badagry - Ibereko, Bada...         26       611   \n",
      "1     [, Badagry - Oko-afor, Badagry - Ilogbo-eremi]          8       123   \n",
      "2  [, Badagry - Ajara Topa, Badagry - Badagry Tow...          7       136   \n",
      "3                                 [, Badagry - Mowo]          7       127   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           59.951634  \n",
      "1           56.830645  \n",
      "2           53.158065  \n",
      "3           46.853056  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (27 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 16.86 km, Duration: 23.97 min\n",
      "  Calculating route for Trip ID: 2 (9 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 30.89 km, Duration: 33.40 min\n",
      "  Calculating route for Trip ID: 3 (8 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 12.63 km, Duration: 19.38 min\n",
      "  Calculating route for Trip ID: 4 (8 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 20.93 km, Duration: 16.30 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1646991.html\n",
      "17/70 \n",
      "Stock Point ID: 1647024 || Stock Point Name: OmniHub Oyigbo Rivers - LAMDA GLOBAL\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Oyigbo Rivers - LAMDA GLOBAL, StockPointID: 1647024,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 11,428\n",
      "Total Quantity: 7,221\n",
      "Total Number of Customers before filter: 307\n",
      "Total Number of Customers: 188\n",
      "✓ Loaded 1764 SKU recommendations\n",
      "✓ Loaded 188 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.49\n",
      "Davies-Bouldin Index: 0.42\n",
      "Calinski-Harabasz Score: 11298.12\n",
      "Silhouette Score: 0.49\n",
      "Davies-Bouldin Index: 0.42\n",
      "Calinski-Harabasz Score: 11298.12\n",
      "Select ClusterIDs: [8, 5, 3, 10]\n",
      "Total Number of Customers: 51\n",
      "   cluster           LGA_list  \\\n",
      "0        8           [Oyigbo]   \n",
      "1        5  [Oyigbo, Etche, ]   \n",
      "2        3    [Etche, Oyigbo]   \n",
      "3       10           [Oyigbo]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [OYIGBO (DUPLICATE), OYIGBO-EGBERU, Komkom, , ...          8       322   \n",
      "1                               [Komkom, Umuebulu, ]         18       685   \n",
      "2             [Umuebulu, Afam, , OYIGBO (DUPLICATE)]         19       682   \n",
      "3  [Komkom, OYIGBO (DUPLICATE), Ndoki, PORTHARCOU...          6       239   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           52.831333  \n",
      "1           44.779939  \n",
      "2           44.548352  \n",
      "3           44.256667  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 3 (20 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 33.61 km, Duration: 35.27 min\n",
      "  Calculating route for Trip ID: 5 (19 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 18.92 km, Duration: 16.80 min\n",
      "  Calculating route for Trip ID: 8 (9 waypoints)...\n",
      "  Trip ID 8 calculated. Distance: 28.14 km, Duration: 37.05 min\n",
      "  Calculating route for Trip ID: 10 (7 waypoints)...\n",
      "  Trip ID 10 calculated. Distance: 17.55 km, Duration: 15.37 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647024.html\n",
      "18/70 \n",
      "Stock Point ID: 1646989 || Stock Point Name: OmniHub Amuwo Odofin Lagos - GOLDVIRTUES\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Amuwo Odofin Lagos - GOLDVIRTUES, StockPointID: 1646989,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "19/70 \n",
      "Stock Point ID: 1647033 || Stock Point Name: OmniHub Ilorin_East Kwara - REAL HEIGHT SERVICES\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ilorin_East Kwara - REAL HEIGHT SERVICES, StockPointID: 1647033,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 940\n",
      "Total Quantity: 713\n",
      "Total Number of Customers before filter: 82\n",
      "Total Number of Customers: 60\n",
      "✓ Loaded 163 SKU recommendations\n",
      "✓ Loaded 60 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.41\n",
      "Davies-Bouldin Index: 0.57\n",
      "Calinski-Harabasz Score: 49.44\n",
      "Silhouette Score: 0.41\n",
      "Davies-Bouldin Index: 0.57\n",
      "Calinski-Harabasz Score: 49.44\n",
      "Select ClusterIDs: [2, 5, 4, 1]\n",
      "Total Number of Customers: 39\n",
      "   cluster                                  LGA_list  \\\n",
      "0        2  [Ilorin West, Ilorin South, Ilorin East]   \n",
      "1        5  [Ilorin West, Ilorin East, Ilorin South]   \n",
      "2        4               [Ilorin East, Ilorin South]   \n",
      "3        1                [Ilorin West, Ilorin East]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [Coca-Cola Road, , Oja-Gboro, Offa Garage, Agb...         11       141   \n",
      "1          [Agbo-Oba, Okelele, Idi-Ape, , Oja-Gboro]          6        73   \n",
      "2              [Oja-Gboro, , Kulende, Maraba, Sango]          7        81   \n",
      "3  [General Hospital, Agbo-Oba, Babaoko, Asa Dam,...         15       176   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           54.570312  \n",
      "1           53.308500  \n",
      "2           43.084737  \n",
      "3           38.442368  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (16 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 32.85 km, Duration: 44.07 min\n",
      "  Calculating route for Trip ID: 2 (12 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 99.74 km, Duration: 705.35 min\n",
      "  Calculating route for Trip ID: 4 (8 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 26.56 km, Duration: 33.10 min\n",
      "  Calculating route for Trip ID: 5 (7 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 25.36 km, Duration: 27.70 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647033.html\n",
      "20/70 \n",
      "Stock Point ID: 1646976 || Stock Point Name: \n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: , StockPointID: 1646976,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "21/70 \n",
      "Stock Point ID: 1646971 || Stock Point Name: OmniHub Abeokuta Ogun - Brooks\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Abeokuta Ogun - Brooks, StockPointID: 1646971,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 1,290\n",
      "Total Quantity: 1,010\n",
      "Total Number of Customers before filter: 86\n",
      "Total Number of Customers: 66\n",
      "✓ Loaded 300 SKU recommendations\n",
      "✓ Loaded 66 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.57\n",
      "Davies-Bouldin Index: 0.42\n",
      "Calinski-Harabasz Score: 623.01\n",
      "Silhouette Score: 0.57\n",
      "Davies-Bouldin Index: 0.42\n",
      "Calinski-Harabasz Score: 623.01\n",
      "Select ClusterIDs: [4, 3, 1, 5]\n",
      "Total Number of Customers: 43\n",
      "   cluster                          LGA_list  \\\n",
      "0        4           [Odeda, Abeokuta South]   \n",
      "1        3  [Abeokuta North, Abeokuta South]   \n",
      "2        1                  [Abeokuta North]   \n",
      "3        5  [Abeokuta South, Abeokuta North]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0                         [Eleweran, Aregbe, Adatan]          8       132   \n",
      "1                 [Elega, Iberekodo, Adatan, Kuto, ]         11       176   \n",
      "2  [Iberekodo, Elega, Akomoje, Bode - Olude, Mokola]         18       263   \n",
      "3  [Gbokoniyi, Onikolobo, Totoro, Akinolugbade, I...          6        82   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           43.536667  \n",
      "1           41.564615  \n",
      "2           40.622625  \n",
      "3           36.853600  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (19 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 31.27 km, Duration: 68.22 min\n",
      "  Calculating route for Trip ID: 3 (12 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 32.02 km, Duration: 33.97 min\n",
      "  Calculating route for Trip ID: 4 (9 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 22.82 km, Duration: 34.00 min\n",
      "  Calculating route for Trip ID: 5 (7 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 19.56 km, Duration: 34.10 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1646971.html\n",
      "22/70 \n",
      "Stock Point ID: 1647011 || Stock Point Name: OmniHub Badagry Lagos - NEEMYGHT MULTI-VENTURE ENTERPRISES\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Badagry Lagos - NEEMYGHT MULTI-VENTURE ENTERPRISES, StockPointID: 1647011,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 1,130\n",
      "Total Quantity: 956\n",
      "Total Number of Customers before filter: 59\n",
      "Total Number of Customers: 48\n",
      "✓ Loaded 241 SKU recommendations\n",
      "✓ Loaded 48 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.76\n",
      "Davies-Bouldin Index: 0.19\n",
      "Calinski-Harabasz Score: 9983.97\n",
      "Silhouette Score: 0.76\n",
      "Davies-Bouldin Index: 0.19\n",
      "Calinski-Harabasz Score: 9983.97\n",
      "Select ClusterIDs: [3, 1, 2]\n",
      "Total Number of Customers: 37\n",
      "   cluster   LGA_list                                          LCDA_List  \\\n",
      "0        3  [Badagry]  [Badagry - Agbara (checking Point), Badagry - ...   \n",
      "1        1  [Badagry]  [Badagry - Agbara (magbon), Badagry - Oko-afor...   \n",
      "2        2  [Badagry]  [, Badagry - Agbara (morogbo), Badagry - Agbar...   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0          8       135           55.874194  \n",
      "1         18       355           46.853218  \n",
      "2         11       241           41.941500  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (19 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 6.32 km, Duration: 9.68 min\n",
      "  Calculating route for Trip ID: 2 (12 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 58.43 km, Duration: 47.22 min\n",
      "  Calculating route for Trip ID: 3 (9 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 50.83 km, Duration: 39.03 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647011.html\n",
      "23/70 \n",
      "Stock Point ID: 1647050 || Stock Point Name: OMNIHUB-OREDO-EDO-AMA-PEE ENTERPRISE\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OMNIHUB-OREDO-EDO-AMA-PEE ENTERPRISE, StockPointID: 1647050,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 1,802\n",
      "Total Quantity: 1,235\n",
      "Total Number of Customers before filter: 186\n",
      "Total Number of Customers: 121\n",
      "✓ Loaded 286 SKU recommendations\n",
      "✓ Loaded 121 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.49\n",
      "Davies-Bouldin Index: 0.79\n",
      "Calinski-Harabasz Score: 789.09\n",
      "Silhouette Score: 0.49\n",
      "Davies-Bouldin Index: 0.79\n",
      "Calinski-Harabasz Score: 789.09\n",
      "Select ClusterIDs: [7, 5, 3, 1]\n",
      "Total Number of Customers: 39\n",
      "   cluster                 LGA_list                           LCDA_List  \\\n",
      "0        7     [Ikpoba Okha, Oredo]         [, Benin, Gorretti, Idogbo]   \n",
      "1        5     [Oredo, Ikpoba Okha]        [Benin, Obayantor, Gorretti]   \n",
      "2        3     [Ikpoba Okha, Oredo]  [Gorretti, , Idogbo, Benin, Etete]   \n",
      "3        1  [Egor, Ovia North East]           [Uselu, Ugbowo, Adolor, ]   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0          6        59           58.387857  \n",
      "1          8        77           54.543333  \n",
      "2         12       132           51.564516  \n",
      "3         13       105           48.561364  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (14 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 62.87 km, Duration: 83.52 min\n",
      "  Calculating route for Trip ID: 3 (13 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 14.37 km, Duration: 17.80 min\n",
      "  Calculating route for Trip ID: 5 (9 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 22.83 km, Duration: 24.53 min\n",
      "  Calculating route for Trip ID: 7 (7 waypoints)...\n",
      "  Trip ID 7 calculated. Distance: 20.37 km, Duration: 25.38 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647050.html\n",
      "24/70 \n",
      "Stock Point ID: 1647006 || Stock Point Name: OmniHub Ogba/Egbema Ndoni Rivers - JIB\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ogba/Egbema Ndoni Rivers - JIB, StockPointID: 1647006,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "25/70 \n",
      "Stock Point ID: 1646995 || Stock Point Name: OmniHub Epe Lagos - WONUOLA SUPER STORE\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Epe Lagos - WONUOLA SUPER STORE, StockPointID: 1646995,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "26/70 \n",
      "Stock Point ID: 1647391 || Stock Point Name: OmniHub Ibeju Lekki Lagos - SI & A\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ibeju Lekki Lagos - SI & A, StockPointID: 1647391,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 703\n",
      "Total Quantity: 520\n",
      "Total Number of Customers before filter: 47\n",
      "Total Number of Customers: 34\n",
      "✓ Loaded 141 SKU recommendations\n",
      "✓ Loaded 34 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.6\n",
      "Davies-Bouldin Index: 0.34\n",
      "Calinski-Harabasz Score: 163.69\n",
      "Silhouette Score: 0.6\n",
      "Davies-Bouldin Index: 0.34\n",
      "Calinski-Harabasz Score: 163.69\n",
      "Select ClusterIDs: [1, 2]\n",
      "Total Number of Customers: 25\n",
      "   cluster       LGA_list                                          LCDA_List  \\\n",
      "0        1  [Ibeju Lekki]  [Ibeju Lekki - Awoyaya - Eko Akete Estate, Ibe...   \n",
      "1        2  [Ibeju Lekki]  [Ibeju Lekki - Igando - Oloja, Ibeju Lekki - E...   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0         20       351           43.132347  \n",
      "1          5        57           32.203333  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (21 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 142.62 km, Duration: 177.17 min\n",
      "  Calculating route for Trip ID: 2 (6 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 34.39 km, Duration: 31.83 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647391.html\n",
      "27/70 \n",
      "Stock Point ID: 1647372 || Stock Point Name: OmniHub AMAC 1 Abuja - Roekwi\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub AMAC 1 Abuja - Roekwi, StockPointID: 1647372,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 2,094\n",
      "Total Quantity: 1,589\n",
      "Total Number of Customers before filter: 160\n",
      "Total Number of Customers: 122\n",
      "✓ Loaded 476 SKU recommendations\n",
      "✓ Loaded 122 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.68\n",
      "Davies-Bouldin Index: 0.41\n",
      "Calinski-Harabasz Score: 4472.29\n",
      "Silhouette Score: 0.68\n",
      "Davies-Bouldin Index: 0.41\n",
      "Calinski-Harabasz Score: 4472.29\n",
      "Select ClusterIDs: [5, 3, 2, 1]\n",
      "Total Number of Customers: 74\n",
      "   cluster                                           LGA_list  \\\n",
      "0        5                                           [AMAC 1]   \n",
      "1        3                            [Kuje/Gwagwalada/Abaji]   \n",
      "2        2                            [Kuje/Gwagwalada/Abaji]   \n",
      "3        1  [Kuje/Gwagwalada/Abaji, Push - Abuja Municipal...   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0                              [Airport Road, Lugbe]          8       117   \n",
      "1                               [ABUJA-KUJE, Pegi, ]         19       206   \n",
      "2                [Kutunku, ABUJA-GWAGWALADA, , Dobi]         20       249   \n",
      "3  [ABUJA-KUJE, , ABUJA-GWAGWALADA, Push - Lugbe,...         27       355   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           50.325526  \n",
      "1           38.263333  \n",
      "2           36.689315  \n",
      "3           36.579159  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (28 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 51.20 km, Duration: 58.95 min\n",
      "  Calculating route for Trip ID: 2 (21 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 104.08 km, Duration: 99.83 min\n",
      "  Calculating route for Trip ID: 3 (20 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 44.41 km, Duration: 55.90 min\n",
      "  Calculating route for Trip ID: 5 (9 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 18.39 km, Duration: 31.78 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647372.html\n",
      "28/70 \n",
      "Stock Point ID: 1647377 || Stock Point Name: OmniHub Ikorodu Lagos - Sitrest\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ikorodu Lagos - Sitrest, StockPointID: 1647377,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 4,111\n",
      "Total Quantity: 3,142\n",
      "Total Number of Customers before filter: 153\n",
      "Total Number of Customers: 115\n",
      "✓ Loaded 852 SKU recommendations\n",
      "✓ Loaded 115 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.42\n",
      "Davies-Bouldin Index: 0.65\n",
      "Calinski-Harabasz Score: 194.03\n",
      "Silhouette Score: 0.42\n",
      "Davies-Bouldin Index: 0.65\n",
      "Calinski-Harabasz Score: 194.03\n",
      "Select ClusterIDs: [5, 9, 3, 8]\n",
      "Total Number of Customers: 31\n",
      "   cluster   LGA_list                                          LCDA_List  \\\n",
      "0        5  [Ikorodu]               [Ikorodu - Igbogbo, Ikorodu - Offin]   \n",
      "1        9  [Ikorodu]      [Ikorodu - Igbogbo, Ikorodu - Oreyo - Igbe, ]   \n",
      "2        3  [Ikorodu]  [Ikorodu - Bayeku, Ikorodu - Igbogbo, Ikorodu ...   \n",
      "3        8  [Ikorodu]  [Ikorodu - Oreyo - Igbe, Ikorodu - Agufoye, Ik...   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0          8       195           32.083148  \n",
      "1          5       170           28.145909  \n",
      "2         12       370           27.463786  \n",
      "3          6       194           27.393200  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 3 (13 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 52.52 km, Duration: 57.23 min\n",
      "  Calculating route for Trip ID: 5 (9 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 53.22 km, Duration: 58.38 min\n",
      "  Calculating route for Trip ID: 8 (7 waypoints)...\n",
      "  Trip ID 8 calculated. Distance: 45.23 km, Duration: 51.98 min\n",
      "  Calculating route for Trip ID: 9 (6 waypoints)...\n",
      "  Trip ID 9 calculated. Distance: 45.50 km, Duration: 47.18 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647377.html\n",
      "29/70 \n",
      "Stock Point ID: 1647387 || Stock Point Name: OmniHub Ogba/Egbema Ndoni Rivers - Nest-Och\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ogba/Egbema Ndoni Rivers - Nest-Och, StockPointID: 1647387,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 3,141\n",
      "Total Quantity: 2,699\n",
      "Total Number of Customers before filter: 154\n",
      "Total Number of Customers: 126\n",
      "✓ Loaded 772 SKU recommendations\n",
      "✓ Loaded 126 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.64\n",
      "Davies-Bouldin Index: 0.43\n",
      "Calinski-Harabasz Score: 18897.11\n",
      "Silhouette Score: 0.64\n",
      "Davies-Bouldin Index: 0.43\n",
      "Calinski-Harabasz Score: 18897.11\n",
      "Select ClusterIDs: [5, 4, 1, 3]\n",
      "Total Number of Customers: 62\n",
      "   cluster                    LGA_list  \\\n",
      "0        5         [Ogba/Egbema Ndoni]   \n",
      "1        4         [Ogba/Egbema Ndoni]   \n",
      "2        1         [Ogba/Egbema Ndoni]   \n",
      "3        3  [Ahoada West, Ahoada East]   \n",
      "\n",
      "                                      LCDA_List  ncustomer  totalQty  \\\n",
      "0                                     [Omoku, ]         10       255   \n",
      "1                      [, Omoku, Egbema, Ndoni]         10       243   \n",
      "2                            [Omoku, Usomini, ]         25       613   \n",
      "3  [Ahoada, Upata, Ikata, Odiemusana, , Ekpene]         17       316   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           48.212500  \n",
      "1           45.332941  \n",
      "2           43.390971  \n",
      "3           41.525632  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (26 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 2.67 km, Duration: 3.90 min\n",
      "  Calculating route for Trip ID: 3 (18 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 58.02 km, Duration: 65.38 min\n",
      "  Calculating route for Trip ID: 4 (11 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 10.92 km, Duration: 19.83 min\n",
      "  Calculating route for Trip ID: 5 (11 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 2.22 km, Duration: 2.82 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647387.html\n",
      "Unable to generate route mapping using orc: Cannot save file into a non-existent directory: 'recommendation_output/2025-06-28/OmniHub Ogba'\n",
      "30/70 \n",
      "Stock Point ID: 1647062 || Stock Point Name: OmniHub Kosofe Lagos - KOLF \n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Kosofe Lagos - KOLF , StockPointID: 1647062,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 6,966\n",
      "Total Quantity: 4,249\n",
      "Total Number of Customers before filter: 225\n",
      "Total Number of Customers: 136\n",
      "✓ Loaded 1265 SKU recommendations\n",
      "✓ Loaded 136 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.48\n",
      "Davies-Bouldin Index: 0.49\n",
      "Calinski-Harabasz Score: 15158.28\n",
      "Silhouette Score: 0.48\n",
      "Davies-Bouldin Index: 0.49\n",
      "Calinski-Harabasz Score: 15158.28\n",
      "Select ClusterIDs: [5, 1, 8, 4]\n",
      "Total Number of Customers: 65\n",
      "   cluster  LGA_list                                          LCDA_List  \\\n",
      "0        5  [Kosofe]   [, Kosofe - Ketu - Ikosi Road, Kosofe - Mile 12]   \n",
      "1        1  [Kosofe]  [Kosofe - Ketu - Alapere, , Kosofe - Mile 12, ...   \n",
      "2        8  [Kosofe]  [Kosofe - Maryland - Onigbongbo, Kosofe - Mary...   \n",
      "3        4  [Kosofe]  [Kosofe - Oworonshoki, , Kosofe - Ketu - Demurin]   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0         15       484           53.686528  \n",
      "1         26       769           52.609741  \n",
      "2          5       128           51.748718  \n",
      "3         19       646           51.488936  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (27 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 47.60 km, Duration: 70.43 min\n",
      "  Calculating route for Trip ID: 4 (20 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 51.91 km, Duration: 60.62 min\n",
      "  Calculating route for Trip ID: 5 (16 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 19.22 km, Duration: 34.70 min\n",
      "  Calculating route for Trip ID: 8 (6 waypoints)...\n",
      "  Trip ID 8 calculated. Distance: 15.33 km, Duration: 22.72 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647062.html\n",
      "31/70 \n",
      "Stock Point ID: 1647381 || Stock Point Name: OmniHub Ado Odo/Ota Ogun - Sam-Samron\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ado Odo/Ota Ogun - Sam-Samron, StockPointID: 1647381,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 64\n",
      "Total Quantity: 57\n",
      "Total Number of Customers before filter: 5\n",
      "Total Number of Customers: 4\n",
      "32/70 \n",
      "Stock Point ID: 1647345 || Stock Point Name: OmniHub Alimosho Lagos - Barka Agro Mix\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Alimosho Lagos - Barka Agro Mix, StockPointID: 1647345,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 3,577\n",
      "Total Quantity: 2,555\n",
      "Total Number of Customers before filter: 163\n",
      "Total Number of Customers: 118\n",
      "✓ Loaded 791 SKU recommendations\n",
      "✓ Loaded 118 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.27\n",
      "Davies-Bouldin Index: 0.71\n",
      "Calinski-Harabasz Score: 4012.38\n",
      "Silhouette Score: 0.27\n",
      "Davies-Bouldin Index: 0.71\n",
      "Calinski-Harabasz Score: 4012.38\n",
      "Select ClusterIDs: [3, 4, 5, 7]\n",
      "Total Number of Customers: 46\n",
      "   cluster                     LGA_list  \\\n",
      "0        3  [Alimosho, Push - Alimosho]   \n",
      "1        4                   [Alimosho]   \n",
      "2        5                   [Alimosho]   \n",
      "3        7     [Alimosho, Oshodi Isolo]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [Alimosho - Ikotun, Push - Alimosho - Ejigbo-I...         14       446   \n",
      "1  [Alimosho - Ikotun, Alimosho - Ijegun, , Alimo...         13       264   \n",
      "2  [Alimosho - Iyana Ejigbo, Alimosho - Idimu, Al...         13       263   \n",
      "3  [Alimosho - Ijegun, Alimosho - Iyana Ejigbo, ,...          6       149   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           50.406154  \n",
      "1           41.848488  \n",
      "2           35.963563  \n",
      "3           35.600426  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 3 (15 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 26.42 km, Duration: 52.92 min\n",
      "  Calculating route for Trip ID: 4 (14 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 45.00 km, Duration: 103.65 min\n",
      "  Calculating route for Trip ID: 5 (14 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 43.34 km, Duration: 85.78 min\n",
      "  Calculating route for Trip ID: 7 (7 waypoints)...\n",
      "  Trip ID 7 calculated. Distance: 63.61 km, Duration: 111.05 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647345.html\n",
      "33/70 \n",
      "Stock Point ID: 1647376 || Stock Point Name: OmniHub Ijebu Ode Ogun - WCG\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ijebu Ode Ogun - WCG, StockPointID: 1647376,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "34/70 \n",
      "Stock Point ID: 1647353 || Stock Point Name: OmniHub Yenagoa Bayelsa - Schist & Scoria\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Yenagoa Bayelsa - Schist & Scoria, StockPointID: 1647353,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 713\n",
      "Total Quantity: 485\n",
      "Total Number of Customers before filter: 85\n",
      "Total Number of Customers: 59\n",
      "✓ Loaded 107 SKU recommendations\n",
      "✓ Loaded 59 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.52\n",
      "Davies-Bouldin Index: 0.53\n",
      "Calinski-Harabasz Score: 359.38\n",
      "Silhouette Score: 0.52\n",
      "Davies-Bouldin Index: 0.53\n",
      "Calinski-Harabasz Score: 359.38\n",
      "Select ClusterIDs: [1, 2, 3, 4]\n",
      "Total Number of Customers: 50\n",
      "   cluster   LGA_list                                      LCDA_List  \\\n",
      "0        1  [Yenagoa]     [Ovelemini, Opolo, Kpansia, Atissa, Ekeki]   \n",
      "1        2  [Yenagoa]  [Amarata, Ekeki, Tombia, Epie, Azikoro, Omom]   \n",
      "2        3  [Yenagoa]              [Ovelemini, Tombia, Agudama-Epie]   \n",
      "3        4  [Yenagoa]             [Anyamabele, Opolo, Epie, Kpansia]   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0         24       221           37.895000  \n",
      "1         13        94           35.758636  \n",
      "2          7        77           34.812941  \n",
      "3          6        42           27.923333  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (25 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 18.13 km, Duration: 23.68 min\n",
      "  Calculating route for Trip ID: 2 (14 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 29.15 km, Duration: 40.02 min\n",
      "  Calculating route for Trip ID: 3 (8 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 16.91 km, Duration: 20.12 min\n",
      "  Calculating route for Trip ID: 4 (7 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 29.37 km, Duration: 30.47 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647353.html\n",
      "35/70 \n",
      "Stock Point ID: 1647347 || Stock Point Name: OmniHub Ikorodu Lagos - Pleck\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ikorodu Lagos - Pleck, StockPointID: 1647347,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 7,142\n",
      "Total Quantity: 4,015\n",
      "Total Number of Customers before filter: 249\n",
      "Total Number of Customers: 138\n",
      "✓ Loaded 1049 SKU recommendations\n",
      "✓ Loaded 138 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.53\n",
      "Davies-Bouldin Index: 0.61\n",
      "Calinski-Harabasz Score: 2429.0\n",
      "Silhouette Score: 0.53\n",
      "Davies-Bouldin Index: 0.61\n",
      "Calinski-Harabasz Score: 2429.0\n",
      "Select ClusterIDs: [8, 4, 6, 2]\n",
      "Total Number of Customers: 45\n",
      "   cluster   LGA_list                                          LCDA_List  \\\n",
      "0        8  [Ikorodu]            [Ikorodu - Gberigbe, , Ikorodu - Adamo]   \n",
      "1        4  [Ikorodu]  [Ikorodu - Adamo, Ikorodu - Elepe, , Ikorodu -...   \n",
      "2        6  [Ikorodu]                                [Ikorodu - Adamo, ]   \n",
      "3        2  [Ikorodu]                             [Ikorodu - Gberigbe, ]   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0          7       157           47.983095  \n",
      "1         12       370           37.204343  \n",
      "2         12       331           35.321084  \n",
      "3         14       392           33.464206  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 2 (15 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 31.57 km, Duration: 41.85 min\n",
      "  Calculating route for Trip ID: 4 (13 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 35.95 km, Duration: 54.13 min\n",
      "  Calculating route for Trip ID: 6 (13 waypoints)...\n",
      "  Trip ID 6 calculated. Distance: 32.21 km, Duration: 47.23 min\n",
      "  Calculating route for Trip ID: 8 (8 waypoints)...\n",
      "  Trip ID 8 calculated. Distance: 13.61 km, Duration: 19.07 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647347.html\n",
      "36/70 \n",
      "Stock Point ID: 1647341 || Stock Point Name: OmniHub AMAC 3 Nasarawa - Utmaab Kurudu\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub AMAC 3 Nasarawa - Utmaab Kurudu, StockPointID: 1647341,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 3,612\n",
      "Total Quantity: 2,200\n",
      "Total Number of Customers before filter: 253\n",
      "Total Number of Customers: 149\n",
      "✓ Loaded 763 SKU recommendations\n",
      "✓ Loaded 149 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.71\n",
      "Davies-Bouldin Index: 0.41\n",
      "Calinski-Harabasz Score: 1008.05\n",
      "Silhouette Score: 0.71\n",
      "Davies-Bouldin Index: 0.41\n",
      "Calinski-Harabasz Score: 1008.05\n",
      "Select ClusterIDs: [9, 5, 4, 7]\n",
      "Total Number of Customers: 45\n",
      "   cluster          LGA_list            LCDA_List  ncustomer  totalQty  \\\n",
      "0        9          [AMAC 3]           [Karshi, ]          7       121   \n",
      "1        5          [AMAC 3]  [Jikwoyi, , Kurudu]         13       179   \n",
      "2        4          [AMAC 3]       [Nyanya, Karu]         14       221   \n",
      "3        7  [AMAC 3, AMAC 2]    [Kurudu, , Orozo]         11       161   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           47.004884  \n",
      "1           41.153750  \n",
      "2           39.571333  \n",
      "3           34.610408  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 4 (15 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 23.48 km, Duration: 21.60 min\n",
      "  Calculating route for Trip ID: 5 (14 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 30.39 km, Duration: 35.62 min\n",
      "  Calculating route for Trip ID: 7 (12 waypoints)...\n",
      "  Trip ID 7 calculated. Distance: 10.53 km, Duration: 13.67 min\n",
      "  Calculating route for Trip ID: 9 (8 waypoints)...\n",
      "  Trip ID 9 calculated. Distance: 19.18 km, Duration: 19.98 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647341.html\n",
      "37/70 \n",
      "Stock Point ID: 1647350 || Stock Point Name: OmniHub OBI AKPOR Rivers - CHARRYSWIFT\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub OBI AKPOR Rivers - CHARRYSWIFT, StockPointID: 1647350,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 18,550\n",
      "Total Quantity: 12,943\n",
      "Total Number of Customers before filter: 512\n",
      "Total Number of Customers: 354\n",
      "✓ Loaded 3346 SKU recommendations\n",
      "✓ Loaded 354 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.49\n",
      "Davies-Bouldin Index: 0.63\n",
      "Calinski-Harabasz Score: 1375.56\n",
      "Silhouette Score: 0.49\n",
      "Davies-Bouldin Index: 0.63\n",
      "Calinski-Harabasz Score: 1375.56\n",
      "Select ClusterIDs: [13, 7, 20, 12]\n",
      "Total Number of Customers: 53\n",
      "   cluster                     LGA_list                   LCDA_List  \\\n",
      "0       13  [Obio Akpor, Port Harcourt]      [Rumuolumeni, , Diobu]   \n",
      "1        7                 [Obio Akpor]  [Rumuolumeni, Mgbuosimini]   \n",
      "2       20                 [Obio Akpor]               [Rumuolumeni]   \n",
      "3       12                 [Obio Akpor]  [Rumuolumeni, , Rumuekini]   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0         13       482           52.908293  \n",
      "1         19       770           52.313333  \n",
      "2          7       264           50.545714  \n",
      "3         14       511           50.113485  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 7 (20 waypoints)...\n",
      "  Trip ID 7 calculated. Distance: 17.67 km, Duration: 29.85 min\n",
      "  Calculating route for Trip ID: 12 (15 waypoints)...\n",
      "  Trip ID 12 calculated. Distance: 11.26 km, Duration: 18.00 min\n",
      "  Calculating route for Trip ID: 13 (14 waypoints)...\n",
      "  Trip ID 13 calculated. Distance: 46.30 km, Duration: 66.45 min\n",
      "  Calculating route for Trip ID: 20 (8 waypoints)...\n",
      "  Trip ID 20 calculated. Distance: 14.86 km, Duration: 23.82 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647350.html\n",
      "38/70 \n",
      "Stock Point ID: 1647125 || Stock Point Name: OmniHub Ikorodu Lagos - Mofaz\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ikorodu Lagos - Mofaz, StockPointID: 1647125,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 14,901\n",
      "Total Quantity: 8,971\n",
      "Total Number of Customers before filter: 560\n",
      "Total Number of Customers: 348\n",
      "✓ Loaded 2460 SKU recommendations\n",
      "✓ Loaded 348 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.34\n",
      "Davies-Bouldin Index: 0.59\n",
      "Calinski-Harabasz Score: 7383.83\n",
      "Silhouette Score: 0.34\n",
      "Davies-Bouldin Index: 0.59\n",
      "Calinski-Harabasz Score: 7383.83\n",
      "Select ClusterIDs: [15, 6, 12, 5]\n",
      "Total Number of Customers: 59\n",
      "   cluster                   LGA_list  \\\n",
      "0       15                  [Ikorodu]   \n",
      "1        6                  [Ikorodu]   \n",
      "2       12          [Ikorodu, Kosofe]   \n",
      "3        5  [Push - Ikorodu, Ikorodu]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [Ikorodu - Eyita, Ikorodu - Odongunyan, Ikorod...          6       105   \n",
      "1  [, Ikorodu - Sabo, Ikorodu - Ajegunle, Ikorodu...         21       513   \n",
      "2  [Ikorodu - Owode Onirin, Kosofe - Mile 12, Iko...          9       252   \n",
      "3  [, Ikorodu - Agbede, Ikorodu - Agric, Ikorodu ...         23       519   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           68.946562  \n",
      "1           56.667183  \n",
      "2           47.288169  \n",
      "3           46.701071  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 5 (24 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 64.07 km, Duration: 88.85 min\n",
      "  Calculating route for Trip ID: 6 (22 waypoints)...\n",
      "  Trip ID 6 calculated. Distance: 45.82 km, Duration: 51.73 min\n",
      "  Calculating route for Trip ID: 12 (10 waypoints)...\n",
      "  Trip ID 12 calculated. Distance: 65.36 km, Duration: 59.28 min\n",
      "  Calculating route for Trip ID: 15 (7 waypoints)...\n",
      "  Trip ID 15 calculated. Distance: 40.92 km, Duration: 64.90 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647125.html\n",
      "39/70 \n",
      "Stock Point ID: 1647120 || Stock Point Name: OmniHub Surulere Lagos - Jimoh Odutola\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Surulere Lagos - Jimoh Odutola, StockPointID: 1647120,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "40/70 \n",
      "Stock Point ID: 1647122 || Stock Point Name: OmniHub Egbeda Oyo - Vizazi\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Egbeda Oyo - Vizazi, StockPointID: 1647122,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 9,413\n",
      "Total Quantity: 5,290\n",
      "Total Number of Customers before filter: 340\n",
      "Total Number of Customers: 196\n",
      "✓ Loaded 1423 SKU recommendations\n",
      "✓ Loaded 196 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.58\n",
      "Davies-Bouldin Index: 0.39\n",
      "Calinski-Harabasz Score: 15198.86\n",
      "Silhouette Score: 0.58\n",
      "Davies-Bouldin Index: 0.39\n",
      "Calinski-Harabasz Score: 15198.86\n",
      "Select ClusterIDs: [6, 7, 3, 1]\n",
      "Total Number of Customers: 76\n",
      "   cluster                                      LGA_list  \\\n",
      "0        6                     [Egbeda, Ona Ara, Ibadan]   \n",
      "1        7  [Lagelu, Ona Ara, Ibadan North East, Egbeda]   \n",
      "2        3       [Lagelu, Ibadan, Ibadan North, Ona Ara]   \n",
      "3        1                             [Egbeda, Oluyole]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [Academy, IBADAN-NEW GBAGI MARKET, Old Ife Roa...         18       555   \n",
      "1  [IBADAN-AKOBO, Olorunsogo, , Ona Ara, Olunloyo...         10       290   \n",
      "2  [Monatan, IBADAN-AKOBO, IYANA CHURCH, , Lalupo...         19       470   \n",
      "3  [IBADAN-NEW GBAGI MARKET, , Old Ife Road, Iwo ...         29       894   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           47.790584  \n",
      "1           42.468228  \n",
      "2           38.743884  \n",
      "3           38.622130  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (30 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 30.64 km, Duration: 43.18 min\n",
      "  Calculating route for Trip ID: 3 (20 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 44.58 km, Duration: 70.63 min\n",
      "  Calculating route for Trip ID: 6 (19 waypoints)...\n",
      "  Trip ID 6 calculated. Distance: 37.57 km, Duration: 57.77 min\n",
      "  Calculating route for Trip ID: 7 (11 waypoints)...\n",
      "  Trip ID 7 calculated. Distance: 22.61 km, Duration: 31.13 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647122.html\n",
      "41/70 \n",
      "Stock Point ID: 1647112 || Stock Point Name: OmniHub Lagos - OmniHub Eti Osa Lagos - Jimbass\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Lagos - OmniHub Eti Osa Lagos - Jimbass, StockPointID: 1647112,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "42/70 \n",
      "Stock Point ID: 1647113 || Stock Point Name: OmniHub Apapa Lagos - CAUSEWAY\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Apapa Lagos - CAUSEWAY, StockPointID: 1647113,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 29,962\n",
      "Total Quantity: 19,113\n",
      "Total Number of Customers before filter: 1,063\n",
      "Total Number of Customers: 676\n",
      "✓ Loaded 5731 SKU recommendations\n",
      "✓ Loaded 676 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.33\n",
      "Davies-Bouldin Index: 0.74\n",
      "Calinski-Harabasz Score: 41074.5\n",
      "Silhouette Score: 0.33\n",
      "Davies-Bouldin Index: 0.74\n",
      "Calinski-Harabasz Score: 41074.5\n",
      "Select ClusterIDs: [28, 2, 26, 15]\n",
      "Total Number of Customers: 72\n",
      "   cluster                                           LGA_list  \\\n",
      "0       28                   [Surulere, Mushin, Lagos Island]   \n",
      "1        2                                           [Mushin]   \n",
      "2       26                         [Ajeromi Ifelodun, Mushin]   \n",
      "3       15  [Ajeromi Ifelodun, Mushin, Lagos Island, Surul...   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [Surulere - Lawanson, Mushin - Mushin Market, ...         10       322   \n",
      "1  [Mushin - Mushin Market, , Mushin - Idi Oro, M...         30       894   \n",
      "2  [Ajeromi Ifelodun - Ajegunle, Ajeromi Ifelodun...         11       331   \n",
      "3  [, Mushin - Mushin Market, Mushin - Isolo Road...         21       698   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           58.455652  \n",
      "1           55.510577  \n",
      "2           54.928878  \n",
      "3           54.096302  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 2 (31 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 14.87 km, Duration: 34.50 min\n",
      "  Calculating route for Trip ID: 15 (22 waypoints)...\n",
      "  Trip ID 15 calculated. Distance: 19.85 km, Duration: 39.23 min\n",
      "  Calculating route for Trip ID: 26 (12 waypoints)...\n",
      "  Trip ID 26 calculated. Distance: 12.93 km, Duration: 40.58 min\n",
      "  Calculating route for Trip ID: 28 (11 waypoints)...\n",
      "  Trip ID 28 calculated. Distance: 20.21 km, Duration: 53.92 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647113.html\n",
      "43/70 \n",
      "Stock Point ID: 1647132 || Stock Point Name: OmniHub Ibadan North Oyo - Eby 99\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ibadan North Oyo - Eby 99, StockPointID: 1647132,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 5,310\n",
      "Total Quantity: 3,302\n",
      "Total Number of Customers before filter: 243\n",
      "Total Number of Customers: 153\n",
      "✓ Loaded 887 SKU recommendations\n",
      "✓ Loaded 153 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.54\n",
      "Davies-Bouldin Index: 0.51\n",
      "Calinski-Harabasz Score: 1209.79\n",
      "Silhouette Score: 0.54\n",
      "Davies-Bouldin Index: 0.51\n",
      "Calinski-Harabasz Score: 1209.79\n",
      "Select ClusterIDs: [7, 8, 1, 3]\n",
      "Total Number of Customers: 59\n",
      "   cluster                                          LGA_list  \\\n",
      "0        7                               [Ido, Ibadan North]   \n",
      "1        8                     [Ibadan North, Akinyele, Ido]   \n",
      "2        1  [Ibadan North West, Ibadan North, Ido, Akinyele]   \n",
      "3        3            [Ibadan North, Ido, Akinyele, Oluyole]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0                             [, Apete, Poly Ibadan]          8       191   \n",
      "1            [Bodija, Ojoo, Apete, , Eleyele, Sango]          7       172   \n",
      "2  [IBADAN-ELEYELE, Bodija, Sabo, Ibadan-UI, Ui, ...         24       585   \n",
      "3           [Poly Ibadan, Apete, Ojoo, , IBADAN-7UP]         20       454   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           44.672157  \n",
      "1           43.540851  \n",
      "2           40.454040  \n",
      "3           37.800800  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (25 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 57.28 km, Duration: 75.32 min\n",
      "  Calculating route for Trip ID: 3 (21 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 24.10 km, Duration: 30.25 min\n",
      "  Calculating route for Trip ID: 7 (9 waypoints)...\n",
      "  Trip ID 7 calculated. Distance: 16.48 km, Duration: 22.22 min\n",
      "  Calculating route for Trip ID: 8 (8 waypoints)...\n",
      "  Trip ID 8 calculated. Distance: 122.88 km, Duration: 110.02 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647132.html\n",
      "44/70 \n",
      "Stock Point ID: 1647124 || Stock Point Name: OmniHub Ibadan South West Oyo - Cemalon\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ibadan South West Oyo - Cemalon, StockPointID: 1647124,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 2,735\n",
      "Total Quantity: 1,349\n",
      "Total Number of Customers before filter: 136\n",
      "Total Number of Customers: 72\n",
      "✓ Loaded 347 SKU recommendations\n",
      "✓ Loaded 72 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.6\n",
      "Davies-Bouldin Index: 0.39\n",
      "Calinski-Harabasz Score: 1282.09\n",
      "Silhouette Score: 0.6\n",
      "Davies-Bouldin Index: 0.39\n",
      "Calinski-Harabasz Score: 1282.09\n",
      "Select ClusterIDs: [2, 4, 3, 1]\n",
      "Total Number of Customers: 57\n",
      "   cluster                                LGA_list  \\\n",
      "0        2                     [Ibadan South West]   \n",
      "1        4            [Oluyole, Ibadan South West]   \n",
      "2        3            [Ibadan South West, Oluyole]   \n",
      "3        1  [Ibadan North West, Ibadan South West]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0                        [Agbeni, , Molete, Oke Ado]         15       360   \n",
      "1           [IBADAN-ODO-ONA ELEWE, , Molete, Agbeni]          6        97   \n",
      "2  [Oluyole Estreet, IBADAN-TIPPER GARAGE, IBADAN...          7       105   \n",
      "3     [Agbeni, , Oke Ado, Orita Merin, IBADAN-DUGBE]         29       447   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           39.074831  \n",
      "1           31.291923  \n",
      "2           26.575000  \n",
      "3           23.090901  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (30 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 23.37 km, Duration: 36.93 min\n",
      "  Calculating route for Trip ID: 2 (16 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 28.62 km, Duration: 37.15 min\n",
      "  Calculating route for Trip ID: 3 (8 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 18.47 km, Duration: 32.20 min\n",
      "  Calculating route for Trip ID: 4 (7 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 21.73 km, Duration: 25.07 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647124.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Dataframe is empty\n",
      "INFO:__main__:Trip Data is empty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/70 \n",
      "Stock Point ID: 1647380 || Stock Point Name: OmniHub Owerri Municipal Imo - Bonaventure \n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Owerri Municipal Imo - Bonaventure , StockPointID: 1647380,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 225\n",
      "Total Quantity: 82\n",
      "Total Number of Customers before filter: 19\n",
      "Total Number of Customers: 10\n",
      "✓ Loaded 17 SKU recommendations\n",
      "✓ Loaded 10 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.39\n",
      "Davies-Bouldin Index: 0.5\n",
      "Calinski-Harabasz Score: 15.71\n",
      "Silhouette Score: 0.39\n",
      "Davies-Bouldin Index: 0.5\n",
      "Calinski-Harabasz Score: 15.71\n",
      "Select ClusterIDs: []\n",
      "Total Number of Customers: 0\n",
      "Empty DataFrame\n",
      "Columns: [cluster, LGA_list, LCDA_List, ncustomer, totalQty, avg_customer_score]\n",
      "Index: []\n",
      "46/70 \n",
      "Stock Point ID: 1647126 || Stock Point Name: OmniHub Sagamu Ogun - Ajaka\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Sagamu Ogun - Ajaka, StockPointID: 1647126,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 78\n",
      "Total Quantity: 50\n",
      "Total Number of Customers before filter: 2\n",
      "Total Number of Customers: 1\n",
      "47/70 \n",
      "Stock Point ID: 1647109 || Stock Point Name: OmniHub Oluyole Oyo - Techcomserve\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Oluyole Oyo - Techcomserve, StockPointID: 1647109,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 302\n",
      "Total Quantity: 277\n",
      "Total Number of Customers before filter: 22\n",
      "Total Number of Customers: 19\n",
      "✓ Loaded 77 SKU recommendations\n",
      "✓ Loaded 19 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.35\n",
      "Davies-Bouldin Index: 0.4\n",
      "Calinski-Harabasz Score: 647.78\n",
      "Silhouette Score: 0.35\n",
      "Davies-Bouldin Index: 0.4\n",
      "Calinski-Harabasz Score: 647.78\n",
      "Select ClusterIDs: [1]\n",
      "Total Number of Customers: 10\n",
      "   cluster                      LGA_list  \\\n",
      "0        1  [Oluyole, Ibadan South West]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [Orita Challenge, IBADAN-OLUYOLE, Ringroad, IB...         10       139   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           38.273571  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (11 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 38.88 km, Duration: 57.33 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647109.html\n",
      "48/70 \n",
      "Stock Point ID: 1647371 || Stock Point Name: OmniHub Alimosho Lagos - Demadek\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Alimosho Lagos - Demadek, StockPointID: 1647371,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 1,258\n",
      "Total Quantity: 808\n",
      "Total Number of Customers before filter: 64\n",
      "Total Number of Customers: 40\n",
      "✓ Loaded 246 SKU recommendations\n",
      "✓ Loaded 40 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.29\n",
      "Davies-Bouldin Index: 0.65\n",
      "Calinski-Harabasz Score: 29824.1\n",
      "Silhouette Score: 0.29\n",
      "Davies-Bouldin Index: 0.65\n",
      "Calinski-Harabasz Score: 29824.1\n",
      "Select ClusterIDs: [1, 3, 4, 2]\n",
      "Total Number of Customers: 33\n",
      "   cluster    LGA_list              LCDA_List  ncustomer  totalQty  \\\n",
      "0        1  [Alimosho]  [Alimosho - Igando, ]         13       237   \n",
      "1        3  [Alimosho]  [, Alimosho - Igando]          7       150   \n",
      "2        4  [Alimosho]  [, Alimosho - Igando]          5       101   \n",
      "3        2  [Alimosho]  [, Alimosho - Igando]          8       195   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           33.381667  \n",
      "1           33.238750  \n",
      "2           21.788125  \n",
      "3           19.376545  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (14 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 47.55 km, Duration: 105.38 min\n",
      "  Calculating route for Trip ID: 2 (9 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 42.26 km, Duration: 88.83 min\n",
      "  Calculating route for Trip ID: 3 (8 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 17.33 km, Duration: 45.05 min\n",
      "  Calculating route for Trip ID: 4 (6 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 28.48 km, Duration: 47.12 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647371.html\n",
      "49/70 \n",
      "Stock Point ID: 1647131 || Stock Point Name: OmniHub Alimosho Lagos - Pafeak\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Alimosho Lagos - Pafeak, StockPointID: 1647131,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 4,550\n",
      "Total Quantity: 2,663\n",
      "Total Number of Customers before filter: 171\n",
      "Total Number of Customers: 98\n",
      "✓ Loaded 859 SKU recommendations\n",
      "✓ Loaded 98 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.32\n",
      "Davies-Bouldin Index: 0.8\n",
      "Calinski-Harabasz Score: 7354.67\n",
      "Silhouette Score: 0.32\n",
      "Davies-Bouldin Index: 0.8\n",
      "Calinski-Harabasz Score: 7354.67\n",
      "Select ClusterIDs: [1, 3, 5, 2]\n",
      "Total Number of Customers: 66\n",
      "   cluster                  LGA_list  \\\n",
      "0        1                [Alimosho]   \n",
      "1        3  [Alimosho, Ifako Ijaiye]   \n",
      "2        5                [Alimosho]   \n",
      "3        2                [Alimosho]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [Alimosho - Abule Egba (alagbado), Alimosho - ...         25       671   \n",
      "1  [Alimosho - Abule Egba (agbado Ijaye Road), , ...         15       457   \n",
      "2  [Alimosho - Abule Egba (alagbado), Alimosho - ...          7       176   \n",
      "3  [Alimosho - Abule Egba (agbado Ijaye Road), , ...         19       503   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           50.759302  \n",
      "1           49.781727  \n",
      "2           47.643871  \n",
      "3           42.202303  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (26 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 58.41 km, Duration: 94.03 min\n",
      "  Calculating route for Trip ID: 2 (20 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 55.67 km, Duration: 77.30 min\n",
      "  Calculating route for Trip ID: 3 (16 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 38.54 km, Duration: 105.92 min\n",
      "  Calculating route for Trip ID: 5 (8 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 28.75 km, Duration: 47.42 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647131.html\n",
      "50/70 \n",
      "Stock Point ID: 1647110 || Stock Point Name: OmniHub Ado Odo/Ota Ogun - Hardej\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ado Odo/Ota Ogun - Hardej, StockPointID: 1647110,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 1,472\n",
      "Total Quantity: 1,058\n",
      "Total Number of Customers before filter: 104\n",
      "Total Number of Customers: 72\n",
      "✓ Loaded 256 SKU recommendations\n",
      "✓ Loaded 72 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.36\n",
      "Davies-Bouldin Index: 0.35\n",
      "Calinski-Harabasz Score: 11879.39\n",
      "Silhouette Score: 0.36\n",
      "Davies-Bouldin Index: 0.35\n",
      "Calinski-Harabasz Score: 11879.39\n",
      "Select ClusterIDs: [5, 3, 1, 4]\n",
      "Total Number of Customers: 37\n",
      "   cluster       LGA_list             LCDA_List  ncustomer  totalQty  \\\n",
      "0        5  [Ado Odo/Ota]      [Ota, Sango-Ota]          5        71   \n",
      "1        3  [Ado Odo/Ota]  [Sango, Sango-Ota, ]          7       112   \n",
      "2        1  [Ado Odo/Ota]    [Sango-Ota, Ota, ]         19       305   \n",
      "3        4  [Ado Odo/Ota]  [Sango, Sango-Ota, ]          6        83   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           59.401176  \n",
      "1           45.951154  \n",
      "2           44.361154  \n",
      "3           38.583333  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (20 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 60.32 km, Duration: 104.75 min\n",
      "  Calculating route for Trip ID: 3 (8 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 21.94 km, Duration: 47.75 min\n",
      "  Calculating route for Trip ID: 4 (7 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 17.15 km, Duration: 31.73 min\n",
      "  Calculating route for Trip ID: 5 (6 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 25.45 km, Duration: 47.12 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647110.html\n",
      "Unable to generate route mapping using orc: Cannot save file into a non-existent directory: 'recommendation_output/2025-06-28/OmniHub Ado Odo'\n",
      "51/70 \n",
      "Stock Point ID: 1647137 || Stock Point Name: OmniHub Shomolu Lagos - Autograph\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Shomolu Lagos - Autograph, StockPointID: 1647137,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 12,140\n",
      "Total Quantity: 7,927\n",
      "Total Number of Customers before filter: 460\n",
      "Total Number of Customers: 296\n",
      "✓ Loaded 2559 SKU recommendations\n",
      "✓ Loaded 296 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.28\n",
      "Davies-Bouldin Index: 0.73\n",
      "Calinski-Harabasz Score: 7014.28\n",
      "Silhouette Score: 0.28\n",
      "Davies-Bouldin Index: 0.73\n",
      "Calinski-Harabasz Score: 7014.28\n",
      "Select ClusterIDs: [13, 16, 4, 11]\n",
      "Total Number of Customers: 54\n",
      "   cluster                   LGA_list  \\\n",
      "0       13                  [Shomolu]   \n",
      "1       16  [Lagos Mainland, Shomolu]   \n",
      "2        4           [Lagos Mainland]   \n",
      "3       11                  [Shomolu]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0                                 [Shomolu - Bariga]          8       216   \n",
      "1  [, Shomolu - Bashua, Lagos Mainland - Yaba - A...          7       142   \n",
      "2  [Lagos Mainland - Yaba - Oyingbo, Lagos Mainla...         27       747   \n",
      "3                               [Shomolu - Bariga, ]         12       341   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           46.901471  \n",
      "1           45.944565  \n",
      "2           42.184531  \n",
      "3           40.740263  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 4 (28 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 110.30 km, Duration: 186.72 min\n",
      "  Calculating route for Trip ID: 11 (13 waypoints)...\n",
      "  Trip ID 11 calculated. Distance: 3.33 km, Duration: 7.28 min\n",
      "  Calculating route for Trip ID: 13 (9 waypoints)...\n",
      "  Trip ID 13 calculated. Distance: 4.50 km, Duration: 9.28 min\n",
      "  Calculating route for Trip ID: 16 (8 waypoints)...\n",
      "  Trip ID 16 calculated. Distance: 12.25 km, Duration: 34.80 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647137.html\n",
      "52/70 \n",
      "Stock Point ID: 1647106 || Stock Point Name: OmniHub Ikeja Lagos - Barka-Agro Food Ogba\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ikeja Lagos - Barka-Agro Food Ogba, StockPointID: 1647106,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 2,982\n",
      "Total Quantity: 1,744\n",
      "Total Number of Customers before filter: 194\n",
      "Total Number of Customers: 112\n",
      "✓ Loaded 489 SKU recommendations\n",
      "✓ Loaded 112 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.36\n",
      "Davies-Bouldin Index: 0.57\n",
      "Calinski-Harabasz Score: 16384.06\n",
      "Silhouette Score: 0.36\n",
      "Davies-Bouldin Index: 0.57\n",
      "Calinski-Harabasz Score: 16384.06\n",
      "Select ClusterIDs: [2, 7, 3, 5]\n",
      "Total Number of Customers: 51\n",
      "   cluster               LGA_list  \\\n",
      "0        2  [Ifako Ijaiye, Agege]   \n",
      "1        7         [Ifako Ijaiye]   \n",
      "2        3  [Ifako Ijaiye, Ikeja]   \n",
      "3        5         [Agege, Ikeja]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [Ifako Ijaiye - Ojokoro, Ifako Ijaiye - Ogba -...         16       341   \n",
      "1  [Ifako Ijaiye - Ogba - College Road, Ifako Ija...          6        78   \n",
      "2  [Ifako Ijaiye - Ojokoro, Ifako Ijaiye - Ogba -...         16       289   \n",
      "3  [Agege - Dopemu, , Agege - Old Abeokuta Road, ...         13       166   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           58.814747  \n",
      "1           54.180870  \n",
      "2           46.381585  \n",
      "3           39.404889  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 2 (17 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 67.75 km, Duration: 128.88 min\n",
      "  Calculating route for Trip ID: 3 (17 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 39.69 km, Duration: 111.57 min\n",
      "  Calculating route for Trip ID: 5 (14 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 62.78 km, Duration: 80.65 min\n",
      "  Calculating route for Trip ID: 7 (7 waypoints)...\n",
      "  Trip ID 7 calculated. Distance: 15.63 km, Duration: 44.12 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647106.html\n",
      "53/70 \n",
      "Stock Point ID: 1647115 || Stock Point Name: OmniHub Lagos - OmniHub Amuwo Odofin Lagos - EMPRESS KOT.\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Lagos - OmniHub Amuwo Odofin Lagos - EMPRESS KOT., StockPointID: 1647115,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "54/70 \n",
      "Stock Point ID: 1647424 || Stock Point Name: OmniHub Obafemi Owode Ogun - Favoured Goodness\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Obafemi Owode Ogun - Favoured Goodness, StockPointID: 1647424,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "55/70 \n",
      "Stock Point ID: 1647127 || Stock Point Name: OmniHub Obio Akpor Rivers - FHS\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Obio Akpor Rivers - FHS, StockPointID: 1647127,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 15,876\n",
      "Total Quantity: 11,187\n",
      "Total Number of Customers before filter: 420\n",
      "Total Number of Customers: 296\n",
      "✓ Loaded 2853 SKU recommendations\n",
      "✓ Loaded 296 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.4\n",
      "Davies-Bouldin Index: 0.71\n",
      "Calinski-Harabasz Score: 14516.04\n",
      "Silhouette Score: 0.4\n",
      "Davies-Bouldin Index: 0.71\n",
      "Calinski-Harabasz Score: 14516.04\n",
      "Select ClusterIDs: [13, 16, 8, 11]\n",
      "Total Number of Customers: 46\n",
      "   cluster      LGA_list                                          LCDA_List  \\\n",
      "0       13  [Obio Akpor]       [Rumuodomaya, Rumuokoro, , Eliozu, Rumuigbo]   \n",
      "1       16  [Obio Akpor]                            [Nkpelu, , Rumuaghaolu]   \n",
      "2        8  [Obio Akpor]       [Nkpelu, Rumuaghaolu, Rumuokoro, , Rumuigbo]   \n",
      "3       11  [Obio Akpor]  [Eliozu, Rumuaghaolu, Rumuodomaya, Rumuokwuota...   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0         11       439           53.842407  \n",
      "1          7       276           53.197143  \n",
      "2         17       628           48.856331  \n",
      "3         11       399           48.475000  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 8 (18 waypoints)...\n",
      "  Trip ID 8 calculated. Distance: 54.65 km, Duration: 75.93 min\n",
      "  Calculating route for Trip ID: 11 (12 waypoints)...\n",
      "  Trip ID 11 calculated. Distance: 34.35 km, Duration: 53.70 min\n",
      "  Calculating route for Trip ID: 13 (12 waypoints)...\n",
      "  Trip ID 13 calculated. Distance: 25.15 km, Duration: 38.23 min\n",
      "  Calculating route for Trip ID: 16 (8 waypoints)...\n",
      "  Trip ID 16 calculated. Distance: 12.96 km, Duration: 19.65 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647127.html\n",
      "56/70 \n",
      "Stock Point ID: 1647130 || Stock Point Name: OmniHub Abuja - OmniHub Bwari Abuja - NETLINK\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Abuja - OmniHub Bwari Abuja - NETLINK, StockPointID: 1647130,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 3,239\n",
      "Total Quantity: 1,765\n",
      "Total Number of Customers before filter: 276\n",
      "Total Number of Customers: 133\n",
      "✓ Loaded 543 SKU recommendations\n",
      "✓ Loaded 133 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.61\n",
      "Davies-Bouldin Index: 0.45\n",
      "Calinski-Harabasz Score: 5421.76\n",
      "Silhouette Score: 0.61\n",
      "Davies-Bouldin Index: 0.45\n",
      "Calinski-Harabasz Score: 5421.76\n",
      "Select ClusterIDs: [2, 6, 1, 3]\n",
      "Total Number of Customers: 70\n",
      "   cluster               LGA_list  \\\n",
      "0        2                [Bwari]   \n",
      "1        6  [Bwari, Push - Bwari]   \n",
      "2        1  [Bwari, Push - Bwari]   \n",
      "3        3        [Bwari, AMAC 1]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0              [, Dutsen Alhaji, Kubwa, ABUJA-BWARI]         18       238   \n",
      "1  [ABUJA-MPAPE, , Push - Abuja-Mpape, Dutsen Alh...          9       137   \n",
      "2  [Kogo, ABUJA-BWARI, Push - Abuja-Bwari, , Kubw...         29       335   \n",
      "3                  [Kubwa, , Dei Dei, Kubwa Central]         14       191   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           57.256849  \n",
      "1           50.768571  \n",
      "2           43.145784  \n",
      "3           40.505667  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (30 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 41.25 km, Duration: 64.03 min\n",
      "  Calculating route for Trip ID: 2 (19 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 83.00 km, Duration: 97.53 min\n",
      "  Calculating route for Trip ID: 3 (15 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 39.32 km, Duration: 66.28 min\n",
      "  Calculating route for Trip ID: 6 (10 waypoints)...\n",
      "  Trip ID 6 calculated. Distance: 61.26 km, Duration: 83.13 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647130.html\n",
      "57/70 \n",
      "Stock Point ID: 1647111 || Stock Point Name: OmniHub Bwari Abuja - BAFAL\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Bwari Abuja - BAFAL, StockPointID: 1647111,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 4,207\n",
      "Total Quantity: 1,747\n",
      "Total Number of Customers before filter: 436\n",
      "Total Number of Customers: 185\n",
      "✓ Loaded 545 SKU recommendations\n",
      "✓ Loaded 185 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.54\n",
      "Davies-Bouldin Index: 0.73\n",
      "Calinski-Harabasz Score: 1300.4\n",
      "Silhouette Score: 0.54\n",
      "Davies-Bouldin Index: 0.73\n",
      "Calinski-Harabasz Score: 1300.4\n",
      "Select ClusterIDs: [10, 8, 3, 13]\n",
      "Total Number of Customers: 39\n",
      "   cluster                          LGA_list                   LCDA_List  \\\n",
      "0       10                          [AMAC 1]                [Idu, Lugbe]   \n",
      "1        8  [AMAC 1, Push - Abuja Municipal]  [Lugbe, Idu, Push - Lugbe]   \n",
      "2        3                          [AMAC 1]           [Jabi, Dei Dei, ]   \n",
      "3       13                          [AMAC 1]                 [Dei Dei, ]   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0          8        64           61.919474  \n",
      "1          8        85           42.513929  \n",
      "2         17       178           42.076964  \n",
      "3          6        46           39.736000  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 3 (18 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 85.51 km, Duration: 104.77 min\n",
      "  Calculating route for Trip ID: 8 (9 waypoints)...\n",
      "  Trip ID 8 calculated. Distance: 69.86 km, Duration: 73.50 min\n",
      "  Calculating route for Trip ID: 10 (9 waypoints)...\n",
      "  Trip ID 10 calculated. Distance: 60.98 km, Duration: 67.32 min\n",
      "  Calculating route for Trip ID: 13 (7 waypoints)...\n",
      "  Trip ID 13 calculated. Distance: 43.60 km, Duration: 41.72 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647111.html\n",
      "58/70 \n",
      "Stock Point ID: 1647382 || Stock Point Name: OmniHub Port Harcourt Rivers - IFO\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Port Harcourt Rivers - IFO, StockPointID: 1647382,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 4,993\n",
      "Total Quantity: 3,724\n",
      "Total Number of Customers before filter: 170\n",
      "Total Number of Customers: 125\n",
      "✓ Loaded 964 SKU recommendations\n",
      "✓ Loaded 125 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.58\n",
      "Davies-Bouldin Index: 0.32\n",
      "Calinski-Harabasz Score: 41815.79\n",
      "Silhouette Score: 0.58\n",
      "Davies-Bouldin Index: 0.32\n",
      "Calinski-Harabasz Score: 41815.79\n",
      "Select ClusterIDs: [3, 1, 5, 4]\n",
      "Total Number of Customers: 79\n",
      "   cluster                     LGA_list  \\\n",
      "0        3              [Port Harcourt]   \n",
      "1        1              [Port Harcourt]   \n",
      "2        5  [Port Harcourt, Obio Akpor]   \n",
      "3        4              [Port Harcourt]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0                        [Diobu, PORTHARCOURT-DIOBU]         22       681   \n",
      "1  [PORTHARCOURT-DIOBU, PORTHARCOURT-MILE 1, Diob...         30       953   \n",
      "2               [, PORTHARCOURT-MILE 3, Diobu, Woji]          6       200   \n",
      "3  [Nkpogu, D-Line, Ogbunabali, Oroworukwo, , New...         21       572   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           44.121404  \n",
      "1           37.035692  \n",
      "2           35.509800  \n",
      "3           33.894777  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (31 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 58.75 km, Duration: 83.77 min\n",
      "  Calculating route for Trip ID: 3 (23 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 24.86 km, Duration: 36.50 min\n",
      "  Calculating route for Trip ID: 4 (22 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 53.63 km, Duration: 71.05 min\n",
      "  Calculating route for Trip ID: 5 (7 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 29.31 km, Duration: 34.30 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647382.html\n",
      "59/70 \n",
      "Stock Point ID: 1647108 || Stock Point Name: OmniHub AMAC 2 Abuja - PearlCity Maraba\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub AMAC 2 Abuja - PearlCity Maraba, StockPointID: 1647108,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 9,292\n",
      "Total Quantity: 5,865\n",
      "Total Number of Customers before filter: 569\n",
      "Total Number of Customers: 348\n",
      "✓ Loaded 2060 SKU recommendations\n",
      "✓ Loaded 348 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.52\n",
      "Davies-Bouldin Index: 0.28\n",
      "Calinski-Harabasz Score: 15951.57\n",
      "Silhouette Score: 0.52\n",
      "Davies-Bouldin Index: 0.28\n",
      "Calinski-Harabasz Score: 15951.57\n",
      "Select ClusterIDs: [11, 2, 12, 4]\n",
      "Total Number of Customers: 77\n",
      "   cluster  LGA_list                                          LCDA_List  \\\n",
      "0       11  [AMAC 3]                                          [Maska, ]   \n",
      "1        2  [AMAC 3]                                          [Maska, ]   \n",
      "2       12  [AMAC 3]                                         [Durumi, ]   \n",
      "3        4  [AMAC 3]  [, Maska, Apo, Garki Village, Garki 2, Durumi,...   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0          9       177           50.736610  \n",
      "1         30       601           50.475333  \n",
      "2          8       121           49.086667  \n",
      "3         30       458           48.764634  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 2 (31 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 34.22 km, Duration: 27.33 min\n",
      "  Calculating route for Trip ID: 4 (31 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 102.87 km, Duration: 78.15 min\n",
      "  Calculating route for Trip ID: 11 (10 waypoints)...\n",
      "  Trip ID 11 calculated. Distance: 35.12 km, Duration: 29.82 min\n",
      "  Calculating route for Trip ID: 12 (9 waypoints)...\n",
      "  Trip ID 12 calculated. Distance: 16.36 km, Duration: 22.35 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647108.html\n",
      "60/70 \n",
      "Stock Point ID: 1647141 || Stock Point Name: OmniHub Ojo Lagos - Mas Global\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ojo Lagos - Mas Global, StockPointID: 1647141,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 8,542\n",
      "Total Quantity: 6,677\n",
      "Total Number of Customers before filter: 493\n",
      "Total Number of Customers: 384\n",
      "✓ Loaded 1696 SKU recommendations\n",
      "✓ Loaded 384 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.37\n",
      "Davies-Bouldin Index: 0.47\n",
      "Calinski-Harabasz Score: 21826.18\n",
      "Silhouette Score: 0.37\n",
      "Davies-Bouldin Index: 0.47\n",
      "Calinski-Harabasz Score: 21826.18\n",
      "Select ClusterIDs: [19, 8, 10, 11]\n",
      "Total Number of Customers: 49\n",
      "   cluster        LGA_list                                          LCDA_List  \\\n",
      "0       19           [Ojo]  [Ojo - Iba Housing Area, , Ojo - Iba, Ojo - Lasu]   \n",
      "1        8  [Amuwo Odofin]  [Amuwo Odofin - Festac (1st Avenue), , Amuwo O...   \n",
      "2       10           [Ojo]                 [Ojo - Okokomaiko, Ojo - Aka Road]   \n",
      "3       11           [Ojo]                 [Ojo - Aka Road, Ojo - Okokomaiko]   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0          5        96           47.120909  \n",
      "1         18       294           46.492821  \n",
      "2         13       244           45.512308  \n",
      "3         13       254           43.095385  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 8 (19 waypoints)...\n",
      "  Trip ID 8 calculated. Distance: 70.88 km, Duration: 115.45 min\n",
      "  Calculating route for Trip ID: 10 (14 waypoints)...\n",
      "  Trip ID 10 calculated. Distance: 37.67 km, Duration: 51.48 min\n",
      "  Calculating route for Trip ID: 11 (14 waypoints)...\n",
      "  Trip ID 11 calculated. Distance: 10.67 km, Duration: 25.98 min\n",
      "  Calculating route for Trip ID: 19 (6 waypoints)...\n",
      "  Trip ID 19 calculated. Distance: 14.06 km, Duration: 24.97 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647141.html\n",
      "61/70 \n",
      "Stock Point ID: 1647187 || Stock Point Name: OmniHub Calabar Municipal Cross River - Eyong Obot\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Calabar Municipal Cross River - Eyong Obot, StockPointID: 1647187,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 1,666\n",
      "Total Quantity: 1,297\n",
      "Total Number of Customers before filter: 203\n",
      "Total Number of Customers: 152\n",
      "✓ Loaded 339 SKU recommendations\n",
      "✓ Loaded 152 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.46\n",
      "Davies-Bouldin Index: 0.59\n",
      "Calinski-Harabasz Score: 92092.26\n",
      "Silhouette Score: 0.46\n",
      "Davies-Bouldin Index: 0.59\n",
      "Calinski-Harabasz Score: 92092.26\n",
      "Select ClusterIDs: [2, 6, 1, 5]\n",
      "Total Number of Customers: 83\n",
      "   cluster                            LGA_list  \\\n",
      "0        2                     [Calabar South]   \n",
      "1        6  [Calabar South, Calabar Municipal]   \n",
      "2        1                     [Calabar South]   \n",
      "3        5                     [Calabar South]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [GOLDIE, Etim Edem Street., Watt Market, Calab...         28       265   \n",
      "1  [GOLDIE, MBUKPA, Esuk Atu Road., Calabar Road....         10        96   \n",
      "2  [MBUKPA, MAYNE AVENUE, YELLOW DUKE, GOLDIE, EG...         29       249   \n",
      "3  [Chambley Street., EGERTON, MAYNE AVENUE, Bedw...         16       117   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           52.295072  \n",
      "1           49.535833  \n",
      "2           46.579077  \n",
      "3           46.318621  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (30 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 26.72 km, Duration: 46.45 min\n",
      "  Calculating route for Trip ID: 2 (29 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 12.30 km, Duration: 22.50 min\n",
      "  Calculating route for Trip ID: 5 (17 waypoints)...\n",
      "  Trip ID 5 calculated. Distance: 9.59 km, Duration: 16.62 min\n",
      "  Calculating route for Trip ID: 6 (11 waypoints)...\n",
      "  Trip ID 6 calculated. Distance: 28.64 km, Duration: 41.77 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647187.html\n",
      "62/70 \n",
      "Stock Point ID: 1647403 || Stock Point Name: OmniHub Calabar Municipal Cross River - Alpha Grafix\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Calabar Municipal Cross River - Alpha Grafix, StockPointID: 1647403,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 712\n",
      "Total Quantity: 483\n",
      "Total Number of Customers before filter: 84\n",
      "Total Number of Customers: 51\n",
      "✓ Loaded 110 SKU recommendations\n",
      "✓ Loaded 51 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Silhouette Score: 0.34\n",
      "Davies-Bouldin Index: 0.55\n",
      "Calinski-Harabasz Score: 3084.68\n",
      "Silhouette Score: 0.34\n",
      "Davies-Bouldin Index: 0.55\n",
      "Calinski-Harabasz Score: 3084.68\n",
      "Select ClusterIDs: [2, 1, 3, 4]\n",
      "Total Number of Customers: 46\n",
      "   cluster                            LGA_list  \\\n",
      "0        2                 [Calabar Municipal]   \n",
      "1        1                 [Calabar Municipal]   \n",
      "2        3  [Calabar Municipal, Calabar South]   \n",
      "3        4                 [Calabar Municipal]   \n",
      "\n",
      "                                           LCDA_List  ncustomer  totalQty  \\\n",
      "0  [Esuk Atu Road., Calabar Municipal Office, Edi...         14       144   \n",
      "1  [Old Odukpani Road., Nsemo Road., Marian Road....         17       150   \n",
      "2  [Old Odukpani Road., Eyo Ita Street., Abang As...         10        77   \n",
      "3  [Asim Ita Close Close, Old Odukpani Road., Iko...          5        58   \n",
      "\n",
      "   avg_customer_score  \n",
      "0           12.502500  \n",
      "1           12.307059  \n",
      "2            8.132632  \n",
      "3            5.000000  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (18 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 34.64 km, Duration: 38.57 min\n",
      "  Calculating route for Trip ID: 2 (15 waypoints)...\n",
      "  Trip ID 2 calculated. Distance: 27.34 km, Duration: 40.52 min\n",
      "  Calculating route for Trip ID: 3 (11 waypoints)...\n",
      "  Trip ID 3 calculated. Distance: 38.50 km, Duration: 52.22 min\n",
      "  Calculating route for Trip ID: 4 (6 waypoints)...\n",
      "  Trip ID 4 calculated. Distance: 16.89 km, Duration: 20.30 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647403.html\n",
      "63/70 \n",
      "Stock Point ID: 1647419 || Stock Point Name: OmniHub Alimosho Lagos - Kay24\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Alimosho Lagos - Kay24, StockPointID: 1647419,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 206\n",
      "Total Quantity: 79\n",
      "Total Number of Customers before filter: 13\n",
      "Total Number of Customers: 5\n",
      "✓ Loaded 24 SKU recommendations\n",
      "✓ Loaded 5 customer records\n",
      "✓ Loaded 1 stock points\n",
      "✓ Route optimizer initialized\n",
      "\n",
      "3. Generating Optimized Routes...\n",
      "----------------------------------------\n",
      "\n",
      "4. Route Analysis & Results...\n",
      "----------------------------------------\n",
      "Select ClusterIDs: [1]\n",
      "Total Number of Customers: 5\n",
      "   cluster    LGA_list                                          LCDA_List  \\\n",
      "0        1  [Alimosho]  [Alimosho - Iyana Ipaja (iyana Ipaja Road), Al...   \n",
      "\n",
      "   ncustomer  totalQty  avg_customer_score  \n",
      "0          5        79            2.708333  \n",
      "Starting route calculations for all trips...\n",
      "  Calculating route for Trip ID: 1 (6 waypoints)...\n",
      "  Trip ID 1 calculated. Distance: 40.10 km, Duration: 65.95 min\n",
      "All route calculations completed.\n",
      "\n",
      "Interactive map saved to: /home/bt/project/demand_engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-06-28/1647419.html\n",
      "64/70 \n",
      "Stock Point ID: 1647420 || Stock Point Name: OmniHub Ojo Lagos - Barka Agro 3\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ojo Lagos - Barka Agro 3, StockPointID: 1647420,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "65/70 \n",
      "Stock Point ID: 1647421 || Stock Point Name: OmniHub Ikpoba Okha Edo - Real Care\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Ikpoba Okha Edo - Real Care, StockPointID: 1647421,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "66/70 \n",
      "Stock Point ID: 1647422 || Stock Point Name: OmniHub Oshodi Isolo Lagos - Fabb\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Oshodi Isolo Lagos - Fabb, StockPointID: 1647422,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "67/70 \n",
      "Stock Point ID: 1647425 || Stock Point Name: OmniHub Keffi Nasarawa - Donsam\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Keffi Nasarawa - Donsam, StockPointID: 1647425,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "68/70 \n",
      "Stock Point ID: 1647434 || Stock Point Name: OmniHub Kuje/Gwagwalada/Abaji Abuja - Deschek\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Kuje/Gwagwalada/Abaji Abuja - Deschek, StockPointID: 1647434,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n",
      "69/70 \n",
      "Stock Point ID: 1647436 || Stock Point Name: OmniHub Egor Edo - 10TH Gear\n",
      "================================================================================\n",
      "ROUTE OPTIMIZATION FOR PUSH SALES RECOMMENDATIONS\n",
      "StockPoint: OmniHub Egor Edo - 10TH Gear, StockPointID: 1647436,\n",
      "================================================================================\n",
      "\n",
      "1. Loading Data...\n",
      "----------------------------------------\n",
      "Total Quantity before filter: 0\n",
      "Total Quantity: 0\n",
      "Total Number of Customers before filter: 0\n",
      "Total Number of Customers: 0\n"
     ]
    }
   ],
   "source": [
    "ALL_STOCKPOINTS_RESULT = {}\n",
    "for index, row in df_stockpoint_dim.iterrows():\n",
    "    # if index == 12:\n",
    "    # if index == 5:\n",
    "    stock_point_id =  row['Stock_Point_ID']\n",
    "    stock_point_name = row['Stock_point_Name']\n",
    "    print(f'{index}/{len(df_stockpoint_dim)} \\nStock Point ID: {stock_point_id} || Stock Point Name: {stock_point_name}')  # Access by column name\n",
    "\n",
    "    res_dict = run_push_recommendation(df_customer_sku_recommendation, \n",
    "                                df_master_customer_dim, \n",
    "                                df_stockpoint_dim, \n",
    "                                stock_point_id,\n",
    "                                stock_point_name,\n",
    "                                sku_recency = 7, \n",
    "                                customer_recency = 60, number_recommendation = 10, \n",
    "                                estimate_qty_scale_factor = 1, max_estimated_qty = 5, \n",
    "                                exclude_recency_customer = 5,\n",
    "                                max_customers_per_route=20,\n",
    "                                max_volume_per_route=300,\n",
    "                                max_distance_km = 5,\n",
    "                                sel_trip_cluster = 4,\n",
    "                                min_ncust_per_cluster = 5,\n",
    "                                clustering_method = 'divisive',\n",
    "                                skip_route_optimization = True)\n",
    "    \n",
    "    ALL_STOCKPOINTS_RESULT[stock_point_name] = res_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d067f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res_dict.keys())\n",
    "# [col  for col in res_dict['all_push_recommendation'].columns if 'KYC_Capture_Status' in col]\n",
    "# res_dict['cluster_summary'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6f9cbb",
   "metadata": {},
   "source": [
    "## Routing 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04decfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = ALL_STOCKPOINTS_RESULT['OmniHub Apapa Lagos - CAUSEWAY'] \n",
    "df_selected_trip = df_test['selected_trip']\n",
    "print(df_selected_trip.TripID.nunique())\n",
    "# dict_keys(['stock_point_name', 'selected_trip', 'all_push_recommendation', 'cluster_summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5b661f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected_trip_summary =  df_selected_trip.groupby(['StockPointID','TripID', \n",
    "                                                                                   'CustomerID', 'Latitude','Longitude',\n",
    "                                                                                   'LGA', 'LCDA','CustomerScore']).agg( \n",
    "                        TotalQuantity = ('EstimatedQuantity','sum')\n",
    "                        ,TotalSKU = ('SKUID','nunique')\n",
    "                    ).reset_index() \n",
    "# trip_dict = create_single_stockpoint_dict(df_selected_trip_summary, df_stockpoint_dim) \n",
    "# route_info = calculated_routes_info = get_valhalla_routes_info(trip_dict)\n",
    "# route_info[0].keys()\n",
    "# len(trip_dict['Trips'][0]['Destinations'])\n",
    "create_route(df_selected_trip_summary, df_stockpoint_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889871c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_route(df_selected_trip_summary, df_stockpoint_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b199e2",
   "metadata": {},
   "source": [
    "# Data Export to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ea7a9217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL_STOCKPOINTS_RESULT.keys()\n",
    "# # ALL_STOCKPOINTS_RESULT['OmniHub Obio Akpor Rivers - Rivoc']\n",
    "# ALL_STOCKPOINTS_RESULT['OmniHub Ado Odo/Ota Ogun - Prince Tunadek']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "58bc8c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_ALL_RECOMMENDATION = pd.DataFrame() \n",
    "for key in ALL_STOCKPOINTS_RESULT.keys():\n",
    "    dict_f = ALL_STOCKPOINTS_RESULT[key]\n",
    "    if dict_f != {}:\n",
    "        df_ = dict_f['all_push_recommendation']\n",
    "    \n",
    "        if len(df_) > 0:\n",
    "            df_['ClusterLGAs'] = df_['ClusterLGAs'].apply(str)\n",
    "            df_['ClusterLCDAs'] = df_['ClusterLCDAs'].apply(str)\n",
    "            DF_ALL_RECOMMENDATION = pd.concat([DF_ALL_RECOMMENDATION, df_])\n",
    "            DF_ALL_RECOMMENDATION['ModifiedDate'] = CURRENT_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f705d251",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_summary = ['StockPointID', 'StockPointName', 'TripID', 'ClusterLGAs', 'ClusterLCDAs', 'TotalCustonerCount', 'TripTotalQuantity','TripAvgCustomerScore', 'ModifiedDate']  \n",
    "DF_CLUSTER_SUMMARY = DF_ALL_RECOMMENDATION[cols_summary].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2d60a7d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StockPointID</th>\n",
       "      <th>StockPointName</th>\n",
       "      <th>TripID</th>\n",
       "      <th>ClusterLGAs</th>\n",
       "      <th>ClusterLCDAs</th>\n",
       "      <th>TotalCustonerCount</th>\n",
       "      <th>TripTotalQuantity</th>\n",
       "      <th>TripAvgCustomerScore</th>\n",
       "      <th>ModifiedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>1647010</td>\n",
       "      <td>OmniHub Alimosho Lagos - LARDAMIC</td>\n",
       "      <td>3</td>\n",
       "      <td>['Alimosho']</td>\n",
       "      <td>['Alimosho - Abule Egba (ajasa Command Rd)', '...</td>\n",
       "      <td>3</td>\n",
       "      <td>93</td>\n",
       "      <td>61.166</td>\n",
       "      <td>2025-06-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     StockPointID                     StockPointName  TripID   ClusterLGAs  \\\n",
       "120       1647010  OmniHub Alimosho Lagos - LARDAMIC       3  ['Alimosho']   \n",
       "\n",
       "                                          ClusterLCDAs  TotalCustonerCount  \\\n",
       "120  ['Alimosho - Abule Egba (ajasa Command Rd)', '...                   3   \n",
       "\n",
       "     TripTotalQuantity  TripAvgCustomerScore ModifiedDate  \n",
       "120                 93                61.166   2025-06-28  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "# DF_ALL_RECOMMENDATION.sample(1)\n",
    "DF_CLUSTER_SUMMARY.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "605ba250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_lengths = DF_ALL_RECOMMENDATION.astype(str).applymap(len).max().reset_index(name = 'max_length')\n",
    "# print(max_lengths)\n",
    "# print(DF_ALL_RECOMMENDATION.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "15686f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsert_dataframe(df, table_name, conn, match_cols, update_cols, batch_size = 2000, fast_executemany = True):\n",
    "    # Input validation\n",
    "    if df.empty:\n",
    "        raise ValueError(\"DataFrame is empty.\")\n",
    "    if not match_cols or not update_cols:\n",
    "        raise ValueError(\"match_cols and update_cols cannot be empty.\")\n",
    "    if not all(col in df.columns for col in match_cols + update_cols):\n",
    "        raise ValueError(\"Some match_cols or update_cols are not in the DataFrame.\")\n",
    "    if not table_name.strip() or any(c in table_name for c in \".;[]\"):\n",
    "        raise ValueError(\"Invalid table_name.\")\n",
    "\n",
    "    cursor = None\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.fast_executemany = fast_executemany \n",
    "\n",
    "        staging_table = f\"#{table_name}_staging\"\n",
    "        cols = df.columns.tolist()\n",
    "        col_list = ', '.join(f\"[{col}]\" for col in cols)\n",
    "        placeholders = ', '.join(['?'] * len(cols))\n",
    "\n",
    "        # Step 1: Create staging table from real schema\n",
    "        create_staging_sql = f\"\"\"\n",
    "        SELECT TOP 0 {col_list}\n",
    "        INTO {staging_table}\n",
    "        FROM {table_name}\n",
    "        WHERE 1 = 0;\n",
    "        \"\"\"\n",
    "        cursor.execute(create_staging_sql)\n",
    "\n",
    "        # Step 2: Bulk insert into staging table using fast_executemany\n",
    "        insert_sql = f\"INSERT INTO {staging_table} ({col_list}) VALUES ({placeholders})\"\n",
    "        cursor.executemany(insert_sql, df[cols].values.tolist())\n",
    "        conn.commit()\n",
    "\n",
    "        # insert_sql = f\"INSERT INTO {staging_table} ({col_list}) VALUES ({placeholders})\"\n",
    "        # data = df[cols].values.tolist()\n",
    "        # for i in range(0, len(data), batch_size):\n",
    "        #     cursor.executemany(insert_sql, data[i:i+batch_size])\n",
    "        # conn.commit()\n",
    "\n",
    "        # Step 3: MERGE for upsert\n",
    "        on_clause = ' AND '.join([f\"TARGET.[{col}] = SOURCE.[{col}]\" for col in match_cols])\n",
    "        update_clause = ', '.join([f\"TARGET.[{col}] = SOURCE.[{col}]\" for col in update_cols])\n",
    "        insert_cols = ', '.join([f\"[{col}]\" for col in cols])\n",
    "        insert_values = ', '.join([f\"SOURCE.[{col}]\" for col in cols])\n",
    "\n",
    "        merge_sql = f\"\"\"\n",
    "        MERGE {table_name} AS TARGET\n",
    "        USING {staging_table} AS SOURCE\n",
    "        ON {on_clause}\n",
    "        WHEN MATCHED THEN\n",
    "            UPDATE SET {update_clause}\n",
    "        WHEN NOT MATCHED THEN\n",
    "            INSERT ({insert_cols})\n",
    "            VALUES ({insert_values});\n",
    "        \"\"\"\n",
    "        cursor.execute(merge_sql)\n",
    "        conn.commit()\n",
    "    except Exception as e:\n",
    "        if conn:\n",
    "            conn.rollback()\n",
    "        logger.error(f\"Upsert failed for table {table_name}: {e}\")\n",
    "        raise Exception(f\"Upsert failed for table {table_name}: {e}\") from e\n",
    "    finally:\n",
    "        if cursor:\n",
    "            cursor.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "605c6399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "df_insert = DF_ALL_RECOMMENDATION.drop(columns=['ClusterLGAs',\t'ClusterLCDAs']).reset_index(drop=True)\n",
    "# Replace 'YourProblematicColumn' with the actual column name you found\n",
    "df_insert['SKUDaysSinceLastBuy'] = df_insert['SKUDaysSinceLastBuy'].astype(float, errors='ignore').astype(int, errors='ignore')\n",
    "df_insert['CustomerDaysSinceLastBuy'] = df_insert['CustomerDaysSinceLastBuy'].astype(float, errors='ignore').astype(int, errors='ignore')\n",
    "\n",
    "match_cols = ['StockPointID', 'CustomerID', 'SKUID', 'ModifiedDate']\n",
    "update_cols = list(set(df_insert.columns) - set(match_cols))\n",
    "\n",
    "conn = get_connection()\n",
    "upsert_dataframe(\n",
    "    df=df_insert,\n",
    "    table_name='dailyPredictedPull',\n",
    "    conn=conn,\n",
    "    match_cols=match_cols,\n",
    "    update_cols=update_cols   \n",
    ") \n",
    " \n",
    "print(conn.closed)\n",
    "conn.close()\n",
    "print(conn.closed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5e9d8104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "df = DF_CLUSTER_SUMMARY.copy() \n",
    "\n",
    "df['ClusterLGAs'] = df['ClusterLGAs'].astype(str).str.slice(0, 500)\n",
    "df['ClusterLCDAs'] = df['ClusterLCDAs'].astype(str).str.slice(0, 500)\n",
    "\n",
    "\n",
    "match_cols = ['StockPointID', 'TripID', 'ModifiedDate']\n",
    "update_cols = list(set(df.columns) - set(match_cols))\n",
    "\n",
    "conn = get_connection()\n",
    "upsert_dataframe(\n",
    "    df=df,\n",
    "    table_name='dailyPredictedPullClusterSummary',\n",
    "    conn=conn,\n",
    "    match_cols=match_cols,\n",
    "    update_cols=update_cols ,\n",
    "    fast_executemany = False  \n",
    ")\n",
    "\n",
    "print(conn.closed)\n",
    "conn.close()\n",
    "print(conn.closed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa188a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d7a360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pd.set_option('display.width', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# res_dict['all_push_recommendation'].sample(1)\n",
    "# # res_dict['cluster_summary'].sort_values('ncustomer', ascending = False)\n",
    "# from collections import Counter\n",
    "# Counter(res_dict['all_push_recommendation'].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d210a690",
   "metadata": {},
   "source": [
    "# Case Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cced9601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Quantity before filter: 16,300\n",
      "Total Quantity: 11,203\n",
      "Total Number of Customers before filter: 476\n",
      "Total Number of Customers: 326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(326, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Filter - Testing \n",
    "causeway, causeway_customer_dim, causeway_stockpoint, = data_filter(df_customer_sku_recommendation, \n",
    "                                                                    df_master_customer_dim, \n",
    "                                                                    df_stockpoint_dim, \n",
    "                                                                    stockpoint_id = 1647394,  \n",
    "                                                                    # stockpoint_id = 1647113,  \n",
    "                                                                    sku_recency = 7, customer_recency = 60, number_recommendation = 10,\n",
    "                                                                    estimate_qty_scale_factor = 1, max_estimated_qty = 5, \n",
    "                                                                    exclude_recency_customer = 4)\n",
    "\n",
    "# Total Number of Customers: 905 || 901\n",
    "\n",
    "df_all_cluster = causeway_customer_dim[['CustomerID', 'Latitude','Longitude']].drop_duplicates()\n",
    "df_all_cluster.shape\n",
    "# df_all_cluster = res_dict['all_push_recommendation'][['CustomerID','TripID', 'Latitude','Longitude']].drop_duplicates().rename(columns={'TripID':'cluster'})\n",
    "\n",
    "\n",
    "# vis_and_save(df_routes = df_all_cluster,\n",
    "#                  df_stockpoint = None,   \n",
    "#                  filename=None,\n",
    "#                  cluster_col = 'cluster')\n",
    "\n",
    "# 459\n",
    "# 364"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb813416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_cluster.Latitude.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a397ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = ['CustomerID', 'SKUID', 'Medium','CustomerPurchaseRecency']\n",
    "# causeway[cols].query('(CustomerID == 5271729) or (CustomerID ==  5266873)')\n",
    "# causeway.groupby(['CustomerPurchaseRecency'])['CustomerID'].nunique().reset_index().sort_values('CustomerID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee26108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# causeway.columns\n",
    "# causeway['Medium'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b73d94d",
   "metadata": {},
   "source": [
    "### Test New Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee242d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clustering.divisive_clustering import DivisiveGeographicClustering, OptimizedDivisiveGeographicClustering\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"2. DIVISIVE HIERARCHICAL CLUSTERING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "divisive_clusterer = OptimizedDivisiveGeographicClustering( \n",
    "    # Rivers: Divisive clusters created: 48 || Silhouette Score: 0.54 || Constraint violations: Size=6, Distance=3\n",
    "    max_customers_per_cluster=30,  # REQUIRED\n",
    "    max_distance_km=5            # REQUIRED\n",
    "    ,use_vectorized_distances=True, balance_clusters=False\n",
    ")\n",
    "\n",
    "divisive_result = divisive_clusterer.divisive_clustering(df_all_cluster.copy())\n",
    "print(f\"\\nDivisive clusters created: {divisive_result['cluster'].nunique()}\")\n",
    "# print(f\"Cluster sizes: {divisive_result['cluster'].value_counts().sort_index().head()}\")\n",
    "_ = evaluate_unsupervised_clustering(divisive_result)\n",
    "\n",
    "# # Get detailed statistics\n",
    "stats = divisive_clusterer.get_cluster_stats(divisive_result)\n",
    "print(f\"Total clusters: {stats['summary']['total_clusters']}\")\n",
    "print(f\"Constraint violations: Size={stats['summary']['size_violations']}, Distance={stats['summary']['distance_violations']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc977318",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clustering.agglomerative_clustering import AgglomerativeGeographicClustering\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"2. AGGLOMERATIVE CLUSTERING\")\n",
    "print(\"=\"*60)\n",
    " \n",
    "agg_clusterer = AgglomerativeGeographicClustering(\n",
    "    max_customers_per_cluster=30, # Aim for clusters of max 50 customers\n",
    "    max_distance_km=5.0,        # Max diameter of 5 km\n",
    "    linkage_method='ward',       # Common choice for compact clusters\n",
    "    sub_cluster_if_oversized=True\n",
    ")\n",
    "clustered_agg_df = agg_clusterer.agglomerative_clustering(df_all_cluster.copy())\n",
    "\n",
    "# print(\"\\nAgglomerative Clustering Stats:\")\n",
    "# for k, v in agg_stats['summary'].items():\n",
    "#     print(f\"  {k}: {v}\")\n",
    "# print(\"\\nSample Agglomerative Cluster Details:\")\n",
    "# for cluster_id, details in list(agg_stats.items())[:5]: # Show first 5 clusters\n",
    "#     if cluster_id != 'summary':\n",
    "#         print(f\"  Cluster {cluster_id}: Size={details['size']}, Diameter={details['diameter_km']:.2f} km, Size OK={details['meets_size_constraint']}, Distance OK={details['meets_distance_constraint']}\")\n",
    "\n",
    "\n",
    "_ = evaluate_unsupervised_clustering(clustered_agg_df)\n",
    "\n",
    "\n",
    "stats = agg_clusterer.get_cluster_stats(clustered_agg_df, agg_clusterer.max_customers_per_cluster, agg_clusterer.max_distance_km) \n",
    "print(f\"Total clusters: {stats['summary']['total_clusters']}\")\n",
    "print(f\"Constraint violations: Size={stats['summary']['size_violations']}, Distance={stats['summary']['distance_violations']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd35595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_and_save(df_routes = clustered_agg_df,\n",
    "                 df_stockpoint = None,   \n",
    "                 filename='agglomerative-clustering-test.html',\n",
    "                 cluster_col = 'cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a73b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_and_save(df_routes = divisive_result,\n",
    "                 df_stockpoint = None,   \n",
    "                 filename='divisive-clustering-test.html',\n",
    "                 cluster_col = 'cluster')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08980d8e",
   "metadata": {},
   "source": [
    "### New Clustering Algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2266ee03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.cluster.hierarchy import fcluster, linkage\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "## Best\n",
    "class OptimizedDivisiveGeographicClustering_b:\n",
    "    def __init__(self, max_customers_per_cluster=20, max_distance_km=50, \n",
    "                 use_vectorized_distances=True, balance_clusters=False):\n",
    "        self.max_customers_per_cluster = max_customers_per_cluster\n",
    "        self.max_distance_km = max_distance_km\n",
    "        self.earth_radius_km = 6371.0\n",
    "        self.use_vectorized_distances = use_vectorized_distances\n",
    "        self.balance_clusters = balance_clusters\n",
    "        \n",
    "    def haversine_vectorized(self, coords1, coords2=None):\n",
    "        \"\"\"\n",
    "        Highly optimized vectorized haversine distance calculation.\n",
    "        If coords2 is None, calculates pairwise distances within coords1.\n",
    "        \"\"\"\n",
    "        if coords2 is None:\n",
    "            # Pairwise distances within coords1\n",
    "            coords1_rad = np.radians(coords1)\n",
    "            n = len(coords1)\n",
    "            \n",
    "            # Create meshgrids for vectorized calculation\n",
    "            lat1 = coords1_rad[:, 0]\n",
    "            lon1 = coords1_rad[:, 1]\n",
    "            \n",
    "            lat1_mesh, lat2_mesh = np.meshgrid(lat1, lat1)\n",
    "            lon1_mesh, lon2_mesh = np.meshgrid(lon1, lon1)\n",
    "            \n",
    "            dlat = lat2_mesh - lat1_mesh\n",
    "            dlon = lon2_mesh - lon1_mesh\n",
    "            \n",
    "            a = (np.sin(dlat / 2) ** 2 + \n",
    "                 np.cos(lat1_mesh) * np.cos(lat2_mesh) * np.sin(dlon / 2) ** 2)\n",
    "            c = 2 * np.arcsin(np.sqrt(np.clip(a, 0, 1)))\n",
    "            \n",
    "            return self.earth_radius_km * c\n",
    "        else:\n",
    "            # Distance from each point in coords1 to each point in coords2\n",
    "            coords1_rad = np.radians(coords1)\n",
    "            coords2_rad = np.radians(coords2)\n",
    "            \n",
    "            lat1 = coords1_rad[:, 0][:, np.newaxis]\n",
    "            lon1 = coords1_rad[:, 1][:, np.newaxis]\n",
    "            lat2 = coords2_rad[:, 0][np.newaxis, :]\n",
    "            lon2 = coords2_rad[:, 1][np.newaxis, :]\n",
    "            \n",
    "            dlat = lat2 - lat1\n",
    "            dlon = lon2 - lon1\n",
    "            \n",
    "            a = (np.sin(dlat / 2) ** 2 + \n",
    "                 np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2)\n",
    "            c = 2 * np.arcsin(np.sqrt(np.clip(a, 0, 1)))\n",
    "            \n",
    "            return self.earth_radius_km * c\n",
    "    \n",
    "    def haversine_pdist(self, coords):\n",
    "        \"\"\"\n",
    "        Optimized haversine distance calculation using scipy's pdist.\n",
    "        \"\"\"\n",
    "        def haversine_metric(u, v):\n",
    "            lat1, lon1 = np.radians(u)\n",
    "            lat2, lon2 = np.radians(v)\n",
    "            \n",
    "            dlat = lat2 - lat1\n",
    "            dlon = lon2 - lon1\n",
    "            \n",
    "            a = (np.sin(dlat / 2) ** 2 + \n",
    "                 np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2)\n",
    "            c = 2 * np.arcsin(np.sqrt(np.clip(a, 0, 1)))\n",
    "            \n",
    "            return self.earth_radius_km * c\n",
    "        \n",
    "        return pdist(coords, metric=haversine_metric)\n",
    "    \n",
    "    def calculate_cluster_diameter_fast(self, coords):\n",
    "        \"\"\"\n",
    "        Fast cluster diameter calculation with multiple optimization strategies.\n",
    "        \"\"\"\n",
    "        n_points = len(coords)\n",
    "        \n",
    "        if n_points <= 1:\n",
    "            return 0\n",
    "        \n",
    "        if n_points == 2:\n",
    "            return self.haversine_single_pair(coords[0], coords[1])\n",
    "        \n",
    "        # Use different strategies based on cluster size\n",
    "        if n_points <= 10:\n",
    "            # Small clusters: exact calculation\n",
    "            distances = self.haversine_pdist(coords)\n",
    "            return np.max(distances)\n",
    "        elif n_points <= 50:\n",
    "            # Medium clusters: vectorized calculation\n",
    "            if self.use_vectorized_distances:\n",
    "                distance_matrix = self.haversine_vectorized(coords)\n",
    "                return np.max(distance_matrix)\n",
    "            else:\n",
    "                distances = self.haversine_pdist(coords)\n",
    "                return np.max(distances)\n",
    "        else:\n",
    "            # Large clusters: smart sampling\n",
    "            return self._smart_diameter_estimation(coords)\n",
    "    \n",
    "    def _smart_diameter_estimation(self, coords):\n",
    "        \"\"\"\n",
    "        Improved diameter estimation using multiple sampling strategies.\n",
    "        \"\"\"\n",
    "        n_points = len(coords)\n",
    "        \n",
    "        # Strategy 1: Convex hull approximation\n",
    "        hull_diameter = self._convex_hull_diameter(coords)\n",
    "        \n",
    "        # Strategy 2: Grid-based sampling for large clusters\n",
    "        if n_points > 200:\n",
    "            grid_diameter = self._grid_based_diameter(coords)\n",
    "            return max(hull_diameter, grid_diameter)\n",
    "        \n",
    "        return hull_diameter\n",
    "    \n",
    "    def _convex_hull_diameter(self, coords):\n",
    "        \"\"\"Enhanced convex hull approximation.\"\"\"\n",
    "        lats, lons = coords[:, 0], coords[:, 1]\n",
    "        \n",
    "        # Get extreme points\n",
    "        extreme_indices = [\n",
    "            np.argmax(lats), np.argmin(lats),\n",
    "            np.argmax(lons), np.argmin(lons)\n",
    "        ]\n",
    "        \n",
    "        # Add points from different quadrants\n",
    "        lat_center, lon_center = np.mean(lats), np.mean(lons)\n",
    "        \n",
    "        quadrants = [\n",
    "            (lats >= lat_center) & (lons >= lon_center),  # NE\n",
    "            (lats >= lat_center) & (lons < lon_center),   # NW\n",
    "            (lats < lat_center) & (lons >= lon_center),   # SE\n",
    "            (lats < lat_center) & (lons < lon_center)     # SW\n",
    "        ]\n",
    "        \n",
    "        for quadrant in quadrants:\n",
    "            if np.any(quadrant):\n",
    "                quad_indices = np.where(quadrant)[0]\n",
    "                # Add furthest point from center in each quadrant\n",
    "                distances_from_center = np.sqrt(\n",
    "                    (lats[quad_indices] - lat_center)**2 + \n",
    "                    (lons[quad_indices] - lon_center)**2\n",
    "                )\n",
    "                furthest_idx = quad_indices[np.argmax(distances_from_center)]\n",
    "                extreme_indices.append(furthest_idx)\n",
    "        \n",
    "        # Add some random points\n",
    "        n_random = min(12, len(coords) - len(set(extreme_indices)))\n",
    "        if n_random > 0:\n",
    "            available_indices = list(set(range(len(coords))) - set(extreme_indices))\n",
    "            if available_indices:\n",
    "                random_indices = np.random.choice(available_indices, \n",
    "                                                min(n_random, len(available_indices)), \n",
    "                                                replace=False)\n",
    "                extreme_indices.extend(random_indices)\n",
    "        \n",
    "        # Get unique sample\n",
    "        sample_indices = list(set(extreme_indices))\n",
    "        sample_coords = coords[sample_indices]\n",
    "        \n",
    "        if len(sample_coords) <= 1:\n",
    "            return 0\n",
    "        \n",
    "        distances = self.haversine_pdist(sample_coords)\n",
    "        return np.max(distances)\n",
    "    \n",
    "    def _grid_based_diameter(self, coords):\n",
    "        \"\"\"Grid-based sampling for very large clusters.\"\"\"\n",
    "        # Create a grid and sample points from each grid cell\n",
    "        lats, lons = coords[:, 0], coords[:, 1]\n",
    "        \n",
    "        # Create 6x6 grid\n",
    "        lat_bins = np.linspace(lats.min(), lats.max(), 7)\n",
    "        lon_bins = np.linspace(lons.min(), lons.max(), 7)\n",
    "        \n",
    "        sample_indices = []\n",
    "        for i in range(len(lat_bins)-1):\n",
    "            for j in range(len(lon_bins)-1):\n",
    "                mask = ((lats >= lat_bins[i]) & (lats < lat_bins[i+1]) & \n",
    "                       (lons >= lon_bins[j]) & (lons < lon_bins[j+1]))\n",
    "                cell_indices = np.where(mask)[0]\n",
    "                if len(cell_indices) > 0:\n",
    "                    # Sample up to 2 points from each cell\n",
    "                    n_sample = min(2, len(cell_indices))\n",
    "                    sampled = np.random.choice(cell_indices, n_sample, replace=False)\n",
    "                    sample_indices.extend(sampled)\n",
    "        \n",
    "        if len(sample_indices) <= 1:\n",
    "            return 0\n",
    "        \n",
    "        sample_coords = coords[sample_indices]\n",
    "        distances = self.haversine_pdist(sample_coords)\n",
    "        return np.max(distances)\n",
    "    \n",
    "    def haversine_single_pair(self, coord1, coord2):\n",
    "        \"\"\"Calculate haversine distance between two points.\"\"\"\n",
    "        lat1, lon1 = np.radians(coord1)\n",
    "        lat2, lon2 = np.radians(coord2)\n",
    "        \n",
    "        dlat = lat2 - lat1\n",
    "        dlon = lon2 - lon1\n",
    "        \n",
    "        a = (np.sin(dlat / 2) ** 2 + \n",
    "             np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2)\n",
    "        c = 2 * np.arcsin(np.sqrt(np.clip(a, 0, 1)))\n",
    "        \n",
    "        return self.earth_radius_km * c\n",
    "    \n",
    "    def should_split_cluster(self, cluster_indices, coords_array):\n",
    "        \"\"\"Enhanced cluster splitting logic with load balancing.\"\"\"\n",
    "        cluster_size = len(cluster_indices)\n",
    "        \n",
    "        if cluster_size <= 2:\n",
    "            return False\n",
    "        \n",
    "        # Hard size constraint\n",
    "        if cluster_size > self.max_customers_per_cluster * 1.5:\n",
    "            return True\n",
    "        \n",
    "        # Soft size constraint with diameter check\n",
    "        if cluster_size > self.max_customers_per_cluster:\n",
    "            cluster_coords = coords_array[cluster_indices]\n",
    "            diameter = self.calculate_cluster_diameter_fast(cluster_coords)\n",
    "            return diameter > self.max_distance_km * 0.8  # More lenient for size\n",
    "        \n",
    "        # Diameter constraint\n",
    "        cluster_coords = coords_array[cluster_indices]\n",
    "        diameter = self.calculate_cluster_diameter_fast(cluster_coords)\n",
    "        \n",
    "        return diameter > self.max_distance_km\n",
    "    \n",
    "    def geographic_split(self, cluster_indices, coords_array):\n",
    "        \"\"\"\n",
    "        Improved geographic splitting with better load balancing.\n",
    "        \"\"\"\n",
    "        if len(cluster_indices) <= 2:\n",
    "            return [cluster_indices]\n",
    "        \n",
    "        cluster_coords = coords_array[cluster_indices]\n",
    "        n_points = len(cluster_coords)\n",
    "        \n",
    "        # For small clusters, use exact method\n",
    "        if n_points <= 50:\n",
    "            return self._exact_geographic_split(cluster_indices, cluster_coords)\n",
    "        \n",
    "        # For medium clusters, use K-means with geographic initialization\n",
    "        if n_points <= 200:\n",
    "            return self._kmeans_geographic_split(cluster_indices, cluster_coords)\n",
    "        \n",
    "        # For large clusters, use hierarchical approach\n",
    "        return self._hierarchical_geographic_split(cluster_indices, cluster_coords)\n",
    "    \n",
    "    def _exact_geographic_split(self, cluster_indices, cluster_coords):\n",
    "        \"\"\"Exact splitting for small clusters.\"\"\"\n",
    "        n_points = len(cluster_coords)\n",
    "        \n",
    "        # Find the two points that are farthest apart\n",
    "        distances = self.haversine_pdist(cluster_coords)\n",
    "        distance_matrix = squareform(distances)\n",
    "        max_idx = np.unravel_index(np.argmax(distance_matrix), distance_matrix.shape)\n",
    "        center1_idx, center2_idx = max_idx[0], max_idx[1]\n",
    "        \n",
    "        center1 = cluster_coords[center1_idx]\n",
    "        center2 = cluster_coords[center2_idx]\n",
    "        \n",
    "        # Assign points to closest center\n",
    "        distances_to_center1 = self.haversine_vectorized(cluster_coords, center1.reshape(1, -1))[:, 0]\n",
    "        distances_to_center2 = self.haversine_vectorized(cluster_coords, center2.reshape(1, -1))[:, 0]\n",
    "        \n",
    "        labels = (distances_to_center1 <= distances_to_center2).astype(int)\n",
    "        \n",
    "        return self._balance_split(cluster_indices, labels)\n",
    "    \n",
    "    def _kmeans_geographic_split(self, cluster_indices, cluster_coords):\n",
    "        \"\"\"K-means splitting with geographic initialization.\"\"\"\n",
    "        n_points = len(cluster_coords)\n",
    "        \n",
    "        # Initialize with farthest pair\n",
    "        center1_idx, center2_idx = self._find_approximate_farthest_pair(cluster_coords)\n",
    "        initial_centers = cluster_coords[[center1_idx, center2_idx]]\n",
    "        \n",
    "        # Apply K-means\n",
    "        kmeans = KMeans(n_clusters=2, init=initial_centers, n_init=1, random_state=42)\n",
    "        labels = kmeans.fit_predict(cluster_coords)\n",
    "        \n",
    "        return self._balance_split(cluster_indices, labels)\n",
    "    \n",
    "    def _hierarchical_geographic_split(self, cluster_indices, cluster_coords):\n",
    "        \"\"\"Hierarchical splitting for large clusters.\"\"\"\n",
    "        # Use linkage-based clustering for very large clusters\n",
    "        n_sample = min(100, len(cluster_coords))\n",
    "        sample_indices = np.random.choice(len(cluster_coords), n_sample, replace=False)\n",
    "        sample_coords = cluster_coords[sample_indices]\n",
    "        \n",
    "        # Compute linkage on sample\n",
    "        distances = self.haversine_pdist(sample_coords)\n",
    "        linkage_matrix = linkage(distances, method='ward')\n",
    "        sample_labels = fcluster(linkage_matrix, 2, criterion='maxclust') - 1\n",
    "        \n",
    "        # Assign all points based on closest sample point\n",
    "        center1_coords = sample_coords[sample_labels == 0]\n",
    "        center2_coords = sample_coords[sample_labels == 1]\n",
    "        \n",
    "        if len(center1_coords) == 0 or len(center2_coords) == 0:\n",
    "            # Fallback to farthest pair method\n",
    "            return self._exact_geographic_split(cluster_indices, cluster_coords)\n",
    "        \n",
    "        center1 = np.mean(center1_coords, axis=0)\n",
    "        center2 = np.mean(center2_coords, axis=0)\n",
    "        \n",
    "        distances_to_center1 = self.haversine_vectorized(cluster_coords, center1.reshape(1, -1))[:, 0]\n",
    "        distances_to_center2 = self.haversine_vectorized(cluster_coords, center2.reshape(1, -1))[:, 0]\n",
    "        \n",
    "        labels = (distances_to_center1 <= distances_to_center2).astype(int)\n",
    "        \n",
    "        return self._balance_split(cluster_indices, labels)\n",
    "    \n",
    "    def _balance_split(self, cluster_indices, labels):\n",
    "        \"\"\"Balance the split to avoid very uneven clusters.\"\"\"\n",
    "        cluster_0_indices = cluster_indices[labels == 0]\n",
    "        cluster_1_indices = cluster_indices[labels == 1]\n",
    "        \n",
    "        # Ensure no empty clusters\n",
    "        if len(cluster_0_indices) == 0:\n",
    "            cluster_0_indices = np.array([cluster_1_indices[0]])\n",
    "            cluster_1_indices = cluster_1_indices[1:]\n",
    "        elif len(cluster_1_indices) == 0:\n",
    "            cluster_1_indices = np.array([cluster_0_indices[0]])\n",
    "            cluster_0_indices = cluster_0_indices[1:]\n",
    "        \n",
    "        # Optional: Balance cluster sizes if one is much larger\n",
    "        if self.balance_clusters:\n",
    "            size_0, size_1 = len(cluster_0_indices), len(cluster_1_indices)\n",
    "            if size_0 > 3 * size_1 and size_1 > 0:\n",
    "                # Move some points from cluster 0 to cluster 1\n",
    "                n_move = (size_0 - size_1) // 4\n",
    "                move_indices = cluster_0_indices[:n_move]\n",
    "                cluster_0_indices = cluster_0_indices[n_move:]\n",
    "                cluster_1_indices = np.concatenate([cluster_1_indices, move_indices])\n",
    "            elif size_1 > 3 * size_0 and size_0 > 0:\n",
    "                # Move some points from cluster 1 to cluster 0\n",
    "                n_move = (size_1 - size_0) // 4\n",
    "                move_indices = cluster_1_indices[:n_move]\n",
    "                cluster_1_indices = cluster_1_indices[n_move:]\n",
    "                cluster_0_indices = np.concatenate([cluster_0_indices, move_indices])\n",
    "        \n",
    "        return [cluster_0_indices, cluster_1_indices]\n",
    "    \n",
    "    def _find_approximate_farthest_pair(self, coords):\n",
    "        \"\"\"Find approximate farthest pair for large clusters.\"\"\"\n",
    "        n_points = len(coords)\n",
    "        \n",
    "        if n_points <= 100:\n",
    "            # For moderate sizes, use exact calculation\n",
    "            distances = self.haversine_pdist(coords)\n",
    "            distance_matrix = squareform(distances)\n",
    "            max_idx = np.unravel_index(np.argmax(distance_matrix), distance_matrix.shape)\n",
    "            return max_idx[0], max_idx[1]\n",
    "        \n",
    "        # For large clusters, use sampling\n",
    "        sample_size = min(50, n_points)\n",
    "        sample_indices = np.random.choice(n_points, sample_size, replace=False)\n",
    "        sample_coords = coords[sample_indices]\n",
    "        \n",
    "        distances = self.haversine_pdist(sample_coords)\n",
    "        distance_matrix = squareform(distances)\n",
    "        max_idx = np.unravel_index(np.argmax(distance_matrix), distance_matrix.shape)\n",
    "        \n",
    "        return sample_indices[max_idx[0]], sample_indices[max_idx[1]]\n",
    "    \n",
    "    def divisive_clustering(self, customers_df):\n",
    "        \"\"\"Perform optimized divisive hierarchical clustering.\"\"\"\n",
    "        customers_df = customers_df.copy().reset_index(drop=True)\n",
    "        \n",
    "        # Validate input\n",
    "        if 'Latitude' not in customers_df.columns or 'Longitude' not in customers_df.columns:\n",
    "            raise ValueError(\"DataFrame must contain 'Latitude' and 'Longitude' columns\")\n",
    "        \n",
    "        coords_array = customers_df[['Latitude', 'Longitude']].values\n",
    "        n_customers = len(customers_df)\n",
    "        \n",
    "        if n_customers == 0:\n",
    "            customers_df['cluster'] = []\n",
    "            return customers_df\n",
    "        \n",
    "        if n_customers == 1:\n",
    "            customers_df['cluster'] = 1\n",
    "            return customers_df\n",
    "        \n",
    "        # Priority queue approach for better clustering\n",
    "        clusters_to_process = [(n_customers, np.arange(n_customers))]  # (size, indices)\n",
    "        final_clusters = []\n",
    "        \n",
    "        iteration_count = 0\n",
    "        max_iterations = n_customers * 2\n",
    "        \n",
    "        while clusters_to_process and iteration_count < max_iterations:\n",
    "            # Process largest cluster first\n",
    "            clusters_to_process.sort(key=lambda x: x[0], reverse=True)\n",
    "            current_size, current_cluster_indices = clusters_to_process.pop(0)\n",
    "            iteration_count += 1\n",
    "            \n",
    "            if self.should_split_cluster(current_cluster_indices, coords_array):\n",
    "                subclusters = self.geographic_split(current_cluster_indices, coords_array)\n",
    "                \n",
    "                for subcluster_indices in subclusters:\n",
    "                    if len(subcluster_indices) > 0:\n",
    "                        clusters_to_process.append((len(subcluster_indices), subcluster_indices))\n",
    "            else:\n",
    "                final_clusters.append(current_cluster_indices)\n",
    "        \n",
    "        # Handle remaining clusters\n",
    "        final_clusters.extend([indices for _, indices in clusters_to_process])\n",
    "        \n",
    "        # Create result DataFrame\n",
    "        result_df = customers_df.copy()\n",
    "        result_df['cluster'] = -1\n",
    "        \n",
    "        for cluster_id, cluster_indices in enumerate(final_clusters, 1):\n",
    "            result_df.loc[cluster_indices, 'cluster'] = cluster_id\n",
    "        \n",
    "        return result_df\n",
    "    \n",
    "    def get_cluster_stats(self, clustered_df):\n",
    "        \"\"\"Get comprehensive clustering statistics.\"\"\"\n",
    "        if 'cluster' not in clustered_df.columns:\n",
    "            raise ValueError(\"DataFrame must contain 'cluster' column\")\n",
    "        \n",
    "        stats = {}\n",
    "        cluster_sizes = []\n",
    "        cluster_diameters = []\n",
    "        \n",
    "        for cluster_id in clustered_df['cluster'].unique():\n",
    "            if cluster_id == -1:\n",
    "                continue\n",
    "                \n",
    "            cluster_data = clustered_df[clustered_df['cluster'] == cluster_id]\n",
    "            coords = cluster_data[['Latitude', 'Longitude']].values\n",
    "            \n",
    "            diameter = self.calculate_cluster_diameter_fast(coords)\n",
    "            cluster_sizes.append(len(cluster_data))\n",
    "            cluster_diameters.append(diameter)\n",
    "            \n",
    "            stats[cluster_id] = {\n",
    "                'size': len(cluster_data),\n",
    "                'diameter_km': diameter,\n",
    "                'centroid_lat': np.mean(coords[:, 0]),\n",
    "                'centroid_lon': np.mean(coords[:, 1]),\n",
    "                'meets_size_constraint': len(cluster_data) <= self.max_customers_per_cluster,\n",
    "                'meets_distance_constraint': diameter <= self.max_distance_km\n",
    "            }\n",
    "        \n",
    "        # Overall statistics\n",
    "        stats['summary'] = {\n",
    "            'total_clusters': len(stats) - 1,  # Excluding summary\n",
    "            'avg_cluster_size': np.mean(cluster_sizes),\n",
    "            'max_cluster_size': np.max(cluster_sizes),\n",
    "            'min_cluster_size': np.min(cluster_sizes),\n",
    "            'avg_diameter': np.mean(cluster_diameters),\n",
    "            'max_diameter': np.max(cluster_diameters),\n",
    "            'size_violations': sum(1 for size in cluster_sizes if size > self.max_customers_per_cluster),\n",
    "            'distance_violations': sum(1 for diameter in cluster_diameters if diameter > self.max_distance_km)\n",
    "        }\n",
    "        \n",
    "        return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d40e0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92b015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.cluster.hierarchy import fcluster, linkage\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from numba import jit, prange\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Fixed Enhanced Geographic Clustering\n",
    "class OptimizedDivisiveGeographicClustering_be:\n",
    "    def __init__(self, max_customers_per_cluster=20, max_distance_km=50, \n",
    "                 use_vectorized_distances=True, balance_clusters=False):\n",
    "        self.max_customers_per_cluster = max_customers_per_cluster\n",
    "        self.max_distance_km = max_distance_km\n",
    "        self.earth_radius_km = 6371.0\n",
    "        self.use_vectorized_distances = use_vectorized_distances\n",
    "        self.balance_clusters = balance_clusters\n",
    "        self._distance_cache = {}\n",
    "        \n",
    "    @staticmethod\n",
    "    @jit(nopython=True, fastmath=True, parallel=True)\n",
    "    def numba_haversine(coords1, coords2, radius):\n",
    "        \"\"\"JIT-optimized haversine distance calculation\"\"\"\n",
    "        n1 = coords1.shape[0]\n",
    "        n2 = coords2.shape[0] if coords2 is not None else n1\n",
    "        dists = np.empty((n1, n2), dtype=np.float64)\n",
    "        \n",
    "        for i in prange(n1):\n",
    "            lat1 = np.radians(coords1[i, 0])\n",
    "            lon1 = np.radians(coords1[i, 1])\n",
    "            \n",
    "            for j in range(n2):\n",
    "                if coords2 is None:\n",
    "                    lat2 = np.radians(coords1[j, 0])\n",
    "                    lon2 = np.radians(coords1[j, 1])\n",
    "                else:\n",
    "                    lat2 = np.radians(coords2[j, 0])\n",
    "                    lon2 = np.radians(coords2[j, 1])\n",
    "                    \n",
    "                dlat = lat2 - lat1\n",
    "                dlon = lon2 - lon1\n",
    "                \n",
    "                a = (np.sin(dlat/2)**2 + \n",
    "                     np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2)**2)\n",
    "                c = 2 * np.arcsin(np.sqrt(min(1.0, a)))\n",
    "                dists[i, j] = radius * c\n",
    "                \n",
    "        return dists\n",
    "\n",
    "    def haversine_vectorized(self, coords1, coords2=None, use_cache=False):\n",
    "        \"\"\"Optimized distance calculation with caching and Numba acceleration\"\"\"\n",
    "        cache_key = None\n",
    "        if use_cache and coords2 is None:\n",
    "            cache_key = tuple(map(tuple, coords1))\n",
    "            if cache_key in self._distance_cache:\n",
    "                return self._distance_cache[cache_key]\n",
    "        \n",
    "        if coords1.size < 500:  # Use Numba for smaller datasets\n",
    "            result = self.numba_haversine(coords1, coords2, self.earth_radius_km)\n",
    "        else:\n",
    "            # Use vectorized calculation for larger datasets\n",
    "            if coords2 is None:\n",
    "                coords_rad = np.radians(coords1)\n",
    "                lat = coords_rad[:, 0]\n",
    "                lon = coords_rad[:, 1]\n",
    "                dlat = lat[:, None] - lat\n",
    "                dlon = lon[:, None] - lon\n",
    "                \n",
    "                a = (np.sin(dlat/2)**2 + \n",
    "                     np.cos(lat[:, None]) * np.cos(lat) * np.sin(dlon/2)**2)\n",
    "            else:\n",
    "                coords1_rad = np.radians(coords1)\n",
    "                coords2_rad = np.radians(coords2)\n",
    "                dlat = coords1_rad[:, 0, None] - coords2_rad[:, 0]\n",
    "                dlon = coords1_rad[:, 1, None] - coords2_rad[:, 1]\n",
    "                \n",
    "                a = (np.sin(dlat/2)**2 + \n",
    "                     np.cos(coords1_rad[:, 0, None]) * \n",
    "                     np.cos(coords2_rad[:, 0]) * \n",
    "                     np.sin(dlon/2)**2)\n",
    "            \n",
    "            result = self.earth_radius_km * 2 * np.arcsin(np.sqrt(np.clip(a, 0, 1)))\n",
    "        \n",
    "        if cache_key is not None:\n",
    "            self._distance_cache[cache_key] = result\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    def haversine_single_pair(self, coord1, coord2):\n",
    "        \"\"\"Calculate haversine distance between two points.\"\"\"\n",
    "        lat1, lon1 = np.radians(coord1)\n",
    "        lat2, lon2 = np.radians(coord2)\n",
    "        \n",
    "        dlat = lat2 - lat1\n",
    "        dlon = lon2 - lon1\n",
    "        \n",
    "        a = (np.sin(dlat / 2) ** 2 + \n",
    "             np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2)\n",
    "        c = 2 * np.arcsin(np.sqrt(np.clip(a, 0, 1)))\n",
    "        \n",
    "        return self.earth_radius_km * c \n",
    "\n",
    "    def haversine_pdist(self, coords):\n",
    "        \"\"\"Calculate pairwise distances using scipy format\"\"\"\n",
    "        n = len(coords)\n",
    "        distances = []\n",
    "        for i in range(n):\n",
    "            for j in range(i + 1, n):\n",
    "                dist = self.haversine_single_pair(coords[i], coords[j])\n",
    "                distances.append(dist)\n",
    "        return np.array(distances)\n",
    "\n",
    "    def calculate_cluster_diameter_fast(self, coords):\n",
    "        \"\"\"Optimized diameter calculation with adaptive strategy\"\"\"\n",
    "        n = len(coords)\n",
    "        if n <= 1: \n",
    "            return 0\n",
    "        if n == 2:\n",
    "            return self.haversine_single_pair(coords[0], coords[1])\n",
    "        \n",
    "        # Use convex hull approximation for medium clusters\n",
    "        if n <= 100:\n",
    "            return self._convex_hull_diameter(coords)\n",
    "            \n",
    "        # Use grid-based sampling for large clusters\n",
    "        return self._grid_based_diameter(coords)\n",
    "\n",
    "    def _convex_hull_diameter(self, coords):\n",
    "        \"\"\"Calculate diameter using convex hull approximation\"\"\"\n",
    "        try:\n",
    "            from scipy.spatial import ConvexHull\n",
    "            if len(coords) < 3:\n",
    "                return max(self.haversine_single_pair(coords[i], coords[j]) \n",
    "                          for i in range(len(coords)) for j in range(i+1, len(coords)))\n",
    "            \n",
    "            hull = ConvexHull(coords)\n",
    "            hull_points = coords[hull.vertices]\n",
    "            \n",
    "            max_distance = 0\n",
    "            for i in range(len(hull_points)):\n",
    "                for j in range(i + 1, len(hull_points)):\n",
    "                    distance = self.haversine_single_pair(hull_points[i], hull_points[j])\n",
    "                    max_distance = max(max_distance, distance)\n",
    "            \n",
    "            return max_distance\n",
    "        except:\n",
    "            # Fallback to brute force for small clusters\n",
    "            return self._brute_force_diameter(coords)\n",
    "\n",
    "    def _grid_based_diameter(self, coords):\n",
    "        \"\"\"Use grid-based sampling for large clusters\"\"\"\n",
    "        n_sample = min(50, len(coords))\n",
    "        sample_indices = np.random.choice(len(coords), n_sample, replace=False)\n",
    "        sample_coords = coords[sample_indices]\n",
    "        return self._brute_force_diameter(sample_coords)\n",
    "\n",
    "    def _brute_force_diameter(self, coords):\n",
    "        \"\"\"Calculate exact diameter using brute force\"\"\"\n",
    "        max_distance = 0\n",
    "        n = len(coords)\n",
    "        for i in range(n):\n",
    "            for j in range(i + 1, n):\n",
    "                distance = self.haversine_single_pair(coords[i], coords[j])\n",
    "                max_distance = max(max_distance, distance)\n",
    "        return max_distance\n",
    "\n",
    "    def should_split_cluster(self, cluster_indices, coords_array):\n",
    "        \"\"\"Determine if a cluster should be split\"\"\"\n",
    "        n_points = len(cluster_indices)\n",
    "        \n",
    "        # Size constraint\n",
    "        if n_points <= self.max_customers_per_cluster:\n",
    "            return False\n",
    "        \n",
    "        # Distance constraint\n",
    "        cluster_coords = coords_array[cluster_indices]\n",
    "        diameter = self.calculate_cluster_diameter_fast(cluster_coords)\n",
    "        \n",
    "        if diameter <= self.max_distance_km:\n",
    "            return False\n",
    "            \n",
    "        return True\n",
    "\n",
    "    def geographic_split(self, cluster_indices, coords_array):\n",
    "        \"\"\"Enhanced splitting with DBSCAN for outlier handling\"\"\"\n",
    "        n_points = len(cluster_indices)\n",
    "        if n_points <= 2:\n",
    "            return [cluster_indices]\n",
    "            \n",
    "        cluster_coords = coords_array[cluster_indices]\n",
    "        \n",
    "        # Handle outliers with DBSCAN for large clusters\n",
    "        if n_points > 100:\n",
    "            try:\n",
    "                # Create distance matrix for DBSCAN\n",
    "                distances = self.haversine_vectorized(cluster_coords)\n",
    "                dbscan = DBSCAN(eps=self.max_distance_km/2, min_samples=3, \n",
    "                               metric='precomputed')\n",
    "                labels = dbscan.fit_predict(distances)\n",
    "                \n",
    "                if len(np.unique(labels[labels != -1])) > 1:\n",
    "                    return self._balance_split(cluster_indices, labels)\n",
    "            except:\n",
    "                pass  # Fall back to other methods\n",
    "        \n",
    "        # Small clusters: exact method\n",
    "        if n_points <= 50:\n",
    "            return self._exact_geographic_split(cluster_indices, cluster_coords)\n",
    "            \n",
    "        # Medium clusters: k-means with improved initialization\n",
    "        if n_points <= 200:\n",
    "            return self._kmeans_geographic_split(cluster_indices, cluster_coords)\n",
    "            \n",
    "        # Large clusters: hierarchical with complete linkage\n",
    "        return self._hierarchical_geographic_split(cluster_indices, cluster_coords)\n",
    "\n",
    "    def _exact_geographic_split(self, cluster_indices, cluster_coords):\n",
    "        \"\"\"Exact splitting for small clusters\"\"\"\n",
    "        if len(cluster_coords) <= 2:\n",
    "            return [cluster_indices]\n",
    "        \n",
    "        # Find the two points that are farthest apart\n",
    "        max_distance = 0\n",
    "        best_pair = (0, 1)\n",
    "        \n",
    "        for i in range(len(cluster_coords)):\n",
    "            for j in range(i + 1, len(cluster_coords)):\n",
    "                distance = self.haversine_single_pair(cluster_coords[i], cluster_coords[j])\n",
    "                if distance > max_distance:\n",
    "                    max_distance = distance\n",
    "                    best_pair = (i, j)\n",
    "        \n",
    "        # Assign points to the closer of the two centers\n",
    "        center1 = cluster_coords[best_pair[0]]\n",
    "        center2 = cluster_coords[best_pair[1]]\n",
    "        \n",
    "        labels = np.zeros(len(cluster_coords))\n",
    "        for i, coord in enumerate(cluster_coords):\n",
    "            dist1 = self.haversine_single_pair(coord, center1)\n",
    "            dist2 = self.haversine_single_pair(coord, center2)\n",
    "            labels[i] = 0 if dist1 <= dist2 else 1\n",
    "        \n",
    "        return self._balance_split(cluster_indices, labels)\n",
    "\n",
    "    def _kmeans_geographic_split(self, cluster_indices, cluster_coords):\n",
    "        \"\"\"K-means splitting for medium clusters\"\"\"\n",
    "        try:\n",
    "            # Use geographic coordinates directly for K-means\n",
    "            kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "            labels = kmeans.fit_predict(cluster_coords)\n",
    "            return self._balance_split(cluster_indices, labels)\n",
    "        except:\n",
    "            # Fallback to exact method\n",
    "            return self._exact_geographic_split(cluster_indices, cluster_coords)\n",
    "\n",
    "    def _hierarchical_geographic_split(self, cluster_indices, cluster_coords):\n",
    "        \"\"\"Improved hierarchical splitting with complete linkage\"\"\"\n",
    "        n_sample = min(150, len(cluster_coords))\n",
    "        sample_indices = np.random.choice(len(cluster_coords), n_sample, replace=False)\n",
    "        sample_coords = cluster_coords[sample_indices]\n",
    "        \n",
    "        distances = self.haversine_pdist(sample_coords)\n",
    "        linkage_matrix = linkage(distances, method='complete')\n",
    "        sample_labels = fcluster(linkage_matrix, 2, criterion='maxclust') - 1\n",
    "        \n",
    "        # Assign based on nearest cluster center\n",
    "        center1 = np.mean(sample_coords[sample_labels == 0], axis=0)\n",
    "        center2 = np.mean(sample_coords[sample_labels == 1], axis=0)\n",
    "        \n",
    "        dist_to_center1 = self.haversine_vectorized(cluster_coords, center1.reshape(1, -1))[:, 0]\n",
    "        dist_to_center2 = self.haversine_vectorized(cluster_coords, center2.reshape(1, -1))[:, 0]\n",
    "        labels = (dist_to_center1 <= dist_to_center2).astype(int)\n",
    "        \n",
    "        return self._balance_split(cluster_indices, labels)\n",
    "\n",
    "    def _balance_split(self, cluster_indices, labels):\n",
    "        \"\"\"Proximity-based balancing for spatial coherence\"\"\"\n",
    "        unique_labels = np.unique(labels)\n",
    "        if len(unique_labels) == 1:\n",
    "            # All points have same label, split arbitrarily\n",
    "            mid = len(cluster_indices) // 2\n",
    "            return [cluster_indices[:mid], cluster_indices[mid:]]\n",
    "        \n",
    "        # Handle noise points from DBSCAN (label -1)\n",
    "        if -1 in unique_labels:\n",
    "            noise_mask = labels == -1\n",
    "            valid_labels = labels[~noise_mask]\n",
    "            if len(np.unique(valid_labels)) == 0:\n",
    "                return [cluster_indices]\n",
    "            \n",
    "            # Assign noise points to nearest valid cluster\n",
    "            for i in np.where(noise_mask)[0]:\n",
    "                # Find nearest non-noise point\n",
    "                distances = []\n",
    "                for j in np.where(~noise_mask)[0]:\n",
    "                    dist = self.haversine_single_pair(\n",
    "                        self.full_coords_array[cluster_indices[i]], \n",
    "                        self.full_coords_array[cluster_indices[j]]\n",
    "                    )\n",
    "                    distances.append((dist, labels[j]))\n",
    "                \n",
    "                if distances:\n",
    "                    labels[i] = min(distances, key=lambda x: x[0])[1]\n",
    "        \n",
    "        # Create clusters based on labels\n",
    "        clusters = []\n",
    "        for label in np.unique(labels):\n",
    "            if label != -1:  # Skip noise label\n",
    "                cluster_mask = labels == label\n",
    "                cluster = cluster_indices[cluster_mask]\n",
    "                if len(cluster) > 0:\n",
    "                    clusters.append(cluster)\n",
    "        \n",
    "        if len(clusters) == 0:\n",
    "            return [cluster_indices]\n",
    "        elif len(clusters) == 1:\n",
    "            # Split the single cluster arbitrarily\n",
    "            cluster = clusters[0]\n",
    "            mid = len(cluster) // 2\n",
    "            return [cluster[:mid], cluster[mid:]]\n",
    "        else:\n",
    "            # Balance clusters if enabled\n",
    "            if self.balance_clusters and len(clusters) == 2:\n",
    "                return self._balance_two_clusters(clusters[0], clusters[1])\n",
    "            return clusters\n",
    "\n",
    "    def _balance_two_clusters(self, cluster_0, cluster_1):\n",
    "        \"\"\"Balance two clusters by size\"\"\"\n",
    "        size0, size1 = len(cluster_0), len(cluster_1)\n",
    "        \n",
    "        if size0 <= 2 * size1 and size1 <= 2 * size0:\n",
    "            return [cluster_0, cluster_1]\n",
    "        \n",
    "        coords0 = self.full_coords_array[cluster_0]\n",
    "        coords1 = self.full_coords_array[cluster_1]\n",
    "        \n",
    "        # Balance only when size difference is significant\n",
    "        if size0 > 2 * size1:\n",
    "            center1 = np.mean(coords1, axis=0)\n",
    "            dist_to_center1 = self.haversine_vectorized(coords0, center1.reshape(1, -1))[:, 0]\n",
    "            n_move = min((size0 - size1) // 2, max(1, size1))\n",
    "            move_idx = np.argsort(dist_to_center1)[:n_move]\n",
    "            cluster_1 = np.concatenate([cluster_1, cluster_0[move_idx]])\n",
    "            cluster_0 = np.delete(cluster_0, move_idx)\n",
    "            \n",
    "        elif size1 > 2 * size0:\n",
    "            center0 = np.mean(coords0, axis=0)\n",
    "            dist_to_center0 = self.haversine_vectorized(coords1, center0.reshape(1, -1))[:, 0]\n",
    "            n_move = min((size1 - size0) // 2, max(1, size0))\n",
    "            move_idx = np.argsort(dist_to_center0)[:n_move]\n",
    "            cluster_0 = np.concatenate([cluster_0, cluster_1[move_idx]])\n",
    "            cluster_1 = np.delete(cluster_1, move_idx)\n",
    "            \n",
    "        return [cluster_0, cluster_1]\n",
    "\n",
    "    def divisive_clustering(self, customers_df):\n",
    "        \"\"\"Main clustering with cache management\"\"\" \n",
    "        customers_df = customers_df.copy().reset_index(drop=True)\n",
    "        \n",
    "        # Validate input\n",
    "        if 'Latitude' not in customers_df.columns or 'Longitude' not in customers_df.columns:\n",
    "            raise ValueError(\"DataFrame must contain 'Latitude' and 'Longitude' columns\")\n",
    "        \n",
    "        coords_array = customers_df[['Latitude', 'Longitude']].values\n",
    "        n_customers = len(customers_df)\n",
    "        \n",
    "        self.full_coords_array = coords_array\n",
    "        self._distance_cache = {}  # Reset cache\n",
    "        \n",
    "        if n_customers == 0:\n",
    "            customers_df['cluster'] = []\n",
    "            return customers_df\n",
    "        \n",
    "        if n_customers == 1:\n",
    "            customers_df['cluster'] = 1\n",
    "            return customers_df\n",
    "        \n",
    "        # Priority queue approach for better clustering\n",
    "        clusters_to_process = [(n_customers, np.arange(n_customers))]  # (size, indices)\n",
    "        final_clusters = []\n",
    "        \n",
    "        iteration_count = 0\n",
    "        max_iterations = n_customers * 2\n",
    "        \n",
    "        while clusters_to_process and iteration_count < max_iterations:\n",
    "            # Process largest cluster first\n",
    "            clusters_to_process.sort(key=lambda x: x[0], reverse=True)\n",
    "            current_size, current_cluster_indices = clusters_to_process.pop(0)\n",
    "            iteration_count += 1\n",
    "            \n",
    "            if self.should_split_cluster(current_cluster_indices, coords_array):\n",
    "                subclusters = self.geographic_split(current_cluster_indices, coords_array)\n",
    "                \n",
    "                for subcluster_indices in subclusters:\n",
    "                    if len(subcluster_indices) > 0:\n",
    "                        clusters_to_process.append((len(subcluster_indices), subcluster_indices))\n",
    "            else:\n",
    "                final_clusters.append(current_cluster_indices)\n",
    "        \n",
    "        # Handle remaining clusters\n",
    "        final_clusters.extend([indices for _, indices in clusters_to_process])\n",
    "        \n",
    "        # Create result DataFrame\n",
    "        result_df = customers_df.copy()\n",
    "        result_df['cluster'] = -1\n",
    "        \n",
    "        for cluster_id, cluster_indices in enumerate(final_clusters, 1):\n",
    "            result_df.loc[cluster_indices, 'cluster'] = cluster_id\n",
    "        \n",
    "        # Clean up stored data\n",
    "        if hasattr(self, 'full_coords_array'):\n",
    "            del self.full_coords_array\n",
    "        self._distance_cache = {}\n",
    "\n",
    "        return result_df\n",
    "    \n",
    "    def get_cluster_stats(self, clustered_df):\n",
    "        \"\"\"Get comprehensive clustering statistics.\"\"\"\n",
    "        if 'cluster' not in clustered_df.columns:\n",
    "            raise ValueError(\"DataFrame must contain 'cluster' column\")\n",
    "        \n",
    "        stats = {}\n",
    "        cluster_sizes = []\n",
    "        cluster_diameters = []\n",
    "        \n",
    "        for cluster_id in clustered_df['cluster'].unique():\n",
    "            if cluster_id == -1:\n",
    "                continue\n",
    "                \n",
    "            cluster_data = clustered_df[clustered_df['cluster'] == cluster_id]\n",
    "            coords = cluster_data[['Latitude', 'Longitude']].values\n",
    "            \n",
    "            diameter = self.calculate_cluster_diameter_fast(coords)\n",
    "            cluster_sizes.append(len(cluster_data))\n",
    "            cluster_diameters.append(diameter)\n",
    "            \n",
    "            stats[cluster_id] = {\n",
    "                'size': len(cluster_data),\n",
    "                'diameter_km': diameter,\n",
    "                'centroid_lat': np.mean(coords[:, 0]),\n",
    "                'centroid_lon': np.mean(coords[:, 1]),\n",
    "                'meets_size_constraint': len(cluster_data) <= self.max_customers_per_cluster,\n",
    "                'meets_distance_constraint': diameter <= self.max_distance_km\n",
    "            }\n",
    "        \n",
    "        # Overall statistics\n",
    "        if cluster_sizes:  # Only calculate if there are clusters\n",
    "            stats['summary'] = {\n",
    "                'total_clusters': len(stats) - 1,  # Excluding summary key\n",
    "                'avg_cluster_size': np.mean(cluster_sizes),\n",
    "                'max_cluster_size': np.max(cluster_sizes),\n",
    "                'min_cluster_size': np.min(cluster_sizes),\n",
    "                'avg_diameter': np.mean(cluster_diameters),\n",
    "                'max_diameter': np.max(cluster_diameters),\n",
    "                'size_violations': sum(1 for size in cluster_sizes if size > self.max_customers_per_cluster),\n",
    "                'distance_violations': sum(1 for diameter in cluster_diameters if diameter > self.max_distance_km)\n",
    "            }\n",
    "        else:\n",
    "            stats['summary'] = {\n",
    "                'total_clusters': 0,\n",
    "                'avg_cluster_size': 0,\n",
    "                'max_cluster_size': 0,\n",
    "                'min_cluster_size': 0,\n",
    "                'avg_diameter': 0,\n",
    "                'max_diameter': 0,\n",
    "                'size_violations': 0,\n",
    "                'distance_violations': 0\n",
    "            }\n",
    "        \n",
    "        return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98368b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import numba\n",
    "\n",
    "### Fastest\n",
    "class OptimizedDivisiveGeographicClustering_fast:\n",
    "    def __init__(self, max_customers_per_cluster=20, max_distance_km=50):\n",
    "        self.max_customers_per_cluster = max_customers_per_cluster\n",
    "        self.max_distance_km = max_distance_km\n",
    "        self.earth_radius_km = 6371.0\n",
    "\n",
    "    @staticmethod\n",
    "    @numba.njit(fastmath=True)\n",
    "    def haversine_single_pair(lat1, lon1, lat2, lon2):\n",
    "        \"\"\"Numba-optimized haversine distance between two points.\"\"\"\n",
    "        lat1, lon1, lat2, lon2 = np.radians([lat1, lon1, lat2, lon2])\n",
    "        dlat = lat2 - lat1\n",
    "        dlon = lon2 - lon1\n",
    "        a = np.sin(dlat/2)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2)**2\n",
    "        return 6371.0 * 2 * np.arcsin(np.sqrt(min(1.0, a)))\n",
    "    \n",
    "    @staticmethod\n",
    "    @numba.njit(fastmath=True, parallel=True)\n",
    "    def haversine_vectorized(coord, coords):\n",
    "        \"\"\"Vectorized haversine distance from one point to many.\"\"\"\n",
    "        lat1, lon1 = np.radians(coord)\n",
    "        dists = np.empty(coords.shape[0])\n",
    "        for i in numba.prange(coords.shape[0]):\n",
    "            lat2, lon2 = np.radians(coords[i])\n",
    "            dlat = lat2 - lat1\n",
    "            dlon = lon2 - lon1\n",
    "            a = np.sin(dlat/2)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2)**2\n",
    "            dists[i] = 6371.0 * 2 * np.arcsin(np.sqrt(min(1.0, a)))\n",
    "        return dists\n",
    "\n",
    "    def compute_diameter_and_farthest_pair(self, coords):\n",
    "        \"\"\"Compute diameter and farthest pair with optimal strategy.\"\"\"\n",
    "        n = len(coords)\n",
    "        if n <= 100:  # Exact for small clusters\n",
    "            dists = self.haversine_pdist(coords)\n",
    "            dist_matrix = squareform(dists)\n",
    "            max_idx = np.unravel_index(np.argmax(dist_matrix), dist_matrix.shape)\n",
    "            return dist_matrix[max_idx], max_idx\n",
    "        else:  # Approximate for large clusters\n",
    "            return self._two_pass_approximation(coords)\n",
    "\n",
    "    def _two_pass_approximation(self, coords):\n",
    "        \"\"\"Two-pass algorithm for approximate diameter and farthest pair.\"\"\"\n",
    "        # First pass: random point to farthest point\n",
    "        idx0 = np.random.randint(len(coords))\n",
    "        dists = self.haversine_vectorized(coords[idx0], coords)\n",
    "        idx1 = np.argmax(dists)\n",
    "        \n",
    "        # Second pass: farthest point to its farthest point\n",
    "        dists = self.haversine_vectorized(coords[idx1], coords)\n",
    "        idx2 = np.argmax(dists)\n",
    "        diameter = dists[idx2]\n",
    "        \n",
    "        return diameter, (idx1, idx2)\n",
    "\n",
    "    def haversine_pdist(self, coords):\n",
    "        \"\"\"Optimized haversine pairwise distances using vectorization.\"\"\"\n",
    "        n = coords.shape[0]\n",
    "        dists = np.zeros(n*(n-1)//2)\n",
    "        k = 0\n",
    "        for i in range(n):\n",
    "            dists_i = self.haversine_vectorized(coords[i], coords[i+1:])\n",
    "            dists[k:k+len(dists_i)] = dists_i\n",
    "            k += len(dists_i)\n",
    "        return dists\n",
    "\n",
    "    def should_split_cluster(self, cluster_indices, coords_array):\n",
    "        \"\"\"Determine if cluster should be split with early termination.\"\"\"\n",
    "        cluster_size = len(cluster_indices)\n",
    "        \n",
    "        if cluster_size <= 1:\n",
    "            return False, None\n",
    "            \n",
    "        if cluster_size > self.max_customers_per_cluster:\n",
    "            return True, None  # Size violation\n",
    "        \n",
    "        # Check diameter constraint\n",
    "        cluster_coords = coords_array[cluster_indices]\n",
    "        diameter, farthest_pair = self.compute_diameter_and_farthest_pair(cluster_coords)\n",
    "        return diameter > self.max_distance_km, farthest_pair\n",
    "\n",
    "    def geographic_split(self, cluster_indices, coords_array, farthest_pair=None):\n",
    "        \"\"\"Efficient cluster splitting with optional precomputed centers.\"\"\"\n",
    "        cluster_coords = coords_array[cluster_indices]\n",
    "        n = len(cluster_coords)\n",
    "        \n",
    "        # Get or compute farthest pair\n",
    "        if farthest_pair is None:\n",
    "            if n <= 100:\n",
    "                _, farthest_pair = self.compute_diameter_and_farthest_pair(cluster_coords)\n",
    "            else:\n",
    "                _, farthest_pair = self._two_pass_approximation(cluster_coords)\n",
    "        \n",
    "        center1_idx, center2_idx = farthest_pair\n",
    "        center1 = cluster_coords[center1_idx]\n",
    "        center2 = cluster_coords[center2_idx]\n",
    "        \n",
    "        # Vectorized distance calculations\n",
    "        dists1 = self.haversine_vectorized(center1, cluster_coords)\n",
    "        dists2 = self.haversine_vectorized(center2, cluster_coords)\n",
    "        labels = (dists1 <= dists2).astype(int)\n",
    "        \n",
    "        # Create subclusters\n",
    "        mask = labels.astype(bool)\n",
    "        cluster_a = cluster_indices[mask]\n",
    "        cluster_b = cluster_indices[~mask]\n",
    "        \n",
    "        # Balance clusters if needed\n",
    "        if len(cluster_a) == 0 or len(cluster_b) == 0:\n",
    "            return self._split_fallback(cluster_indices, cluster_coords)\n",
    "            \n",
    "        return [cluster_a, cluster_b]\n",
    "\n",
    "    def _split_fallback(self, cluster_indices, cluster_coords):\n",
    "        \"\"\"Fallback split when primary method fails.\"\"\"\n",
    "        # Use longitude-based split as fallback\n",
    "        sorted_idx = np.argsort(cluster_coords[:, 1])\n",
    "        mid = len(sorted_idx) // 2\n",
    "        return [\n",
    "            cluster_indices[sorted_idx[:mid]],\n",
    "            cluster_indices[sorted_idx[mid:]]\n",
    "        ]\n",
    "\n",
    "    def divisive_clustering(self, customers_df):\n",
    "        \"\"\"Optimized divisive clustering with efficient diameter checks.\"\"\"\n",
    "        # Initialization and validation\n",
    "        if 'Latitude' not in customers_df or 'Longitude' not in customers_df:\n",
    "            raise ValueError(\"Missing Latitude/Longitude columns\")\n",
    "            \n",
    "        coords_array = customers_df[['Latitude', 'Longitude']].values\n",
    "        n = len(customers_df)\n",
    "        \n",
    "        # Edge cases\n",
    "        if n == 0:\n",
    "            return customers_df.assign(cluster=pd.Series(dtype=int))\n",
    "        if n == 1:\n",
    "            return customers_df.assign(cluster=1)\n",
    "        \n",
    "        # Initialize clustering\n",
    "        clusters_to_process = [np.arange(n)]\n",
    "        final_clusters = []\n",
    "        \n",
    "        # Process clusters\n",
    "        while clusters_to_process:\n",
    "            current = clusters_to_process.pop(0)\n",
    "            should_split, farthest_pair = self.should_split_cluster(current, coords_array)\n",
    "            \n",
    "            if should_split:\n",
    "                subclusters = self.geographic_split(\n",
    "                    current, coords_array, farthest_pair\n",
    "                )\n",
    "                clusters_to_process.extend(subclusters)\n",
    "            else:\n",
    "                final_clusters.append(current)\n",
    "        \n",
    "        # Assign cluster labels\n",
    "        cluster_labels = np.zeros(n, dtype=int)\n",
    "        for idx, cluster in enumerate(final_clusters, 1):\n",
    "            cluster_labels[cluster] = idx\n",
    "            \n",
    "        return customers_df.assign(cluster=cluster_labels)\n",
    "\n",
    "    def get_cluster_stats(self, clustered_df):\n",
    "        \"\"\"Get comprehensive clustering statistics.\"\"\"\n",
    "        if 'cluster' not in clustered_df.columns:\n",
    "            raise ValueError(\"DataFrame must contain 'cluster' column\")\n",
    "        \n",
    "        stats = {}\n",
    "        cluster_sizes = []\n",
    "        cluster_diameters = []\n",
    "        \n",
    "        for cluster_id in clustered_df['cluster'].unique():\n",
    "            if cluster_id == -1:\n",
    "                continue\n",
    "                \n",
    "            cluster_data = clustered_df[clustered_df['cluster'] == cluster_id]\n",
    "            coords = cluster_data[['Latitude', 'Longitude']].values\n",
    "            n_points = len(coords)\n",
    "            \n",
    "            # Handle diameter calculation efficiently\n",
    "            if n_points == 0:\n",
    "                diameter = 0.0\n",
    "            elif n_points == 1:\n",
    "                diameter = 0.0\n",
    "            else:\n",
    "                diameter, _ = self.compute_diameter_and_farthest_pair(coords)\n",
    "            \n",
    "            cluster_sizes.append(n_points)\n",
    "            cluster_diameters.append(diameter)\n",
    "            \n",
    "            stats[cluster_id] = {\n",
    "                'size': n_points,\n",
    "                'diameter_km': diameter,\n",
    "                'centroid_lat': np.mean(coords[:, 0]) if n_points > 0 else None,\n",
    "                'centroid_lon': np.mean(coords[:, 1]) if n_points > 0 else None,\n",
    "                'meets_size_constraint': n_points <= self.max_customers_per_cluster,\n",
    "                'meets_distance_constraint': diameter <= self.max_distance_km\n",
    "            }\n",
    "        \n",
    "        # Calculate overall statistics\n",
    "        total_clusters = len(stats)\n",
    "        size_violations = sum(1 for size in cluster_sizes if size > self.max_customers_per_cluster)\n",
    "        distance_violations = sum(1 for d in cluster_diameters if d > self.max_distance_km)\n",
    "        \n",
    "        # Handle empty case\n",
    "        summary = {\n",
    "            'total_clusters': total_clusters,\n",
    "            'size_violations': size_violations,\n",
    "            'distance_violations': distance_violations,\n",
    "        }\n",
    "        \n",
    "        # Add statistical measures only if clusters exist\n",
    "        if cluster_sizes:\n",
    "            summary.update({\n",
    "                'avg_cluster_size': np.mean(cluster_sizes),\n",
    "                'max_cluster_size': np.max(cluster_sizes),\n",
    "                'min_cluster_size': np.min(cluster_sizes),\n",
    "                'avg_diameter': np.mean(cluster_diameters),\n",
    "                'max_diameter': np.max(cluster_diameters),\n",
    "            })\n",
    "        else:\n",
    "            summary.update({\n",
    "                'avg_cluster_size': 0,\n",
    "                'max_cluster_size': 0,\n",
    "                'min_cluster_size': 0,\n",
    "                'avg_diameter': 0,\n",
    "                'max_diameter': 0,\n",
    "            })\n",
    "        \n",
    "        stats['summary'] = summary\n",
    "        return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f978e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2. DIVISIVE HIERARCHICAL CLUSTERING\n",
    "# =============================================================================\n",
    "\n",
    "from clustering.divisive_clustering import DivisiveGeographicClustering, OptimizedDivisiveGeographicClustering\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"2. DIVISIVE HIERARCHICAL CLUSTERING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# divisive_clusterer = OptimizedDivisiveGeographicClustering( # Rivers: Too Long --\n",
    "#     max_customers_per_cluster=20,  # REQUIRED\n",
    "#     max_distance_km=5            # REQUIRED  \n",
    "# ) \n",
    "\n",
    "divisive_clusterer = OptimizedDivisiveGeographicClustering_b( \n",
    "    # Rivers: Divisive clusters created: 48 || Silhouette Score: 0.54 || Constraint violations: Size=6, Distance=3\n",
    "    max_customers_per_cluster=20,  # REQUIRED\n",
    "    max_distance_km=5            # REQUIRED\n",
    "    ,use_vectorized_distances=True, balance_clusters=False\n",
    ")\n",
    "\n",
    "# divisive_clusterer = OptimizedDivisiveGeographicClustering_be( \n",
    "#     # Rivers: Divisive clusters created: 26 || Silhouette Score: 0.57 || Constraint violations: Size=9, Distance=6\n",
    "#     max_customers_per_cluster=20,  # REQUIRED\n",
    "#     max_distance_km=10            # REQUIRED\n",
    "#     ,use_vectorized_distances=True, balance_clusters=False\n",
    "# )\n",
    "\n",
    "# divisive_clusterer = OptimizedDivisiveGeographicClustering_bo( \n",
    "# # Rivers: Divisive clusters created: 60 || Silhouette Score: 0.58 || Constraint violations: Size=9, Distance=7\n",
    "#     max_customers_per_cluster=20,  # REQUIRED\n",
    "#     max_distance_km=5            # REQUIRED \n",
    "# ) \n",
    "\n",
    "# divisive_clusterer = OptimizedDivisiveGeographicClustering_fast(\n",
    "#     # Rivers: Divisive clusters created: 63 || Silhouette Score: 0.46 || Constraint violations: Size=0, Distance=0\n",
    "#     max_customers_per_cluster=20,  # REQUIRED\n",
    "#     max_distance_km=5            # REQUIRED\n",
    "# )\n",
    "\n",
    "# divisive_clusterer = OptimizedDivisiveGeographicClustering_Main( \n",
    "#     # Rivers: Divisive clusters created: 69 ||Silhouette Score: 0.41\n",
    "#     max_customers_per_cluster=20,  # REQUIRED\n",
    "#     max_distance_km=5            # REQUIRED \n",
    "# ) \n",
    "\n",
    "divisive_result = divisive_clusterer.divisive_clustering(df_all_cluster.copy())\n",
    "print(f\"\\nDivisive clusters created: {divisive_result['cluster'].nunique()}\")\n",
    "# print(f\"Cluster sizes: {divisive_result['cluster'].value_counts().sort_index().head()}\")\n",
    "_ = evaluate_unsupervised_clustering(divisive_result)\n",
    "\n",
    "# # Get detailed statistics\n",
    "stats = divisive_clusterer.get_cluster_stats(divisive_result)\n",
    "print(f\"Total clusters: {stats['summary']['total_clusters']}\")\n",
    "print(f\"Constraint violations: Size={stats['summary']['size_violations']}, Distance={stats['summary']['distance_violations']}\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ea47e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "divisive_result.cluster.value_counts().reset_index().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd968c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_and_save(df_routes = divisive_result,\n",
    "                 df_stockpoint = None,   \n",
    "                 filename=None,\n",
    "                 cluster_col = 'cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6a8784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.cluster.hierarchy import fcluster, linkage\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class BaseGeographicClustering:\n",
    "    \"\"\"\n",
    "    A base class containing common geographic utility methods\n",
    "    used by both Divisive and Agglomerative clustering implementations.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.earth_radius_km = 6371.0\n",
    "\n",
    "    def haversine_vectorized(self, coords1, coords2=None):\n",
    "        \"\"\"\n",
    "        Highly optimized vectorized haversine distance calculation.\n",
    "        If coords2 is None, calculates pairwise distances within coords1.\n",
    "        Assumes coords are [latitude, longitude].\n",
    "        \"\"\"\n",
    "        if coords2 is None:\n",
    "            # Pairwise distances within coords1 (NxN matrix)\n",
    "            coords1_rad = np.radians(coords1)\n",
    "            \n",
    "            lat1 = coords1_rad[:, 0]\n",
    "            lon1 = coords1_rad[:, 1]\n",
    "            \n",
    "            lat1_mesh, lat2_mesh = np.meshgrid(lat1, lat1)\n",
    "            lon1_mesh, lon2_mesh = np.meshgrid(lon1, lon1)\n",
    "            \n",
    "            dlat = lat2_mesh - lat1_mesh\n",
    "            dlon = lon2_mesh - lon1_mesh\n",
    "            \n",
    "            a = (np.sin(dlat / 2) ** 2 + \n",
    "                 np.cos(lat1_mesh) * np.cos(lat2_mesh) * np.sin(dlon / 2) ** 2)\n",
    "            c = 2 * np.arcsin(np.sqrt(np.clip(a, 0, 1)))\n",
    "            \n",
    "            return self.earth_radius_km * c\n",
    "        else:\n",
    "            # Distance from each point in coords1 to each point in coords2 (NxM matrix)\n",
    "            coords1_rad = np.radians(coords1)\n",
    "            coords2_rad = np.radians(coords2)\n",
    "            \n",
    "            lat1 = coords1_rad[:, 0][:, np.newaxis]\n",
    "            lon1 = coords1_rad[:, 1][:, np.newaxis]\n",
    "            lat2 = coords2_rad[:, 0][np.newaxis, :]\n",
    "            lon2 = coords2_rad[:, 1][np.newaxis, :]\n",
    "            \n",
    "            dlat = lat2 - lat1\n",
    "            dlon = lon2 - lon1\n",
    "            \n",
    "            a = (np.sin(dlat / 2) ** 2 + \n",
    "                 np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2)\n",
    "            c = 2 * np.arcsin(np.sqrt(np.clip(a, 0, 1)))\n",
    "            \n",
    "            return self.earth_radius_km * c\n",
    "    \n",
    "    def haversine_pdist(self, coords):\n",
    "        \"\"\"\n",
    "        Optimized haversine distance calculation for pdist, returning condensed distance matrix.\n",
    "        Assumes coords are [latitude, longitude].\n",
    "        \"\"\"\n",
    "        def haversine_metric(u, v):\n",
    "            lat1, lon1 = np.radians(u)\n",
    "            lat2, lon2 = np.radians(v)\n",
    "            \n",
    "            dlat = lat2 - lat1\n",
    "            dlon = lon2 - lon1\n",
    "            \n",
    "            a = (np.sin(dlat / 2) ** 2 + \n",
    "                 np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2)\n",
    "            c = 2 * np.arcsin(np.sqrt(np.clip(a, 0, 1)))\n",
    "            \n",
    "            return self.earth_radius_km * c\n",
    "        \n",
    "        return pdist(coords, metric=haversine_metric)\n",
    "    \n",
    "    def haversine_single_pair(self, coord1, coord2):\n",
    "        \"\"\"Calculate haversine distance between two points.\"\"\"\n",
    "        lat1, lon1 = np.radians(coord1)\n",
    "        lat2, lon2 = np.radians(coord2)\n",
    "        \n",
    "        dlat = lat2 - lat1\n",
    "        dlon = lon2 - lon1\n",
    "        \n",
    "        a = (np.sin(dlat / 2) ** 2 + \n",
    "             np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2)\n",
    "        c = 2 * np.arcsin(np.sqrt(np.clip(a, 0, 1)))\n",
    "        \n",
    "        return self.earth_radius_km * c\n",
    "\n",
    "    def _convex_hull_diameter(self, coords):\n",
    "        \"\"\"Enhanced convex hull approximation for diameter estimation.\"\"\"\n",
    "        lats, lons = coords[:, 0], coords[:, 1]\n",
    "        \n",
    "        # Get extreme points (min/max lat/lon)\n",
    "        extreme_indices = [\n",
    "            np.argmax(lats), np.argmin(lats),\n",
    "            np.argmax(lons), np.argmin(lons)\n",
    "        ]\n",
    "        \n",
    "        # Add points from different quadrants relative to the mean center\n",
    "        lat_center, lon_center = np.mean(lats), np.mean(lons)\n",
    "        \n",
    "        quadrants = [\n",
    "            (lats >= lat_center) & (lons >= lon_center),   # NE\n",
    "            (lats >= lat_center) & (lons < lon_center),    # NW\n",
    "            (lats < lat_center) & (lons >= lon_center),    # SE\n",
    "            (lats < lat_center) & (lons < lon_center)      # SW\n",
    "        ]\n",
    "        \n",
    "        for quadrant in quadrants:\n",
    "            if np.any(quadrant):\n",
    "                quad_indices = np.where(quadrant)[0]\n",
    "                # Add furthest point from center in each non-empty quadrant\n",
    "                distances_from_center = np.sqrt(\n",
    "                    (lats[quad_indices] - lat_center)**2 + \n",
    "                    (lons[quad_indices] - lon_center)**2\n",
    "                )\n",
    "                furthest_idx = quad_indices[np.argmax(distances_from_center)]\n",
    "                extreme_indices.append(furthest_idx)\n",
    "        \n",
    "        # Add some random points to further improve approximation for larger clusters\n",
    "        n_random = min(12, len(coords) - len(set(extreme_indices)))\n",
    "        if n_random > 0:\n",
    "            available_indices = list(set(range(len(coords))) - set(extreme_indices))\n",
    "            if available_indices:\n",
    "                random_indices = np.random.choice(available_indices, \n",
    "                                                  min(n_random, len(available_indices)), \n",
    "                                                  replace=False)\n",
    "                extreme_indices.extend(random_indices)\n",
    "        \n",
    "        # Get unique sample coordinates\n",
    "        sample_indices = list(set(extreme_indices))\n",
    "        sample_coords = coords[sample_indices]\n",
    "        \n",
    "        if len(sample_coords) <= 1:\n",
    "            return 0\n",
    "        \n",
    "        # Calculate max distance among the sampled points\n",
    "        distances = self.haversine_pdist(sample_coords)\n",
    "        return np.max(distances)\n",
    "    \n",
    "    def _grid_based_diameter(self, coords):\n",
    "        \"\"\"Grid-based sampling for very large clusters.\"\"\"\n",
    "        lats, lons = coords[:, 0], coords[:, 1]\n",
    "        \n",
    "        # Create 6x6 grid\n",
    "        lat_bins = np.linspace(lats.min(), lats.max(), 7)\n",
    "        lon_bins = np.linspace(lons.min(), lons.max(), 7)\n",
    "        \n",
    "        sample_indices = []\n",
    "        for i in range(len(lat_bins)-1):\n",
    "            for j in range(len(lon_bins)-1):\n",
    "                mask = ((lats >= lat_bins[i]) & (lats < lat_bins[i+1]) & \n",
    "                        (lons >= lon_bins[j]) & (lons < lon_bins[j+1]))\n",
    "                cell_indices = np.where(mask)[0]\n",
    "                if len(cell_indices) > 0:\n",
    "                    # Sample up to 2 points from each cell\n",
    "                    n_sample = min(2, len(cell_indices))\n",
    "                    sampled = np.random.choice(cell_indices, n_sample, replace=False)\n",
    "                    sample_indices.extend(sampled)\n",
    "        \n",
    "        if len(sample_indices) <= 1:\n",
    "            return 0\n",
    "        \n",
    "        sample_coords = coords[sample_indices]\n",
    "        distances = self.haversine_pdist(sample_coords)\n",
    "        return np.max(distances)\n",
    "    \n",
    "    def calculate_cluster_diameter_fast(self, coords):\n",
    "        \"\"\"\n",
    "        Fast cluster diameter calculation with multiple optimization strategies.\n",
    "        \"\"\"\n",
    "        n_points = len(coords)\n",
    "        \n",
    "        if n_points <= 1:\n",
    "            return 0\n",
    "        \n",
    "        if n_points == 2:\n",
    "            return self.haversine_single_pair(coords[0], coords[1])\n",
    "        \n",
    "        # Use different strategies based on cluster size\n",
    "        if n_points <= 10:\n",
    "            # Small clusters: exact calculation using pdist\n",
    "            distances = self.haversine_pdist(coords)\n",
    "            return np.max(distances)\n",
    "        elif n_points <= 50:\n",
    "            # Medium clusters: vectorized calculation or pdist\n",
    "            # Prioritize vectorized if available and faster for this range\n",
    "            distance_matrix = self.haversine_vectorized(coords)\n",
    "            # Ensure we're not taking max of diagonal (self-distances = 0)\n",
    "            return np.max(distance_matrix[np.triu_indices(n_points, k=1)])\n",
    "        else:\n",
    "            # Large clusters: smart sampling\n",
    "            return self._smart_diameter_estimation(coords)\n",
    "    \n",
    "    def _smart_diameter_estimation(self, coords):\n",
    "        \"\"\"\n",
    "        Improved diameter estimation using multiple sampling strategies.\n",
    "        \"\"\"\n",
    "        n_points = len(coords)\n",
    "        \n",
    "        # Strategy 1: Convex hull approximation\n",
    "        hull_diameter = self._convex_hull_diameter(coords)\n",
    "        \n",
    "        # Strategy 2: Grid-based sampling for very large clusters (higher confidence for max)\n",
    "        if n_points > 200: # Threshold for when grid sampling might be beneficial\n",
    "            grid_diameter = self._grid_based_diameter(coords)\n",
    "            return max(hull_diameter, grid_diameter)\n",
    "        \n",
    "        return hull_diameter\n",
    "\n",
    "    def _find_approximate_farthest_pair(self, coords):\n",
    "        \"\"\"Find approximate farthest pair for large clusters.\n",
    "           Moved from OptimizedDivisiveGeographicClustering to BaseGeographicClustering.\"\"\"\n",
    "        n_points = len(coords)\n",
    "        \n",
    "        if n_points <= 100:\n",
    "            # For moderate sizes, use exact calculation\n",
    "            distances = self.haversine_pdist(coords)\n",
    "            distance_matrix = squareform(distances)\n",
    "            max_idx = np.unravel_index(np.argmax(distance_matrix), distance_matrix.shape)\n",
    "            return max_idx[0], max_idx[1]\n",
    "        \n",
    "        # For large clusters, use sampling\n",
    "        sample_size = min(50, n_points)\n",
    "        sample_indices = np.random.choice(n_points, sample_size, replace=False)\n",
    "        sample_coords = coords[sample_indices]\n",
    "        \n",
    "        distances = self.haversine_pdist(sample_coords)\n",
    "        distance_matrix = squareform(distances)\n",
    "        max_idx = np.unravel_index(np.argmax(distance_matrix), distance_matrix.shape)\n",
    "        \n",
    "        return sample_indices[max_idx[0]], sample_indices[max_idx[1]]\n",
    "\n",
    "    def get_cluster_stats(self, clustered_df, max_customers_per_cluster, max_distance_km):\n",
    "        \"\"\"Get comprehensive clustering statistics.\"\"\"\n",
    "        if 'cluster' not in clustered_df.columns:\n",
    "            raise ValueError(\"DataFrame must contain 'cluster' column\")\n",
    "        \n",
    "        stats = {}\n",
    "        cluster_sizes = []\n",
    "        cluster_diameters = []\n",
    "        \n",
    "        for cluster_id in clustered_df['cluster'].unique():\n",
    "            if cluster_id == -1: # Unassigned points if any\n",
    "                continue\n",
    "            \n",
    "            cluster_data = clustered_df[clustered_df['cluster'] == cluster_id]\n",
    "            coords = cluster_data[['Latitude', 'Longitude']].values\n",
    "            \n",
    "            diameter = self.calculate_cluster_diameter_fast(coords)\n",
    "            cluster_sizes.append(len(cluster_data))\n",
    "            cluster_diameters.append(diameter)\n",
    "            \n",
    "            stats[cluster_id] = {\n",
    "                'size': len(cluster_data),\n",
    "                'diameter_km': diameter,\n",
    "                'centroid_lat': np.mean(coords[:, 0]),\n",
    "                'centroid_lon': np.mean(coords[:, 1]),\n",
    "                'meets_size_constraint': len(cluster_data) <= max_customers_per_cluster,\n",
    "                'meets_distance_constraint': diameter <= max_distance_km\n",
    "            }\n",
    "        \n",
    "        # Overall statistics\n",
    "        stats['summary'] = {\n",
    "            'total_clusters': len(stats), \n",
    "            'avg_cluster_size': np.mean(cluster_sizes) if cluster_sizes else 0,\n",
    "            'max_cluster_size': np.max(cluster_sizes) if cluster_sizes else 0,\n",
    "            'min_cluster_size': np.min(cluster_sizes) if cluster_sizes else 0,\n",
    "            'avg_diameter': np.mean(cluster_diameters) if cluster_diameters else 0,\n",
    "            'max_diameter': np.max(cluster_diameters) if cluster_diameters else 0,\n",
    "            'size_violations': sum(1 for size in cluster_sizes if size > max_customers_per_cluster),\n",
    "            'distance_violations': sum(1 for diameter in cluster_diameters if diameter > max_distance_km)\n",
    "        }\n",
    "        \n",
    "        return stats\n",
    "\n",
    "\n",
    "class AgglomerativeGeographicClustering(BaseGeographicClustering):\n",
    "    def __init__(self, max_customers_per_cluster=20, max_distance_km=50, \n",
    "                 linkage_method='ward', sub_cluster_if_oversized=True):\n",
    "        \"\"\"\n",
    "        Initializes the Agglomerative Geographic Clustering.\n",
    "\n",
    "        Args:\n",
    "            max_customers_per_cluster (int): Maximum number of customers allowed in a single cluster.\n",
    "            max_distance_km (float): Maximum diameter (distance between two farthest points)\n",
    "                                     allowed within a cluster in kilometers.\n",
    "            linkage_method (str): Method to use for calculating the distance between clusters\n",
    "                                  in hierarchical clustering. Options: 'ward', 'single', 'complete', 'average'.\n",
    "            sub_cluster_if_oversized (bool): If True, clusters that exceed max_customers_per_cluster\n",
    "                                             after distance-based cutting will be further sub-clustered\n",
    "                                             using K-Means.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.max_customers_per_cluster = max_customers_per_cluster\n",
    "        self.max_distance_km = max_distance_km\n",
    "        self.linkage_method = linkage_method\n",
    "        self.sub_cluster_if_oversized = sub_cluster_if_oversized\n",
    "\n",
    "    def agglomerative_clustering(self, customers_df):\n",
    "        \"\"\"\n",
    "        Performs agglomerative hierarchical clustering on geographic data\n",
    "        with constraints on cluster size and diameter.\n",
    "        \"\"\"\n",
    "        customers_df = customers_df.copy().reset_index(drop=True)\n",
    "        \n",
    "        if 'Latitude' not in customers_df.columns or 'Longitude' not in customers_df.columns:\n",
    "            raise ValueError(\"DataFrame must contain 'Latitude' and 'Longitude' columns\")\n",
    "        \n",
    "        coords_array = customers_df[['Latitude', 'Longitude']].values\n",
    "        n_customers = len(customers_df)\n",
    "        \n",
    "        if n_customers == 0:\n",
    "            customers_df['cluster'] = []\n",
    "            return customers_df\n",
    "        \n",
    "        if n_customers == 1:\n",
    "            customers_df['cluster'] = 1\n",
    "            return customers_df\n",
    "\n",
    "        # Step 1: Calculate pairwise Haversine distances\n",
    "        print(f\"Calculating {n_customers*(n_customers-1)//2} pairwise distances...\")\n",
    "        # Check if the number of points is too large for pdist to avoid MemoryError\n",
    "        # A rough heuristic: 5000 points * 5000 points / 2 * 8 bytes/float ~ 100MB\n",
    "        # For very large N, consider approximate methods if pdist is too slow/memory intensive\n",
    "        if n_customers > 2000 and self.linkage_method != 'ward': # Ward only works with Euclidean-like pdist\n",
    "             # For very large datasets, pdist might be too slow or memory intensive.\n",
    "             # In such cases, one might consider sampling or approximate hierarchical methods,\n",
    "             # or other clustering algorithms like DBSCAN that don't require a full distance matrix.\n",
    "             # For now, we proceed with pdist as it's standard for scipy.hierarchy.\n",
    "            print(\"Warning: Large dataset for pdist. This might take a while or consume a lot of memory.\")\n",
    "\n",
    "        distances = self.haversine_pdist(coords_array)\n",
    "        \n",
    "        # Step 2: Perform hierarchical clustering using linkage\n",
    "        print(f\"Performing linkage using '{self.linkage_method}' method...\")\n",
    "        linkage_matrix = linkage(distances, method=self.linkage_method)\n",
    "        \n",
    "        # Step 3: Cut the dendrogram based on max_distance_km\n",
    "        # This creates clusters where no two points are farther apart than max_distance_km\n",
    "        print(f\"Cutting dendrogram at max_distance_km={self.max_distance_km}...\")\n",
    "        initial_labels = fcluster(linkage_matrix, self.max_distance_km, criterion='distance')\n",
    "        \n",
    "        customers_df['cluster_temp'] = initial_labels\n",
    "        final_cluster_id = 0\n",
    "        final_clusters = {}\n",
    "\n",
    "        # Step 4: Post-process for max_customers_per_cluster constraint\n",
    "        print(f\"Post-processing clusters for size constraint (max {self.max_customers_per_cluster} customers)...\")\n",
    "        for current_cluster_label in sorted(customers_df['cluster_temp'].unique()):\n",
    "            cluster_indices = customers_df[customers_df['cluster_temp'] == current_cluster_label].index.values\n",
    "            current_coords = coords_array[cluster_indices]\n",
    "            \n",
    "            if len(cluster_indices) > self.max_customers_per_cluster and self.sub_cluster_if_oversized:\n",
    "                print(f\"  Cluster {current_cluster_label} (size {len(cluster_indices)}) is oversized. Sub-clustering...\")\n",
    "                # Sub-cluster using K-Means. Determine optimal k based on current size / max_customers_per_cluster\n",
    "                k_sub = int(np.ceil(len(cluster_indices) / self.max_customers_per_cluster))\n",
    "                k_sub = max(2, k_sub) # Ensure at least 2 clusters if splitting\n",
    "                \n",
    "                # Use approximate farthest pair for K-Means initialization\n",
    "                initial_centers_indices = self._find_approximate_farthest_pair(current_coords)\n",
    "                # Ensure initial_centers_indices has enough elements for k_sub.\n",
    "                # If k_sub > 2, KMeans++ initialization is generally more robust than a simple farthest pair.\n",
    "                if k_sub > 2:\n",
    "                    kmeans_sub = KMeans(n_clusters=k_sub, n_init=10, random_state=42) # Let KMeans find its own init\n",
    "                elif len(initial_centers_indices) >= 2: # k_sub = 2, use the farthest pair if available\n",
    "                    kmeans_sub = KMeans(n_clusters=k_sub, init=current_coords[[initial_centers_indices[0], initial_centers_indices[1]]], n_init=1, random_state=42)\n",
    "                else: # Fallback if initial_centers_indices is not sufficient for k_sub=2\n",
    "                    kmeans_sub = KMeans(n_clusters=k_sub, n_init=10, random_state=42)\n",
    "\n",
    "\n",
    "                sub_labels = kmeans_sub.fit_predict(current_coords)\n",
    "                \n",
    "                for sub_label in np.unique(sub_labels):\n",
    "                    final_cluster_id += 1\n",
    "                    sub_cluster_indices = cluster_indices[sub_labels == sub_label]\n",
    "                    final_clusters[final_cluster_id] = sub_cluster_indices\n",
    "            else:\n",
    "                final_cluster_id += 1\n",
    "                final_clusters[final_cluster_id] = cluster_indices\n",
    "        \n",
    "        # Assign final cluster labels to the DataFrame\n",
    "        result_df = customers_df.copy()\n",
    "        result_df['cluster'] = -1 # Initialize with unassigned\n",
    "\n",
    "        for cluster_id, indices in final_clusters.items():\n",
    "            result_df.loc[indices, 'cluster'] = cluster_id\n",
    "        \n",
    "        result_df = result_df.drop(columns=['cluster_temp'])\n",
    "        print(\"Agglomerative clustering completed.\\n\")\n",
    "        return result_df\n",
    "\n",
    "class OptimizedDivisiveGeographicClustering(BaseGeographicClustering):\n",
    "    \"\"\" Best - Fast and Accurate Divisive Geographic Clustering\n",
    "    \"\"\"\n",
    "    def __init__(self, max_customers_per_cluster=20, max_distance_km=50, \n",
    "                 use_vectorized_distances=True, balance_clusters=False):\n",
    "        super().__init__()\n",
    "        self.max_customers_per_cluster = max_customers_per_cluster\n",
    "        self.max_distance_km = max_distance_km\n",
    "        self.use_vectorized_distances = use_vectorized_distances\n",
    "        self.balance_clusters = balance_clusters\n",
    "        \n",
    "    def calculate_cluster_diameter_fast(self, coords): # Overrides Base class method\n",
    "        \"\"\"\n",
    "        Fast cluster diameter calculation with multiple optimization strategies.\n",
    "        \"\"\"\n",
    "        n_points = len(coords)\n",
    "        \n",
    "        if n_points <= 1:\n",
    "            return 0\n",
    "        \n",
    "        if n_points == 2:\n",
    "            return self.haversine_single_pair(coords[0], coords[1])\n",
    "        \n",
    "        # Use different strategies based on cluster size\n",
    "        if n_points <= 10:\n",
    "            # Small clusters: exact calculation\n",
    "            distances = self.haversine_pdist(coords)\n",
    "            return np.max(distances)\n",
    "        elif n_points <= 50:\n",
    "            # Medium clusters: vectorized calculation\n",
    "            if self.use_vectorized_distances:\n",
    "                distance_matrix = self.haversine_vectorized(coords)\n",
    "                return np.max(distance_matrix)\n",
    "            else:\n",
    "                distances = self.haversine_pdist(coords)\n",
    "                return np.max(distances)\n",
    "        else:\n",
    "            # Large clusters: smart sampling\n",
    "            return self._smart_diameter_estimation(coords)\n",
    "    \n",
    "    def _smart_diameter_estimation(self, coords): # Overrides Base class method\n",
    "        \"\"\"\n",
    "        Improved diameter estimation using multiple sampling strategies.\n",
    "        \"\"\"\n",
    "        n_points = len(coords)\n",
    "        \n",
    "        # Strategy 1: Convex hull approximation\n",
    "        hull_diameter = self._convex_hull_diameter(coords)\n",
    "        \n",
    "        # Strategy 2: Grid-based sampling for large clusters\n",
    "        if n_points > 200:\n",
    "            grid_diameter = self._grid_based_diameter(coords)\n",
    "            return max(hull_diameter, grid_diameter)\n",
    "        \n",
    "        return hull_diameter\n",
    "    \n",
    "    def should_split_cluster(self, cluster_indices, coords_array):\n",
    "        \"\"\"Enhanced cluster splitting logic with load balancing.\"\"\"\n",
    "        cluster_size = len(cluster_indices)\n",
    "        \n",
    "        if cluster_size <= 2:\n",
    "            return False\n",
    "        \n",
    "        # Hard size constraint\n",
    "        if cluster_size > self.max_customers_per_cluster * 1.5:\n",
    "            return True\n",
    "        \n",
    "        # Soft size constraint with diameter check\n",
    "        if cluster_size > self.max_customers_per_cluster:\n",
    "            cluster_coords = coords_array[cluster_indices]\n",
    "            diameter = self.calculate_cluster_diameter_fast(cluster_coords)\n",
    "            return diameter > self.max_distance_km * 0.8  # More lenient for size\n",
    "        \n",
    "        # Diameter constraint\n",
    "        cluster_coords = coords_array[cluster_indices]\n",
    "        diameter = self.calculate_cluster_diameter_fast(cluster_coords)\n",
    "        \n",
    "        return diameter > self.max_distance_km\n",
    "    \n",
    "    def geographic_split(self, cluster_indices, coords_array):\n",
    "        \"\"\"\n",
    "        Improved geographic splitting with better load balancing.\n",
    "        \"\"\"\n",
    "        if len(cluster_indices) <= 2:\n",
    "            return [cluster_indices]\n",
    "        \n",
    "        cluster_coords = coords_array[cluster_indices]\n",
    "        n_points = len(cluster_coords)\n",
    "        \n",
    "        # For small clusters, use exact method\n",
    "        if n_points <= 50:\n",
    "            return self._exact_geographic_split(cluster_indices, cluster_coords)\n",
    "        \n",
    "        # For medium clusters, use K-means with geographic initialization\n",
    "        if n_points <= 200:\n",
    "            return self._kmeans_geographic_split(cluster_indices, cluster_coords)\n",
    "        \n",
    "        # For large clusters, use hierarchical approach\n",
    "        return self._hierarchical_geographic_split(cluster_indices, cluster_coords)\n",
    "    \n",
    "    def _exact_geographic_split(self, cluster_indices, cluster_coords):\n",
    "        \"\"\"Exact splitting for small clusters.\"\"\"\n",
    "        n_points = len(cluster_coords)\n",
    "        \n",
    "        # Find the two points that are farthest apart\n",
    "        distances = self.haversine_pdist(cluster_coords)\n",
    "        distance_matrix = squareform(distances)\n",
    "        max_idx = np.unravel_index(np.argmax(distance_matrix), distance_matrix.shape)\n",
    "        center1_idx, center2_idx = max_idx[0], max_idx[1]\n",
    "        \n",
    "        center1 = cluster_coords[center1_idx]\n",
    "        center2 = cluster_coords[center2_idx]\n",
    "        \n",
    "        # Assign points to closest center\n",
    "        distances_to_center1 = self.haversine_vectorized(cluster_coords, center1.reshape(1, -1))[:, 0]\n",
    "        distances_to_center2 = self.haversine_vectorized(cluster_coords, center2.reshape(1, -1))[:, 0]\n",
    "        \n",
    "        labels = (distances_to_center1 <= distances_to_center2).astype(int)\n",
    "        \n",
    "        return self._balance_split(cluster_indices, labels)\n",
    "    \n",
    "    def _kmeans_geographic_split(self, cluster_indices, cluster_coords):\n",
    "        \"\"\"K-means splitting with geographic initialization.\"\"\"\n",
    "        n_points = len(cluster_coords)\n",
    "        \n",
    "        # Initialize with farthest pair\n",
    "        # This calls _find_approximate_farthest_pair from BaseGeographicClustering\n",
    "        center1_idx, center2_idx = self._find_approximate_farthest_pair(cluster_coords) \n",
    "        initial_centers = cluster_coords[[center1_idx, center2_idx]]\n",
    "        \n",
    "        # Apply K-means\n",
    "        kmeans = KMeans(n_clusters=2, init=initial_centers, n_init=1, random_state=42)\n",
    "        labels = kmeans.fit_predict(cluster_coords)\n",
    "        \n",
    "        return self._balance_split(cluster_indices, labels)\n",
    "    \n",
    "    def _hierarchical_geographic_split(self, cluster_indices, cluster_coords):\n",
    "        \"\"\"Hierarchical splitting for large clusters.\"\"\"\n",
    "        # Use linkage-based clustering for very large clusters\n",
    "        n_sample = min(100, len(cluster_coords))\n",
    "        sample_indices = np.random.choice(len(cluster_coords), n_sample, replace=False)\n",
    "        sample_coords = cluster_coords[sample_indices]\n",
    "        \n",
    "        # Compute linkage on sample\n",
    "        distances = self.haversine_pdist(sample_coords)\n",
    "        linkage_matrix = linkage(distances, method='ward')\n",
    "        sample_labels = fcluster(linkage_matrix, 2, criterion='maxclust') - 1\n",
    "        \n",
    "        # Ensure that both sub-clusters have points from the sample\n",
    "        center1_coords = sample_coords[sample_labels == 0]\n",
    "        center2_coords = sample_coords[sample_labels == 1]\n",
    "        \n",
    "        if len(center1_coords) == 0 or len(center2_coords) == 0:\n",
    "            # Fallback to exact split if hierarchical sample leads to empty sub-clusters\n",
    "            return self._exact_geographic_split(cluster_indices, cluster_coords)\n",
    "        \n",
    "        center1 = np.mean(center1_coords, axis=0)\n",
    "        center2 = np.mean(center2_coords, axis=0)\n",
    "        \n",
    "        distances_to_center1 = self.haversine_vectorized(cluster_coords, center1.reshape(1, -1))[:, 0]\n",
    "        distances_to_center2 = self.haversine_vectorized(cluster_coords, center2.reshape(1, -1))[:, 0]\n",
    "        \n",
    "        labels = (distances_to_center1 <= distances_to_center2).astype(int)\n",
    "        \n",
    "        return self._balance_split(cluster_indices, labels)\n",
    "    \n",
    "    def _balance_split(self, cluster_indices, labels):\n",
    "        \"\"\"Balance the split to avoid very uneven clusters.\"\"\"\n",
    "        cluster_0_indices = cluster_indices[labels == 0]\n",
    "        cluster_1_indices = cluster_indices[labels == 1]\n",
    "        \n",
    "        # Ensure no empty clusters (very important for recursive calls)\n",
    "        if len(cluster_0_indices) == 0:\n",
    "            # If one cluster is empty, move one point from the other to it.\n",
    "            # This handles edge cases but might lead to a single point cluster,\n",
    "            # which the should_split_cluster check will prevent further splitting if <= 2.\n",
    "            if len(cluster_1_indices) > 0:\n",
    "                cluster_0_indices = np.array([cluster_1_indices[0]])\n",
    "                cluster_1_indices = cluster_1_indices[1:]\n",
    "            else: # Both empty, should not happen if initial cluster_indices was not empty\n",
    "                return [np.array([]), np.array([])]\n",
    "        elif len(cluster_1_indices) == 0:\n",
    "            if len(cluster_0_indices) > 0:\n",
    "                cluster_1_indices = np.array([cluster_0_indices[0]])\n",
    "                cluster_0_indices = cluster_0_indices[1:]\n",
    "            else: # Both empty\n",
    "                return [np.array([]), np.array([])]\n",
    "        \n",
    "        # Optional: Balance cluster sizes if one is much larger\n",
    "        if self.balance_clusters:\n",
    "            size_0, size_1 = len(cluster_0_indices), len(cluster_1_indices)\n",
    "            if size_0 > 3 * size_1 and size_1 > 0: # If cluster 0 is significantly larger\n",
    "                n_move = (size_0 - size_1) // 4 # Move a quarter of the difference\n",
    "                move_indices = cluster_0_indices[:n_move]\n",
    "                cluster_0_indices = cluster_0_indices[n_move:]\n",
    "                cluster_1_indices = np.concatenate([cluster_1_indices, move_indices])\n",
    "            elif size_1 > 3 * size_0 and size_0 > 0: # If cluster 1 is significantly larger\n",
    "                n_move = (size_1 - size_0) // 4\n",
    "                move_indices = cluster_1_indices[:n_move]\n",
    "                cluster_1_indices = cluster_1_indices[n_move:]\n",
    "                cluster_0_indices = np.concatenate([cluster_0_indices, move_indices])\n",
    "        \n",
    "        return [cluster_0_indices, cluster_1_indices]\n",
    "    \n",
    "    def divisive_clustering(self, customers_df):\n",
    "        \"\"\"Perform optimized divisive hierarchical clustering.\"\"\"\n",
    "        customers_df = customers_df.copy().reset_index(drop=True)\n",
    "        \n",
    "        # Validate input\n",
    "        if 'Latitude' not in customers_df.columns or 'Longitude' not in customers_df.columns:\n",
    "            raise ValueError(\"DataFrame must contain 'Latitude' and 'Longitude' columns\")\n",
    "        \n",
    "        coords_array = customers_df[['Latitude', 'Longitude']].values\n",
    "        n_customers = len(customers_df)\n",
    "        \n",
    "        if n_customers == 0:\n",
    "            customers_df['cluster'] = []\n",
    "            return customers_df\n",
    "        \n",
    "        if n_customers == 1:\n",
    "            customers_df['cluster'] = 1\n",
    "            return customers_df\n",
    "        \n",
    "        # Priority queue approach for better clustering\n",
    "        clusters_to_process = [(n_customers, np.arange(n_customers))]   # (size, indices)\n",
    "        final_clusters = []\n",
    "        \n",
    "        iteration_count = 0\n",
    "        max_iterations = n_customers * 2 # Safety break to prevent infinite loops\n",
    "        \n",
    "        while clusters_to_process and iteration_count < max_iterations:\n",
    "            # Process largest cluster first to tackle the biggest problems\n",
    "            clusters_to_process.sort(key=lambda x: x[0], reverse=True)\n",
    "            current_size, current_cluster_indices = clusters_to_process.pop(0)\n",
    "            iteration_count += 1\n",
    "            \n",
    "            if self.should_split_cluster(current_cluster_indices, coords_array):\n",
    "                subclusters = self.geographic_split(current_cluster_indices, coords_array)\n",
    "                \n",
    "                for subcluster_indices in subclusters:\n",
    "                    if len(subcluster_indices) > 0:\n",
    "                        clusters_to_process.append((len(subcluster_indices), subcluster_indices))\n",
    "            else:\n",
    "                final_clusters.append(current_cluster_indices)\n",
    "        \n",
    "        # Handle any clusters remaining in `clusters_to_process` if max_iterations was hit\n",
    "        final_clusters.extend([indices for _, indices in clusters_to_process])\n",
    "        \n",
    "        # Create result DataFrame\n",
    "        result_df = customers_df.copy()\n",
    "        result_df['cluster'] = -1 # Initialize with -1 for unassigned\n",
    "        \n",
    "        for cluster_id, cluster_indices in enumerate(final_clusters, 1):\n",
    "            result_df.loc[cluster_indices, 'cluster'] = cluster_id\n",
    "        \n",
    "        return result_df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c64bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad756b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### My custom testing\n",
    "print(\"--- Running Agglomerative Clustering ---\")\n",
    "agg_clusterer = AgglomerativeGeographicClustering(\n",
    "    max_customers_per_cluster=20, # Aim for clusters of max 50 customers\n",
    "    max_distance_km=5.0,        # Max diameter of 5 km\n",
    "    linkage_method='ward',       # Common choice for compact clusters\n",
    "    sub_cluster_if_oversized=True\n",
    ")\n",
    "clustered_agg_df = agg_clusterer.agglomerative_clustering(df_all_cluster.copy())\n",
    "agg_stats = agg_clusterer.get_cluster_stats(clustered_agg_df, agg_clusterer.max_customers_per_cluster, agg_clusterer.max_distance_km)\n",
    "print(\"\\nAgglomerative Clustering Stats:\")\n",
    "for k, v in agg_stats['summary'].items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "print(\"\\nSample Agglomerative Cluster Details:\")\n",
    "for cluster_id, details in list(agg_stats.items())[:5]: # Show first 5 clusters\n",
    "    if cluster_id != 'summary':\n",
    "        print(f\"  Cluster {cluster_id}: Size={details['size']}, Diameter={details['diameter_km']:.2f} km, Size OK={details['meets_size_constraint']}, Distance OK={details['meets_distance_constraint']}\")\n",
    "\n",
    "\n",
    "_ = evaluate_unsupervised_clustering(clustered_agg_df)\n",
    "\n",
    "# # # Get detailed statistics\n",
    "stats = divisive_clusterer.get_cluster_stats(clustered_agg_df)\n",
    "print(f\"Total clusters: {stats['summary']['total_clusters']}\")\n",
    "print(f\"Constraint violations: Size={stats['summary']['size_violations']}, Distance={stats['summary']['distance_violations']}\")\n",
    " \n",
    "\n",
    " \n",
    "vis_and_save(df_routes = clustered_agg_df,\n",
    "                 df_stockpoint = None,   \n",
    "                 filename=None,\n",
    "                 cluster_col = 'cluster')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92bf2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### My custom testing\n",
    "print(\"\\n--- Running Divisive Clustering (for comparison) ---\")\n",
    "div_clusterer = OptimizedDivisiveGeographicClustering(\n",
    "    max_customers_per_cluster=50,\n",
    "    max_distance_km=5.0,\n",
    "    balance_clusters=True\n",
    ")\n",
    "clustered_div_df = div_clusterer.divisive_clustering(df_all_cluster.copy())\n",
    "div_stats = div_clusterer.get_cluster_stats(clustered_div_df, div_clusterer.max_customers_per_cluster, div_clusterer.max_distance_km) # Added missing arguments\n",
    "print(\"\\nDivisive Clustering Stats:\")\n",
    "for k, v in div_stats['summary'].items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "print(\"\\nSample Divisive Cluster Details:\")\n",
    "for cluster_id, details in list(div_stats.items())[:5]: # Show first 5 clusters\n",
    "    if cluster_id != 'summary':\n",
    "        print(f\"  Cluster {cluster_id}: Size={details['size']}, Diameter={details['diameter_km']:.2f} km, Size OK={details['meets_size_constraint']}, Distance OK={details['meets_distance_constraint']}\")\n",
    "\n",
    "\n",
    "_ = evaluate_unsupervised_clustering(clustered_div_df)\n",
    "\n",
    "# # # Get detailed statistics\n",
    "stats = divisive_clusterer.get_cluster_stats(clustered_div_df)\n",
    "print(f\"Total clusters: {stats['summary']['total_clusters']}\")\n",
    "print(f\"Constraint violations: Size={stats['summary']['size_violations']}, Distance={stats['summary']['distance_violations']}\")\n",
    "\n",
    "\n",
    "\n",
    "vis_and_save(df_routes = clustered_div_df,\n",
    "                df_stockpoint = None,   \n",
    "                filename=None,\n",
    "                cluster_col = 'cluster')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33c5c24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f57385",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Example Usage ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate some sample geographic data\n",
    "    np.random.seed(42)\n",
    "    num_customers = 500 # Testing with more customers for better demonstration\n",
    "    \n",
    "    # Simulate clusters\n",
    "    center1 = [6.5, 3.3] # Lagos area\n",
    "    center2 = [6.6, 3.4]\n",
    "    center3 = [6.4, 3.2]\n",
    "\n",
    "    customers_data = []\n",
    "    # Cluster 1 (dense)\n",
    "    for _ in range(200):\n",
    "        customers_data.append({\n",
    "            'CustomerID': f'C1_{_}',\n",
    "            'Latitude': center1[0] + np.random.randn() * 0.01,\n",
    "            'Longitude': center1[1] + np.random.randn() * 0.01\n",
    "        })\n",
    "    # Cluster 2 (dense)\n",
    "    for _ in range(150):\n",
    "        customers_data.append({\n",
    "            'CustomerID': f'C2_{_}',\n",
    "            'Latitude': center2[0] + np.random.randn() * 0.015,\n",
    "            'Longitude': center2[1] + np.random.randn() * 0.015\n",
    "        })\n",
    "    # Cluster 3 (sparse, might get split or remain single if large enough)\n",
    "    for _ in range(150):\n",
    "        customers_data.append({\n",
    "            'CustomerID': f'C3_{_}',\n",
    "            'Latitude': center3[0] + np.random.randn() * 0.02,\n",
    "            'Longitude': center3[1] + np.random.randn() * 0.02\n",
    "        })\n",
    "\n",
    "    customers_df = pd.DataFrame(customers_data)\n",
    "\n",
    "    print(\"--- Running Agglomerative Clustering ---\")\n",
    "    agg_clusterer = AgglomerativeGeographicClustering(\n",
    "        max_customers_per_cluster=50, # Aim for clusters of max 50 customers\n",
    "        max_distance_km=5.0,        # Max diameter of 5 km\n",
    "        linkage_method='ward',       # Common choice for compact clusters\n",
    "        sub_cluster_if_oversized=True\n",
    "    )\n",
    "    clustered_agg_df = agg_clusterer.agglomerative_clustering(customers_df.copy())\n",
    "    agg_stats = agg_clusterer.get_cluster_stats(clustered_agg_df, agg_clusterer.max_customers_per_cluster, agg_clusterer.max_distance_km)\n",
    "    print(\"\\nAgglomerative Clustering Stats:\")\n",
    "    for k, v in agg_stats['summary'].items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "    print(\"\\nSample Agglomerative Cluster Details:\")\n",
    "    for cluster_id, details in list(agg_stats.items())[:5]: # Show first 5 clusters\n",
    "        if cluster_id != 'summary':\n",
    "            print(f\"  Cluster {cluster_id}: Size={details['size']}, Diameter={details['diameter_km']:.2f} km, Size OK={details['meets_size_constraint']}, Distance OK={details['meets_distance_constraint']}\")\n",
    "\n",
    "    print(\"\\n--- Running Divisive Clustering (for comparison) ---\")\n",
    "    div_clusterer = OptimizedDivisiveGeographicClustering(\n",
    "        max_customers_per_cluster=50,\n",
    "        max_distance_km=5.0,\n",
    "        balance_clusters=True\n",
    "    )\n",
    "    clustered_div_df = div_clusterer.divisive_clustering(customers_df.copy())\n",
    "    div_stats = div_clusterer.get_cluster_stats(clustered_div_df, div_clusterer.max_customers_per_cluster, div_clusterer.max_distance_km) # Added missing arguments\n",
    "    print(\"\\nDivisive Clustering Stats:\")\n",
    "    for k, v in div_stats['summary'].items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "    print(\"\\nSample Divisive Cluster Details:\")\n",
    "    for cluster_id, details in list(div_stats.items())[:5]: # Show first 5 clusters\n",
    "        if cluster_id != 'summary':\n",
    "            print(f\"  Cluster {cluster_id}: Size={details['size']}, Diameter={details['diameter_km']:.2f} km, Size OK={details['meets_size_constraint']}, Distance OK={details['meets_distance_constraint']}\")\n",
    "\n",
    "    # --- Plotting the clusters (optional, requires matplotlib/folium) ---\n",
    "    # To visualize, you'd typically plot these clustered_agg_df or clustered_div_df\n",
    "    # on a map using Folium, similar to our routing visualization.\n",
    "    # For a quick visual check (requires matplotlib):\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        plt.figure(figsize=(15, 7))\n",
    "\n",
    "        # Plot Agglomerative Clusters\n",
    "        ax1 = plt.subplot(121)\n",
    "        for cluster_id in clustered_agg_df['cluster'].unique():\n",
    "            if cluster_id == -1: continue\n",
    "            cluster_points = clustered_agg_df[clustered_agg_df['cluster'] == cluster_id]\n",
    "            ax1.scatter(cluster_points['Longitude'], cluster_points['Latitude'], \n",
    "                        label=f'Agg C{cluster_id} (n={len(cluster_points)})', s=20, alpha=0.6)\n",
    "        ax1.set_title('Agglomerative Clusters')\n",
    "        ax1.set_xlabel('Longitude')\n",
    "        ax1.set_ylabel('Latitude')\n",
    "        ax1.grid(True)\n",
    "\n",
    "        # Plot Divisive Clusters\n",
    "        ax2 = plt.subplot(122)\n",
    "        for cluster_id in clustered_div_df['cluster'].unique():\n",
    "            if cluster_id == -1: continue\n",
    "            cluster_points = clustered_div_df[clustered_div_df['cluster'] == cluster_id]\n",
    "            ax2.scatter(cluster_points['Longitude'], cluster_points['Latitude'], \n",
    "                        label=f'Div C{cluster_id} (n={len(cluster_points)})', s=20, alpha=0.6)\n",
    "        ax2.set_title('Divisive Clusters')\n",
    "        ax2.set_xlabel('Longitude')\n",
    "        ax2.set_ylabel('Latitude')\n",
    "        ax2.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    except ImportError:\n",
    "        print(\"\\nMatplotlib not found. Skipping cluster visualization.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during plotting: {e}. Skipping cluster visualization.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da02ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
