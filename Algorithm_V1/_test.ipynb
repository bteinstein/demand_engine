{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84561739",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56187ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import pandas as pd \n",
    "import logging\n",
    "from src.data.get_data import get_all_input_data #get_data_reco_custdim_spdim , get_kyc_customers, get_customer_score\n",
    "from datetime import datetime, timedelta \n",
    "from src.data.preprocessing import preprocessing\n",
    "from src.routing.ValhallaManager import ValhallaManager\n",
    "from src.data.data_filter import data_filter \n",
    "from src.main import run_push_recommendation \n",
    "from src.utils_and_postprocessing.utils import setup_logger, setup_directories, list_files_in_directory, load_feather_inputs\n",
    "\n",
    "from src.data.export import export_data \n",
    "from src.data.get_connection import get_connection\n",
    "from src.clustering.evaluate_cluster import evaluate_unsupervised_clustering\n",
    "from src.utils_and_postprocessing.utils import cluster_summary_and_selection, postprocess_selected_trip\n",
    "from src.utils_and_postprocessing.run_clustering_and_routing import create_and_plot_route, create_cluster_trip_optroute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82f679a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9dc433",
   "metadata": {},
   "source": [
    "### Logger Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de38fcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: This is an info message\n",
      "WARNING: This is a warning\n"
     ]
    }
   ],
   "source": [
    "logger = setup_logger(__name__, log_file='test.log')\n",
    "\n",
    "logger.info(\"This is an info message\")\n",
    "logger.warning(\"This is a warning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d4620c",
   "metadata": {},
   "source": [
    "### Parameter Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9b67c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Ensured directory exists: /home/azureuser/BT/11_Demand_Engine/Algorithm_V1/recommendation_output/2025-07-02/selected_trip_map/2025-07-02\n",
      "INFO: Ensured directory exists: /home/azureuser/BT/11_Demand_Engine/Algorithm_V1/recommendation_output/2025-07-02/cluster_map/2025-07-02\n",
      "INFO: Ensured directory exists: /home/azureuser/BT/11_Demand_Engine/Algorithm_V1/recommendation_output/2025-07-02/excel_docs/2025-07-02\n",
      "INFO: Copied index.html to /home/azureuser/BT/11_Demand_Engine/Algorithm_V1/recommendation_output/2025-07-02/selected_trip_map/2025-07-02/index.html\n",
      "INFO: Copied index.html to /home/azureuser/BT/11_Demand_Engine/Algorithm_V1/recommendation_output/2025-07-02/cluster_map/2025-07-02/index.html\n"
     ]
    }
   ],
   "source": [
    "# Constants for directory structure\n",
    "# BASE_DIR = Path(__file__).resolve().parent\n",
    "BASE_DIR = Path('').resolve()#.parent \n",
    "\n",
    "CURRENT_DATE = datetime.today().date() # + timedelta(days=1)\n",
    "\n",
    "INPUT_DIR, SELECTED_TRIP_PATH, ALL_CLUSTER_PATH, LOCAL_EXCEL_PATH = setup_directories(base_dir = BASE_DIR, current_date = CURRENT_DATE, logger = logger) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2cbee35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Valhalla container...\n",
      " Container valhalla_nigeria_project-valhalla-1  Running\n",
      "\n",
      "Waiting 10 seconds for Valhalla to initialize...\n",
      "Valhalla container started.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the manager\n",
    "valhalla_manager = ValhallaManager(logger=logger)\n",
    "\n",
    "# Start the server\n",
    "valhalla_manager.start_valhalla()\n",
    "\n",
    "# Check valhalla status\n",
    "valhalla_manager.check_valhalla_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f9c277",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad364b7e",
   "metadata": {},
   "source": [
    "## MAIN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fb9693",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Reloading recommendation data is enabled. Fetching fresh data...\n",
      "INFO: Connecting to database and Reloading Recommendation\n",
      "INFO: Running EXEC getCustomerSKURecommendationChecks ...\n"
     ]
    }
   ],
   "source": [
    "# Get input data\n",
    "df_customer_sku_recommendation_raw, df_customer_dim_with_affinity_score_raw, \\\n",
    "    df_stockpoint_dim_raw, df_kyc_customer, df_customer_score = get_all_input_data(logger=logger,\n",
    "                                                                                    save_local = False,\n",
    "                                                                                    input_dir_path = None, # Added optional input_dir_path\n",
    "                                                                                    reload_recommendation_data = True # Added parameter to control data reloading\n",
    "                                                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017be562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Development: save the inputs to feather for quick access\n",
    "# # Load all feather files\n",
    "# try:\n",
    "#     dfs = load_feather_inputs(input_dir=INPUT_DIR, logger=logger)\n",
    "\n",
    "#     # Unpack individual DataFrames\n",
    "#     df_customer_sku_recommendation_raw = dfs['df_customer_sku_recommendation_raw']\n",
    "#     df_customer_dim_with_affinity_score_raw = dfs['df_customer_dim_with_affinity_score_raw']\n",
    "#     df_stockpoint_dim_raw = dfs['df_stockpoint_dim_raw']\n",
    "#     df_kyc_customer = dfs['df_kyc_customer']\n",
    "#     df_customer_score = dfs['df_customer_score']\n",
    "\n",
    "# except FileNotFoundError as e:\n",
    "#     logger.error(\"Missing required input file. Exiting pipeline.\")\n",
    "#     raise\n",
    "# except Exception as e:\n",
    "#     logger.error(\"Failed to load input data due to unexpected error.\")\n",
    "#     raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f2fc41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05d8f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read the dataframes from feather files\n",
    "# input_data_path = BASE_DIR / 'input'\n",
    "# df_customer_sku_recommendation_raw = pd.read_feather(input_data_path / 'df_customer_sku_recommendation_raw.feather')\n",
    "# df_customer_dim_with_affinity_score_raw = pd.read_feather(input_data_path / 'df_customer_dim_with_affinity_score_raw.feather')  \n",
    "# df_stockpoint_dim_raw = pd.read_feather(input_data_path / 'df_stockpoint_dim_raw.feather')\n",
    "# df_kyc_customer = pd.read_feather(input_data_path / 'df_kyc_customer.feather')\n",
    "# df_customer_score = pd.read_feather(input_data_path / 'df_customer_score.feather') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16495a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "df_customer_sku_recommendation, df_master_customer_dim, df_stockpoint_dim = preprocessing(df_customer_sku_recommendation_raw, \n",
    "                                                                                            df_customer_dim_with_affinity_score_raw, \n",
    "                                                                                            df_stockpoint_dim_raw,\n",
    "                                                                                            df_customer_score,\n",
    "                                                                                            df_kyc_customer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16962e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Filter - Testing \n",
    "df_sku_rec, df_customer_dim, df_stockpoint = data_filter(df_customer_sku_recommendation, \n",
    "                                                                    df_master_customer_dim, \n",
    "                                                                    df_stockpoint_dim, \n",
    "                                                                    stockpoint_id = 1647394,  \n",
    "                                                                    # stockpoint_id = 1647113,  \n",
    "                                                                    sku_recency = 7, customer_recency = 60, number_recommendation = 10,\n",
    "                                                                    estimate_qty_scale_factor = 1, max_estimated_qty = 5, \n",
    "                                                                    exclude_recency_customer = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd3e5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # stock_point_id = 1647394 #\n",
    "# stock_point_id =  1647113\n",
    "# stock_point_name = df_stockpoint_dim.query(f'Stock_Point_ID == {1647394}')['Stock_point_Name'].iloc[0] \n",
    "# res_dict = run_push_recommendation(df_customer_sku_recommendation, \n",
    "#                             df_master_customer_dim, \n",
    "#                             df_stockpoint_dim, \n",
    "#                             stock_point_id,\n",
    "#                             stock_point_name,\n",
    "#                             sku_recency = 7, \n",
    "#                             customer_recency = 60, number_recommendation = 5, \n",
    "#                             estimate_qty_scale_factor = 1, max_estimated_qty = 5, \n",
    "#                             exclude_recency_customer = 4,\n",
    "#                             max_customers_per_route=20,\n",
    "#                             max_volume_per_route=300,\n",
    "#                             max_distance_km = 40,\n",
    "#                             sel_trip_cluster = 5,\n",
    "#                             min_ncust_per_cluster = 5,\n",
    "#                             clustering_method = 'divisive',\n",
    "#                             skip_route_optimization = False,\n",
    "#                             save_to_disk = False,\n",
    "#                             logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39ba531",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_STOCKPOINTS_RESULT = {}\n",
    "for index, row in df_stockpoint_dim.iterrows():\n",
    "    # if index == 12:\n",
    "    # if index == 5:\n",
    "    stock_point_id =  row['Stock_Point_ID']\n",
    "    stock_point_name = row['Stock_point_Name']\n",
    "    print(f'{index}/{len(df_stockpoint_dim)} \\nStock Point ID: {stock_point_id} || Stock Point Name: {stock_point_name}')  # Access by column name\n",
    "\n",
    "    res_dict = run_push_recommendation(df_customer_sku_recommendation, \n",
    "                            df_master_customer_dim, \n",
    "                            df_stockpoint_dim, \n",
    "                            stock_point_id,\n",
    "                            stock_point_name,\n",
    "                            sku_recency = 7, \n",
    "                            customer_recency = 60, number_recommendation = 5, \n",
    "                            estimate_qty_scale_factor = 1, max_estimated_qty = 5, \n",
    "                            exclude_recency_customer = 4,\n",
    "                            max_customers_per_route=20,\n",
    "                            max_volume_per_route=300,\n",
    "                            max_distance_km = 40,\n",
    "                            sel_trip_cluster = 5,\n",
    "                            min_ncust_per_cluster = 5,\n",
    "                            clustering_method = 'divisive',\n",
    "                            skip_route_optimization = False,\n",
    "                            save_to_disk = True,\n",
    "                            # Global variables\n",
    "                            valhalla_manager = valhalla_manager,\n",
    "                            CURRENT_DATE = CURRENT_DATE,\n",
    "                            SELECTED_TRIP_PATH = SELECTED_TRIP_PATH,\n",
    "                            ALL_CLUSTER_PATH = ALL_CLUSTER_PATH,\n",
    "                            LOCAL_EXCEL_PATH = LOCAL_EXCEL_PATH,\n",
    "                            logger=logger)\n",
    "    \n",
    "    ALL_STOCKPOINTS_RESULT[stock_point_name] = res_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5aa8694",
   "metadata": {},
   "source": [
    "## Fix Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85bf522",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_spid_list = df_stockpoint_dim['Stock_Point_ID'].to_list()\n",
    "selected_trip_spid_list = [int(spid) for spid in list_files_in_directory(SELECTED_TRIP_PATH) if not spid.startswith('index')]\n",
    "all_cluster_spid_list = [int(spid) for spid in list_files_in_directory(ALL_CLUSTER_PATH) if not spid.startswith('index')]\n",
    "\n",
    "unmapped_selected_trip_spid_list = list(set(all_spid_list) - set(selected_trip_spid_list))\n",
    "unmapped_all_cluster_spid_list = list(set(all_spid_list) - set(all_cluster_spid_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7891f614",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"All Stock Points: {len(all_spid_list)}\")\n",
    "print(f\"All Stock Points: {len(selected_trip_spid_list)}\")\n",
    "print(f\"All Stock Points: {len(all_cluster_spid_list)}\")\n",
    "print(f\"All Stock Points: {len(unmapped_selected_trip_spid_list)}\")\n",
    "print(f\"All Stock Points: {len(unmapped_all_cluster_spid_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3758e460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy index.html files from source directories to date-based subdirectories\n",
    "source_cluster_map_index = BASE_DIR / 'html' / 'default_cluster_map_index.html'\n",
    "source_selected_trip_index = BASE_DIR / 'html' / 'default_selected_cluster_map_index.html' \n",
    "        \n",
    "if len(unmapped_all_cluster_spid_list) > 0:\n",
    "    try:\n",
    "        if source_cluster_map_index.exists():\n",
    "            for spid in unmapped_all_cluster_spid_list:\n",
    "                spid_path = ALL_CLUSTER_PATH / f'{str(spid)}.html'       \n",
    "                shutil.copy2(source_cluster_map_index, spid_path)\n",
    "                logger.debug(f\"Copied index.html to {ALL_CLUSTER_PATH / str(spid)}.html\")\n",
    "        else:\n",
    "            logger.warning(f\"Source index.html not found at {source_selected_trip_index}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to copy index.html to {ALL_CLUSTER_PATH}: {str(e)}\")\n",
    "        \n",
    "        \n",
    "# Copy index.html for selected_trip_map\n",
    "if len(unmapped_selected_trip_spid_list) > 0:\n",
    "    try:\n",
    "        if source_selected_trip_index.exists():\n",
    "            for spid in unmapped_selected_trip_spid_list:\n",
    "                spid_path = SELECTED_TRIP_PATH / f'{str(spid)}.html'       \n",
    "                shutil.copy2(source_selected_trip_index, spid_path)\n",
    "                logger.debug(f\"Copied index.html to {SELECTED_TRIP_PATH / INDEX_HTML}\")\n",
    "        else:\n",
    "            logger.warning(f\"Source index.html not found at {source_selected_trip_index}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to copy index.html to {SELECTED_TRIP_PATH}: {str(e)}\")\n",
    "\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97f5d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unmapped_selected_trip_spid_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dcc413",
   "metadata": {},
   "source": [
    "## Export to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a701f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.export2db import RecommendationProcessor\n",
    "from src.data.get_connection import get_connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554df99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple usage\n",
    "# main(ALL_STOCKPOINTS_RESULT, CURRENT_DATE, get_connection)\n",
    "\n",
    "# Or use the processor directly\n",
    "processor = RecommendationProcessor(get_connection)\n",
    "processor.process(ALL_STOCKPOINTS_RESULT, CURRENT_DATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6440ee",
   "metadata": {},
   "source": [
    "# Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1305e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the server when done\n",
    "valhalla_manager.stop_valhalla()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8033d80b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
