{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84561739",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56187ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import pandas as pd \n",
    "import logging\n",
    "from src.data.get_data import get_all_input_data #get_data_reco_custdim_spdim , get_kyc_customers, get_customer_score\n",
    "from datetime import datetime, timedelta \n",
    "from src.data.preprocessing import preprocessing\n",
    "from src.routing.ValhallaManager import ValhallaManager\n",
    "from src.data.data_filter import data_filter \n",
    "from src.main import run_push_recommendation \n",
    "\n",
    "from src.data.export import export_data \n",
    "from src.data.get_connection import get_connection\n",
    "from src.clustering.evaluate_cluster import evaluate_unsupervised_clustering\n",
    "from src.utils_and_postprocessing.utils import cluster_summary_and_selection, postprocess_selected_trip\n",
    "from src.utils_and_postprocessing.run_clustering_and_routing import create_and_plot_route, create_cluster_trip_optroute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82f679a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9dc433",
   "metadata": {},
   "source": [
    "### Logger Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de38fcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os # Good practice to import os for path manipulation, especially for log files\n",
    "\n",
    "# Get the logger instance for the current module\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set the overall logging level for the logger.\n",
    "# Messages below this level will be ignored by this logger.\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# --- 1. File Handler (for logging to a file) ---\n",
    "log_file_path = 'test.log' # You might want to make this dynamic later\n",
    "file_handler = logging.FileHandler(log_file_path)\n",
    "file_handler.setLevel(logging.INFO) # Set the level for this handler\n",
    "file_formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "file_handler.setFormatter(file_formatter)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "# --- 2. Stream Handler (for logging to the console/notebook output) ---\n",
    "stream_handler = logging.StreamHandler() # By default, this logs to sys.stderr\n",
    "stream_handler.setLevel(logging.INFO) # Set the level for this handler\n",
    "stream_formatter = logging.Formatter('%(levelname)s: %(message)s') # Often a simpler format for console\n",
    "stream_handler.setFormatter(stream_formatter)\n",
    "logger.addHandler(stream_handler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d4620c",
   "metadata": {},
   "source": [
    "### Parameter Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9b67c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Ensured directory exists: /home/azureuser/BT/11_Demand_Engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-07-01\n",
      "INFO:__main__:Ensured directory exists: /home/azureuser/BT/11_Demand_Engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-07-01\n",
      "INFO: Ensured directory exists: /home/azureuser/BT/11_Demand_Engine/Algorithm_V1/recommendation_output/cluster_map/2025-07-01\n",
      "INFO:__main__:Ensured directory exists: /home/azureuser/BT/11_Demand_Engine/Algorithm_V1/recommendation_output/cluster_map/2025-07-01\n",
      "INFO: Ensured directory exists: /home/azureuser/BT/11_Demand_Engine/Algorithm_V1/recommendation_output/excel_docs/2025-07-01\n",
      "INFO:__main__:Ensured directory exists: /home/azureuser/BT/11_Demand_Engine/Algorithm_V1/recommendation_output/excel_docs/2025-07-01\n",
      "INFO: Copied index.html to /home/azureuser/BT/11_Demand_Engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-07-01/index.html\n",
      "INFO:__main__:Copied index.html to /home/azureuser/BT/11_Demand_Engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-07-01/index.html\n",
      "INFO: Copied index.html to /home/azureuser/BT/11_Demand_Engine/Algorithm_V1/recommendation_output/cluster_map/2025-07-01/index.html\n",
      "INFO:__main__:Copied index.html to /home/azureuser/BT/11_Demand_Engine/Algorithm_V1/recommendation_output/cluster_map/2025-07-01/index.html\n"
     ]
    }
   ],
   "source": [
    "# Constants for directory structure\n",
    "# BASE_DIR = Path(__file__).resolve().parent\n",
    "BASE_DIR = Path('').resolve()#.parent\n",
    "RECOMMENDATION_DIR = BASE_DIR / 'recommendation_output'\n",
    "SELECTED_TRIP_DIR = 'selected_trip_map'\n",
    "CLUSTER_MAP_DIR = 'cluster_map'\n",
    "EXCEL_DOCS_DIR = 'excel_docs'\n",
    "INDEX_HTML = 'index.html'\n",
    "\n",
    "# Global variables\n",
    "CURRENT_DATE = None\n",
    "SELECTED_TRIP_PATH = None\n",
    "ALL_CLUSTER_PATH = None\n",
    "LOCAL_EXCEL_PATH = None\n",
    "\n",
    "def setup_directories():\n",
    "    \"\"\"Set up directory structure for recommendation output with date-based subdirectories.\"\"\"\n",
    "    global CURRENT_DATE, SELECTED_TRIP_PATH, ALL_CLUSTER_PATH, LOCAL_EXCEL_PATH\n",
    "    try:\n",
    "        # Set current date\n",
    "        CURRENT_DATE = datetime.today().date()\n",
    "        \n",
    "        # Define date-based directory paths\n",
    "        SELECTED_TRIP_PATH = RECOMMENDATION_DIR / SELECTED_TRIP_DIR / str(CURRENT_DATE)\n",
    "        ALL_CLUSTER_PATH = RECOMMENDATION_DIR / CLUSTER_MAP_DIR / str(CURRENT_DATE)\n",
    "        LOCAL_EXCEL_PATH = RECOMMENDATION_DIR / EXCEL_DOCS_DIR / str(CURRENT_DATE)\n",
    "        \n",
    "        # Create directories if they don't exist\n",
    "        for directory in (SELECTED_TRIP_PATH, ALL_CLUSTER_PATH, LOCAL_EXCEL_PATH):\n",
    "            directory.mkdir(parents=True, exist_ok=True)\n",
    "            logger.info(f\"Ensured directory exists: {directory}\")\n",
    "\n",
    "        # Copy index.html files from source directories to date-based subdirectories\n",
    "        source_cluster_map_index = BASE_DIR / 'html' / 'default_cluster_map_index.html'\n",
    "        source_selected_trip_index = BASE_DIR / 'html' / 'default_selected_cluster_map_index.html' \n",
    "\n",
    "        # Copy index.html for selected_trip_map\n",
    "        try:\n",
    "            if source_selected_trip_index.exists():\n",
    "                shutil.copy2(source_selected_trip_index, SELECTED_TRIP_PATH / INDEX_HTML)\n",
    "                logger.info(f\"Copied index.html to {SELECTED_TRIP_PATH / INDEX_HTML}\")\n",
    "            else:\n",
    "                logger.warning(f\"Source index.html not found at {source_selected_trip_index}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to copy index.html to {SELECTED_TRIP_PATH}: {str(e)}\")\n",
    "\n",
    "        # Copy index.html for cluster_map\n",
    "        try:\n",
    "            if source_cluster_map_index.exists():\n",
    "                shutil.copy2(source_cluster_map_index, ALL_CLUSTER_PATH / INDEX_HTML)\n",
    "                logger.info(f\"Copied index.html to {ALL_CLUSTER_PATH / INDEX_HTML}\")\n",
    "            else:\n",
    "                logger.warning(f\"Source index.html not found at {source_cluster_map_index}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to copy index.html to {ALL_CLUSTER_PATH}: {str(e)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error setting up directories: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set up basic logging configuration\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    setup_directories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1de7cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df07b963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all files in the SELECTED_TRIP_PATH directory stripping the extension\n",
    "def list_files_in_directory(directory):\n",
    "    \"\"\"List all files in the given directory, stripping the file extension.\"\"\"\n",
    "    try:\n",
    "        files = [f.stem for f in directory.glob('*') if f.is_file()]\n",
    "        # logger.info(f\"Files in {directory}: {files}\")\n",
    "        return files\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error listing files in directory {directory}: {str(e)}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2cbee35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Valhalla container...\n",
      " Network valhalla_nigeria_project_default  Creating\n",
      " Network valhalla_nigeria_project_default  Created\n",
      " Container valhalla_nigeria_project-valhalla-1  Creating\n",
      " Container valhalla_nigeria_project-valhalla-1  Created\n",
      " Container valhalla_nigeria_project-valhalla-1  Starting\n",
      " Container valhalla_nigeria_project-valhalla-1  Started\n",
      "\n",
      "Waiting 10 seconds for Valhalla to initialize...\n",
      "Valhalla container started.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the manager\n",
    "valhalla_manager = ValhallaManager(logger=logger)\n",
    "\n",
    "# Start the server\n",
    "valhalla_manager.start_valhalla()\n",
    "\n",
    "# Check valhalla status\n",
    "valhalla_manager.check_valhalla_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f9c277",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43a060a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad364b7e",
   "metadata": {},
   "source": [
    "## MAIN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2fb9693",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Executing stored procedure(s) to fetch data...\n",
      "INFO:__main__:Executing stored procedure(s) to fetch data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Data fetch complete.\n",
      "INFO:__main__:Data fetch complete.\n",
      "INFO: --- Fetched DataFrames Shapes ---\n",
      "INFO:__main__:--- Fetched DataFrames Shapes ---\n",
      "INFO: Customer SKU Recommendation: (154592, 13)\n",
      "INFO:__main__:Customer SKU Recommendation: (154592, 13)\n",
      "INFO: Customer Dimension with Affinity Score: (10782, 22)\n",
      "INFO:__main__:Customer Dimension with Affinity Score: (10782, 22)\n",
      "INFO: Stockpoint Dimension: (72, 4)\n",
      "INFO:__main__:Stockpoint Dimension: (72, 4)\n",
      "INFO: ---------------------------------\n",
      "\n",
      "INFO:__main__:---------------------------------\n",
      "\n",
      "INFO: Connecting to database and fetching KYC customer data...\n",
      "INFO:__main__:Connecting to database and fetching KYC customer data...\n",
      "INFO: Successfully fetched KYC customer data. Shape: (343144, 57)\n",
      "INFO:__main__:Successfully fetched KYC customer data. Shape: (343144, 57)\n",
      "INFO: KYC customers DataFrame shape: (343144, 57)\n",
      "INFO:__main__:KYC customers DataFrame shape: (343144, 57)\n",
      "INFO: Connecting to database and fetching customer score data...\n",
      "INFO:__main__:Connecting to database and fetching customer score data...\n",
      "INFO: Successfully fetched customer score data. Shape: (27818, 15)\n",
      "INFO:__main__:Successfully fetched customer score data. Shape: (27818, 15)\n",
      "INFO: Customer scores DataFrame shape: (27818, 15)\n",
      "INFO:__main__:Customer scores DataFrame shape: (27818, 15)\n"
     ]
    }
   ],
   "source": [
    "# Get input data\n",
    "df_customer_sku_recommendation_raw, df_customer_dim_with_affinity_score_raw, \\\n",
    "    df_stockpoint_dim_raw, df_kyc_customer, df_customer_score = get_all_input_data(logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017be562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Development: save the inputs to feather for quick access\n",
    "# input_data_path = BASE_DIR / 'input'\n",
    "# # df_customer_sku_recommendation_raw, df_customer_dim_with_affinity_score_raw, \\\n",
    "#     # df_stockpoint_dim_raw, df_kyc_customer, df_customer_score\n",
    "    \n",
    "# # Save the dataframes to feather files\n",
    "# df_customer_sku_recommendation_raw.to_feather(input_data_path / 'df_customer_sku_recommendation_raw.feather')\n",
    "# df_customer_dim_with_affinity_score_raw.to_feather(input_data_path / 'df_customer_dim_with_affinity_score_raw.feather')\n",
    "# df_stockpoint_dim_raw.to_feather(input_data_path / 'df_stockpoint_dim_raw.feather')\n",
    "# df_kyc_customer.to_feather(input_data_path / 'df_kyc_customer.feather')\n",
    "# df_customer_score.to_feather(input_data_path / 'df_customer_score.feather')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16495a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "df_customer_sku_recommendation, df_master_customer_dim, df_stockpoint_dim = preprocessing(df_customer_sku_recommendation_raw, \n",
    "                                                                                            df_customer_dim_with_affinity_score_raw, \n",
    "                                                                                            df_stockpoint_dim_raw,\n",
    "                                                                                            df_customer_score,\n",
    "                                                                                            df_kyc_customer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16962e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Quantity before filter: 16,131\n",
      "Total Quantity: 11,998\n",
      "Total Number of Customers before filter: 476\n",
      "Total Number of Customers: 353\n"
     ]
    }
   ],
   "source": [
    "# Data Filter - Testing \n",
    "df_sku_rec, df_customer_dim, df_stockpoint = data_filter(df_customer_sku_recommendation, \n",
    "                                                                    df_master_customer_dim, \n",
    "                                                                    df_stockpoint_dim, \n",
    "                                                                    stockpoint_id = 1647394,  \n",
    "                                                                    # stockpoint_id = 1647113,  \n",
    "                                                                    sku_recency = 7, customer_recency = 60, number_recommendation = 10,\n",
    "                                                                    estimate_qty_scale_factor = 1, max_estimated_qty = 5, \n",
    "                                                                    exclude_recency_customer = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbd3e5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # stock_point_id = 1647394 #\n",
    "# stock_point_id =  1647113\n",
    "# stock_point_name = df_stockpoint_dim.query(f'Stock_Point_ID == {1647394}')['Stock_point_Name'].iloc[0] \n",
    "# res_dict = run_push_recommendation(df_customer_sku_recommendation, \n",
    "#                             df_master_customer_dim, \n",
    "#                             df_stockpoint_dim, \n",
    "#                             stock_point_id,\n",
    "#                             stock_point_name,\n",
    "#                             sku_recency = 7, \n",
    "#                             customer_recency = 60, number_recommendation = 5, \n",
    "#                             estimate_qty_scale_factor = 1, max_estimated_qty = 5, \n",
    "#                             exclude_recency_customer = 4,\n",
    "#                             max_customers_per_route=20,\n",
    "#                             max_volume_per_route=300,\n",
    "#                             max_distance_km = 40,\n",
    "#                             sel_trip_cluster = 5,\n",
    "#                             min_ncust_per_cluster = 5,\n",
    "#                             clustering_method = 'divisive',\n",
    "#                             skip_route_optimization = False,\n",
    "#                             save_to_disk = False,\n",
    "#                             logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39ba531",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_STOCKPOINTS_RESULT = {}\n",
    "for index, row in df_stockpoint_dim.iterrows():\n",
    "    # if index == 12:\n",
    "    # if index == 5:\n",
    "    stock_point_id =  row['Stock_Point_ID']\n",
    "    stock_point_name = row['Stock_point_Name']\n",
    "    print(f'{index}/{len(df_stockpoint_dim)} \\nStock Point ID: {stock_point_id} || Stock Point Name: {stock_point_name}')  # Access by column name\n",
    "\n",
    "    res_dict = run_push_recommendation(df_customer_sku_recommendation, \n",
    "                            df_master_customer_dim, \n",
    "                            df_stockpoint_dim, \n",
    "                            stock_point_id,\n",
    "                            stock_point_name,\n",
    "                            sku_recency = 7, \n",
    "                            customer_recency = 60, number_recommendation = 5, \n",
    "                            estimate_qty_scale_factor = 1, max_estimated_qty = 5, \n",
    "                            exclude_recency_customer = 4,\n",
    "                            max_customers_per_route=20,\n",
    "                            max_volume_per_route=300,\n",
    "                            max_distance_km = 40,\n",
    "                            sel_trip_cluster = 5,\n",
    "                            min_ncust_per_cluster = 5,\n",
    "                            clustering_method = 'divisive',\n",
    "                            skip_route_optimization = False,\n",
    "                            save_to_disk = False,\n",
    "                            logger=logger)\n",
    "    \n",
    "    ALL_STOCKPOINTS_RESULT[stock_point_name] = res_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5aa8694",
   "metadata": {},
   "source": [
    "## Fix Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f85bf522",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_spid_list = df_stockpoint_dim['Stock_Point_ID'].to_list()\n",
    "selected_trip_spid_list = [int(spid) for spid in list_files_in_directory(SELECTED_TRIP_PATH) if not spid.startswith('index')]\n",
    "all_cluster_spid_list = [int(spid) for spid in list_files_in_directory(ALL_CLUSTER_PATH) if not spid.startswith('index')]\n",
    "\n",
    "unmapped_selected_trip_spid_list = list(set(all_spid_list) - set(selected_trip_spid_list))\n",
    "unmapped_all_cluster_spid_list = list(set(all_spid_list) - set(all_cluster_spid_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7891f614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Stock Points: 72\n",
      "All Stock Points: 72\n",
      "All Stock Points: 51\n",
      "All Stock Points: 0\n",
      "All Stock Points: 21\n"
     ]
    }
   ],
   "source": [
    "print(f\"All Stock Points: {len(all_spid_list)}\")\n",
    "print(f\"All Stock Points: {len(selected_trip_spid_list)}\")\n",
    "print(f\"All Stock Points: {len(all_cluster_spid_list)}\")\n",
    "print(f\"All Stock Points: {len(unmapped_selected_trip_spid_list)}\")\n",
    "print(f\"All Stock Points: {len(unmapped_all_cluster_spid_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc5294fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/azureuser/BT/11_Demand_Engine/Algorithm_V1/recommendation_output/selected_trip_map/2025-07-01\n"
     ]
    }
   ],
   "source": [
    "print(SELECTED_TRIP_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3758e460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy index.html files from source directories to date-based subdirectories\n",
    "source_cluster_map_index = BASE_DIR / 'html' / 'default_cluster_map_index.html'\n",
    "source_selected_trip_index = BASE_DIR / 'html' / 'default_selected_cluster_map_index.html' \n",
    "\n",
    "# Copy index.html for selected_trip_map\n",
    "if len(unmapped_selected_trip_spid_list) > 0:\n",
    "    try:\n",
    "        if source_selected_trip_index.exists():\n",
    "            for spid in unmapped_selected_trip_spid_list:\n",
    "                spid_path = SELECTED_TRIP_PATH / f'{str(spid)}.html'       \n",
    "                shutil.copy2(source_selected_trip_index, spid_path)\n",
    "                logger.debug(f\"Copied index.html to {SELECTED_TRIP_PATH / INDEX_HTML}\")\n",
    "        else:\n",
    "            logger.warning(f\"Source index.html not found at {source_selected_trip_index}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to copy index.html to {SELECTED_TRIP_PATH}: {str(e)}\")\n",
    "        \n",
    "if len(unmapped_all_cluster_spid_list) > 0:\n",
    "    try:\n",
    "        if source_cluster_map_index.exists():\n",
    "            for spid in unmapped_all_cluster_spid_list:\n",
    "                spid_path = ALL_CLUSTER_PATH / f'{str(spid)}.html'       \n",
    "                shutil.copy2(source_selected_trip_index, spid_path)\n",
    "                logger.debug(f\"Copied index.html to {ALL_CLUSTER_PATH / INDEX_HTML}\")\n",
    "        else:\n",
    "            logger.warning(f\"Source index.html not found at {source_selected_trip_index}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to copy index.html to {ALL_CLUSTER_PATH}: {str(e)}\")\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e97f5d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1646976,\n",
       " 1647112,\n",
       " 1647115,\n",
       " 1646989,\n",
       " 1647376,\n",
       " 1647120,\n",
       " 1646995,\n",
       " 1647381,\n",
       " 1647126,\n",
       " 1647128,\n",
       " 1647006,\n",
       " 1647136,\n",
       " 1647401,\n",
       " 1647419,\n",
       " 1647420,\n",
       " 1647421,\n",
       " 1647422,\n",
       " 1647424,\n",
       " 1647425,\n",
       " 1647434,\n",
       " 1647436,\n",
       " 1647437,\n",
       " 1647438,\n",
       " 1646945,\n",
       " 1647075,\n",
       " 1647076,\n",
       " 1647077]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmapped_selected_trip_spid_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dcc413",
   "metadata": {},
   "source": [
    "## Export to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29a701f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.export2db import RecommendationProcessor\n",
    "from src.data.get_connection import get_connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "554df99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.data.export2db:Successfully upserted 29436 rows to dailyPredictedPull\n",
      "INFO:src.data.export2db:Successfully upserted 674 rows to dailyPredictedPullClusterSummary\n",
      "INFO:src.data.export2db:Recommendation processing completed successfully\n"
     ]
    }
   ],
   "source": [
    "# Simple usage\n",
    "# main(ALL_STOCKPOINTS_RESULT, CURRENT_DATE, get_connection)\n",
    "\n",
    "# Or use the processor directly\n",
    "processor = RecommendationProcessor(get_connection)\n",
    "processor.process(ALL_STOCKPOINTS_RESULT, CURRENT_DATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6440ee",
   "metadata": {},
   "source": [
    "# Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1305e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Valhalla container...\n",
      " Container valhalla_nigeria_project-valhalla-1  Stopping\n",
      " Container valhalla_nigeria_project-valhalla-1  Stopped\n",
      " Container valhalla_nigeria_project-valhalla-1  Removing\n",
      " Container valhalla_nigeria_project-valhalla-1  Removed\n",
      " Network valhalla_nigeria_project_default  Removing\n",
      " Network valhalla_nigeria_project_default  Removed\n",
      "\n",
      "Valhalla container stopped.\n"
     ]
    }
   ],
   "source": [
    "# Stop the server when done\n",
    "valhalla_manager.stop_valhalla()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
