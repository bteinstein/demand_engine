{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6330a259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "from geopy.distance import geodesic\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "from math import radians \n",
    "from geopy.distance import geodesic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6ecf780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd7a79f",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a38a04c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_output = pd.read_excel('../data/business_algo_output/recommendation_output.xlsx')\n",
    "prediction_output = prediction_output.rename(columns={'FCID': 'StockPointID'})\n",
    "customer_dim = pd.read_excel('../data/business_algo_output/customer_data.xlsx')\n",
    "customer_dim = customer_dim.rename(columns={'Longitude': 'Long', 'Latitude': 'Lat'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ad55d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['StockPointName', 'StockPointID', 'CustomerID', 'Category', 'SKUID', 'SKUCODE', 'rank_hist_cust_cat', 'L4M_n_orders', 'L4M_tot_qty', 'L4M_AOV', 'L4M_AOQ', 'L4M_Cust_Activity_SKU', 'L4M_Cust_Activity_Day_SKU', 'rank_hist_sp_cat', 'L4M_SP_Activity_SKU', 'rank_survey', 'SuggestType', 'SP_Product_Tag', 'RECOMMEND_FOR_PUSH']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StockPointName</th>\n",
       "      <th>StockPointID</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Category</th>\n",
       "      <th>SKUID</th>\n",
       "      <th>SKUCODE</th>\n",
       "      <th>rank_hist_cust_cat</th>\n",
       "      <th>L4M_n_orders</th>\n",
       "      <th>L4M_tot_qty</th>\n",
       "      <th>L4M_AOV</th>\n",
       "      <th>L4M_AOQ</th>\n",
       "      <th>L4M_Cust_Activity_SKU</th>\n",
       "      <th>L4M_Cust_Activity_Day_SKU</th>\n",
       "      <th>rank_hist_sp_cat</th>\n",
       "      <th>L4M_SP_Activity_SKU</th>\n",
       "      <th>rank_survey</th>\n",
       "      <th>SuggestType</th>\n",
       "      <th>SP_Product_Tag</th>\n",
       "      <th>RECOMMEND_FOR_PUSH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OmniHub Alimosho Lagos - Barka-Agro and Genera...</td>\n",
       "      <td>1647081</td>\n",
       "      <td>1770455</td>\n",
       "      <td>Noodles</td>\n",
       "      <td>19679</td>\n",
       "      <td>IOC001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>117000.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2025-04-05</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-05-31</td>\n",
       "      <td>3.0</td>\n",
       "      <td>TOP 5 - Customer By Category</td>\n",
       "      <td>Express</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OmniHub Alimosho Lagos - Barka-Agro and Genera...</td>\n",
       "      <td>1647081</td>\n",
       "      <td>1770455</td>\n",
       "      <td>Noodles</td>\n",
       "      <td>22026</td>\n",
       "      <td>MIMEE_RC070</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>117000.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2025-05-27</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-05-31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TOP 5 - Customer By Category</td>\n",
       "      <td>Express</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OmniHub Alimosho Lagos - Barka-Agro and Genera...</td>\n",
       "      <td>1647081</td>\n",
       "      <td>1770455</td>\n",
       "      <td>Noodles</td>\n",
       "      <td>22028</td>\n",
       "      <td>MIMEE_RC100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>117000.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-05-31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TOP 5 - Customer By Category</td>\n",
       "      <td>Express</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OmniHub Alimosho Lagos - Barka-Agro and Genera...</td>\n",
       "      <td>1647081</td>\n",
       "      <td>1770455</td>\n",
       "      <td>Noodles</td>\n",
       "      <td>22298</td>\n",
       "      <td>GPNOOD70G</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>117000.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-05-31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TOP 5 - Customer By Category</td>\n",
       "      <td>Express</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OmniHub Alimosho Lagos - Barka-Agro and Genera...</td>\n",
       "      <td>1647081</td>\n",
       "      <td>1770455</td>\n",
       "      <td>Noodles</td>\n",
       "      <td>22462</td>\n",
       "      <td>GPJCNOOD70G</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>117000.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2025-04-17</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-05-31</td>\n",
       "      <td>2.0</td>\n",
       "      <td>TOP 5 - Customer By Category</td>\n",
       "      <td>Express</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      StockPointName  StockPointID  \\\n",
       "0  OmniHub Alimosho Lagos - Barka-Agro and Genera...       1647081   \n",
       "1  OmniHub Alimosho Lagos - Barka-Agro and Genera...       1647081   \n",
       "2  OmniHub Alimosho Lagos - Barka-Agro and Genera...       1647081   \n",
       "3  OmniHub Alimosho Lagos - Barka-Agro and Genera...       1647081   \n",
       "4  OmniHub Alimosho Lagos - Barka-Agro and Genera...       1647081   \n",
       "\n",
       "   CustomerID Category  SKUID      SKUCODE  rank_hist_cust_cat  L4M_n_orders  \\\n",
       "0     1770455  Noodles  19679       IOC001                 1.0           1.0   \n",
       "1     1770455  Noodles  22026  MIMEE_RC070                 1.0           1.0   \n",
       "2     1770455  Noodles  22028  MIMEE_RC100                 1.0           1.0   \n",
       "3     1770455  Noodles  22298    GPNOOD70G                 1.0           1.0   \n",
       "4     1770455  Noodles  22462  GPJCNOOD70G                 1.0           1.0   \n",
       "\n",
       "   L4M_tot_qty   L4M_AOV  L4M_AOQ L4M_Cust_Activity_SKU  \\\n",
       "0         15.0  117000.0     15.0            2025-04-05   \n",
       "1         15.0  117000.0     15.0            2025-05-27   \n",
       "2         15.0  117000.0     15.0                   NaT   \n",
       "3         15.0  117000.0     15.0                   NaT   \n",
       "4         15.0  117000.0     15.0            2025-04-17   \n",
       "\n",
       "   L4M_Cust_Activity_Day_SKU  rank_hist_sp_cat L4M_SP_Activity_SKU  \\\n",
       "0                       56.0                 1          2025-05-31   \n",
       "1                        4.0                 1          2025-05-31   \n",
       "2                        NaN                 1          2025-05-31   \n",
       "3                        NaN                 1          2025-05-31   \n",
       "4                       44.0                 1          2025-05-31   \n",
       "\n",
       "   rank_survey                   SuggestType SP_Product_Tag RECOMMEND_FOR_PUSH  \n",
       "0          3.0  TOP 5 - Customer By Category        Express                Yes  \n",
       "1          1.0  TOP 5 - Customer By Category        Express                 No  \n",
       "2          1.0  TOP 5 - Customer By Category        Express                Yes  \n",
       "3          1.0  TOP 5 - Customer By Category        Express                Yes  \n",
       "4          2.0  TOP 5 - Customer By Category        Express                Yes  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print columns in prediction_output\n",
    "print(prediction_output.columns.tolist())\n",
    "\n",
    "# print top 5 rows of prediction_output\n",
    "prediction_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "582fb102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StockPointName</th>\n",
       "      <th>UniqueCustomerCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OmniHub Alimosho Lagos - Barka-Agro and Genera...</td>\n",
       "      <td>483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OmniHub Apapa Lagos - CAUSEWAY</td>\n",
       "      <td>1843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      StockPointName  UniqueCustomerCount\n",
       "0  OmniHub Alimosho Lagos - Barka-Agro and Genera...                  483\n",
       "1                     OmniHub Apapa Lagos - CAUSEWAY                 1843"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# per StockPointName and RECOMMEND_FOR_PUSH = \"Yes\", count number of unique CustomerID\n",
    "stockpoint_recommendation = prediction_output[prediction_output['RECOMMEND_FOR_PUSH'] == 'Yes'].groupby('StockPointName')\n",
    "stockpoint_recommendation['CustomerID'].nunique().reset_index().rename(columns={'CustomerID': 'UniqueCustomerCount'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a017d4c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44441"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique SKU per SP_Product_Tag \n",
    "prediction_output.query('RECOMMEND_FOR_PUSH == \"Yes\" and SP_Product_Tag != \"Standard-Inactive\"')\\\n",
    "    .shape[0]\n",
    "    # (prediction_output['RECOMMEND_FOR_PUSH'] == 'Yes') & ()] \\ \n",
    "    # .groupby(['StockPointName','SP_Product_Tag'])\\\n",
    "    # ['CustomerID'].nunique().reset_index().rename(columns={'CustomerID': 'UniqueCustomerCount'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8f97e3",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5323df92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_customers_dbscan(prediction_output, customer_dim, eps_km=2.0, min_samples=3):\n",
    "    \"\"\"\n",
    "    Cluster customers by location for each stock point using DBSCAN and provide cluster metadata.\n",
    "    \n",
    "    Args:\n",
    "        prediction_output (pd.DataFrame): DataFrame with StockPointID and CustomerID\n",
    "        customer_dim (pd.DataFrame): DataFrame with CustomerID, Long, and Lat\n",
    "        eps_km (float): Maximum distance (in kilometers) for points to be in the same cluster\n",
    "        min_samples (int): Minimum number of points to form a cluster\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (assignment_df, summary_df) containing customer assignments and cluster summaries\n",
    "    \"\"\"\n",
    "    # Merge prediction_output with customer_dim to get coordinates\n",
    "    merged_data = prediction_output.merge(customer_dim, on='CustomerID')\n",
    "    \n",
    "    # Initialize lists to hold results\n",
    "    assignment_list = []\n",
    "    summary_list = []\n",
    "    \n",
    "    # Get unique stock points\n",
    "    stock_points = merged_data['StockPointID'].unique()\n",
    "    \n",
    "    for sp in stock_points:\n",
    "        # Filter customers for this stock point\n",
    "        sp_data = merged_data[merged_data['StockPointID'] == sp]\n",
    "        customers = sp_data[['CustomerID', 'Long', 'Lat']].copy()\n",
    "        \n",
    "        # Number of customers\n",
    "        n_customers = len(customers)\n",
    "        \n",
    "        if n_customers == 0:\n",
    "            continue  # No customers, skip\n",
    "        \n",
    "        # Prepare coordinates for DBSCAN (latitude, longitude in radians)\n",
    "        coords = customers[['Lat', 'Long']].values\n",
    "        coords_rad = np.radians(coords)\n",
    "        \n",
    "        # Convert eps from kilometers to radians (approximate Earth radius: 6371 km)\n",
    "        eps_rad = eps_km / 6371.0\n",
    "        \n",
    "        # Apply DBSCAN with haversine metric for geodesic distances\n",
    "        dbscan = DBSCAN(eps=eps_rad, min_samples=min_samples, metric='haversine').fit(coords_rad)\n",
    "        labels = dbscan.labels_\n",
    "        \n",
    "        # Handle case where no clusters are formed (all noise)\n",
    "        if max(labels) < 0 and n_customers >= min_samples:\n",
    "            # Try a larger eps to ensure at least one cluster\n",
    "            eps_rad *= 2\n",
    "            dbscan = DBSCAN(eps=eps_rad, min_samples=min_samples, metric='haversine').fit(coords_rad)\n",
    "            labels = dbscan.labels_\n",
    "        \n",
    "        # Assign cluster labels to customers\n",
    "        customers['ClusterID'] = labels\n",
    "        \n",
    "        # Handle noise points (ClusterID = -1) by assigning to nearest cluster\n",
    "        if -1 in labels:\n",
    "            non_noise = customers[customers['ClusterID'] != -1]\n",
    "            noise = customers[customers['ClusterID'] == -1]\n",
    "            if len(non_noise) > 0:\n",
    "                # Calculate centroids of non-noise clusters\n",
    "                centroids = non_noise.groupby('ClusterID')[['Lat', 'Long']].mean().values\n",
    "                noise_coords = noise[['Lat', 'Long']].values\n",
    "                # Compute distances to centroids\n",
    "                distances = np.zeros((len(noise), len(centroids)))\n",
    "                for i, n_coord in enumerate(noise_coords):\n",
    "                    for j, c_coord in enumerate(centroids):\n",
    "                        distances[i, j] = geodesic(n_coord, c_coord).kilometers\n",
    "                # Assign noise points to nearest cluster\n",
    "                nearest_clusters = np.argmin(distances, axis=1)\n",
    "                noise['ClusterID'] = nearest_clusters\n",
    "                customers.update(noise)\n",
    "        \n",
    "        # Ensure at least 3 clusters if possible\n",
    "        unique_clusters = customers[customers['ClusterID'] != -1]['ClusterID'].nunique()\n",
    "        if unique_clusters < 3 and n_customers >= min_samples * 3:\n",
    "            # Reduce eps to encourage more clusters\n",
    "            eps_rad /= 1.5\n",
    "            dbscan = DBSCAN(eps=eps_rad, min_samples=min_samples, metric='haversine').fit(coords_rad)\n",
    "            customers['ClusterID'] = dbscan.labels_\n",
    "            # Reassign noise points if any\n",
    "            if -1 in customers['ClusterID'].values:\n",
    "                non_noise = customers[customers['ClusterID'] != -1]\n",
    "                noise = customers[customers['ClusterID'] == -1]\n",
    "                if len(non_noise) > 0:\n",
    "                    centroids = non_noise.groupby('ClusterID')[['Lat', 'Long']].mean().values\n",
    "                    noise_coords = noise[['Lat', 'Long']].values\n",
    "                    distances = np.zeros((len(noise), len(centroids)))\n",
    "                    for i, n_coord in enumerate(noise_coords):\n",
    "                        for j, c_coord in enumerate(centroids):\n",
    "                            distances[i, j] = geodesic(n_coord, c_coord).kilometers\n",
    "                    nearest_clusters = np.argmin(distances, axis=1)\n",
    "                    noise['ClusterID'] = nearest_clusters\n",
    "                    customers.update(noise)\n",
    "        \n",
    "        # Calculate distances to centroids\n",
    "        centroids = customers[customers['ClusterID'] != -1].groupby('ClusterID')[['Lat', 'Long']].mean().reset_index()\n",
    "        distances = []\n",
    "        for i, row in customers.iterrows():\n",
    "            if row['ClusterID'] == -1:\n",
    "                distances.append(0)  # Should not occur after noise assignment\n",
    "            else:\n",
    "                customer_coord = (row['Lat'], row['Long'])\n",
    "                centroid_coord = centroids[centroids['ClusterID'] == row['ClusterID']][['Lat', 'Long']].values[0]\n",
    "                distance = geodesic(customer_coord, centroid_coord).kilometers\n",
    "                distances.append(distance)\n",
    "        \n",
    "        customers['DistanceToCentroid'] = distances\n",
    "        \n",
    "        # Add StockPointID to the assignment table\n",
    "        customers['StockPointID'] = sp\n",
    "        \n",
    "        # Select relevant columns for the assignment table\n",
    "        assignment = customers[['StockPointID', 'CustomerID', 'ClusterID', 'DistanceToCentroid']]\n",
    "        assignment_list.append(assignment)\n",
    "        \n",
    "        # Create summary table for each cluster\n",
    "        summary = customers.groupby('ClusterID').agg(\n",
    "            NumCustomers=('CustomerID', 'count'),\n",
    "            AvgDistance=('DistanceToCentroid', 'mean')\n",
    "        ).reset_index()\n",
    "        \n",
    "        # Add centroid coordinates to the summary table\n",
    "        if not centroids.empty:\n",
    "            summary = summary.merge(centroids[['ClusterID', 'Lat', 'Long']], on='ClusterID', how='left')\n",
    "            summary = summary.rename(columns={'Lat': 'CentroidLat', 'Long': 'CentroidLong'})\n",
    "        else:\n",
    "            summary['CentroidLat'] = np.nan\n",
    "            summary['CentroidLong'] = np.nan\n",
    "        \n",
    "        # Add StockPointID to the summary table\n",
    "        summary['StockPointID'] = sp\n",
    "        \n",
    "        # Reorder columns in the summary table\n",
    "        summary = summary[['StockPointID', 'ClusterID', 'NumCustomers', 'AvgDistance', 'CentroidLong', 'CentroidLat']]\n",
    "        \n",
    "        summary_list.append(summary)\n",
    "    \n",
    "    # Concatenate all assignments and summaries\n",
    "    final_assignment = pd.concat(assignment_list, ignore_index=True)\n",
    "    final_summary = pd.concat(summary_list, ignore_index=True)\n",
    "    \n",
    "    return final_assignment, final_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0028e6",
   "metadata": {},
   "source": [
    "### Run Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9216d250",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_output = pd.read_excel('../data/business_algo_output/recommendation_output.xlsx')\n",
    "prediction_output = prediction_output.rename(columns={'FCID': 'StockPointID'})\n",
    "customer_dim = pd.read_excel('../data/business_algo_output/customer_data.xlsx')\n",
    "customer_dim = customer_dim.rename(columns={'Longitude': 'Long', 'Latitude': 'Lat'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cbc0af82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing coordinates or 0 long and lat\n",
    "# Convert Lat and Long to numeric, handle invalid values\n",
    "customer_dim[['Lat', 'Long']] = customer_dim[['Lat', 'Long']].apply(pd.to_numeric, errors='coerce')\n",
    "customer_dim = customer_dim[(customer_dim['Long'] != 0) & (customer_dim['Lat'] != 0)]\n",
    "customer_dim = customer_dim[customer_dim['Lat'].between(-90, 90)]\n",
    "customer_dim = customer_dim[customer_dim['Long'].between(-180, 180)]\n",
    "# Drop rows with NaN coordinates\n",
    "customer_dim = customer_dim.dropna(subset=['Lat', 'Long']) \n",
    " \n",
    "# Drop rows with NaN coordinates\n",
    "customer_dim = customer_dim.dropna(subset=['Lat', 'Long'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05bcde17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only transactional customers with valid coordinates from transactional data\n",
    "prediction_output = prediction_output[prediction_output['CustomerID'].isin(customer_dim['CustomerID'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a160823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['StockPointName', 'StockPointID', 'CustomerID', 'Category', 'SKUID', 'SKUCODE', 'rank_hist_cust_cat', 'L4M_n_orders', 'L4M_tot_qty', 'L4M_AOV', 'L4M_AOQ', 'L4M_Cust_Activity_SKU', 'L4M_Cust_Activity_Day_SKU', 'rank_hist_sp_cat', 'L4M_SP_Activity_SKU', 'rank_survey', 'SuggestType', 'SP_Product_Tag', 'RECOMMEND_FOR_PUSH']\n",
      "['CustomerID', 'ContactName', 'BusinessName', 'CustomerModeName', 'ContactPhone', 'CustomerType', 'CustomerCreatedDate', 'Location', 'Address', 'FullAddress', 'StateName', 'CityName', 'TownID', 'TownName', 'Lat', 'Long', 'status', 'FirstName', 'LastName', 'IsLocationSubmitted', 'LocationSubmittedDate', 'IsLocationCaptured', 'IsLocationVerified', 'LocationVerifiedDate', 'RecaptureCount', 'CustomerStatus', 'RejectReason', 'RejectionDate']\n"
     ]
    }
   ],
   "source": [
    "print(prediction_output.columns.tolist())\n",
    "print(customer_dim.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f94bda79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "# Assuming prediction_output and customer_dim are your DataFrames\n",
    "assignment_df, summary_df = cluster_customers_dbscan(prediction_output, customer_dim, eps_km=2.0, min_samples=3)\n",
    "# print(\"Customer Assignments:\")\n",
    "# print(assignment_df)\n",
    "# print(\"\\nCluster Summaries:\")\n",
    "# print(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46dd9cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StockPointID</th>\n",
       "      <th>ClusterID</th>\n",
       "      <th>NumCustomers</th>\n",
       "      <th>AvgDistance</th>\n",
       "      <th>CentroidLong</th>\n",
       "      <th>CentroidLat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1647081</td>\n",
       "      <td>0</td>\n",
       "      <td>7019</td>\n",
       "      <td>2.795363e+00</td>\n",
       "      <td>3.291009</td>\n",
       "      <td>6.587949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1647081</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-78.865791</td>\n",
       "      <td>43.897093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1647081</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.076232</td>\n",
       "      <td>6.484355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1647081</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>9.563824e-01</td>\n",
       "      <td>6.592320</td>\n",
       "      <td>3.244106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1647081</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.345957</td>\n",
       "      <td>6.538340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1647113</td>\n",
       "      <td>37</td>\n",
       "      <td>46</td>\n",
       "      <td>9.366078e-01</td>\n",
       "      <td>6.456529</td>\n",
       "      <td>3.389495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1647113</td>\n",
       "      <td>38</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.312712</td>\n",
       "      <td>6.534257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1647113</td>\n",
       "      <td>39</td>\n",
       "      <td>48</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.877997</td>\n",
       "      <td>8.382902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1647113</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>8.819352e-14</td>\n",
       "      <td>3.430813</td>\n",
       "      <td>6.416737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1647113</td>\n",
       "      <td>41</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.601464</td>\n",
       "      <td>6.503759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    StockPointID  ClusterID  NumCustomers   AvgDistance  CentroidLong  \\\n",
       "0        1647081          0          7019  2.795363e+00      3.291009   \n",
       "1        1647081          1            11  0.000000e+00    -78.865791   \n",
       "2        1647081          2            10  0.000000e+00      3.076232   \n",
       "3        1647081          3            30  9.563824e-01      6.592320   \n",
       "4        1647081          4            10  0.000000e+00      3.345957   \n",
       "..           ...        ...           ...           ...           ...   \n",
       "68       1647113         37            46  9.366078e-01      6.456529   \n",
       "69       1647113         38            10  0.000000e+00      3.312712   \n",
       "70       1647113         39            48  0.000000e+00      4.877997   \n",
       "71       1647113         40             5  8.819352e-14      3.430813   \n",
       "72       1647113         41            10  0.000000e+00      3.601464   \n",
       "\n",
       "    CentroidLat  \n",
       "0      6.587949  \n",
       "1     43.897093  \n",
       "2      6.484355  \n",
       "3      3.244106  \n",
       "4      6.538340  \n",
       "..          ...  \n",
       "68     3.389495  \n",
       "69     6.534257  \n",
       "70     8.382902  \n",
       "71     6.416737  \n",
       "72     6.503759  \n",
       "\n",
       "[73 rows x 6 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e666e610",
   "metadata": {},
   "source": [
    "## Route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "14304889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plan_routes(assignment_df, customer_dim, stock_point_dim):\n",
    "    \"\"\"\n",
    "    Generate route plans for each cluster, starting and ending at the stock point.\n",
    "    \n",
    "    Args:\n",
    "        assignment_df (pd.DataFrame): From Task 1, with StockPointID, CustomerID, ClusterID, SubclusterID\n",
    "        customer_dim (pd.DataFrame): With CustomerID, Long, Lat\n",
    "        stock_point_dim (pd.DataFrame): With StockPointID, Long, Lat\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (route_df, route_summary_df) containing route plans and summary of route distances\n",
    "    \"\"\"\n",
    "    # Merge assignment_df with customer_dim to get customer coordinates\n",
    "    route_data = assignment_df.merge(customer_dim[['CustomerID', 'Long', 'Lat']], on='CustomerID')\n",
    "    \n",
    "    # Validate customer coordinates\n",
    "    route_data[['Long', 'Lat']] = route_data[['Long', 'Lat']].apply(pd.to_numeric, errors='coerce')\n",
    "    route_data = route_data[route_data['Lat'].between(-90, 90) & route_data['Long'].between(-180, 180)]\n",
    "    route_data = route_data.dropna(subset=['Long', 'Lat'])\n",
    "    \n",
    "    # Validate stock_point_dim coordinates\n",
    "    stock_point_dim[['Long', 'Lat']] = stock_point_dim[['Long', 'Lat']].apply(pd.to_numeric, errors='coerce')\n",
    "    stock_point_dim = stock_point_dim[stock_point_dim['Lat'].between(-90, 90) & stock_point_dim['Long'].between(-180, 180)]\n",
    "    stock_point_dim = stock_point_dim.dropna(subset=['Long', 'Lat'])\n",
    "    \n",
    "    # Initialize lists for results\n",
    "    route_list = []\n",
    "    route_summary_list = []\n",
    "    \n",
    "    # Group by StockPointID and ClusterID\n",
    "    groups = route_data.groupby(['StockPointID', 'ClusterID'])\n",
    "    \n",
    "    for (sp_id, cluster_id), group in groups:\n",
    "        # Get stock point coordinates\n",
    "        sp_coords = stock_point_dim[stock_point_dim['StockPointID'] == sp_id][['Long', 'Lat']]\n",
    "        if sp_coords.empty:\n",
    "            continue  # Skip if stock point not found\n",
    "        sp_coord = (sp_coords['Lat'].iloc[0], sp_coords['Long'].iloc[0])\n",
    "        \n",
    "        # Get customer coordinates\n",
    "        customers = group[['CustomerID', 'Long', 'Lat']].copy()\n",
    "        if len(customers) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Initialize route with stock point\n",
    "        route = [(sp_id, cluster_id, 'StockPoint', sp_coord[1], sp_coord[0], 0)]\n",
    "        visited = set()\n",
    "        current_coord = sp_coord\n",
    "        total_distance = 0.0\n",
    "        \n",
    "        # Nearest Neighbor algorithm\n",
    "        while len(visited) < len(customers):\n",
    "            min_dist = float('inf')\n",
    "            next_customer = None\n",
    "            next_coord = None\n",
    "            next_id = None\n",
    "            \n",
    "            # Find closest unvisited customer\n",
    "            for _, row in customers.iterrows():\n",
    "                if row['CustomerID'] not in visited:\n",
    "                    cust_coord = (row['Lat'], row['Long'])\n",
    "                    dist = geodesic(current_coord, cust_coord).kilometers\n",
    "                    if dist < min_dist:\n",
    "                        min_dist = dist\n",
    "                        next_customer = row['CustomerID']\n",
    "                        next_coord = cust_coord\n",
    "                        next_id = row['CustomerID']\n",
    "            \n",
    "            if next_customer is None:\n",
    "                break  # No more customers to visit\n",
    "            \n",
    "            # Add customer to route\n",
    "            visited.add(next_customer)\n",
    "            route.append((sp_id, cluster_id, next_id, next_coord[1], next_coord[0], len(visited)))\n",
    "            total_distance += min_dist\n",
    "            current_coord = next_coord\n",
    "        \n",
    "        # Return to stock point\n",
    "        return_dist = geodesic(current_coord, sp_coord).kilometers\n",
    "        total_distance += return_dist\n",
    "        route.append((sp_id, cluster_id, 'StockPoint', sp_coord[1], sp_coord[0], len(visited) + 1))\n",
    "        \n",
    "        # Create route DataFrame\n",
    "        route_df = pd.DataFrame(route, columns=['StockPointID', 'ClusterID', 'CustomerID', 'Long', 'Lat', 'RouteOrder'])\n",
    "        route_list.append(route_df)\n",
    "        \n",
    "        # Create summary entry\n",
    "        summary_df = pd.DataFrame({\n",
    "            'StockPointID': [sp_id],\n",
    "            'ClusterID': [cluster_id],\n",
    "            'NumCustomers': [len(customers)],\n",
    "            'TotalRouteDistance': [total_distance]\n",
    "        })\n",
    "        route_summary_list.append(summary_df)\n",
    "    \n",
    "    # Concatenate results\n",
    "    final_route = pd.concat(route_list, ignore_index=True) if route_list else pd.DataFrame(columns=['StockPointID', 'ClusterID', 'CustomerID', 'Long', 'Lat', 'RouteOrder'])\n",
    "    final_summary = pd.concat(route_summary_list, ignore_index=True) if route_summary_list else pd.DataFrame(columns=['StockPointID', 'ClusterID', 'NumCustomers', 'TotalRouteDistance'])\n",
    "    \n",
    "    return final_route, final_summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e8f7c659",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stock_point_dim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Assuming assignment_df, customer_dim, and stock_point_dim are your DataFrames\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m route_df, route_summary_df \u001b[38;5;241m=\u001b[39m plan_routes(assignment_df, customer_dim, \u001b[43mstock_point_dim\u001b[49m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRoute Plans:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(route_df)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stock_point_dim' is not defined"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "# Assuming assignment_df, customer_dim, and stock_point_dim are your DataFrames\n",
    "route_df, route_summary_df = plan_routes(assignment_df, customer_dim, stock_point_dim)\n",
    "print(\"Route Plans:\")\n",
    "print(route_df)\n",
    "print(\"\\nRoute Summaries:\")\n",
    "print(route_summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e4a0ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
